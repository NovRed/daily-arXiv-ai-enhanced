{"id": "2508.11696", "pdf": "https://arxiv.org/pdf/2508.11696", "abs": "https://arxiv.org/abs/2508.11696", "authors": ["Sami Sadat", "Mohammad Irtiza Hossain", "Junaid Ahmed Sifat", "Suhail Haque Rafi", "Md. Waseq Alauddin Alvi", "Md. Khalilur Rhaman"], "title": "A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones", "categories": ["cs.CV"], "comment": null, "summary": "A deep learning real-time smoking detection system for CCTV surveillance of\nfire exit areas is proposed due to critical safety requirements. The dataset\ncontains 8,124 images from 20 different scenarios along with 2,708 raw samples\ndemonstrating low-light areas. We evaluated three advanced object detection\nmodels: YOLOv8, YOLOv11, and YOLOv12, followed by development of a custom model\nderived from YOLOv8 with added structures for challenging surveillance\ncontexts. The proposed model outperformed the others, achieving a recall of\n78.90 percent and mAP at 50 of 83.70 percent, delivering optimal object\ndetection across varied environments. Performance evaluation on multiple edge\ndevices using multithreaded operations showed the Jetson Xavier NX processed\ndata at 52 to 97 milliseconds per inference, establishing its suitability for\ntime-sensitive operations. This system offers a robust and adaptable platform\nfor monitoring public safety and enabling automatic regulatory compliance.", "AI": {"tldr": "A deep learning-based real-time smoking detection system using CCTV surveillance achieves high performance (78.90% recall, 83.70% mAP) with optimized YOLOv8 architecture, suitable for fire exit monitoring and safety compliance.", "motivation": "Critical safety requirements for monitoring fire exit areas where smoking poses significant fire hazards, necessitating real-time detection systems for public safety and regulatory compliance.", "method": "Evaluated YOLOv8, YOLOv11, and YOLOv12 models, then developed a custom YOLOv8-based model with additional structures for challenging surveillance contexts. Used dataset of 8,124 images from 20 scenarios with 2,708 low-light samples. Tested on edge devices with multithreaded operations.", "result": "Proposed custom model outperformed others with 78.90% recall and 83.70% mAP at 50. Jetson Xavier NX achieved 52-97ms per inference, suitable for real-time operations. Demonstrated robust performance across varied environments including low-light conditions.", "conclusion": "The system provides a robust and adaptable platform for real-time smoking detection in surveillance contexts, enabling automatic regulatory compliance and enhancing public safety in critical areas like fire exits."}}
{"id": "2508.11697", "pdf": "https://arxiv.org/pdf/2508.11697", "abs": "https://arxiv.org/abs/2508.11697", "authors": ["Adri\u00e1n Rodr\u00edguez-Mu\u00f1oz", "Manel Baradad", "Phillip Isola", "Antonio Torralba"], "title": "Separating Knowledge and Perception with Procedural Data", "categories": ["cs.CV", "cs.AI", "I.5.1"], "comment": "17 pages, 18 figures, 3 tables, to be published in ICML 2025", "summary": "We train representation models with procedural data only, and apply them on\nvisual similarity, classification, and semantic segmentation tasks without\nfurther training by using visual memory -- an explicit database of reference\nimage embeddings. Unlike prior work on visual memory, our approach achieves\nfull compartmentalization with respect to all real-world images while retaining\nstrong performance. Compared to a model trained on Places, our procedural model\nperforms within $1\\%$ on NIGHTS visual similarity, outperforms by $8\\%$ and\n$15\\%$ on CUB200 and Flowers102 fine-grained classification, and is within\n$10\\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot\nsegmentation, achieving an $R^2$ on COCO within $10\\%$ of the models trained on\nreal data. Finally, we analyze procedural versus real data models, showing that\nparts of the same object have dissimilar representations in procedural models,\nresulting in incorrect searches in memory and explaining the remaining\nperformance gap.", "AI": {"tldr": "Procedural data-trained models achieve near-real performance on visual tasks using visual memory without real-world images, with strong results on similarity, classification, and segmentation tasks.", "motivation": "To achieve full compartmentalization from real-world images while maintaining strong visual task performance by using only procedural data and visual memory techniques.", "method": "Train representation models exclusively on procedural data and apply them to visual tasks using visual memory - an explicit database of reference image embeddings, without further training on real images.", "result": "Performs within 1% on NIGHTS visual similarity, outperforms by 8-15% on fine-grained classification (CUB200, Flowers102), within 10% on ImageNet-1K classification, and achieves strong zero-shot segmentation (R^2 within 10% of real-data models on COCO).", "conclusion": "Procedural models can achieve competitive performance to real-data models while maintaining full compartmentalization, though object part dissimilarity in representations causes incorrect memory searches that explain remaining performance gaps."}}
{"id": "2508.11721", "pdf": "https://arxiv.org/pdf/2508.11721", "abs": "https://arxiv.org/abs/2508.11721", "authors": ["Ke Zou", "Jocelyn Hui Lin Goh", "Yukun Zhou", "Tian Lin", "Samantha Min Er Yew", "Sahana Srinivasan", "Meng Wang", "Rui Santos", "Gabor M. Somfai", "Huazhu Fu", "Haoyu Chen", "Pearse A. Keane", "Ching-Yu Cheng", "Yih Chung Tham"], "title": "FusionFM: Fusing Eye-specific Foundational Models for Optimized Ophthalmic Diagnosis", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 3 figures", "summary": "Foundation models (FMs) have shown great promise in medical image analysis by\nimproving generalization across diverse downstream tasks. In ophthalmology,\nseveral FMs have recently emerged, but there is still no clear answer to\nfundamental questions: Which FM performs the best? Are they equally good across\ndifferent tasks? What if we combine all FMs together? To our knowledge, this is\nthe first study to systematically evaluate both single and fused ophthalmic\nFMs. To address these questions, we propose FusionFM, a comprehensive\nevaluation suite, along with two fusion approaches to integrate different\nophthalmic FMs. Our framework covers both ophthalmic disease detection\n(glaucoma, diabetic retinopathy, and age-related macular degeneration) and\nsystemic disease prediction (diabetes and hypertension) based on retinal\nimaging. We benchmarked four state-of-the-art FMs (RETFound, VisionFM,\nRetiZero, and DINORET) using standardized datasets from multiple countries and\nevaluated their performance using AUC and F1 metrics. Our results show that\nDINORET and RetiZero achieve superior performance in both ophthalmic and\nsystemic disease tasks, with RetiZero exhibiting stronger generalization on\nexternal datasets. Regarding fusion strategies, the Gating-based approach\nprovides modest improvements in predicting glaucoma, AMD, and hypertension.\nDespite these advances, predicting systemic diseases, especially hypertension\nin external cohort remains challenging. These findings provide an\nevidence-based evaluation of ophthalmic FMs, highlight the benefits of model\nfusion, and point to strategies for enhancing their clinical applicability.", "AI": {"tldr": "Systematic evaluation of four ophthalmic foundation models (RETFound, VisionFM, RetiZero, DINORET) and their fusion approaches for both ophthalmic and systemic disease prediction from retinal imaging, showing DINORET and RetiZero perform best with RetiZero having better generalization.", "motivation": "Foundation models show promise in medical imaging but there's no clear understanding of which performs best in ophthalmology, how they compare across different tasks, and whether combining them improves performance.", "method": "Proposed FusionFM evaluation suite with two fusion approaches to integrate different ophthalmic FMs. Evaluated on standardized datasets from multiple countries using AUC and F1 metrics for both ophthalmic diseases (glaucoma, diabetic retinopathy, AMD) and systemic diseases (diabetes, hypertension).", "result": "DINORET and RetiZero achieved superior performance in both ophthalmic and systemic disease tasks. RetiZero showed stronger generalization on external datasets. Gating-based fusion provided modest improvements for glaucoma, AMD, and hypertension prediction. Systemic disease prediction, especially hypertension in external cohorts, remains challenging.", "conclusion": "This study provides the first evidence-based evaluation of ophthalmic foundation models, demonstrates benefits of model fusion, and identifies strategies for enhancing clinical applicability while highlighting remaining challenges in systemic disease prediction."}}
{"id": "2508.11728", "pdf": "https://arxiv.org/pdf/2508.11728", "abs": "https://arxiv.org/abs/2508.11728", "authors": ["Chunxia Ren", "Ning Zhu", "Yue Lai", "Gui Chen", "Ruijie Wang", "Yangyi Hu", "Suyao Liu", "Shuwen Mao", "Hong Su", "Yu Zhang", "Li Xiao"], "title": "UniDCF: A Foundation Model for Comprehensive Dentocraniofacial Hard Tissue Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "23 pages, 6 figures", "summary": "Dentocraniofacial hard tissue defects profoundly affect patients'\nphysiological functions, facial aesthetics, and psychological well-being,\nposing significant challenges for precise reconstruction. Current deep learning\nmodels are limited to single-tissue scenarios and modality-specific imaging\ninputs, resulting in poor generalizability and trade-offs between anatomical\nfidelity, computational efficiency, and cross-tissue adaptability. Here we\nintroduce UniDCF, a unified framework capable of reconstructing multiple\ndentocraniofacial hard tissues through multimodal fusion encoding of point\nclouds and multi-view images. By leveraging the complementary strengths of each\nmodality and incorporating a score-based denoising module to refine surface\nsmoothness, UniDCF overcomes the limitations of prior single-modality\napproaches. We curated the largest multimodal dataset, comprising intraoral\nscans, CBCT, and CT from 6,609 patients, resulting in 54,555 annotated\ninstances. Evaluations demonstrate that UniDCF outperforms existing\nstate-of-the-art methods in terms of geometric precision, structural\ncompleteness, and spatial accuracy. Clinical simulations indicate UniDCF\nreduces reconstruction design time by 99% and achieves clinician-rated\nacceptability exceeding 94%. Overall, UniDCF enables rapid, automated, and\nhigh-fidelity reconstruction, supporting personalized and precise restorative\ntreatments, streamlining clinical workflows, and enhancing patient outcomes.", "AI": {"tldr": "UniDCF is a unified deep learning framework that reconstructs multiple dentocraniofacial hard tissues using multimodal fusion of point clouds and multi-view images, achieving superior geometric precision and clinical efficiency.", "motivation": "Current deep learning models are limited to single-tissue scenarios and modality-specific inputs, resulting in poor generalizability and trade-offs between anatomical fidelity, computational efficiency, and cross-tissue adaptability for dentocraniofacial reconstruction.", "method": "UniDCF uses multimodal fusion encoding of point clouds and multi-view images, leveraging complementary strengths of each modality with a score-based denoising module to refine surface smoothness. It was trained on the largest multimodal dataset with 54,555 annotated instances from 6,609 patients.", "result": "UniDCF outperforms state-of-the-art methods in geometric precision, structural completeness, and spatial accuracy. It reduces reconstruction design time by 99% and achieves clinician-rated acceptability exceeding 94%.", "conclusion": "UniDCF enables rapid, automated, high-fidelity reconstruction for personalized restorative treatments, streamlining clinical workflows and enhancing patient outcomes through its unified multimodal approach."}}
{"id": "2508.11676", "pdf": "https://arxiv.org/pdf/2508.11676", "abs": "https://arxiv.org/abs/2508.11676", "authors": ["Maksym Shamrai", "Vladyslav Hamolia"], "title": "Deep Language Geometry: Constructing a Metric Space from LLM Weights", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "18 pages, accepted to RANLP 2025", "summary": "We introduce a novel framework that utilizes the internal weight activations\nof modern Large Language Models (LLMs) to construct a metric space of\nlanguages. Unlike traditional approaches based on hand-crafted linguistic\nfeatures, our method automatically derives high-dimensional vector\nrepresentations by computing weight importance scores via an adapted pruning\nalgorithm. Our approach captures intrinsic language characteristics that\nreflect linguistic phenomena. We validate our approach across diverse datasets\nand multilingual LLMs, covering 106 languages. The results align well with\nestablished linguistic families while also revealing unexpected inter-language\nconnections that may indicate historical contact or language evolution. The\nsource code, computed language latent vectors, and visualization tool are made\npublicly available at https://github.com/mshamrai/deep-language-geometry.", "AI": {"tldr": "A framework using LLM weight activations to create language metric space, automatically generating vector representations that capture linguistic characteristics and reveal language relationships.", "motivation": "To move beyond traditional hand-crafted linguistic features by leveraging internal LLM representations to automatically capture intrinsic language characteristics and relationships.", "method": "Uses adapted pruning algorithm to compute weight importance scores from LLM internal activations, deriving high-dimensional vector representations for languages across multilingual models.", "result": "Validated on 106 languages, results align with established linguistic families while revealing unexpected inter-language connections suggesting historical contact or evolution.", "conclusion": "The framework successfully creates a language metric space from LLM internals, providing insights into language relationships and making tools publicly available for further research."}}
{"id": "2508.11661", "pdf": "https://arxiv.org/pdf/2508.11661", "abs": "https://arxiv.org/abs/2508.11661", "authors": ["Ziyi Cao", "Qingyi Si", "Jingbin Zhang", "Bingquan Liu"], "title": "Sparse Attention across Multiple-context KV Cache", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large language models face significant cost challenges in long-sequence\ninference. To address this, reusing historical Key-Value (KV) Cache for\nimproved inference efficiency has become a mainstream approach. Recent advances\nfurther enhance throughput by sparse attention mechanisms to select the most\nrelevant KV Cache, thereby reducing sequence length. However, such techniques\nare limited to single-context scenarios, where historical KV Cache is computed\nsequentially with causal-attention dependencies. In retrieval-augmented\ngeneration (RAG) scenarios, where retrieved documents as context are unknown\nbeforehand, each document's KV Cache is computed and stored independently\n(termed multiple-context KV Cache), lacking cross-attention between contexts.\nThis renders existing methods ineffective. Although prior work partially\nrecomputes multiple-context KV Cache to mitigate accuracy loss from missing\ncross-attention, it requires retaining all KV Cache throughout, failing to\nreduce memory overhead. This paper presents SamKV, the first exploration of\nattention sparsification for multiple-context KV Cache. Specifically, SamKV\ntakes into account the complementary information of other contexts when\nsparsifying one context, and then locally recomputes the sparsified\ninformation. Experiments demonstrate that our method compresses sequence length\nto 15% without accuracy degradation compared with full-recompuation baselines,\nsignificantly boosting throughput in multi-context RAG scenarios.", "AI": {"tldr": "SamKV is a novel method that applies attention sparsification to multiple-context KV Cache in RAG scenarios, enabling 85% sequence length compression without accuracy loss by considering cross-context information during sparsification and local recomputation.", "motivation": "Existing KV Cache sparsification methods only work for single-context scenarios with causal attention dependencies, but fail in RAG where multiple documents have independent KV Caches without cross-attention. Prior approaches require retaining all KV Cache, failing to reduce memory overhead.", "method": "SamKV performs attention sparsification for multiple-context KV Cache by considering complementary information from other contexts when sparsifying one context, followed by local recomputation of the sparsified information to maintain accuracy.", "result": "The method compresses sequence length to 15% (85% reduction) without accuracy degradation compared to full-recomputation baselines, significantly improving throughput in multi-context RAG scenarios.", "conclusion": "SamKV successfully addresses the challenge of efficient inference in RAG scenarios by enabling effective sparsification of multiple-context KV Cache while maintaining accuracy, representing the first exploration of attention sparsification for this problem domain."}}
{"id": "2508.11836", "pdf": "https://arxiv.org/pdf/2508.11836", "abs": "https://arxiv.org/abs/2508.11836", "authors": ["Dave Goel", "Matthew Guzdial", "Anurag Sarkar"], "title": "Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video", "categories": ["cs.AI"], "comment": null, "summary": "World models are defined as a compressed spatial and temporal learned\nrepresentation of an environment. The learned representation is typically a\nneural network, making transfer of the learned environment dynamics and\nexplainability a challenge. In this paper, we propose an approach, Finite\nAutomata Extraction (FAE), that learns a neuro-symbolic world model from\ngameplay video represented as programs in a novel domain-specific language\n(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more\nprecise model of the environment and more general code than prior DSL-based\napproaches.", "AI": {"tldr": "FAE extracts neuro-symbolic world models from gameplay video as programs in Retro Coder DSL, achieving more precise environment modeling than neural approaches and more general code than prior DSL methods.", "motivation": "Traditional neural network world models lack explainability and transferability of learned environment dynamics, while existing DSL-based approaches produce code that is not sufficiently general.", "method": "Finite Automata Extraction (FAE) learns neuro-symbolic world models from gameplay video, representing them as programs in a novel domain-specific language called Retro Coder.", "result": "FAE learns more precise environment models than neural world models and produces more general code compared to prior DSL-based approaches.", "conclusion": "The proposed FAE approach successfully bridges the gap between neural and symbolic representations, creating explainable and transferable world models with improved precision and generality."}}
{"id": "2508.11737", "pdf": "https://arxiv.org/pdf/2508.11737", "abs": "https://arxiv.org/abs/2508.11737", "authors": ["Shiyin Lu", "Yang Li", "Yu Xia", "Yuwei Hu", "Shanshan Zhao", "Yanqing Ma", "Zhichao Wei", "Yinglun Li", "Lunhao Duan", "Jianshan Zhao", "Yuxuan Han", "Haijun Li", "Wanying Chen", "Junke Tang", "Chengkun Hou", "Zhixing Du", "Tianli Zhou", "Wenjie Zhang", "Huping Ding", "Jiahe Li", "Wen Li", "Gui Hu", "Yiliang Gu", "Siran Yang", "Jiamang Wang", "Hailong Sun", "Yibo Wang", "Hui Sun", "Jinlong Huang", "Yuping He", "Shengze Shi", "Weihong Zhang", "Guodong Zheng", "Junpeng Jiang", "Sensen Gao", "Yi-Feng Wu", "Sijia Chen", "Yuhui Chen", "Qing-Guo Chen", "Zhao Xu", "Weihua Luo", "Kaifu Zhang"], "title": "Ovis2.5 Technical Report", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "We present Ovis2.5, a successor to Ovis2 designed for native-resolution\nvisual perception and strong multimodal reasoning. Ovis2.5 integrates a\nnative-resolution vision transformer that processes images at their native,\nvariable resolutions, avoiding the degradation from fixed-resolution tiling and\npreserving both fine detail and global layout -- crucial for visually dense\ncontent like complex charts. To strengthen reasoning, we train the model to\nmove beyond linear chain-of-thought and perform reflection -- including\nself-checking and revision. This advanced capability is exposed as an optional\n\"thinking mode\" at inference time, allowing users to trade latency for enhanced\naccuracy on difficult inputs. The model is trained via a comprehensive\nfive-phase curriculum that progressively builds its skills. The process begins\nwith foundational visual and multimodal pretraining, advances through\nlarge-scale instruction tuning, and culminates in alignment and reasoning\nenhancement using DPO and GRPO. To scale these upgrades efficiently, we employ\nmultimodal data packing and hybrid parallelism, yielding a significant\nend-to-end speedup. We release two open-source models: Ovis2.5-9B and\nOvis2.5-2B. The latter continues the \"small model, big performance\" philosophy\nof Ovis2, making it ideal for resource-constrained, on-device scenarios. On the\nOpenCompass multimodal leaderboard, Ovis2.5-9B averages 78.3, marking a\nsubstantial improvement over its predecessor, Ovis2-8B, and achieving\nstate-of-the-art results among open-source MLLMs in the sub-40B parameter\nrange; Ovis2.5-2B scores 73.9, establishing SOTA for its size. Beyond aggregate\nscores, Ovis2.5 achieves leading results on STEM benchmarks, exhibits strong\ncapabilities on grounding and video tasks, and achieves open-source SOTA at its\nscale for complex chart analysis.", "AI": {"tldr": "Ovis2.5 is an advanced multimodal model that processes images at native resolution using a vision transformer, features reflection-based reasoning with self-checking capabilities, and achieves state-of-the-art performance on multiple benchmarks with both 9B and 2B parameter versions.", "motivation": "To overcome limitations of fixed-resolution image processing that degrades fine details and global layout, particularly for visually dense content like complex charts, and to enhance reasoning capabilities beyond simple chain-of-thought approaches.", "method": "Uses native-resolution vision transformer for variable-resolution image processing, implements reflection-based reasoning with self-checking and revision, employs a five-phase curriculum training (visual/multimodal pretraining, instruction tuning, DPO/GRPO alignment), and utilizes multimodal data packing with hybrid parallelism for efficiency.", "result": "Ovis2.5-9B scores 78.3 on OpenCompass leaderboard (substantial improvement over Ovis2-8B), Ovis2.5-2B scores 73.9 (SOTA for its size), achieves leading results on STEM benchmarks, strong grounding/video capabilities, and SOTA for complex chart analysis at its scale.", "conclusion": "Ovis2.5 successfully addresses native-resolution visual perception and advanced reasoning, delivering state-of-the-art performance across multiple domains while maintaining efficiency through optimized training methods and offering both large and small model variants for different deployment scenarios."}}
{"id": "2508.11758", "pdf": "https://arxiv.org/pdf/2508.11758", "abs": "https://arxiv.org/abs/2508.11758", "authors": ["Jonas van Elburg", "Peter van der Putten", "Maarten Marx"], "title": "Can we Evaluate RAGs with Synthetic Data?", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for the SynDAiTE workshop at the European Conference on\n  Machine Learning and Principles and Practice of Knowledge Discovery in\n  Databases (ECML-PKDD 2025), September 15, 2025 - Porto, Portugal", "summary": "We investigate whether synthetic question-answer (QA) data generated by large\nlanguage models (LLMs) can serve as an effective proxy for human-labeled\nbenchmarks when such data is unavailable. We assess the reliability of\nsynthetic benchmarks across two experiments: one varying retriever parameters\nwhile keeping the generator fixed, and another varying the generator with fixed\nretriever parameters. Across four datasets, of which two open-domain and two\nproprietary, we find that synthetic benchmarks reliably rank the RAGs varying\nin terms of retriever configuration, aligning well with human-labeled benchmark\nbaselines. However, they fail to produce consistent RAG rankings when comparing\ngenerator architectures. The breakdown possibly arises from a combination of\ntask mismatch between the synthetic and human benchmarks, and stylistic bias\nfavoring certain generators.", "AI": {"tldr": "Synthetic QA benchmarks from LLMs work well for evaluating retriever configurations but fail to consistently rank generator architectures due to task mismatch and stylistic biases.", "motivation": "To determine if synthetic question-answer data generated by LLMs can effectively substitute for human-labeled benchmarks when human data is unavailable, particularly for evaluating Retrieval-Augmented Generation (RAG) systems.", "method": "Conducted two experiments: 1) varying retriever parameters with fixed generator, and 2) varying generator architectures with fixed retriever parameters. Tested across four datasets (two open-domain, two proprietary) comparing synthetic benchmarks against human-labeled baseline benchmarks.", "result": "Synthetic benchmarks reliably ranked RAG systems with different retriever configurations, aligning well with human benchmarks. However, they failed to produce consistent rankings when comparing different generator architectures.", "conclusion": "While synthetic QA data can serve as a proxy for human benchmarks when evaluating retriever components, it is unreliable for assessing generator architectures due to task mismatch issues and stylistic biases that favor certain generators over others."}}
{"id": "2508.11667", "pdf": "https://arxiv.org/pdf/2508.11667", "abs": "https://arxiv.org/abs/2508.11667", "authors": ["Bryan E. Tuck", "Rakesh M. Verma"], "title": "Assessing Representation Stability for Transformer Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "19 pages, 19 figures, 8 tables. Code available at\n  https://github.com/ReDASers/representation-stability", "summary": "Adversarial text attacks remain a persistent threat to transformer models,\nyet existing defenses are typically attack-specific or require costly model\nretraining. We introduce Representation Stability (RS), a model-agnostic\ndetection framework that identifies adversarial examples by measuring how\nembedding representations change when important words are masked. RS first\nranks words using importance heuristics, then measures embedding sensitivity to\nmasking top-k critical words, and processes the resulting patterns with a\nBiLSTM detector. Experiments show that adversarially perturbed words exhibit\ndisproportionately high masking sensitivity compared to naturally important\nwords. Across three datasets, three attack types, and two victim models, RS\nachieves over 88% detection accuracy and demonstrates competitive performance\ncompared to existing state-of-the-art methods, often at lower computational\ncost. Using Normalized Discounted Cumulative Gain (NDCG) to measure\nperturbation identification quality, we reveal that gradient-based ranking\noutperforms attention and random selection approaches, with identification\nquality correlating with detection performance for word-level attacks. RS also\ngeneralizes well to unseen datasets, attacks, and models without retraining,\nproviding a practical solution for adversarial text detection.", "AI": {"tldr": "RS is a model-agnostic adversarial text detection framework that identifies attacks by measuring embedding sensitivity when masking important words, achieving over 88% accuracy across multiple datasets and attacks without retraining.", "motivation": "Adversarial text attacks threaten transformer models, but existing defenses are attack-specific or require costly model retraining, creating a need for practical, generalizable detection methods.", "method": "Ranks words using importance heuristics, measures embedding sensitivity when masking top-k critical words, and processes patterns with a BiLSTM detector. Uses gradient-based ranking for perturbation identification.", "result": "Achieves over 88% detection accuracy across 3 datasets, 3 attack types, and 2 victim models. Gradient-based ranking outperforms attention and random selection. Generalizes well to unseen datasets/attacks/models.", "conclusion": "RS provides a practical, effective solution for adversarial text detection with competitive performance, lower computational cost, and strong generalization without requiring model retraining."}}
{"id": "2508.11850", "pdf": "https://arxiv.org/pdf/2508.11850", "abs": "https://arxiv.org/abs/2508.11850", "authors": ["Milad Yazdani", "Mahdi Mostajabdaveh", "Samin Aref", "Zirui Zhou"], "title": "EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Integer programming lies at the heart of crucial combinatorial optimization\ntasks but remains challenging due to its NP-hard nature. An effective approach\nfor practically solving integer programs is the manual design of acceleration\ncuts, i.e. inequalities that improve solver performance. However, this creative\nprocess demands deep expertise and is yet to be automated. Our proposed\nframework, EvoCut, automates the generation of acceleration cuts by combining\nlarge language models (LLMs) with an evolutionary search. EvoCut (i)\ninitializes a diverse population of candidate cuts via an LLM-based initializer\nagent; (ii) for each cut empirically evaluates both preservation of the optimal\nsolution and its ability to cut off fractional solutions across a verification\nset; and (iii) iteratively refines the population through evolutionary\ncrossover and mutation agents. We quantify each cut's utility by its relative\nreduction in the solver's optimality gap. Our comparisons against standard\ninteger programming practice show that EvoCut reduces optimality gap by 17-57%\nwithin a fixed time. It obtains the same solutions up to 4 times as fast, and\nobtains higher-quality solutions within the same time limit. Requiring no human\nexpert input, EvoCut reliably generates, improves, and empirically verifies\ncuts that generalize to unseen instances. The code is available at\nhttps://github.com/milad1378yz/EvoCut.", "AI": {"tldr": "EvoCut automates acceleration cut generation for integer programming using LLMs and evolutionary search, reducing optimality gaps by 17-57% and speeding up solutions up to 4x faster than standard methods.", "motivation": "Integer programming is NP-hard and relies on manual design of acceleration cuts by experts, which is time-consuming and requires deep domain knowledge. There is a need to automate this creative process to improve solver performance.", "method": "EvoCut combines large language models with evolutionary search: (i) initializes diverse candidate cuts via LLM-based agent, (ii) evaluates cuts on preservation of optimal solutions and ability to cut off fractional solutions, (iii) iteratively refines population through evolutionary crossover and mutation agents.", "result": "EvoCut reduces optimality gap by 17-57% within fixed time, obtains same solutions up to 4 times faster, and achieves higher-quality solutions within same time limits compared to standard integer programming practice.", "conclusion": "The framework successfully automates cut generation without human input, producing effective cuts that generalize to unseen instances, demonstrating significant performance improvements in integer programming solvers."}}
{"id": "2508.11801", "pdf": "https://arxiv.org/pdf/2508.11801", "abs": "https://arxiv.org/abs/2508.11801", "authors": ["Ming Cheng", "Tong Wu", "Jiazhen Hu", "Jiaying Gong", "Hoda Eldardiry"], "title": "VideoAVE: A Multi-Attribute Video-to-Text Attribute Value Extraction Dataset and Benchmark Models", "categories": ["cs.CV", "cs.CL"], "comment": "5 pages, 2 figures, 5 tables, accepted in CIKM 2025", "summary": "Attribute Value Extraction (AVE) is important for structuring product\ninformation in e-commerce. However, existing AVE datasets are primarily limited\nto text-to-text or image-to-text settings, lacking support for product videos,\ndiverse attribute coverage, and public availability. To address these gaps, we\nintroduce VideoAVE, the first publicly available video-to-text e-commerce AVE\ndataset across 14 different domains and covering 172 unique attributes. To\nensure data quality, we propose a post-hoc CLIP-based Mixture of Experts\nfiltering system (CLIP-MoE) to remove the mismatched video-product pairs,\nresulting in a refined dataset of 224k training data and 25k evaluation data.\nIn order to evaluate the usability of the dataset, we further establish a\ncomprehensive benchmark by evaluating several state-of-the-art video vision\nlanguage models (VLMs) under both attribute-conditioned value prediction and\nopen attribute-value pair extraction tasks. Our results analysis reveals that\nvideo-to-text AVE remains a challenging problem, particularly in open settings,\nand there is still room for developing more advanced VLMs capable of leveraging\neffective temporal information. The dataset and benchmark code for VideoAVE are\navailable at: https://github.com/gjiaying/VideoAVE", "AI": {"tldr": "VideoAVE is the first public video-to-text e-commerce attribute value extraction dataset covering 14 domains and 172 attributes, with 224k training and 25k evaluation samples filtered by CLIP-MoE, showing current VLMs struggle with temporal information in open attribute extraction.", "motivation": "Existing AVE datasets lack support for product videos, diverse attribute coverage, and public availability, creating a gap for video-based e-commerce product structuring.", "method": "Created VideoAVE dataset with CLIP-based Mixture of Experts filtering to remove mismatched video-product pairs, then benchmarked state-of-the-art video VLMs on attribute-conditioned and open attribute-value extraction tasks.", "result": "Video-to-text AVE remains challenging, especially in open settings, with current VLMs showing limited ability to leverage temporal information effectively.", "conclusion": "There is significant room for developing more advanced video VLMs that can better utilize temporal information for attribute value extraction from product videos."}}
{"id": "2508.11767", "pdf": "https://arxiv.org/pdf/2508.11767", "abs": "https://arxiv.org/abs/2508.11767", "authors": ["Noah Kasmanoff", "Rahul Zalkikar"], "title": "Limitation Learning: Catching Adverse Dialog with GAIL", "categories": ["cs.CL", "cs.LG"], "comment": "Paper from 2021", "summary": "Imitation learning is a proven method for creating a policy in the absence of\nrewards, by leveraging expert demonstrations. In this work, we apply imitation\nlearning to conversation. In doing so, we recover a policy capable of talking\nto a user given a prompt (input state), and a discriminator capable of\nclassifying between expert and synthetic conversation. While our policy is\neffective, we recover results from our discriminator that indicate the\nlimitations of dialog models. We argue that this technique can be used to\nidentify adverse behavior of arbitrary data models common for dialog oriented\ntasks.", "AI": {"tldr": "Applying imitation learning to conversation tasks to create dialog policies and discriminators that can identify limitations in dialog models", "motivation": "To leverage imitation learning for conversation tasks where explicit rewards are unavailable, using expert demonstrations to create effective dialog policies", "method": "Applied imitation learning to conversation by training both a policy (to generate responses) and a discriminator (to classify between expert and synthetic conversation)", "result": "Successfully recovered an effective conversation policy, but the discriminator revealed limitations in dialog models", "conclusion": "This imitation learning technique can be used to identify adverse behavior in dialog-oriented data models"}}
{"id": "2508.11669", "pdf": "https://arxiv.org/pdf/2508.11669", "abs": "https://arxiv.org/abs/2508.11669", "authors": ["Wentao Li", "Yonghu He", "Kun Gao", "Qing Liu", "Yali Zheng"], "title": "Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Noninvasive arterial blood pressure (ABP) monitoring is essential for patient\nmanagement in critical care and perioperative settings, providing continuous\nassessment of cardiovascular hemodynamics with minimal risks. Numerous deep\nlearning models have developed to reconstruct ABP waveform from noninvasively\nacquired physiological signals such as electrocardiogram and\nphotoplethysmogram. However, limited research has addressed the issue of model\nperformance and computational load for deployment on embedded systems. The\nstudy introduces a lightweight sInvResUNet, along with a collaborative learning\nscheme named KDCL_sInvResUNet. With only 0.89 million parameters and a\ncomputational load of 0.02 GFLOPS, real-time ABP estimation was successfully\nachieved on embedded devices with an inference time of just 8.49 milliseconds\nfor a 10-second output. We performed subject-independent validation in a\nlarge-scale and heterogeneous perioperative dataset containing 1,257,141 data\nsegments from 2,154 patients, with a wide BP range (41-257 mmHg for SBP, and\n31-234 mmHg for DBP). The proposed KDCL_sInvResUNet achieved lightly better\nperformance compared to large models, with a mean absolute error of 10.06 mmHg\nand mean Pearson correlation of 0.88 in tracking ABP changes. Despite these\npromising results, all deep learning models showed significant performance\nvariations across different demographic and cardiovascular conditions,\nhighlighting their limited ability to generalize across such a broad and\ndiverse population. This study lays a foundation work for real-time,\nunobtrusive ABP monitoring in real-world perioperative settings, providing\nbaseline for future advancements in this area.", "AI": {"tldr": "Lightweight sInvResUNet model with collaborative learning achieves real-time arterial blood pressure monitoring on embedded devices with minimal computational load (0.89M params, 0.02 GFLOPS, 8.49ms inference).", "motivation": "Existing deep learning models for ABP waveform reconstruction lack optimization for embedded system deployment due to high computational requirements and limited research on performance-computation tradeoffs.", "method": "Proposed lightweight sInvResUNet architecture with KDCL (collaborative learning scheme), validated on large perioperative dataset (1.25M segments from 2,154 patients) with subject-independent testing.", "result": "Achieved MAE of 10.06 mmHg and Pearson correlation of 0.88 for ABP tracking, outperforming larger models while enabling real-time inference on embedded devices.", "conclusion": "Successfully demonstrated real-time ABP monitoring on embedded systems but revealed significant performance variations across demographic groups, highlighting generalization challenges in diverse populations."}}
{"id": "2508.11860", "pdf": "https://arxiv.org/pdf/2508.11860", "abs": "https://arxiv.org/abs/2508.11860", "authors": ["Frazier N. Baker", "Daniel Adu-Ampratwum", "Reza Averly", "Botao Yu", "Huan Sun", "Xia Ning"], "title": "LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework", "categories": ["cs.AI", "cs.CL"], "comment": "24 pages, 5 figures", "summary": "Large language model (LLM) agent evaluators leverage specialized tools to\nground the rational decision-making of LLMs, making them well-suited to aid in\nscientific discoveries, such as constrained retrosynthesis planning.\nConstrained retrosynthesis planning is an essential, yet challenging, process\nwithin chemistry for identifying synthetic routes from commercially available\nstarting materials to desired target molecules, subject to practical\nconstraints. Here, we present LARC, the first LLM-based Agentic framework for\nRetrosynthesis planning under Constraints. LARC incorporates agentic constraint\nevaluation, through an Agent-as-a-Judge, directly into the retrosynthesis\nplanning process, using agentic feedback grounded in tool-based reasoning to\nguide and constrain route generation. We rigorously evaluate LARC on a\ncarefully curated set of 48 constrained retrosynthesis planning tasks across 3\nconstraint types. LARC achieves a 72.9% success rate on these tasks, vastly\noutperforming LLM baselines and approaching human expert-level success in\nsubstantially less time. The LARC framework is extensible, and serves as a\nfirst step towards an effective agentic tool or a co-scientist to human experts\nfor constrained retrosynthesis.", "AI": {"tldr": "LARC is the first LLM-based agentic framework for constrained retrosynthesis planning that uses agentic constraint evaluation and tool-based reasoning to guide route generation, achieving 72.9% success rate and approaching human expert performance.", "motivation": "Constrained retrosynthesis planning is essential but challenging in chemistry for identifying synthetic routes from available materials to target molecules under practical constraints. Current approaches lack effective constraint integration.", "method": "LARC incorporates agentic constraint evaluation through an Agent-as-a-Judge directly into retrosynthesis planning, using agentic feedback grounded in tool-based reasoning to guide and constrain route generation.", "result": "LARC achieved 72.9% success rate on 48 constrained retrosynthesis tasks across 3 constraint types, vastly outperforming LLM baselines and approaching human expert-level success in substantially less time.", "conclusion": "LARC framework is extensible and serves as a first step towards an effective agentic tool or co-scientist for human experts in constrained retrosynthesis planning."}}
{"id": "2508.11803", "pdf": "https://arxiv.org/pdf/2508.11803", "abs": "https://arxiv.org/abs/2508.11803", "authors": ["Azam Nouri"], "title": "An MLP Baseline for Handwriting Recognition Using Planar Curvature and Gradient Orientation", "categories": ["cs.CV", "cs.LG"], "comment": "5 pages, No figure", "summary": "This study investigates whether second-order geometric cues - planar\ncurvature magnitude, curvature sign, and gradient orientation - are sufficient\non their own to drive a multilayer perceptron (MLP) classifier for handwritten\ncharacter recognition (HCR), offering an alternative to convolutional neural\nnetworks (CNNs). Using these three handcrafted feature maps as inputs, our\ncurvature-orientation MLP achieves 97 percent accuracy on MNIST digits and 89\npercent on EMNIST letters. These results underscore the discriminative power of\ncurvature-based representations for handwritten character images and\ndemonstrate that the advantages of deep learning can be realized even with\ninterpretable, hand-engineered features.", "AI": {"tldr": "A curvature-orientation MLP using second-order geometric cues achieves 97% accuracy on MNIST and 89% on EMNIST, showing interpretable handcrafted features can rival deep learning performance.", "motivation": "To investigate whether second-order geometric cues alone can drive effective handwritten character recognition as an alternative to convolutional neural networks, using interpretable hand-engineered features.", "method": "Used three handcrafted feature maps (planar curvature magnitude, curvature sign, and gradient orientation) as inputs to a multilayer perceptron classifier for handwritten character recognition.", "result": "Achieved 97% accuracy on MNIST digits and 89% accuracy on EMNIST letters, demonstrating strong performance comparable to deep learning approaches.", "conclusion": "Curvature-based representations have significant discriminative power for handwritten characters, and the advantages of deep learning can be achieved with interpretable, hand-engineered features without complex CNNs."}}
{"id": "2508.11771", "pdf": "https://arxiv.org/pdf/2508.11771", "abs": "https://arxiv.org/abs/2508.11771", "authors": ["Leo Peckham", "Michael Ong", "Naomi Nagy", "Ewan Dunbar"], "title": "Investigating Transcription Normalization in the Faetar ASR Benchmark", "categories": ["cs.CL"], "comment": null, "summary": "We examine the role of transcription inconsistencies in the Faetar Automatic\nSpeech Recognition benchmark, a challenging low-resource ASR benchmark. With\nthe help of a small, hand-constructed lexicon, we conclude that find that,\nwhile inconsistencies do exist in the transcriptions, they are not the main\nchallenge in the task. We also demonstrate that bigram word-based language\nmodelling is of no added benefit, but that constraining decoding to a finite\nlexicon can be beneficial. The task remains extremely difficult.", "AI": {"tldr": "Transcription inconsistencies in Faetar ASR benchmark are not the main challenge; lexicon-constrained decoding helps but task remains very difficult.", "motivation": "To examine the role of transcription inconsistencies in the challenging low-resource Faetar Automatic Speech Recognition benchmark and determine if they are the primary obstacle.", "method": "Used a small hand-constructed lexicon to analyze transcription inconsistencies and tested different approaches including bigram word-based language modeling and lexicon-constrained decoding.", "result": "Found that transcription inconsistencies exist but are not the main challenge; bigram word-based language modeling provided no benefit, but lexicon-constrained decoding showed some improvement.", "conclusion": "The Faetar ASR task remains extremely difficult despite addressing transcription inconsistencies, with lexicon-constrained decoding being the only beneficial approach identified."}}
{"id": "2508.11673", "pdf": "https://arxiv.org/pdf/2508.11673", "abs": "https://arxiv.org/abs/2508.11673", "authors": ["Haojie Zhang", "Yixiong Liang", "Hulin Kuang", "Lihui Cen", "Zhe Qu", "Yigang Cen", "Min Zeng", "Shichao Kan"], "title": "Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MM"], "comment": "10 pages, 3 figures, submitted to ACM Multimedia 2025", "summary": "Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for\nhandling diverse tasks and modalities in the biomedical domain, as training\nseparate models for each modality or task significantly increases inference\ncosts. Existing incremental learning methods focus on task expansion within a\nsingle modality, whereas MBIIL seeks to train a unified model incrementally\nacross modalities. The MBIIL faces two challenges: I) How to preserve\npreviously learned knowledge during incremental updates? II) How to effectively\nleverage knowledge acquired from existing modalities to support new modalities?\nTo address these challenges, we propose MSLoRA-CR, a method that fine-tunes\nModality-Specific LoRA modules while incorporating Contrastive Regularization\nto enhance intra-modality knowledge sharing and promote inter-modality\nknowledge differentiation. Our approach builds upon a large vision-language\nmodel (LVLM), keeping the pretrained model frozen while incrementally adapting\nnew LoRA modules for each modality or task. Experiments on the incremental\nlearning of biomedical images demonstrate that MSLoRA-CR outperforms both the\nstate-of-the-art (SOTA) approach of training separate models for each modality\nand the general incremental learning method (incrementally fine-tuning LoRA).\nSpecifically, MSLoRA-CR achieves a 1.88% improvement in overall performance\ncompared to unconstrained incremental learning methods while maintaining\ncomputational efficiency. Our code is publicly available at\nhttps://github.com/VentusAislant/MSLoRA_CR.", "AI": {"tldr": "MSLoRA-CR is a multimodal biomedical image incremental learning method that uses modality-specific LoRA modules with contrastive regularization to enable efficient knowledge sharing across modalities while preventing catastrophic forgetting.", "motivation": "Existing incremental learning methods focus on task expansion within single modalities, but biomedical applications require handling diverse modalities. Training separate models for each modality significantly increases inference costs, creating a need for unified multimodal incremental learning.", "method": "The method fine-tunes Modality-Specific LoRA modules while incorporating Contrastive Regularization. It builds upon a large vision-language model, keeping the pretrained model frozen while incrementally adapting new LoRA modules for each modality/task to enhance intra-modality knowledge sharing and promote inter-modality knowledge differentiation.", "result": "MSLoRA-CR outperforms both training separate models for each modality and general incremental learning methods. It achieves a 1.88% improvement in overall performance compared to unconstrained incremental learning methods while maintaining computational efficiency.", "conclusion": "The proposed MSLoRA-CR method effectively addresses the challenges of multimodal biomedical image incremental learning by preserving previously learned knowledge and leveraging cross-modal knowledge transfer through modality-specific LoRA adaptation with contrastive regularization."}}
{"id": "2508.11894", "pdf": "https://arxiv.org/pdf/2508.11894", "abs": "https://arxiv.org/abs/2508.11894", "authors": ["Ao Li", "Bin Yan", "Bingfeng Cai", "Chenxi Li", "Cunzhong Zhao", "Fugen Yao", "Gaoqiang Liu", "Guanjun Jiang", "Jian Xu", "Liang Dong", "Liansheng Sun", "Rongshen Zhang", "Xiaolei Gui", "Xin Liu", "Xin Shang", "Yao Wu", "Yu Cao", "Zhenxin Ma", "Zhuang Jia"], "title": "QuarkMed Medical Foundation Model Technical Report", "categories": ["cs.AI"], "comment": "20 pages", "summary": "Recent advancements in large language models have significantly accelerated\ntheir adoption in healthcare applications, including AI-powered medical\nconsultations, diagnostic report assistance, and medical search tools. However,\nmedical tasks often demand highly specialized knowledge, professional accuracy,\nand customization capabilities, necessitating a robust and reliable foundation\nmodel. QuarkMed addresses these needs by leveraging curated medical data\nprocessing, medical-content Retrieval-Augmented Generation (RAG), and a\nlarge-scale, verifiable reinforcement learning pipeline to develop a\nhigh-performance medical foundation model. The model achieved 70% accuracy on\nthe Chinese Medical Licensing Examination, demonstrating strong generalization\nacross diverse medical benchmarks. QuarkMed offers a powerful yet versatile\npersonal medical AI solution, already serving over millions of users at\nai.quark.cn.", "AI": {"tldr": "QuarkMed is a medical foundation model that achieves 70% accuracy on Chinese Medical Licensing Exam using curated data processing, medical RAG, and verifiable reinforcement learning.", "motivation": "Medical applications require specialized knowledge, professional accuracy, and customization that current LLMs lack, necessitating a robust medical foundation model.", "method": "Leverages curated medical data processing, medical-content Retrieval-Augmented Generation (RAG), and large-scale verifiable reinforcement learning pipeline.", "result": "Achieved 70% accuracy on Chinese Medical Licensing Examination with strong generalization across diverse medical benchmarks.", "conclusion": "QuarkMed provides a powerful and versatile personal medical AI solution currently serving millions of users at ai.quark.cn."}}
{"id": "2508.11808", "pdf": "https://arxiv.org/pdf/2508.11808", "abs": "https://arxiv.org/abs/2508.11808", "authors": ["Sahajpreet Singh", "Rongxin Ouyang", "Subhayan Mukerjee", "Kokil Jaidka"], "title": "Labels or Input? Rethinking Augmentation in Multimodal Hate Detection", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.CY", "cs.MM", "I.2.7; I.2.10"], "comment": "13 pages, 2 figures, 7 tables", "summary": "The modern web is saturated with multimodal content, intensifying the\nchallenge of detecting hateful memes, where harmful intent is often conveyed\nthrough subtle interactions between text and image under the guise of humor or\nsatire. While recent advances in Vision-Language Models (VLMs) show promise,\nthese models lack support for fine-grained supervision and remain susceptible\nto implicit hate speech. In this paper, we present a dual-pronged approach to\nimprove multimodal hate detection. First, we propose a prompt optimization\nframework that systematically varies prompt structure, supervision granularity,\nand training modality. We show that prompt design and label scaling both\ninfluence performance, with structured prompts improving robustness even in\nsmall models, and InternVL2 achieving the best F1-scores across binary and\nscaled settings. Second, we introduce a multimodal data augmentation pipeline\nthat generates 2,479 counterfactually neutral memes by isolating and rewriting\nthe hateful modality. This pipeline, powered by a multi-agent LLM-VLM setup,\nsuccessfully reduces spurious correlations and improves classifier\ngeneralization. Our approaches inspire new directions for building synthetic\ndata to train robust and fair vision-language models. Our findings demonstrate\nthat prompt structure and data composition are as critical as model size, and\nthat targeted augmentation can support more trustworthy and context-sensitive\nhate detection.", "AI": {"tldr": "A dual approach combining prompt optimization and multimodal data augmentation improves hateful meme detection by enhancing model robustness and reducing spurious correlations.", "motivation": "The web is saturated with multimodal hate content disguised as humor, and current Vision-Language Models lack fine-grained supervision and struggle with implicit hate speech detection.", "method": "1) Prompt optimization framework varying structure, supervision granularity, and training modality; 2) Multimodal data augmentation pipeline generating 2,479 counterfactually neutral memes using multi-agent LLM-VLM setup.", "result": "Structured prompts improve robustness even in small models, InternVL2 achieves best F1-scores, and the augmentation pipeline successfully reduces spurious correlations and improves classifier generalization.", "conclusion": "Prompt structure and data composition are as critical as model size, and targeted augmentation enables more trustworthy, context-sensitive hate detection while inspiring synthetic data approaches for robust vision-language models."}}
{"id": "2508.11779", "pdf": "https://arxiv.org/pdf/2508.11779", "abs": "https://arxiv.org/abs/2508.11779", "authors": ["Tianyi Li", "Yu Qin", "Olivia R. Liu Sheng"], "title": "A Multi-Task Evaluation of LLMs' Processing of Academic Text Input", "categories": ["cs.CL", "econ.GN", "q-fin.EC"], "comment": null, "summary": "How much large language models (LLMs) can aid scientific discovery, notably\nin assisting academic peer review, is in heated debate. Between a literature\ndigest and a human-comparable research assistant lies their practical\napplication potential. We organize individual tasks that computer science\nstudies employ in separate terms into a guided and robust workflow to evaluate\nLLMs' processing of academic text input. We employ four tasks in the\nassessment: content reproduction/comparison/scoring/reflection, each demanding\na specific role of the LLM (oracle/judgmental arbiter/knowledgeable\narbiter/collaborator) in assisting scholarly works, and altogether testing LLMs\nwith questions that increasingly require intellectual capabilities towards a\nsolid understanding of scientific texts to yield desirable solutions. We\nexemplify a rigorous performance evaluation with detailed instructions on the\nprompts. Adopting first-rate Information Systems articles at three top journals\nas the input texts and an abundant set of text metrics, we record a compromised\nperformance of the leading LLM - Google's Gemini: its summary and paraphrase of\nacademic text is acceptably reliable; using it to rank texts through pairwise\ntext comparison is faintly scalable; asking it to grade academic texts is prone\nto poor discrimination; its qualitative reflection on the text is\nself-consistent yet hardly insightful to inspire meaningful research. This\nevidence against an endorsement of LLMs' text-processing capabilities is\nconsistent across metric-based internal (linguistic assessment), external\n(comparing to the ground truth), and human evaluation, and is robust to the\nvariations of the prompt. Overall, we do not recommend an unchecked use of LLMs\nin constructing peer reviews.", "AI": {"tldr": "LLMs show limited capability in academic peer review tasks - acceptable at summarization but poor at grading, comparison, and providing meaningful research insights.", "motivation": "To evaluate how effectively large language models can assist in scientific peer review processes by testing their text processing capabilities on academic content.", "method": "Used a four-task workflow: content reproduction, comparison, scoring, and reflection on first-rate Information Systems articles from top journals, employing multiple text metrics and rigorous prompt instructions with Google's Gemini.", "result": "Compromised performance - acceptable summarization but poor discrimination in grading, faintly scalable text comparison, and self-consistent but uninsightful qualitative reflections.", "conclusion": "LLMs should not be used unchecked for peer review construction due to consistent limitations across linguistic assessment, ground truth comparison, and human evaluation."}}
{"id": "2508.11679", "pdf": "https://arxiv.org/pdf/2508.11679", "abs": "https://arxiv.org/abs/2508.11679", "authors": ["Shaodi Feng", "Zhuoyi Lin", "Jianan Zhou", "Cong Zhang", "Jingwen Li", "Kuan-Wen Chen", "Senthilnath Jayavelu", "Yew-Soon Ong"], "title": "Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Deep learning has been extensively explored to solve vehicle routing problems\n(VRPs), which yields a range of data-driven neural solvers with promising\noutcomes. However, most neural solvers are trained to tackle VRP instances in a\nrelatively monotonous context, e.g., simplifying VRPs by using Euclidean\ndistance between nodes and adhering to a single problem size, which harms their\noff-the-shelf application in different scenarios. To enhance their versatility,\nthis paper presents a novel lifelong learning framework that incrementally\ntrains a neural solver to manage VRPs in distinct contexts. Specifically, we\npropose a lifelong learner (LL), exploiting a Transformer network as the\nbackbone, to solve a series of VRPs. The inter-context self-attention mechanism\nis proposed within LL to transfer the knowledge obtained from solving preceding\nVRPs into the succeeding ones. On top of that, we develop a dynamic context\nscheduler (DCS), employing the cross-context experience replay to further\nfacilitate LL looking back on the attained policies of solving preceding VRPs.\nExtensive results on synthetic and benchmark instances (problem sizes up to\n18k) show that our LL is capable of discovering effective policies for tackling\ngeneric VRPs in varying contexts, which outperforms other neural solvers and\nachieves the best performance for most VRPs.", "AI": {"tldr": "Lifelong learning framework for neural VRP solvers that handles varying problem contexts through inter-context self-attention and dynamic context scheduling.", "motivation": "Most neural solvers are trained in monotonous contexts (Euclidean distance, single problem size), limiting their off-the-shelf application in different scenarios.", "method": "Proposes a lifelong learner (LL) with Transformer backbone and inter-context self-attention to transfer knowledge between VRPs, plus dynamic context scheduler (DCS) with cross-context experience replay.", "result": "Outperforms other neural solvers on synthetic and benchmark instances (up to 18k problem sizes), achieving best performance for most VRPs.", "conclusion": "The framework enables neural solvers to discover effective policies for generic VRPs across varying contexts, enhancing versatility and practical applicability."}}
{"id": "2508.11944", "pdf": "https://arxiv.org/pdf/2508.11944", "abs": "https://arxiv.org/abs/2508.11944", "authors": ["Hongtao Liu", "Zhicheng Du", "Zihe Wang", "Weiran Shen"], "title": "CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Game-playing ability serves as an indicator for evaluating the strategic\nreasoning capability of large language models (LLMs). While most existing\nstudies rely on utility performance metrics, which are not robust enough due to\nvariations in opponent behavior and game structure. To address this limitation,\nwe propose \\textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation\nframework inspired by the cognitive hierarchy models from behavioral economics.\nWe hypothesize that agents have bounded rationality -- different agents behave\nat varying reasoning depths/levels. We evaluate LLMs' strategic reasoning\nthrough a three-phase systematic framework, utilizing behavioral data from six\nstate-of-the-art LLMs across fifteen carefully selected normal-form games.\nExperiments show that LLMs exhibit consistent strategic reasoning levels across\ndiverse opponents, confirming the framework's robustness and generalization\ncapability. We also analyze the effects of two key mechanisms (Chat Mechanism\nand Memory Mechanism) on strategic reasoning performance. Results indicate that\nthe Chat Mechanism significantly degrades strategic reasoning, whereas the\nMemory Mechanism enhances it. These insights position CHBench as a promising\ntool for evaluating LLM capabilities, with significant potential for future\nresearch and practical applications.", "AI": {"tldr": "CHBench is a new evaluation framework using cognitive hierarchy models to assess LLMs' strategic reasoning in games, showing consistent reasoning levels across opponents and revealing that chat mechanisms degrade while memory mechanisms enhance strategic performance.", "motivation": "Existing game-playing evaluations for LLMs rely on utility metrics that lack robustness due to variations in opponent behavior and game structure, requiring a more systematic approach to assess strategic reasoning capabilities.", "method": "Proposed Cognitive Hierarchy Benchmark (CHBench) using a three-phase systematic framework with behavioral data from six state-of-the-art LLMs across fifteen normal-form games, analyzing reasoning levels through cognitive hierarchy models from behavioral economics.", "result": "LLMs exhibit consistent strategic reasoning levels across diverse opponents, confirming framework robustness. Chat Mechanism significantly degrades strategic reasoning while Memory Mechanism enhances it.", "conclusion": "CHBench provides a robust and generalizable tool for evaluating LLM strategic reasoning capabilities, with significant potential for future research and practical applications in assessing bounded rationality and reasoning depths."}}
{"id": "2508.11825", "pdf": "https://arxiv.org/pdf/2508.11825", "abs": "https://arxiv.org/abs/2508.11825", "authors": ["Sherlon Almeida da Silva", "Davi Geiger", "Luiz Velho", "Moacir Antonelli Ponti"], "title": "Towards Understanding 3D Vision: the Role of Gaussian Curvature", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in computer vision have predominantly relied on data-driven\napproaches that leverage deep learning and large-scale datasets. Deep neural\nnetworks have achieved remarkable success in tasks such as stereo matching and\nmonocular depth reconstruction. However, these methods lack explicit models of\n3D geometry that can be directly analyzed, transferred across modalities, or\nsystematically modified for controlled experimentation. We investigate the role\nof Gaussian curvature in 3D surface modeling. Besides Gaussian curvature being\nan invariant quantity under change of observers or coordinate systems, we\ndemonstrate using the Middlebury stereo dataset that it offers: (i) a sparse\nand compact description of 3D surfaces, (ii) state-of-the-art monocular and\nstereo methods seem to implicitly consider it, but no explicit module of such\nuse can be extracted, (iii) a form of geometric prior that can inform and\nimprove 3D surface reconstruction, and (iv) a possible use as an unsupervised\nmetric for stereo methods.", "AI": {"tldr": "The paper investigates Gaussian curvature as an invariant geometric prior for 3D surface modeling, showing it provides sparse surface descriptions, is implicitly used by state-of-the-art methods, and can improve reconstruction and serve as an unsupervised stereo metric.", "motivation": "Current deep learning approaches for 3D vision lack explicit geometric models that can be analyzed, transferred, or systematically modified. The researchers want to explore Gaussian curvature as a fundamental geometric invariant for better 3D surface understanding.", "method": "The study investigates Gaussian curvature properties using the Middlebury stereo dataset, analyzing its role as a sparse descriptor, examining implicit use in existing methods, and exploring its potential as a geometric prior and unsupervised metric.", "result": "Gaussian curvature offers a compact 3D surface description, state-of-the-art methods implicitly consider it but lack explicit modules, it serves as an effective geometric prior for reconstruction improvement, and shows promise as an unsupervised stereo evaluation metric.", "conclusion": "Gaussian curvature provides a valuable geometric foundation for 3D surface modeling that complements data-driven approaches, offering explicit geometric understanding, transferability across modalities, and systematic experimental control missing in current deep learning methods."}}
{"id": "2508.11816", "pdf": "https://arxiv.org/pdf/2508.11816", "abs": "https://arxiv.org/abs/2508.11816", "authors": ["Krishna Chaitanya Marturi", "Heba H. Elwazzan"], "title": "LLM-Guided Planning and Summary-Based Scientific Text Simplification: DS@GT at CLEF 2025 SimpleText", "categories": ["cs.CL"], "comment": "Text Simplification, hallucination detection, LLMs, CLEF 2025,\n  SimpleText, CEUR-WS", "summary": "In this paper, we present our approach for the CLEF 2025 SimpleText Task 1,\nwhich addresses both sentence-level and document-level scientific text\nsimplification. For sentence-level simplification, our methodology employs\nlarge language models (LLMs) to first generate a structured plan, followed by\nplan-driven simplification of individual sentences. At the document level, we\nleverage LLMs to produce concise summaries and subsequently guide the\nsimplification process using these summaries. This two-stage, LLM-based\nframework enables more coherent and contextually faithful simplifications of\nscientific text.", "AI": {"tldr": "Two-stage LLM approach for scientific text simplification using structured planning at sentence level and summary-guided simplification at document level", "motivation": "To address both sentence-level and document-level scientific text simplification while maintaining coherence and contextual faithfulness", "method": "Uses large language models to generate structured plans for sentence simplification and concise summaries for document-level simplification guidance", "result": "Enables more coherent and contextually faithful simplifications of scientific text", "conclusion": "The two-stage LLM-based framework effectively handles scientific text simplification at both granular levels while preserving context and coherence"}}
{"id": "2508.11680", "pdf": "https://arxiv.org/pdf/2508.11680", "abs": "https://arxiv.org/abs/2508.11680", "authors": ["Aditya Akella", "Jonathan Farah"], "title": "Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics", "categories": ["cs.LG", "cs.AI", "es: 62M10 (primary), 62P20, 68T05, 91B72 (secondary)"], "comment": "6 pages, 4 figures, 3 tables", "summary": "Demographic shifts, influenced by globalization, economic conditions,\ngeopolitical events, and environmental factors, pose significant challenges for\npolicymakers and researchers. Accurate demographic forecasting is essential for\ninformed decision-making in areas such as urban planning, healthcare, and\neconomic policy. This study explores the application of time series foundation\nmodels to predict demographic changes in the United States using datasets from\nthe U.S. Census Bureau and Federal Reserve Economic Data (FRED). We evaluate\nthe performance of the Time Series Foundation Model (TimesFM) against\ntraditional baselines including Long Short-Term Memory (LSTM) networks,\nAutoregressive Integrated Moving Average (ARIMA), and Linear Regression. Our\nexperiments across six demographically diverse states demonstrate that TimesFM\nachieves the lowest Mean Squared Error (MSE) in 86.67% of test cases, with\nparticularly strong performance on minority populations with sparse historical\ndata. These findings highlight the potential of pre-trained foundation models\nto enhance demographic analysis and inform proactive policy interventions\nwithout requiring extensive task-specific fine-tuning.", "AI": {"tldr": "TimesFM foundation model outperforms traditional methods (LSTM, ARIMA, Linear Regression) in demographic forecasting, achieving lowest MSE in 86.67% of cases across diverse US states, especially for minority populations with sparse data.", "motivation": "Accurate demographic forecasting is crucial for policymaking in urban planning, healthcare, and economic policy, but traditional methods struggle with complex demographic shifts influenced by globalization, economic conditions, and environmental factors.", "method": "Applied Time Series Foundation Model (TimesFM) to predict US demographic changes using Census Bureau and FRED data, comparing against LSTM, ARIMA, and Linear Regression baselines across six demographically diverse states.", "result": "TimesFM achieved the lowest Mean Squared Error in 86.67% of test cases, with particularly strong performance on minority populations that have sparse historical data.", "conclusion": "Pre-trained foundation models like TimesFM show significant potential for enhancing demographic analysis and informing proactive policy interventions without requiring extensive task-specific fine-tuning."}}
{"id": "2508.11953", "pdf": "https://arxiv.org/pdf/2508.11953", "abs": "https://arxiv.org/abs/2508.11953", "authors": ["Yuan Li", "Zhengzhong Liu", "Eric Xing"], "title": "Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Optimizing data mixtures for supervised fine-tuning (SFT) of large language\nmodels (LLMs) is critical for developing general-purpose models, yet this area\nremains underexplored. In this paper, we frame data mixing as an optimization\nproblem and introduce a novel method designed to minimize validation loss. Our\napproach parametrizes the loss by modeling effective data transferred and\nleveraging scaling laws for fine-tuning. By experimenting with various\nsmall-scale data mixtures, we fit these parameters and derive the optimal\nweights. We provide both mathematical proofs and empirical results\ndemonstrating that our algorithm achieves excellent overall and individual\nperformance across all domains. Through controlled experiments, we show that\nmodels trained with our optimized weights perform on par with those using\noptimal weights determined via grid search, with per-domain loss only 0.66%\nhigher than the best domain loss from grid search on average. Additionally, we\nshow that reweighting popular SFT datasets using our method improves both\nvalidation loss and downstream performance. Finally, we discuss how our method\ncan generalize to guide data selection for domain-specific models and provide\ninsights into SFT.", "AI": {"tldr": "A novel optimization method for data mixing in supervised fine-tuning of LLMs that minimizes validation loss by modeling effective data transfer and leveraging scaling laws, achieving performance comparable to grid search with only 0.66% higher domain loss.", "motivation": "Optimizing data mixtures for SFT of LLMs is critical for developing general-purpose models but remains underexplored, with current approaches lacking systematic optimization frameworks.", "method": "Frames data mixing as optimization problem, parametrizes loss by modeling effective data transferred and leveraging scaling laws for fine-tuning. Experiments with small-scale mixtures to fit parameters and derive optimal weights.", "result": "Models trained with optimized weights perform on par with grid search optimal weights, with per-domain loss only 0.66% higher than best grid search results. Reweighting popular SFT datasets improves both validation loss and downstream performance.", "conclusion": "The method provides an effective optimization framework for data mixing in SFT, generalizes to domain-specific model data selection, and offers valuable insights into supervised fine-tuning processes."}}
{"id": "2508.11826", "pdf": "https://arxiv.org/pdf/2508.11826", "abs": "https://arxiv.org/abs/2508.11826", "authors": ["Dehn Xu", "Tim Katzke", "Emmanuel M\u00fcller"], "title": "From Pixels to Graphs: Deep Graph-Level Anomaly Detection on Dermoscopic Images", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have emerged as a powerful approach for\ngraph-based machine learning tasks. Previous work applied GNNs to image-derived\ngraph representations for various downstream tasks such as classification or\nanomaly detection. These transformations include segmenting images, extracting\nfeatures from segments, mapping them to nodes, and connecting them. However, to\nthe best of our knowledge, no study has rigorously compared the effectiveness\nof the numerous potential image-to-graph transformation approaches for\nGNN-based graph-level anomaly detection (GLAD). In this study, we\nsystematically evaluate the efficacy of multiple segmentation schemes, edge\nconstruction strategies, and node feature sets based on color, texture, and\nshape descriptors to produce suitable image-derived graph representations to\nperform graph-level anomaly detection. We conduct extensive experiments on\ndermoscopic images using state-of-the-art GLAD models, examining performance\nand efficiency in purely unsupervised, weakly supervised, and fully supervised\nregimes. Our findings reveal, for example, that color descriptors contribute\nthe best standalone performance, while incorporating shape and texture features\nconsistently enhances detection efficacy. In particular, our best unsupervised\nconfiguration using OCGTL achieves a competitive AUC-ROC score of up to 0.805\nwithout relying on pretrained backbones like comparable image-based approaches.\nWith the inclusion of sparse labels, the performance increases substantially to\n0.872 and with full supervision to 0.914 AUC-ROC.", "AI": {"tldr": "Systematic comparison of image-to-graph transformation methods for GNN-based anomaly detection, finding color features perform best alone but shape/texture combinations improve results across all supervision levels.", "motivation": "No previous study has rigorously compared the effectiveness of various image-to-graph transformation approaches for graph-level anomaly detection using GNNs, despite their growing popularity in graph-based machine learning.", "method": "Systematically evaluated multiple segmentation schemes, edge construction strategies, and node feature sets (color, texture, shape descriptors) for producing image-derived graph representations. Conducted experiments on dermoscopic images using state-of-the-art GLAD models in unsupervised, weakly supervised, and fully supervised regimes.", "result": "Color descriptors provided the best standalone performance. Incorporating shape and texture features consistently enhanced detection efficacy. Best unsupervised configuration achieved AUC-ROC of 0.805 without pretrained backbones. Performance increased to 0.872 with sparse labels and 0.914 with full supervision.", "conclusion": "Comprehensive image-to-graph transformation evaluation provides valuable insights for GNN-based anomaly detection, demonstrating competitive performance across different supervision levels and the importance of feature combination strategies."}}
{"id": "2508.11823", "pdf": "https://arxiv.org/pdf/2508.11823", "abs": "https://arxiv.org/abs/2508.11823", "authors": ["Krishna Chaitanya Marturi", "Heba H. Elwazzan"], "title": "Hallucination Detection and Mitigation in Scientific Text Simplification using Ensemble Approaches: DS@GT at CLEF 2025 SimpleText", "categories": ["cs.CL"], "comment": "Text Simplification, hallucination detection, LLMs, CLEF 2025,\n  SimpleText, CEUR-WS", "summary": "In this paper, we describe our methodology for the CLEF 2025 SimpleText Task\n2, which focuses on detecting and evaluating creative generation and\ninformation distortion in scientific text simplification. Our solution\nintegrates multiple strategies: we construct an ensemble framework that\nleverages BERT-based classifier, semantic similarity measure, natural language\ninference model, and large language model (LLM) reasoning. These diverse\nsignals are combined using meta-classifiers to enhance the robustness of\nspurious and distortion detection. Additionally, for grounded generation, we\nemploy an LLM-based post-editing system that revises simplifications based on\nthe original input texts.", "AI": {"tldr": "Ensemble framework combining BERT classifier, semantic similarity, NLI model, and LLM reasoning for detecting creative generation and information distortion in scientific text simplification, with LLM-based post-editing for grounded generation.", "motivation": "To address the challenge of detecting and evaluating creative generation and information distortion in scientific text simplification, particularly for the CLEF 2025 SimpleText Task 2.", "method": "Constructed an ensemble framework integrating multiple strategies: BERT-based classifier, semantic similarity measures, natural language inference model, and LLM reasoning. Combined these signals using meta-classifiers. Employed LLM-based post-editing system for grounded generation that revises simplifications based on original input texts.", "result": "The methodology aims to enhance robustness in detecting spurious content and information distortion in simplified scientific texts.", "conclusion": "The proposed multi-strategy ensemble approach with LLM-based post-editing provides a comprehensive solution for detecting and addressing creative generation and information distortion in scientific text simplification tasks."}}
{"id": "2508.11723", "pdf": "https://arxiv.org/pdf/2508.11723", "abs": "https://arxiv.org/abs/2508.11723", "authors": ["Qian Cao", "Jielin Chen", "Junchao Zhao", "Rudi Stouffs"], "title": "From Heuristics to Data: Quantifying Site Planning Layout Indicators with Deep Learning and Multi-Modal Data", "categories": ["cs.LG", "68T07, 91D10", "I.2.10; H.2.8"], "comment": "42 pages, 32 figures, submitted to Environment and Planning B: Urban\n  Analytics and City Science", "summary": "The spatial layout of urban sites shapes land-use efficiency and spatial\norganization. Traditional site planning often relies on experiential judgment\nand single-source data, limiting systematic quantification of multifunctional\nlayouts. We propose a Site Planning Layout Indicator (SPLI) system, a\ndata-driven framework integrating empirical knowledge with heterogeneous\nmulti-source data to produce structured urban spatial information. The SPLI\nsupports multimodal spatial data systems for analytics, inference, and\nretrieval by combining OpenStreetMap (OSM), Points of Interest (POI), building\nmorphology, land use, and satellite imagery. It extends conventional metrics\nthrough five dimensions: (1) Hierarchical Building Function Classification,\nrefining empirical systems into clear hierarchies; (2) Spatial Organization,\nquantifying seven layout patterns (e.g., symmetrical, concentric,\naxial-oriented); (3) Functional Diversity, transforming qualitative assessments\ninto measurable indicators using Functional Ratio (FR) and Simpson Index (SI);\n(4) Accessibility to Essential Services, integrating facility distribution and\ntransport networks for comprehensive accessibility metrics; and (5) Land Use\nIntensity, using Floor Area Ratio (FAR) and Building Coverage Ratio (BCR) to\nassess utilization efficiency. Data gaps are addressed through deep learning,\nincluding Relational Graph Neural Networks (RGNN) and Graph Neural Networks\n(GNN). Experiments show the SPLI improves functional classification accuracy\nand provides a standardized basis for automated, data-driven urban spatial\nanalytics.", "AI": {"tldr": "Proposes a Site Planning Layout Indicator (SPLI) system that integrates multi-source data and deep learning to quantitatively analyze urban spatial layouts across five dimensions: building function classification, spatial organization, functional diversity, accessibility, and land use intensity.", "motivation": "Traditional urban site planning relies on experiential judgment and single-source data, limiting systematic quantification of multifunctional layouts and hindering data-driven urban spatial analytics.", "method": "Developed a data-driven framework integrating OSM, POI, building morphology, land use, and satellite imagery with deep learning (RGNN and GNN) to create structured indicators across five dimensions: hierarchical building function classification, spatial organization patterns, functional diversity metrics, accessibility measures, and land use intensity ratios.", "result": "The SPLI system improves functional classification accuracy and provides a standardized basis for automated urban spatial analytics, successfully addressing data gaps and enabling comprehensive quantitative assessment of urban layouts.", "conclusion": "The proposed SPLI framework enables systematic, data-driven quantification of urban spatial layouts, overcoming limitations of traditional planning methods and supporting advanced analytics, inference, and retrieval for urban planning applications."}}
{"id": "2508.11954", "pdf": "https://arxiv.org/pdf/2508.11954", "abs": "https://arxiv.org/abs/2508.11954", "authors": ["Sehyuk Park", "Soyeon Caren Han", "Eduard Hovy"], "title": "UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting", "categories": ["cs.AI"], "comment": null, "summary": "Time series forecasting is a foundational task across domains, such as\nfinance, healthcare, and environmental monitoring. While recent advances in\nTime Series Foundation Models (TSFMs) have demonstrated strong generalisation\nthrough large-scale pretraining, existing models operate predominantly in a\nunimodal setting, ignoring the rich multimodal context, such as visual and\ntextual signals, that often accompanies time series data in real-world\nscenarios. This paper introduces a novel parameter-efficient multimodal\nframework, UniCast, that extends TSFMs to jointly leverage time series, vision,\nand text modalities for enhanced forecasting performance. Our method integrates\nmodality-specific embeddings from pretrained Vision and Text Encoders with a\nfrozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal\nparameter updates. This design not only preserves the generalisation strength\nof the foundation model but also enables effective cross-modal interaction.\nExtensive experiments across diverse time-series forecasting benchmarks\ndemonstrate that UniCast consistently and significantly outperforms all\nexisting TSFM baselines. The findings highlight the critical role of multimodal\ncontext in advancing the next generation of general-purpose time series\nforecasters.", "AI": {"tldr": "UniCast introduces a parameter-efficient multimodal framework that extends time series foundation models to incorporate visual and textual context, achieving superior forecasting performance through soft prompt tuning.", "motivation": "Existing time series foundation models operate in unimodal settings, ignoring the rich multimodal context (visual and textual signals) that often accompanies real-world time series data, limiting their forecasting capabilities.", "method": "Integrates modality-specific embeddings from pretrained Vision and Text Encoders with a frozen Time Series Foundation Model via soft prompt tuning, enabling efficient adaptation with minimal parameter updates while preserving the model's generalization strength.", "result": "Extensive experiments across diverse time-series forecasting benchmarks demonstrate that UniCast consistently and significantly outperforms all existing TSFM baselines.", "conclusion": "The findings highlight the critical role of multimodal context in advancing the next generation of general-purpose time series forecasters."}}
{"id": "2508.11834", "pdf": "https://arxiv.org/pdf/2508.11834", "abs": "https://arxiv.org/abs/2508.11834", "authors": ["Hamza Kheddar", "Yassine Habchi", "Mohamed Chahine Ghanem", "Mustapha Hemis", "Dusit Niyato"], "title": "Recent Advances in Transformer and Large Language Models for UAV Applications", "categories": ["cs.CV", "cs.AI", "cs.RO", "cs.SY", "eess.IV", "eess.SY"], "comment": null, "summary": "The rapid advancement of Transformer-based models has reshaped the landscape\nof uncrewed aerial vehicle (UAV) systems by enhancing perception,\ndecision-making, and autonomy. This review paper systematically categorizes and\nevaluates recent developments in Transformer architectures applied to UAVs,\nincluding attention mechanisms, CNN-Transformer hybrids, reinforcement learning\nTransformers, and large language models (LLMs). Unlike previous surveys, this\nwork presents a unified taxonomy of Transformer-based UAV models, highlights\nemerging applications such as precision agriculture and autonomous navigation,\nand provides comparative analyses through structured tables and performance\nbenchmarks. The paper also reviews key datasets, simulators, and evaluation\nmetrics used in the field. Furthermore, it identifies existing gaps in the\nliterature, outlines critical challenges in computational efficiency and\nreal-time deployment, and offers future research directions. This comprehensive\nsynthesis aims to guide researchers and practitioners in understanding and\nadvancing Transformer-driven UAV technologies.", "AI": {"tldr": "Comprehensive review of Transformer-based models in UAV systems, covering architectures, applications, datasets, and future research directions.", "motivation": "To systematically categorize and evaluate recent developments in Transformer architectures applied to UAVs, addressing the rapid advancement that has reshaped UAV perception, decision-making, and autonomy.", "method": "Presents a unified taxonomy of Transformer-based UAV models, provides comparative analyses through structured tables and performance benchmarks, and reviews key datasets, simulators, and evaluation metrics.", "result": "The review highlights emerging applications (precision agriculture, autonomous navigation), identifies existing literature gaps, and outlines critical challenges in computational efficiency and real-time deployment.", "conclusion": "This comprehensive synthesis aims to guide researchers and practitioners in understanding and advancing Transformer-driven UAV technologies, offering future research directions for the field."}}
{"id": "2508.11828", "pdf": "https://arxiv.org/pdf/2508.11828", "abs": "https://arxiv.org/abs/2508.11828", "authors": ["Michael Flor", "Xinyi Liu", "Anna Feldman"], "title": "A Survey of Idiom Datasets for Psycholinguistic and Computational Research", "categories": ["cs.CL"], "comment": "KONVENS 2025. To appear", "summary": "Idioms are figurative expressions whose meanings often cannot be inferred\nfrom their individual words, making them difficult to process computationally\nand posing challenges for human experimental studies. This survey reviews\ndatasets developed in psycholinguistics and computational linguistics for\nstudying idioms, focusing on their content, form, and intended use.\nPsycholinguistic resources typically contain normed ratings along dimensions\nsuch as familiarity, transparency, and compositionality, while computational\ndatasets support tasks like idiomaticity detection/classification,\nparaphrasing, and cross-lingual modeling. We present trends in annotation\npractices, coverage, and task framing across 53 datasets. Although recent\nefforts expanded language coverage and task diversity, there seems to be no\nrelation yet between psycholinguistic and computational research on idioms.", "AI": {"tldr": "Survey of 53 idiom datasets from psycholinguistics and computational linguistics, analyzing their content, annotation practices, and applications, finding a disconnect between the two research fields.", "motivation": "Idioms are challenging for both computational processing and human experimental studies due to their figurative nature, requiring specialized datasets for research.", "method": "Comprehensive review and analysis of 53 existing datasets, examining their content, form, annotation practices, coverage, and intended use cases across both psycholinguistics and computational linguistics.", "result": "Found that psycholinguistic resources focus on normed ratings (familiarity, transparency, compositionality) while computational datasets support tasks like idiomaticity detection, paraphrasing, and cross-lingual modeling. Recent efforts expanded language coverage and task diversity, but no connection exists between the two research domains.", "conclusion": "Despite progress in dataset development, there remains a significant gap between psycholinguistic and computational research on idioms that needs to be bridged for more comprehensive understanding and processing of figurative language."}}
{"id": "2508.11727", "pdf": "https://arxiv.org/pdf/2508.11727", "abs": "https://arxiv.org/abs/2508.11727", "authors": ["Songyao Jin", "Biwei Huang"], "title": "Causal Structure Learning in Hawkes Processes with Complex Latent Confounder Networks", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multivariate Hawkes process provides a powerful framework for modeling\ntemporal dependencies and event-driven interactions in complex systems. While\nexisting methods primarily focus on uncovering causal structures among observed\nsubprocesses, real-world systems are often only partially observed, with latent\nsubprocesses posing significant challenges. In this paper, we show that\ncontinuous-time event sequences can be represented by a discrete-time model as\nthe time interval shrinks, and we leverage this insight to establish necessary\nand sufficient conditions for identifying latent subprocesses and the causal\ninfluences. Accordingly, we propose a two-phase iterative algorithm that\nalternates between inferring causal relationships among discovered subprocesses\nand uncovering new latent subprocesses, guided by path-based conditions that\nguarantee identifiability. Experiments on both synthetic and real-world\ndatasets show that our method effectively recovers causal structures despite\nthe presence of latent subprocesses.", "AI": {"tldr": "The paper presents a method for identifying latent subprocesses and causal influences in multivariate Hawkes processes, addressing the challenge of partially observed real-world systems.", "motivation": "Real-world systems are often only partially observed with latent subprocesses, which existing methods fail to address as they primarily focus on causal structures among observed subprocesses only.", "method": "A two-phase iterative algorithm that alternates between inferring causal relationships among discovered subprocesses and uncovering new latent subprocesses, guided by path-based identifiability conditions derived from discrete-time representation of continuous-time event sequences.", "result": "Experiments on synthetic and real-world datasets demonstrate that the method effectively recovers causal structures despite the presence of latent subprocesses.", "conclusion": "The proposed approach successfully addresses the challenge of latent subprocesses in multivariate Hawkes processes by establishing identifiability conditions and providing an effective algorithmic solution for causal structure recovery."}}
{"id": "2508.11959", "pdf": "https://arxiv.org/pdf/2508.11959", "abs": "https://arxiv.org/abs/2508.11959", "authors": ["Xuanxiang Huang", "Olivier L\u00e9toff\u00e9", "Joao Marques-Silva"], "title": "Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index", "categories": ["cs.AI"], "comment": null, "summary": "Feature attribution methods based on game theory are ubiquitous in the field\nof eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous\nfeature attribution using logic-based explanations, specifically targeting\nhigh-stakes uses of machine learning (ML) models. Typically, such works exploit\nweak abductive explanation (WAXp) as the characteristic function to assign\nimportance to features. However, one possible downside is that the contribution\nof non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important\ninformation, because of the relationship between formal explanations (XPs) and\nadversarial examples (AExs). Accordingly, this paper leverages Shapley value\nand Banzhaf index to devise two novel feature importance scores. We take into\naccount non-WAXp sets when computing feature contribution, and the novel scores\nquantify how effective each feature is at excluding AExs. Furthermore, the\npaper identifies properties and studies the computational complexity of the\nproposed scores.", "AI": {"tldr": "Novel feature importance scores using Shapley value and Banzhaf index that incorporate non-WAXp sets to quantify feature effectiveness at excluding adversarial examples.", "motivation": "Current feature attribution methods based on WAXp neglect the contribution of non-WAXp sets, which can provide important information about the relationship between formal explanations and adversarial examples.", "method": "Leverage Shapley value and Banzhaf index to devise two novel feature importance scores that account for non-WAXp sets when computing feature contributions.", "result": "The proposed scores effectively quantify how each feature contributes to excluding adversarial examples, with identified properties and computational complexity analysis.", "conclusion": "The novel feature attribution approach provides more comprehensive feature importance assessment by incorporating both WAXp and non-WAXp sets, offering better insights into model behavior and adversarial example exclusion."}}
{"id": "2508.11854", "pdf": "https://arxiv.org/pdf/2508.11854", "abs": "https://arxiv.org/abs/2508.11854", "authors": ["Matthew Hull", "Haoyang Yang", "Pratham Mehta", "Mansi Phute", "Aeree Cho", "Haorang Wang", "Matthew Lau", "Wenke Lee", "Wilian Lunardi", "Martin Andreoni", "Polo Chau"], "title": "ComplicitSplat: Downstream Models are Vulnerable to Blackbox Attacks by 3D Gaussian Splat Camouflages", "categories": ["cs.CV", "cs.LG"], "comment": "7 pages, 6 figures", "summary": "As 3D Gaussian Splatting (3DGS) gains rapid adoption in safety-critical tasks\nfor efficient novel-view synthesis from static images, how might an adversary\ntamper images to cause harm? We introduce ComplicitSplat, the first attack that\nexploits standard 3DGS shading methods to create viewpoint-specific camouflage\n- colors and textures that change with viewing angle - to embed adversarial\ncontent in scene objects that are visible only from specific viewpoints and\nwithout requiring access to model architecture or weights. Our extensive\nexperiments show that ComplicitSplat generalizes to successfully attack a\nvariety of popular detector - both single-stage, multi-stage, and\ntransformer-based models on both real-world capture of physical objects and\nsynthetic scenes. To our knowledge, this is the first black-box attack on\ndownstream object detectors using 3DGS, exposing a novel safety risk for\napplications like autonomous navigation and other mission-critical robotic\nsystems.", "AI": {"tldr": "ComplicitSplat is the first black-box attack that exploits 3D Gaussian Splatting shading methods to create viewpoint-specific adversarial camouflage, making malicious content visible only from certain angles without needing model access.", "motivation": "As 3DGS becomes widely used in safety-critical applications like autonomous navigation, there's a need to understand how adversaries could tamper with images to cause harm through novel attack vectors.", "method": "The attack exploits standard 3DGS shading methods to create viewpoint-specific camouflage - colors and textures that change with viewing angle to embed adversarial content visible only from specific viewpoints, operating in a black-box manner without requiring model architecture or weights.", "result": "Extensive experiments show ComplicitSplat successfully attacks various popular detectors including single-stage, multi-stage, and transformer-based models on both real-world physical object captures and synthetic scenes.", "conclusion": "This exposes a novel safety risk for mission-critical applications, demonstrating the first black-box attack on downstream object detectors using 3DGS, highlighting vulnerabilities in safety-critical robotic systems."}}
{"id": "2508.11829", "pdf": "https://arxiv.org/pdf/2508.11829", "abs": "https://arxiv.org/abs/2508.11829", "authors": ["Leigh Levinson", "Christopher J. Agostino"], "title": "Every 28 Days the AI Dreams of Soft Skin and Burning Stars: Scaffolding AI Agents with Hormones and Emotions", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": "9 pages, 1 figure, submitted to NeurIPS Creative AI track", "summary": "Despite significant advances, AI systems struggle with the frame problem:\ndetermining what information is contextually relevant from an exponentially\nlarge possibility space. We hypothesize that biological rhythms, particularly\nhormonal cycles, serve as natural relevance filters that could address this\nfundamental challenge. We develop a framework that embeds simulated menstrual\nand circadian cycles into Large Language Models through system prompts\ngenerated from periodic functions modeling key hormones including estrogen,\ntestosterone, and cortisol. Across multiple state-of-the-art models, linguistic\nanalysis reveals emotional and stylistic variations that track biological\nphases; sadness peaks during menstruation while happiness dominates ovulation\nand circadian patterns show morning optimism transitioning to nocturnal\nintrospection. Benchmarking on SQuAD, MMLU, Hellaswag, and AI2-ARC demonstrates\nsubtle but consistent performance variations aligning with biological\nexpectations, including optimal function in moderate rather than extreme\nhormonal ranges. This methodology provides a novel approach to contextual AI\nwhile revealing how societal biases regarding gender and biology are embedded\nwithin language models.", "AI": {"tldr": "AI systems embed simulated biological rhythms (menstrual/circadian cycles) to address the frame problem, showing performance variations and emotional patterns that track hormonal phases.", "motivation": "Address the fundamental frame problem in AI systems by leveraging biological rhythms as natural relevance filters to determine contextual information from large possibility spaces.", "method": "Develop a framework embedding simulated menstrual and circadian cycles into Large Language Models through system prompts generated from periodic functions modeling key hormones (estrogen, testosterone, cortisol).", "result": "Linguistic analysis reveals emotional/stylistic variations tracking biological phases; benchmark testing shows subtle but consistent performance variations aligning with biological expectations, with optimal function in moderate hormonal ranges.", "conclusion": "The methodology provides a novel approach to contextual AI while revealing how societal biases regarding gender and biology are embedded within language models."}}
{"id": "2508.11732", "pdf": "https://arxiv.org/pdf/2508.11732", "abs": "https://arxiv.org/abs/2508.11732", "authors": ["Xiangxiang Cui", "Min Zhao", "Dongmei Zhi", "Shile Qi", "Vince D Calhoun", "Jing Sui"], "title": "BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Existing deep learning models for functional MRI-based classification have\nlimitations in network architecture determination (relying on experience) and\nfeature space fusion (mostly simple concatenation, lacking mutual learning).\nInspired by the human brain's mechanism of updating neural connections through\nlearning and decision-making, we proposed a novel BRain-Inspired feature Fusion\n(BRIEF) framework, which is able to optimize network architecture automatically\nby incorporating an improved neural network connection search (NCS) strategy\nand a Transformer-based multi-feature fusion module. Specifically, we first\nextracted 4 types of fMRI temporal representations, i.e., time series (TCs),\nstatic/dynamic functional connection (FNC/dFNC), and multi-scale dispersion\nentropy (MsDE), to construct four encoders. Within each encoder, we employed a\nmodified Q-learning to dynamically optimize the NCS to extract high-level\nfeature vectors, where the NCS is formulated as a Markov Decision Process.\nThen, all feature vectors were fused via a Transformer, leveraging both\nstable/time-varying connections and multi-scale dependencies across different\nbrain regions to achieve the final classification. Additionally, an attention\nmodule was embedded to improve interpretability. The classification performance\nof our proposed BRIEF was compared with 21 state-of-the-art models by\ndiscriminating two mental disorders from healthy controls: schizophrenia (SZ,\nn=1100) and autism spectrum disorder (ASD, n=1550). BRIEF demonstrated\nsignificant improvements of 2.2% to 12.1% compared to 21 algorithms, reaching\nan AUC of 91.5% - 0.6% for SZ and 78.4% - 0.5% for ASD, respectively. This is\nthe first attempt to incorporate a brain-inspired, reinforcement learning\nstrategy to optimize fMRI-based mental disorder classification, showing\nsignificant potential for identifying precise neuroimaging biomarkers.", "AI": {"tldr": "A brain-inspired feature fusion framework (BRIEF) using neural connection search and Transformer fusion for fMRI-based mental disorder classification, achieving 2.2-12.1% improvement over 21 state-of-the-art models.", "motivation": "Existing deep learning models for fMRI classification have limitations in network architecture determination (relying on experience) and feature space fusion (mostly simple concatenation without mutual learning). The authors were inspired by the human brain's mechanism of updating neural connections through learning.", "method": "Proposed BRIEF framework with improved neural network connection search (NCS) strategy and Transformer-based multi-feature fusion. Extracted 4 fMRI temporal representations (TCs, FNC, dFNC, MsDE) to construct encoders. Used modified Q-learning to dynamically optimize NCS as Markov Decision Process. Fused features via Transformer with attention module for interpretability.", "result": "BRIEF demonstrated 2.2% to 12.1% improvements compared to 21 state-of-the-art algorithms, reaching AUC of 91.5% for schizophrenia and 78.4% for autism spectrum disorder classification.", "conclusion": "This is the first attempt to incorporate brain-inspired reinforcement learning strategy for fMRI-based mental disorder classification, showing significant potential for identifying precise neuroimaging biomarkers."}}
{"id": "2508.11975", "pdf": "https://arxiv.org/pdf/2508.11975", "abs": "https://arxiv.org/abs/2508.11975", "authors": ["Gongyao Jiang", "Qiong Luo"], "title": "Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering", "categories": ["cs.AI"], "comment": "Accepted to CIKM 2025", "summary": "Vision Language Models (VLMs) often struggle with chart understanding tasks,\nparticularly in accurate chart description and complex reasoning. Synthetic\ndata generation is a promising solution, while usually facing the challenge of\nnoise labels. To address this challenge, we first introduce a chart synthesis\npipeline that generates aligned chart-question-answer triplets through code\ngeneration and execution, ensuring the reliability of synthetic data without\nhuman intervention. Furthermore, inspired by test-time scaling that increases\ninference budget and thereby improves performance, we design a\ncandidate-conditioned answering process. The VLM first generates multiple\nresponses per query, and then synthesizes the final answer by contextualizing\nthese candidates. Experiments demonstrate significant improvements, with up to\n15.50 points accuracy gain over the initial VLM, in a fully self-improving\nparadigm without either human-labeled data or external models.", "AI": {"tldr": "A self-improving method for Vision Language Models that uses synthetic chart data generation and candidate-conditioned answering to significantly improve chart understanding without human-labeled data.", "motivation": "VLMs struggle with chart understanding tasks due to inaccurate descriptions and complex reasoning, and synthetic data generation often faces noise label challenges.", "method": "Introduces a chart synthesis pipeline generating aligned chart-question-answer triplets via code generation/execution, plus a candidate-conditioned answering process where VLM generates multiple responses per query and synthesizes the final answer.", "result": "Achieves up to 15.50 points accuracy gain over initial VLM in a fully self-improving paradigm without human-labeled data or external models.", "conclusion": "The approach effectively addresses chart understanding challenges through reliable synthetic data generation and improved inference processes, enabling significant performance gains without external supervision."}}
{"id": "2508.11864", "pdf": "https://arxiv.org/pdf/2508.11864", "abs": "https://arxiv.org/abs/2508.11864", "authors": ["Yucheng Tang", "Pawel Rajwa", "Alexander Ng", "Yipei Wang", "Wen Yan", "Natasha Thorley", "Aqua Asif", "Clare Allen", "Louise Dickinson", "Francesco Giganti", "Shonit Punwani", "Daniel C. Alexander", "Veeru Kasivisvanathan", "Yipeng Hu"], "title": "Impact of Clinical Image Quality on Efficient Foundation Model Finetuning", "categories": ["cs.CV"], "comment": null, "summary": "Foundation models in medical imaging have shown promising label efficiency,\nachieving high downstream performance with only a fraction of annotated data.\nHere, we evaluate this in prostate multiparametric MRI using ProFound, a\ndomain-specific vision foundation model pretrained on large-scale prostate MRI\ndatasets. We investigate how variable image quality affects label-efficient\nfinetuning by measuring the generalisability of finetuned models. Experiments\nsystematically vary high-/low-quality image ratios in finetuning and evaluation\nsets. Our findings indicate that image quality distribution and its\nfinetune-and-test mismatch significantly affect model performance. In\nparticular: a) Varying the ratio of high- to low-quality images between\nfinetuning and test sets leads to notable differences in downstream\nperformance; and b) The presence of sufficient high-quality images in the\nfinetuning set is critical for maintaining strong performance, whilst the\nimportance of matched finetuning and testing distribution varies between\ndifferent downstream tasks, such as automated radiology reporting and prostate\ncancer detection.When quality ratios are consistent, finetuning needs far less\nlabeled data than training from scratch, but label efficiency depends on image\nquality distribution. Without enough high-quality finetuning data, pretrained\nmodels may fail to outperform those trained without pretraining. This\nhighlights the importance of assessing and aligning quality distributions\nbetween finetuning and deployment, and the need for quality standards in\nfinetuning data for specific downstream tasks. Using ProFound, we show the\nvalue of quantifying image quality in both finetuning and deployment to fully\nrealise the data and compute efficiency benefits of foundation models.", "AI": {"tldr": "Image quality distribution significantly impacts label-efficient finetuning of medical foundation models, with performance depending on high-quality image ratios and distribution alignment between finetuning and test sets.", "motivation": "To evaluate how variable image quality affects label-efficient finetuning of foundation models in medical imaging, specifically investigating the impact of quality distribution mismatches between finetuning and deployment datasets.", "method": "Systematic experiments varying high-/low-quality image ratios in both finetuning and evaluation sets using ProFound, a domain-specific vision foundation model pretrained on large-scale prostate MRI datasets.", "result": "Image quality distribution and finetune-test mismatch significantly affect performance. Sufficient high-quality finetuning data is critical, and performance varies by downstream task. Consistent quality ratios enable far less labeled data than training from scratch.", "conclusion": "Assessing and aligning quality distributions between finetuning and deployment is crucial. Quality standards in finetuning data are needed to realize the full efficiency benefits of foundation models in medical imaging."}}
{"id": "2508.11831", "pdf": "https://arxiv.org/pdf/2508.11831", "abs": "https://arxiv.org/abs/2508.11831", "authors": ["Julia Sammartino", "Libby Barak", "Jing Peng", "Anna Feldman"], "title": "When Does Language Transfer Help? Sequential Fine-Tuning for Cross-Lingual Euphemism Detection", "categories": ["cs.CL", "cs.AI"], "comment": "RANLP 2025", "summary": "Euphemisms are culturally variable and often ambiguous, posing challenges for\nlanguage models, especially in low-resource settings. This paper investigates\nhow cross-lingual transfer via sequential fine-tuning affects euphemism\ndetection across five languages: English, Spanish, Chinese, Turkish, and\nYoruba. We compare sequential fine-tuning with monolingual and simultaneous\nfine-tuning using XLM-R and mBERT, analyzing how performance is shaped by\nlanguage pairings, typological features, and pretraining coverage. Results show\nthat sequential fine-tuning with a high-resource L1 improves L2 performance,\nespecially for low-resource languages like Yoruba and Turkish. XLM-R achieves\nlarger gains but is more sensitive to pretraining gaps and catastrophic\nforgetting, while mBERT yields more stable, though lower, results. These\nfindings highlight sequential fine-tuning as a simple yet effective strategy\nfor improving euphemism detection in multilingual models, particularly when\nlow-resource languages are involved.", "AI": {"tldr": "Cross-lingual sequential fine-tuning improves euphemism detection, especially for low-resource languages like Yoruba and Turkish, with XLM-R showing larger gains but more sensitivity to pretraining gaps compared to mBERT.", "motivation": "Euphemisms are culturally variable and ambiguous, posing challenges for language models, particularly in low-resource settings where data is scarce.", "method": "Investigates cross-lingual transfer via sequential fine-tuning for euphemism detection across five languages (English, Spanish, Chinese, Turkish, Yoruba), comparing sequential fine-tuning with monolingual and simultaneous fine-tuning using XLM-R and mBERT models.", "result": "Sequential fine-tuning with a high-resource L1 improves L2 performance, especially for low-resource languages. XLM-R achieves larger gains but is more sensitive to pretraining gaps and catastrophic forgetting, while mBERT yields more stable though lower results.", "conclusion": "Sequential fine-tuning is a simple yet effective strategy for improving euphemism detection in multilingual models, particularly beneficial for low-resource languages."}}
{"id": "2508.11739", "pdf": "https://arxiv.org/pdf/2508.11739", "abs": "https://arxiv.org/abs/2508.11739", "authors": ["Luc Houriez", "Sebastian Pilarski", "Behzad Vahedi", "Ali Ahmadalipour", "Teo Honda Scully", "Nicholas Aflitto", "David Andre", "Caroline Jaffe", "Martha Wedner", "Rich Mazzola", "Josh Jeffery", "Ben Messinger", "Sage McGinley-Smith", "Sarah Russell"], "title": "Scalable Geospatial Data Generation Using AlphaEarth Foundations Model", "categories": ["cs.LG", "cs.CV", "I.4.6; I.5.5"], "comment": "15 pages, 10 figures, 5 tables", "summary": "High-quality labeled geospatial datasets are essential for extracting\ninsights and understanding our planet. Unfortunately, these datasets often do\nnot span the entire globe and are limited to certain geographic regions where\ndata was collected. Google DeepMind's recently released AlphaEarth Foundations\n(AEF) provides an information-dense global geospatial representation designed\nto serve as a useful input across a wide gamut of tasks. In this article we\npropose and evaluate a methodology which leverages AEF to extend geospatial\nlabeled datasets beyond their initial geographic regions. We show that even\nbasic models like random forests or logistic regression can be used to\naccomplish this task. We investigate a case study of extending LANDFIRE's\nExisting Vegetation Type (EVT) dataset beyond the USA into Canada at two levels\nof granularity: EvtPhys (13 classes) and EvtGp (80 classes). Qualitatively, for\nEvtPhys, model predictions align with ground truth. Trained models achieve 81%\nand 73% classification accuracy on EvtPhys validation sets in the USA and\nCanada, despite discussed limitations.", "AI": {"tldr": "Using Google DeepMind's AlphaEarth Foundations to extend geospatial labeled datasets beyond their original regions with basic models like random forests, achieving 81% and 73% accuracy on vegetation classification.", "motivation": "High-quality labeled geospatial datasets are often limited to specific geographic regions where data was collected, creating gaps in global coverage.", "method": "Leveraging AlphaEarth Foundations (AEF) as input representation and using basic models (random forests, logistic regression) to extend geospatial datasets beyond initial regions.", "result": "Achieved 81% classification accuracy on USA validation set and 73% on Canada validation set for EvtPhys vegetation type classification, with qualitative alignment to ground truth.", "conclusion": "Even basic models can effectively extend geospatial datasets using AEF representations, demonstrating practical applicability for global geospatial analysis despite limitations."}}
{"id": "2508.11987", "pdf": "https://arxiv.org/pdf/2508.11987", "abs": "https://arxiv.org/abs/2508.11987", "authors": ["Zhiyuan Zeng", "Jiashuo Liu", "Siyuan Chen", "Tianci He", "Yali Liao", "Jinpeng Wang", "Zaiyuan Wang", "Yang Yang", "Lingyue Yin", "Mingren Yin", "Zhenwei Zhu", "Tianle Cai", "Zehui Chen", "Jiecao Chen", "Yantao Du", "Xiang Gao", "Jiacheng Guo", "Liang Hu", "Jianpeng Jiao", "Xiangsheng Li", "Jingkai Liu", "Shuang Ni", "Zhoufutu Wen", "Ge Zhang", "Kaiyuan Zhang", "Xin Zhou", "Jose Blanchet", "Xipeng Qiu", "Mengdi Wang", "Wenhao Huang"], "title": "FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction", "categories": ["cs.AI", "cs.LG"], "comment": "Technical report, 51 pages", "summary": "Future prediction is a complex task for LLM agents, requiring a high level of\nanalytical thinking, information gathering, contextual understanding, and\ndecision-making under uncertainty. Agents must not only gather and interpret\nvast amounts of dynamic information but also integrate diverse data sources,\nweigh uncertainties, and adapt predictions based on emerging trends, just as\nhuman experts do in fields like politics, economics, and finance. Despite its\nimportance, no large-scale benchmark exists for evaluating agents on future\nprediction, largely due to challenges in handling real-time updates and\nretrieving timely, accurate answers. To address this, we introduce\n$\\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically\ndesigned for LLM agents performing future prediction tasks. FutureX is the\nlargest and most diverse live benchmark for future prediction, supporting\nreal-time daily updates and eliminating data contamination through an automated\npipeline for question gathering and answer collection. We evaluate 25 LLM/agent\nmodels, including those with reasoning, search capabilities, and integration of\nexternal tools such as the open-source Deep Research Agent and closed-source\nDeep Research models. This comprehensive evaluation assesses agents' adaptive\nreasoning and performance in dynamic environments. Additionally, we provide\nin-depth analyses of agents' failure modes and performance pitfalls in\nfuture-oriented tasks, including the vulnerability to fake web pages and the\ntemporal validity. Our goal is to establish a dynamic, contamination-free\nevaluation standard that drives the development of LLM agents capable of\nperforming at the level of professional human analysts in complex reasoning and\npredictive thinking.", "AI": {"tldr": "FutureX is a dynamic live benchmark for evaluating LLM agents on future prediction tasks, featuring real-time updates and contamination-free evaluation of 25 models.", "motivation": "No large-scale benchmark exists for evaluating LLM agents on future prediction due to challenges with real-time updates and accurate answer retrieval.", "method": "Created FutureX benchmark with automated pipeline for question gathering and answer collection, evaluating 25 LLM/agent models including reasoning/search capabilities and external tool integration.", "result": "Comprehensive evaluation assessed agents' adaptive reasoning in dynamic environments, identified failure modes including vulnerability to fake web pages and temporal validity issues.", "conclusion": "FutureX establishes a dynamic, contamination-free evaluation standard to drive development of LLM agents capable of professional-level predictive thinking."}}
{"id": "2508.11870", "pdf": "https://arxiv.org/pdf/2508.11870", "abs": "https://arxiv.org/abs/2508.11870", "authors": ["Ying Huang", "Yuanbin Man", "Wenqi Jia", "Zhengzhong Tu", "Junzhou Huang", "Miao Yin"], "title": "AdaRing: Towards Ultra-Light Vision-Language Adaptation via Cross-Layer Tensor Ring Decomposition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Adapter-based fine-tuning has gained remarkable attention in adapting large\npre-trained vision language models (VLMs) for a wide range of downstream tasks\nefficiently. In this paradigm, only the inserted adapters are fine-tuned,\nwithout the need for training the original VLM backbone. Existing works scale\nadapters by integrating them into every layer of VLMs to increase the capacity\nof adapters. However, these methods face two primary limitations: 1) limited\ncompression rate due to ignoring cross-layer redundancy, and 2) limited\nrepresentational capacity across homogeneous adapters. In this paper, we\npropose a novel vision-language fine-tuning framework based on cross-layer\ntensor ring decomposition (TRD) with the integration and collaboration of\ndiverse adapters, called AdaRing, achieving ultra-light parameter-efficient\nadaptation of VLMs on various tasks. To remove the high redundancy that exists\namong adapters across layers, we exploit the tensor-level low-rankness to\nformulate adapters as layer-shared tensor cores and layer-specific slices.\nMoreover, guided by generalization-aware fine-tuning, diverse rank-driven\nadapters cooperate to handle tasks that require different representations. Our\nexperiments show that the proposed AdaRing achieves the state-of-the-art\nperformance while reducing average training parameters by 90%.", "AI": {"tldr": "AdaRing proposes a cross-layer tensor ring decomposition framework for vision-language model fine-tuning that reduces parameter redundancy and improves adapter diversity, achieving SOTA performance with 90% fewer parameters.", "motivation": "Existing adapter-based fine-tuning methods suffer from limited compression rates due to cross-layer redundancy and limited representational capacity across homogeneous adapters.", "method": "Uses tensor ring decomposition to formulate adapters as layer-shared tensor cores and layer-specific slices, with diverse rank-driven adapters guided by generalization-aware fine-tuning.", "result": "Achieves state-of-the-art performance while reducing average training parameters by 90% across various tasks.", "conclusion": "The proposed AdaRing framework effectively addresses redundancy issues in adapter-based fine-tuning and enables ultra-light parameter-efficient adaptation of vision-language models."}}
{"id": "2508.11857", "pdf": "https://arxiv.org/pdf/2508.11857", "abs": "https://arxiv.org/abs/2508.11857", "authors": ["Andrei-Valentin T\u0103nase", "Elena Pelican"], "title": "SupraTok: Cross-Boundary Tokenization for Enhanced Language Model Performance", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Tokenization remains a fundamental yet underexplored bottleneck in natural\nlanguage processing, with strategies largely static despite remarkable progress\nin model architectures. We present SupraTok, a novel tokenization architecture\nthat reimagines subword segmentation through three innovations: cross-boundary\npattern learning that discovers multi-word semantic units, entropy-driven data\ncuration that optimizes training corpus quality, and multi-phase curriculum\nlearning for stable convergence. Our approach extends Byte-Pair Encoding by\nlearning \"superword\" tokens, coherent multi-word expressions that preserve\nsemantic unity while maximizing compression efficiency. SupraTok achieves 31%\nimprovement in English tokenization efficiency (5.91 versus 4.51 characters per\ntoken) compared to OpenAI's o200k tokenizer and 30% improvement over Google's\nGemma 3 tokenizer (256k vocabulary), while maintaining competitive performance\nacross 38 languages. When integrated with a GPT-2 scale model (124M parameters)\ntrained on 10 billion tokens from the FineWeb-Edu dataset, SupraTok yields 8.4%\nimprovement on HellaSWAG and 9.5% on MMLU benchmarks without architectural\nmodifications. While these results are promising at this scale, further\nvalidation at larger model scales is needed. These findings suggest that\nefficient tokenization can complement architectural innovations as a path to\nimproved language model performance.", "AI": {"tldr": "SupraTok is a novel tokenization architecture that improves tokenization efficiency by 31% over leading tokenizers while maintaining competitive performance across 38 languages, and yields 8.4-9.5% improvements on benchmarks when integrated with GPT-2 scale models.", "motivation": "Tokenization remains a fundamental yet underexplored bottleneck in NLP, with strategies largely static despite remarkable progress in model architectures.", "method": "SupraTok extends Byte-Pair Encoding with three innovations: cross-boundary pattern learning for multi-word semantic units, entropy-driven data curation for optimal training corpus quality, and multi-phase curriculum learning for stable convergence. It learns \"superword\" tokens that preserve semantic unity while maximizing compression efficiency.", "result": "Achieves 31% improvement in English tokenization efficiency (5.91 vs 4.51 characters per token) compared to OpenAI's o200k and 30% over Google's Gemma 3 tokenizer. When integrated with GPT-2 scale model (124M parameters), yields 8.4% improvement on HellaSWAG and 9.5% on MMLU benchmarks without architectural modifications.", "conclusion": "Efficient tokenization can complement architectural innovations as a path to improved language model performance, though further validation at larger model scales is needed."}}
{"id": "2508.11794", "pdf": "https://arxiv.org/pdf/2508.11794", "abs": "https://arxiv.org/abs/2508.11794", "authors": ["Hemanth Macharla", "Mayukha Pal"], "title": "Fed-Meta-Align: A Similarity-Aware Aggregation and Personalization Pipeline for Federated TinyML on Heterogeneous Data", "categories": ["cs.LG"], "comment": null, "summary": "Real-time fault classification in resource-constrained Internet of Things\n(IoT) devices is critical for industrial safety, yet training robust models in\nsuch heterogeneous environments remains a significant challenge. Standard\nFederated Learning (FL) often fails in the presence of non-IID data, leading to\nmodel divergence. This paper introduces Fed-Meta-Align, a novel four-phase\nframework designed to overcome these limitations through a sophisticated\ninitialization and training pipeline. Our process begins by training a\nfoundational model on a general public dataset to establish a competent\nstarting point. This model then undergoes a serial meta-initialization phase,\nwhere it sequentially trains on a subset of IOT Device data to learn a\nheterogeneity-aware initialization that is already situated in a favorable\nregion of the loss landscape. This informed model is subsequently refined in a\nparallel FL phase, which utilizes a dual-criterion aggregation mechanism that\nweights for IOT devices updates based on both local performance and cosine\nsimilarity alignment. Finally, an on-device personalization phase adapts the\nconverged global model into a specialized expert for each IOT Device.\nComprehensive experiments demonstrate that Fed-Meta-Align achieves an average\ntest accuracy of 91.27% across heterogeneous IOT devices, outperforming\npersonalized FedAvg and FedProx by up to 3.87% and 3.37% on electrical and\nmechanical fault datasets, respectively. This multi-stage approach of sequenced\ninitialization and adaptive aggregation provides a robust pathway for deploying\nhigh-performance intelligence on diverse TinyML networks.", "AI": {"tldr": "Fed-Meta-Align is a novel four-phase federated learning framework that addresses non-IID data challenges in IoT fault classification through meta-initialization and dual-criterion aggregation, achieving 91.27% average accuracy.", "motivation": "Real-time fault classification in resource-constrained IoT devices is critical for industrial safety, but standard Federated Learning fails with non-IID data, leading to model divergence.", "method": "Four-phase framework: 1) foundational model training on public dataset, 2) serial meta-initialization on IoT subset for heterogeneity-aware initialization, 3) parallel FL with dual-criterion aggregation (local performance + cosine similarity), 4) on-device personalization for specialized experts.", "result": "Achieves 91.27% average test accuracy across heterogeneous IoT devices, outperforming personalized FedAvg by 3.87% and FedProx by 3.37% on electrical and mechanical fault datasets.", "conclusion": "The multi-stage approach of sequenced initialization and adaptive aggregation provides a robust pathway for deploying high-performance intelligence on diverse TinyML networks."}}
{"id": "2508.11991", "pdf": "https://arxiv.org/pdf/2508.11991", "abs": "https://arxiv.org/abs/2508.11991", "authors": ["Weihao Sun"], "title": "Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network", "categories": ["cs.AI"], "comment": null, "summary": "The automation of logic circuit design enhances chip performance, energy\nefficiency, and reliability, and is widely applied in the field of Electronic\nDesign Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,\noptimize, and verify the functional characteristics of digital circuits,\nenhancing the efficiency of EDA development.Due to the complex structure and\nlarge scale of nodes in real-world AIGs, accurate modeling is challenging,\nleading to existing work lacking the ability to jointly model functional and\nstructural characteristics, as well as insufficient dynamic information\npropagation capability.To address the aforementioned challenges, we propose\nAIGer.Specifically, AIGer consists of two components: 1) Node logic feature\ninitialization embedding component and 2) AIGs feature learning network\ncomponent.The node logic feature initialization embedding component projects\nlogic nodes, such as AND and NOT, into independent semantic spaces, to enable\neffective node embedding for subsequent processing.Building upon this, the AIGs\nfeature learning network component employs a heterogeneous graph convolutional\nnetwork, designing dynamic relationship weight matrices and differentiated\ninformation aggregation approaches to better represent the original structure\nand information of AIGs.The combination of these two components enhances\nAIGer's ability to jointly model functional and structural characteristics and\nimproves its message passing capability. Experimental results indicate that\nAIGer outperforms the current best models in the Signal Probability Prediction\n(SSP) task, improving MAE and MSE by 18.95\\% and 44.44\\%, respectively. In the\nTruth Table Distance Prediction (TTDP) task, AIGer achieves improvements of\n33.57\\% and 14.79\\% in MAE and MSE, respectively, compared to the\nbest-performing models.", "AI": {"tldr": "AIGer is a novel framework that combines node logic feature initialization and heterogeneous graph convolutional networks to jointly model functional and structural characteristics of And-Inverter Graphs, achieving significant performance improvements in circuit analysis tasks.", "motivation": "Existing methods struggle with accurate modeling of real-world AIGs due to their complex structure and large scale, lacking joint modeling of functional/structural characteristics and dynamic information propagation capabilities.", "method": "Two-component approach: 1) Node logic feature initialization embedding that projects logic nodes into semantic spaces, and 2) AIGs feature learning network using heterogeneous graph convolutional networks with dynamic relationship weight matrices and differentiated information aggregation.", "result": "Outperforms current best models: 18.95% MAE and 44.44% MSE improvement in Signal Probability Prediction; 33.57% MAE and 14.79% MSE improvement in Truth Table Distance Prediction.", "conclusion": "AIGer effectively addresses the challenges of joint functional-structural modeling and dynamic information propagation in AIG analysis, demonstrating superior performance in key EDA tasks."}}
{"id": "2508.11886", "pdf": "https://arxiv.org/pdf/2508.11886", "abs": "https://arxiv.org/abs/2508.11886", "authors": ["Wenhui Zhu", "Xiwen Chen", "Zhipeng Wang", "Shao Tang", "Sayan Ghosh", "Xuanzhao Dong", "Rajat Koner", "Yalin Wang"], "title": "EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "eess.IV"], "comment": null, "summary": "Instructed Visual Segmentation (IVS) tasks require segmenting objects in\nimages or videos based on natural language instructions. While recent\nmultimodal large language models (MLLMs) have achieved strong performance on\nIVS, their inference cost remains a major bottleneck, particularly in video. We\nempirically analyze visual token sampling in MLLMs and observe a strong\ncorrelation between subset token coverage and segmentation performance. This\nmotivates our design of a simple and effective token pruning method that\nselects a compact yet spatially representative subset of tokens to accelerate\ninference. In this paper, we introduce a novel visual token pruning method for\nIVS, called EVTP-IV, which builds upon the k-center by integrating spatial\ninformation to ensure better coverage. We further provide an\ninformation-theoretic analysis to support our design. Experiments on standard\nIVS benchmarks show that our method achieves up to 5X speed-up on video tasks\nand 3.5X on image tasks, while maintaining comparable accuracy using only 20%\nof the tokens. Our method also consistently outperforms state-of-the-art\npruning baselines under varying pruning ratios.", "AI": {"tldr": "EVTP-IV is a visual token pruning method that achieves 3.5-5X speedup in Instructed Visual Segmentation tasks while maintaining comparable accuracy using only 20% of tokens.", "motivation": "Multimodal large language models (MLLMs) have strong performance on Instructed Visual Segmentation but suffer from high inference costs, especially in video processing. The authors observed a correlation between token coverage and segmentation performance.", "method": "A novel visual token pruning method called EVTP-IV that builds upon k-center algorithm by integrating spatial information to ensure better coverage of representative tokens. Includes information-theoretic analysis to support the design.", "result": "Achieves up to 5X speed-up on video tasks and 3.5X on image tasks while maintaining comparable accuracy using only 20% of tokens. Consistently outperforms state-of-the-art pruning baselines across varying pruning ratios.", "conclusion": "The proposed EVTP-IV method effectively reduces computational costs for MLLMs in visual segmentation tasks while preserving performance through intelligent token selection based on spatial coverage principles."}}
{"id": "2508.11889", "pdf": "https://arxiv.org/pdf/2508.11889", "abs": "https://arxiv.org/abs/2508.11889", "authors": ["Hui Ma", "Bo Zhang", "Jinpeng Hu", "Zenglin Shi"], "title": "In-Context Examples Matter: Improving Emotion Recognition in Conversation with Instruction Tuning", "categories": ["cs.CL"], "comment": null, "summary": "Emotion recognition in conversation (ERC) aims to identify the emotion of\neach utterance in a conversation, playing a vital role in empathetic artificial\nintelligence. With the growing of large language models (LLMs), instruction\ntuning has emerged as a critical paradigm for ERC. Existing studies mainly\nfocus on multi-stage instruction tuning, which first endows LLMs with speaker\ncharacteristics, and then conducts context-aware instruction tuning to\ncomprehend emotional states. However, these methods inherently constrains the\ncapacity to jointly capture the dynamic interaction between speaker\ncharacteristics and conversational context, resulting in weak alignment among\nspeaker identity, contextual cues, and emotion states within a unified\nframework. In this paper, we propose InitERC, a simple yet effective one-stage\nin-context instruction tuning framework for ERC. InitERC adapts LLMs to learn\nspeaker-context-emotion alignment from context examples via in-context\ninstruction tuning. Specifically, InitERC comprises four components, i.e.,\ndemonstration pool construction, in-context example selection, prompt template\ndesign, and in-context instruction tuning. To explore the impact of in-context\nexamples, we conduct a comprehensive study on three key factors: retrieval\nstrategy, example ordering, and the number of examples. Extensive experiments\non three widely used datasets demonstrate that our proposed InitERC achieves\nsubstantial improvements over the state-of-the-art baselines.", "AI": {"tldr": "InitERC is a one-stage in-context instruction tuning framework for emotion recognition in conversation that jointly captures speaker characteristics and contextual cues through unified learning.", "motivation": "Existing multi-stage instruction tuning methods for emotion recognition in conversation fail to jointly capture dynamic interactions between speaker characteristics and conversational context, leading to weak alignment among speaker identity, contextual cues, and emotion states.", "method": "InitERC uses a one-stage in-context instruction tuning framework with four components: demonstration pool construction, in-context example selection, prompt template design, and in-context instruction tuning. It explores retrieval strategies, example ordering, and number of examples.", "result": "Extensive experiments on three widely used datasets show that InitERC achieves substantial improvements over state-of-the-art baselines.", "conclusion": "The proposed one-stage in-context instruction tuning framework effectively learns speaker-context-emotion alignment and outperforms existing multi-stage approaches."}}
{"id": "2508.11800", "pdf": "https://arxiv.org/pdf/2508.11800", "abs": "https://arxiv.org/abs/2508.11800", "authors": ["Michael Bereket", "Jure Leskovec"], "title": "Uncalibrated Reasoning: GRPO Induces Overconfidence for Stochastic Outcomes", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has proven remarkably effective at improving the\naccuracy of language models in verifiable and deterministic domains like\nmathematics. Here, we examine if current RL methods are also effective at\noptimizing language models in verifiable domains with stochastic outcomes, like\nscientific experiments. Through applications to synthetic data and real-world\nbiological experiments, we demonstrate that Group Relative Policy Optimization\n(GRPO) induces overconfident probability predictions for binary stochastic\noutcomes, while Proximal Policy Optimization (PPO) and REINFORCE Leave-One-Out\n(RLOO) yield well-calibrated models. We show that removing group standard\nnormalization in GRPO fixes its miscalibration and provide a theoretical\nexplanation for why normalization causes overconfidence. Our results provide\nnew evidence against the use of standard normalization in GRPO and help pave\nthe way for applications of RL for reasoning language models beyond\ndeterministic domains.", "AI": {"tldr": "RL methods for language models in stochastic domains: GRPO causes overconfidence in probability predictions, while PPO and RLOO yield well-calibrated models. Removing group normalization in GRPO fixes the issue.", "motivation": "To examine if current RL methods are effective at optimizing language models in verifiable domains with stochastic outcomes like scientific experiments, beyond deterministic domains like mathematics.", "method": "Applied Group Relative Policy Optimization (GRPO), Proximal Policy Optimization (PPO), and REINFORCE Leave-One-Out (RLOO) to synthetic data and real-world biological experiments to evaluate their performance in stochastic domains.", "result": "GRPO induced overconfident probability predictions for binary stochastic outcomes, while PPO and RLOO yielded well-calibrated models. Removing group standard normalization in GRPO fixed its miscalibration.", "conclusion": "Provides evidence against using standard normalization in GRPO and helps enable RL applications for reasoning language models beyond deterministic domains into stochastic environments like scientific experiments."}}
{"id": "2508.11995", "pdf": "https://arxiv.org/pdf/2508.11995", "abs": "https://arxiv.org/abs/2508.11995", "authors": ["Xuyang Zhao", "Shiwan Zhao", "Hualong Yu", "Liting Zhang", "Qicheng Li"], "title": "AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Multi-agent systems (MAS) powered by large language models (LLMs) hold\nsignificant promise for solving complex decision-making tasks. However, the\ncore process of collaborative decision-making (CDM) within these systems\nremains underexplored. Existing approaches often rely on either ``dictatorial\"\nstrategies that are vulnerable to the cognitive biases of a single agent, or\n``voting-based\" methods that fail to fully harness collective intelligence. To\naddress these limitations, we propose \\textbf{AgentCDM}, a structured framework\nfor enhancing collaborative decision-making in LLM-based multi-agent systems.\nDrawing inspiration from the Analysis of Competing Hypotheses (ACH) in\ncognitive science, AgentCDM introduces a structured reasoning paradigm that\nsystematically mitigates cognitive biases and shifts decision-making from\npassive answer selection to active hypothesis evaluation and construction. To\ninternalize this reasoning process, we develop a two-stage training paradigm:\nthe first stage uses explicit ACH-inspired scaffolding to guide the model\nthrough structured reasoning, while the second stage progressively removes this\nscaffolding to encourage autonomous generalization. Experiments on multiple\nbenchmark datasets demonstrate that AgentCDM achieves state-of-the-art\nperformance and exhibits strong generalization, validating its effectiveness in\nimproving the quality and robustness of collaborative decisions in MAS.", "AI": {"tldr": "AgentCDM is a structured framework for enhancing collaborative decision-making in LLM-based multi-agent systems by mitigating cognitive biases through ACH-inspired reasoning and two-stage training.", "motivation": "Existing multi-agent systems use either dictatorial strategies vulnerable to single agent biases or voting-based methods that fail to leverage collective intelligence effectively, leaving collaborative decision-making underexplored.", "method": "Proposes AgentCDM framework inspired by Analysis of Competing Hypotheses (ACH) with structured reasoning paradigm and two-stage training: first stage uses explicit ACH scaffolding, second stage removes scaffolding for autonomous generalization.", "result": "Achieves state-of-the-art performance on multiple benchmark datasets and exhibits strong generalization capabilities.", "conclusion": "AgentCDM effectively improves the quality and robustness of collaborative decisions in multi-agent systems by shifting from passive answer selection to active hypothesis evaluation and construction."}}
{"id": "2508.11893", "pdf": "https://arxiv.org/pdf/2508.11893", "abs": "https://arxiv.org/abs/2508.11893", "authors": ["Quanwei Hu", "Yinggan Tang", "Xuguang Zhang"], "title": "Large Kernel Modulation Network for Efficient Image Super-Resolution", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Image super-resolution (SR) in resource-constrained scenarios demands\nlightweight models balancing performance and latency. Convolutional neural\nnetworks (CNNs) offer low latency but lack non-local feature capture, while\nTransformers excel at non-local modeling yet suffer slow inference. To address\nthis trade-off, we propose the Large Kernel Modulation Network (LKMN), a pure\nCNN-based model. LKMN has two core components: Enhanced Partial Large Kernel\nBlock (EPLKB) and Cross-Gate Feed-Forward Network (CGFN). The EPLKB utilizes\nchannel shuffle to boost inter-channel interaction, incorporates channel\nattention to focus on key information, and applies large kernel strip\nconvolutions on partial channels for non-local feature extraction with reduced\ncomplexity. The CGFN dynamically adjusts discrepancies between input, local,\nand non-local features via a learnable scaling factor, then employs a\ncross-gate strategy to modulate and fuse these features, enhancing their\ncomplementarity. Extensive experiments demonstrate that our method outperforms\nexisting state-of-the-art (SOTA) lightweight SR models while balancing quality\nand efficiency. Specifically, LKMN-L achieves 0.23 dB PSNR improvement over\nDAT-light on the Manga109 dataset at $\\times$4 upscale, with nearly $\\times$4.8\ntimes faster. Codes are in the supplementary materials. The code is available\nat https://github.com/Supereeeee/LKMN.", "AI": {"tldr": "LKMN is a pure CNN-based image super-resolution model that uses large kernel modulation to achieve better performance than Transformers while maintaining fast inference speed, outperforming SOTA lightweight models with 0.23dB PSNR improvement and 4.8x faster speed.", "motivation": "Address the trade-off between CNNs (low latency but poor non-local feature capture) and Transformers (excellent non-local modeling but slow inference) in resource-constrained image super-resolution scenarios.", "method": "Proposes Large Kernel Modulation Network (LKMN) with two core components: Enhanced Partial Large Kernel Block (EPLKB) using channel shuffle, channel attention, and large kernel strip convolutions for non-local feature extraction; and Cross-Gate Feed-Forward Network (CGFN) that dynamically adjusts feature discrepancies and employs cross-gate strategy for feature fusion.", "result": "Outperforms existing SOTA lightweight SR models, achieving 0.23 dB PSNR improvement over DAT-light on Manga109 dataset at 4x upscale with nearly 4.8 times faster inference speed.", "conclusion": "LKMN successfully balances quality and efficiency in image super-resolution, demonstrating that pure CNN architectures can achieve superior non-local feature modeling while maintaining fast inference speeds compared to Transformer-based approaches."}}
{"id": "2508.11915", "pdf": "https://arxiv.org/pdf/2508.11915", "abs": "https://arxiv.org/abs/2508.11915", "authors": ["Punya Syon Pandey", "Yongjin Yang", "Jiarui Liu", "Zhijing Jin"], "title": "CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Game-theoretic interactions between agents with Large Language Models (LLMs)\nhave revealed many emergent capabilities, yet the linguistic diversity of these\ninteractions has not been sufficiently quantified. In this paper, we present\nthe Conversational Robustness Evaluation Score: CORE, a metric to quantify the\neffectiveness of language use within multi-agent systems across different\ngame-theoretic interactions. CORE integrates measures of cluster entropy,\nlexical repetition, and semantic similarity, providing a direct lens of dialog\nquality. We apply CORE to pairwise LLM dialogs across competitive, cooperative,\nand neutral settings, further grounding our analysis in Zipf's and Heaps' Laws\nto characterize word frequency distributions and vocabulary growth. Our\nfindings show that cooperative settings exhibit both steeper Zipf distributions\nand higher Heap exponents, indicating more repetition alongside greater\nvocabulary expansion. In contrast, competitive interactions display lower Zipf\nand Heaps exponents, reflecting less repetition and more constrained\nvocabularies. These results provide new insights into how social incentives\ninfluence language adaptation, and highlight CORE as a robust diagnostic for\nmeasuring linguistic robustness in multi-agent LLM systems. Our code is\navailable at https://github.com/psyonp/core.", "AI": {"tldr": "CORE metric evaluates linguistic robustness in LLM multi-agent systems across game-theoretic settings, revealing cooperative interactions show more repetition with vocabulary expansion while competitive ones have constrained vocabularies.", "motivation": "Linguistic diversity in LLM game-theoretic interactions hasn't been sufficiently quantified, requiring a metric to measure language effectiveness across different multi-agent scenarios.", "method": "Developed CORE metric integrating cluster entropy, lexical repetition, and semantic similarity. Applied to pairwise LLM dialogs in competitive, cooperative, and neutral settings, analyzed through Zipf's and Heaps' Laws.", "result": "Cooperative settings show steeper Zipf distributions and higher Heap exponents (more repetition with vocabulary expansion). Competitive interactions display lower exponents (less repetition, constrained vocabularies).", "conclusion": "Social incentives significantly influence language adaptation, and CORE serves as a robust diagnostic tool for measuring linguistic robustness in multi-agent LLM systems."}}
{"id": "2508.11810", "pdf": "https://arxiv.org/pdf/2508.11810", "abs": "https://arxiv.org/abs/2508.11810", "authors": ["Nitish Nagesh", "Salar Shakibhamedan", "Mahdi Bagheri", "Ziyu Wang", "Nima TaheriNejad", "Axel Jantsch", "Amir M. Rahmani"], "title": "FairTabGen: Unifying Counterfactual and Causal Fairness in Synthetic Tabular Data Generation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generating synthetic data is crucial in privacy-sensitive, data-scarce\nsettings, especially for tabular datasets widely used in real-world\napplications. A key challenge is improving counterfactual and causal fairness,\nwhile preserving high utility. We present FairTabGen, a fairness-aware large\nlanguage model-based framework for tabular synthetic data generation. We\nintegrate multiple fairness definitions including counterfactual and causal\nfairness into both its generation and evaluation pipelines. We use in-context\nlearning, prompt refinement, and fairness-aware data curation to balance\nfairness and utility. Across diverse datasets, our method outperforms\nstate-of-the-art GAN-based and LLM-based methods, achieving up to 10%\nimprovements on fairness metrics such as demographic parity and path-specific\ncausal effects while retaining statistical utility. Remarkably, it achieves\nthese gains using less than 20% of the original data, highlighting its\nefficiency in low-data regimes. These results demonstrate a principled and\npractical approach for generating fair and useful synthetic tabular data.", "AI": {"tldr": "FairTabGen is an LLM-based framework that generates fair synthetic tabular data with improved counterfactual and causal fairness while maintaining utility, outperforming existing methods using only 20% of original data.", "motivation": "Addressing the challenge of improving counterfactual and causal fairness in synthetic tabular data generation while preserving utility, especially in privacy-sensitive and data-scarce settings.", "method": "Uses in-context learning, prompt refinement, and fairness-aware data curation to integrate multiple fairness definitions into both generation and evaluation pipelines.", "result": "Outperforms state-of-the-art GAN-based and LLM-based methods with up to 10% improvements on fairness metrics (demographic parity, path-specific causal effects) while retaining statistical utility, using less than 20% of original data.", "conclusion": "Demonstrates a principled and practical approach for generating fair and useful synthetic tabular data that works efficiently in low-data regimes."}}
{"id": "2508.12022", "pdf": "https://arxiv.org/pdf/2508.12022", "abs": "https://arxiv.org/abs/2508.12022", "authors": ["Dorsa Macky Aleagha", "Payam Zohari", "Mostafa Haghir Chehreghani"], "title": "AI Models for Depressive Disorder Detection and Diagnosis: A Review", "categories": ["cs.AI"], "comment": null, "summary": "Major Depressive Disorder is one of the leading causes of disability\nworldwide, yet its diagnosis still depends largely on subjective clinical\nassessments. Integrating Artificial Intelligence (AI) holds promise for\ndeveloping objective, scalable, and timely diagnostic tools. In this paper, we\npresent a comprehensive survey of state-of-the-art AI methods for depression\ndetection and diagnosis, based on a systematic review of 55 key studies. We\nintroduce a novel hierarchical taxonomy that structures the field by primary\nclinical task (diagnosis vs. prediction), data modality (text, speech,\nneuroimaging, multimodal), and computational model class (e.g., graph neural\nnetworks, large language models, hybrid approaches). Our in-depth analysis\nreveals three major trends: the predominance of graph neural networks for\nmodeling brain connectivity, the rise of large language models for linguistic\nand conversational data, and an emerging focus on multimodal fusion,\nexplainability, and algorithmic fairness. Alongside methodological insights, we\nprovide an overview of prominent public datasets and standard evaluation\nmetrics as a practical guide for researchers. By synthesizing current advances\nand highlighting open challenges, this survey offers a comprehensive roadmap\nfor future innovation in computational psychiatry.", "AI": {"tldr": "Survey of AI methods for depression diagnosis, categorizing 55 studies by clinical task, data modality, and model type, highlighting trends in graph neural networks, large language models, and multimodal approaches.", "motivation": "Depression diagnosis relies heavily on subjective clinical assessments, creating need for objective, scalable AI tools to improve diagnostic accuracy and accessibility.", "method": "Systematic review of 55 key studies with novel hierarchical taxonomy organizing research by clinical task (diagnosis/prediction), data modality (text/speech/neuroimaging/multimodal), and computational model class.", "result": "Identified three major trends: graph neural networks dominate brain connectivity modeling, large language models excel with linguistic data, and emerging focus on multimodal fusion, explainability, and algorithmic fairness.", "conclusion": "Provides comprehensive roadmap for future computational psychiatry innovation, synthesizing current advances and highlighting open challenges in AI-based depression diagnosis."}}
{"id": "2508.11902", "pdf": "https://arxiv.org/pdf/2508.11902", "abs": "https://arxiv.org/abs/2508.11902", "authors": ["Azam Nouri"], "title": "A Sobel-Gradient MLP Baseline for Handwritten Character Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "This paper is under consideration at Pattern Recognition Letters", "summary": "We revisit the classical Sobel operator to ask a simple question: Are\nfirst-order edge maps sufficient to drive an all-dense multilayer perceptron\n(MLP) for handwritten character recognition (HCR), as an alternative to\nconvolutional neural networks (CNNs)? Using only horizontal and vertical Sobel\nderivatives as input, we train an MLP on MNIST and EMNIST Letters. Despite its\nextreme simplicity, the resulting network reaches 98% accuracy on MNIST digits\nand 92% on EMNIST letters -- approaching CNNs while offering a smaller memory\nfootprint and transparent features. Our findings highlight that much of the\nclass-discriminative information in handwritten character images is already\ncaptured by first-order gradients, making edge-aware MLPs a compelling option\nfor HCR.", "AI": {"tldr": "Using only horizontal and vertical Sobel derivatives as input, an MLP achieves near-CNN performance on handwritten character recognition with smaller memory footprint and transparent features.", "motivation": "To investigate whether first-order edge maps (Sobel derivatives) are sufficient for handwritten character recognition as an alternative to convolutional neural networks, exploring simpler and more transparent architectures.", "method": "Train a multilayer perceptron (MLP) using only horizontal and vertical Sobel derivatives as input features on MNIST and EMNIST Letters datasets.", "result": "The MLP achieved 98% accuracy on MNIST digits and 92% on EMNIST letters, approaching CNN performance while offering smaller memory footprint and more transparent features.", "conclusion": "First-order gradients capture most class-discriminative information in handwritten characters, making edge-aware MLPs a compelling alternative to CNNs for HCR tasks."}}
{"id": "2508.11927", "pdf": "https://arxiv.org/pdf/2508.11927", "abs": "https://arxiv.org/abs/2508.11927", "authors": ["Jie Lu", "Du Jin", "Hitomi Yanaka"], "title": "LLMs Struggle with NLI for Perfect Aspect: A Cross-Linguistic Study in Chinese and Japanese", "categories": ["cs.CL"], "comment": "9 pages, 3 figures", "summary": "Unlike English, which uses distinct forms (e.g., had, has, will have) to mark\nthe perfect aspect across tenses, Chinese and Japanese lack separate\ngrammatical forms for tense within the perfect aspect, which complicates\nNatural Language Inference (NLI). Focusing on the perfect aspect in these\nlanguages, we construct a linguistically motivated, template-based NLI dataset\n(1,350 pairs per language). Experiments reveal that even advanced LLMs struggle\nwith temporal inference, particularly in detecting subtle tense and\nreference-time shifts. These findings highlight model limitations and\nunderscore the need for cross-linguistic evaluation in temporal semantics. Our\ndataset is available at https://github.com/Lujie2001/CrossNLI.", "AI": {"tldr": "Chinese and Japanese lack distinct grammatical forms for tense within perfect aspect, causing challenges for Natural Language Inference. A template-based dataset was created, revealing LLMs struggle with temporal inference and subtle tense shifts.", "motivation": "Unlike English which has clear tense markers for perfect aspect (had, has, will have), Chinese and Japanese lack separate grammatical forms for tense within perfect aspect, complicating Natural Language Inference tasks.", "method": "Constructed a linguistically motivated, template-based NLI dataset with 1,350 pairs per language (Chinese and Japanese) focusing on perfect aspect.", "result": "Experiments show even advanced LLMs struggle with temporal inference, particularly in detecting subtle tense and reference-time shifts.", "conclusion": "Findings highlight model limitations and underscore the need for cross-linguistic evaluation in temporal semantics. Dataset is publicly available."}}
{"id": "2508.11876", "pdf": "https://arxiv.org/pdf/2508.11876", "abs": "https://arxiv.org/abs/2508.11876", "authors": ["Hoang-Thang Ta", "Duy-Quy Thai", "Phuong-Linh Tran-Thi"], "title": "Combinations of Fast Activation and Trigonometric Functions in Kolmogorov-Arnold Networks", "categories": ["cs.LG"], "comment": "6pages", "summary": "For years, many neural networks have been developed based on the\nKolmogorov-Arnold Representation Theorem (KART), which was created to address\nHilbert's 13th problem. Recently, relying on KART, Kolmogorov-Arnold Networks\n(KANs) have attracted attention from the research community, stimulating the\nuse of polynomial functions such as B-splines and RBFs. However, these\nfunctions are not fully supported by GPU devices and are still considered less\npopular. In this paper, we propose the use of fast computational functions,\nsuch as ReLU and trigonometric functions (e.g., ReLU, sin, cos, arctan), as\nbasis components in Kolmogorov-Arnold Networks (KANs). By integrating these\nfunction combinations into the network structure, we aim to enhance\ncomputational efficiency. Experimental results show that these combinations\nmaintain competitive performance while offering potential improvements in\ntraining time and generalization.", "AI": {"tldr": "Proposes using GPU-friendly functions (ReLU, trigonometric) instead of polynomial functions in Kolmogorov-Arnold Networks to improve computational efficiency while maintaining performance.", "motivation": "Existing KANs use polynomial functions like B-splines and RBFs that are not well-supported by GPUs and are less popular, limiting computational efficiency.", "method": "Replace polynomial basis functions with fast computational functions (ReLU, sin, cos, arctan) in Kolmogorov-Arnold Network structure to enhance GPU compatibility and efficiency.", "result": "Experimental results show the proposed function combinations maintain competitive performance while offering potential improvements in training time and generalization.", "conclusion": "GPU-friendly function combinations (ReLU and trigonometric functions) can effectively replace polynomial functions in KANs, providing computational efficiency benefits without sacrificing performance."}}
{"id": "2508.12026", "pdf": "https://arxiv.org/pdf/2508.12026", "abs": "https://arxiv.org/abs/2508.12026", "authors": ["Szymon Pawlonka", "Miko\u0142aj Ma\u0142ki\u0144ski", "Jacek Ma\u0144dziuk"], "title": "Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Bongard Problems (BPs) provide a challenging testbed for abstract visual\nreasoning (AVR), requiring models to identify visual concepts fromjust a few\nexamples and describe them in natural language. Early BP benchmarks featured\nsynthetic black-and-white drawings, which might not fully capture the\ncomplexity of real-world scenes. Subsequent BP datasets employed real-world\nimages, albeit the represented concepts are identifiable from high-level image\nfeatures, reducing the task complexity. Differently, the recently released\nBongard-RWR dataset aimed at representing abstract concepts formulated in the\noriginal BPs using fine-grained real-world images. Its manual construction,\nhowever, limited the dataset size to just $60$ instances, constraining\nevaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset\ncomposed of $5\\,400$ instances that represent original BP abstract concepts\nusing real-world-like images generated via a vision language model (VLM)\npipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually\ncurated images and generate new descriptions aligned with the underlying\nconcepts, use Flux.1-dev to synthesize images from these descriptions, and\nmanually verify that the generated images faithfully reflect the intended\nconcepts. We evaluate state-of-the-art VLMs across diverse BP formulations,\nincluding binary and multiclass classification, as well as textual answer\ngeneration. Our findings reveal that while VLMs can recognize coarse-grained\nvisual concepts, they consistently struggle with discerning fine-grained\nconcepts, highlighting limitations in their reasoning capabilities.", "AI": {"tldr": "Bongard-RWR+ is a new 5,400-instance dataset using VLM-generated real-world images to test abstract visual reasoning, showing VLMs struggle with fine-grained concepts despite handling coarse ones.", "motivation": "Existing Bongard Problem datasets have limitations - synthetic images lack real-world complexity, while real-world image datasets are either too small (Bongard-RWR with 60 instances) or use high-level features that reduce task complexity.", "method": "Used Pixtral-12B to describe manually curated images and generate new concept-aligned descriptions, then employed Flux.1-dev to synthesize images from these descriptions, with manual verification to ensure concept fidelity.", "result": "State-of-the-art VLMs performed well on coarse-grained visual concepts but consistently struggled with discerning fine-grained concepts across various BP formulations (binary/multiclass classification and textual answer generation).", "conclusion": "Current VLMs have significant limitations in fine-grained abstract reasoning capabilities, highlighting the need for improved reasoning abilities despite their competence with coarse-grained visual concepts."}}
{"id": "2508.11903", "pdf": "https://arxiv.org/pdf/2508.11903", "abs": "https://arxiv.org/abs/2508.11903", "authors": ["Runhao Zeng", "Jiaqi Mao", "Minghao Lai", "Minh Hieu Phan", "Yanjie Dong", "Wei Wang", "Qi Chen", "Xiping Hu"], "title": "OVG-HQ: Online Video Grounding with Hybrid-modal Queries", "categories": ["cs.CV"], "comment": "Accepted to ICCV 2025", "summary": "Video grounding (VG) task focuses on locating specific moments in a video\nbased on a query, usually in text form. However, traditional VG struggles with\nsome scenarios like streaming video or queries using visual cues. To fill this\ngap, we present a new task named Online Video Grounding with Hybrid-modal\nQueries (OVG-HQ), which enables online segment localization using text, images,\nvideo segments, and their combinations. This task poses two new challenges:\nlimited context in online settings and modality imbalance during training,\nwhere dominant modalities overshadow weaker ones. To address these, we propose\nOVG-HQ-Unify, a unified framework featuring a Parametric Memory Block (PMB)\nthat retain previously learned knowledge to enhance current decision and a\ncross-modal distillation strategy that guides the learning of non-dominant\nmodalities. This design enables a single model to effectively handle\nhybrid-modal queries. Due to the lack of suitable datasets, we construct\nQVHighlights-Unify, an expanded dataset with multi-modal queries. Besides,\nsince offline metrics overlook prediction timeliness, we adapt them to the\nonline setting, introducing oR@n, IoU=m, and online mean Average Precision\n(omAP) to evaluate both accuracy and efficiency. Experiments show that our\nOVG-HQ-Unify outperforms existing models, offering a robust solution for\nonline, hybrid-modal video grounding. Source code and datasets are available at\nhttps://github.com/maojiaqi2324/OVG-HQ.", "AI": {"tldr": "Proposes OVG-HQ, a new online video grounding task with hybrid-modal queries (text, images, video segments), and introduces OVG-HQ-Unify framework with Parametric Memory Block and cross-modal distillation to handle modality imbalance and limited context.", "motivation": "Traditional video grounding struggles with streaming video scenarios and visual-based queries, creating a need for online processing and support for multiple query modalities beyond just text.", "method": "Developed OVG-HQ-Unify framework with Parametric Memory Block (PMB) to retain past knowledge for current decisions, and cross-modal distillation to balance modality learning. Created QVHighlights-Unify dataset with multi-modal queries and adapted online evaluation metrics.", "result": "OVG-HQ-Unify outperforms existing models, providing robust performance for online hybrid-modal video grounding with both accuracy and efficiency improvements.", "conclusion": "The proposed framework successfully addresses challenges of online video grounding with hybrid queries, offering a unified solution that handles multiple modalities effectively while maintaining real-time processing capabilities."}}
{"id": "2508.11933", "pdf": "https://arxiv.org/pdf/2508.11933", "abs": "https://arxiv.org/abs/2508.11933", "authors": ["Yue Wang", "Liesheng Wei", "Yuxiang Wang"], "title": "CAMF: Collaborative Adversarial Multi-agent Framework for Machine Generated Text Detection", "categories": ["cs.CL"], "comment": null, "summary": "Detecting machine-generated text (MGT) from contemporary Large Language\nModels (LLMs) is increasingly crucial amid risks like disinformation and\nthreats to academic integrity. Existing zero-shot detection paradigms, despite\ntheir practicality, often exhibit significant deficiencies. Key challenges\ninclude: (1) superficial analyses focused on limited textual attributes, and\n(2) a lack of investigation into consistency across linguistic dimensions such\nas style, semantics, and logic. To address these challenges, we introduce the\n\\textbf{C}ollaborative \\textbf{A}dversarial \\textbf{M}ulti-agent\n\\textbf{F}ramework (\\textbf{CAMF}), a novel architecture using multiple\nLLM-based agents. CAMF employs specialized agents in a synergistic three-phase\nprocess: \\emph{Multi-dimensional Linguistic Feature Extraction},\n\\emph{Adversarial Consistency Probing}, and \\emph{Synthesized Judgment\nAggregation}. This structured collaborative-adversarial process enables a deep\nanalysis of subtle, cross-dimensional textual incongruities indicative of\nnon-human origin. Empirical evaluations demonstrate CAMF's significant\nsuperiority over state-of-the-art zero-shot MGT detection techniques.", "AI": {"tldr": "CAMF is a novel multi-agent framework that detects machine-generated text by analyzing cross-dimensional linguistic inconsistencies through collaborative adversarial agents, outperforming existing zero-shot detection methods.", "motivation": "Existing zero-shot machine-generated text detection methods have significant deficiencies, including superficial analyses focused on limited textual attributes and lack of investigation into consistency across linguistic dimensions like style, semantics, and logic.", "method": "CAMF uses multiple LLM-based agents in a three-phase process: Multi-dimensional Linguistic Feature Extraction, Adversarial Consistency Probing, and Synthesized Judgment Aggregation to analyze subtle cross-dimensional textual incongruities.", "result": "Empirical evaluations demonstrate CAMF's significant superiority over state-of-the-art zero-shot MGT detection techniques.", "conclusion": "The collaborative adversarial multi-agent framework provides a more effective approach for detecting machine-generated text by deeply analyzing linguistic inconsistencies across multiple dimensions."}}
{"id": "2508.11880", "pdf": "https://arxiv.org/pdf/2508.11880", "abs": "https://arxiv.org/abs/2508.11880", "authors": ["Yuto Omae"], "title": "PCA- and SVM-Grad-CAM for Convolutional Neural Networks: Closed-form Jacobian Expression", "categories": ["cs.LG", "I.2.0; I.5.0"], "comment": "15 pages", "summary": "Convolutional Neural Networks (CNNs) are an effective approach for\nclassification tasks, particularly when the training dataset is large. Although\nCNNs have long been considered a black-box classification method, they can be\nused as a white-box method through visualization techniques such as Grad-CAM.\nWhen training samples are limited, incorporating a Principal Component Analysis\n(PCA) layer and/or a Support Vector Machine (SVM) classifier into a CNN can\neffectively improve classification performance. However, traditional Grad-CAM\ncannot be directly applied to PCA and/or SVM layers. It is important to\ngenerate attention regions for PCA and/or SVM layers in CNNs to facilitate the\ndevelopment of white-box methods. Therefore, we propose ``PCA-Grad-CAM'', a\nmethod for visualizing attention regions in PCA feature vectors, and\n``SVM-Grad-CAM'', a method for visualizing attention regions in an SVM\nclassifier layer. To complete our methods analytically, it is necessary to\nsolve the closed-form Jacobian consisting of partial derivatives from the last\nconvolutional layer to the PCA and/or SVM layers. In this paper, we present the\nexact closed-form Jacobian and the visualization results of our methods applied\nto several major datasets.", "AI": {"tldr": "Proposes PCA-Grad-CAM and SVM-Grad-CAM methods to visualize attention regions in PCA and SVM layers within CNNs, enabling white-box interpretation for models with limited training data.", "motivation": "Traditional Grad-CAM cannot visualize attention regions in PCA and SVM layers integrated into CNNs for improved performance with limited training samples, creating a need for specialized visualization methods.", "method": "Develops closed-form Jacobian solutions for partial derivatives from the last convolutional layer to PCA and SVM layers, enabling exact computation of attention maps for PCA feature vectors and SVM classifier layers.", "result": "Successfully derived exact closed-form Jacobian formulations and demonstrated visualization results on several major datasets, showing effective attention region generation for PCA and SVM layers.", "conclusion": "The proposed PCA-Grad-CAM and SVM-Grad-CAM methods enable effective visualization of attention regions in PCA and SVM layers within CNNs, facilitating white-box interpretation for models using these components with limited training data."}}
{"id": "2508.12027", "pdf": "https://arxiv.org/pdf/2508.12027", "abs": "https://arxiv.org/abs/2508.12027", "authors": ["Filippo Torresan", "Keisuke Suzuki", "Ryota Kanai", "Manuel Baltieri"], "title": "Active inference for action-unaware agents", "categories": ["cs.AI", "cs.LG", "q-bio.NC"], "comment": "59 pages, 47 figures", "summary": "Active inference is a formal approach to study cognition based on the notion\nthat adaptive agents can be seen as engaging in a process of approximate\nBayesian inference, via the minimisation of variational and expected free\nenergies. Minimising the former provides an account of perceptual processes and\nlearning as evidence accumulation, while minimising the latter describes how\nagents select their actions over time. In this way, adaptive agents are able to\nmaximise the likelihood of preferred observations or states, given a generative\nmodel of the environment. In the literature, however, different strategies have\nbeen proposed to describe how agents can plan their future actions. While they\nall share the notion that some kind of expected free energy offers an\nappropriate way to score policies, sequences of actions, in terms of their\ndesirability, there are different ways to consider the contribution of past\nmotor experience to the agent's future behaviour. In some approaches, agents\nare assumed to know their own actions, and use such knowledge to better plan\nfor the future. In other approaches, agents are unaware of their actions, and\nmust infer their motor behaviour from recent observations in order to plan for\nthe future. This difference reflects a standard point of departure in two\nleading frameworks in motor control based on the presence, or not, of an\nefference copy signal representing knowledge about an agent's own actions. In\nthis work we compare the performances of action-aware and action-unaware agents\nin two navigations tasks, showing how action-unaware agents can achieve\nperformances comparable to action-aware ones while at a severe disadvantage.", "AI": {"tldr": "Comparison of action-aware vs action-unaware agents in active inference frameworks, showing action-unaware agents can achieve comparable performance despite severe disadvantages in navigation tasks.", "motivation": "To address the different strategies in active inference literature regarding how agents plan future actions - specifically whether agents know their own actions (action-aware) or must infer them from observations (action-unaware), and to compare their performance.", "method": "The study compares action-aware and action-unaware agents in two navigation tasks within the active inference framework, where action-aware agents have knowledge of their own actions while action-unaware agents must infer motor behavior from recent observations.", "result": "Action-unaware agents achieved performances comparable to action-aware agents despite being at a severe disadvantage, demonstrating their capability to effectively plan future actions through inference rather than direct knowledge.", "conclusion": "Action-unaware approaches in active inference can be effective alternatives to action-aware methods, showing that agents can successfully plan future actions by inferring motor behavior from observations rather than requiring direct knowledge of their own actions."}}
{"id": "2508.11904", "pdf": "https://arxiv.org/pdf/2508.11904", "abs": "https://arxiv.org/abs/2508.11904", "authors": ["Lingyun Zhang", "Yu Xie", "Yanwei Fu", "Ping Chen"], "title": "SafeCtrl: Region-Based Safety Control for Text-to-Image Diffusion via Detect-Then-Suppress", "categories": ["cs.CV"], "comment": null, "summary": "The widespread deployment of text-to-image models is challenged by their\npotential to generate harmful content. While existing safety methods, such as\nprompt rewriting or model fine-tuning, provide valuable interventions, they\noften introduce a trade-off between safety and fidelity. Recent\nlocalization-based approaches have shown promise, yet their reliance on\nexplicit ``concept replacement\" can sometimes lead to semantic incongruity. To\naddress these limitations, we explore a more flexible detect-then-suppress\nparadigm. We introduce SafeCtrl, a lightweight, non-intrusive plugin that first\nprecisely localizes unsafe content. Instead of performing a hard A-to-B\nsubstitution, SafeCtrl then suppresses the harmful semantics, allowing the\ngenerative process to naturally and coherently resolve into a safe,\ncontext-aware alternative. A key aspect of our work is a novel training\nstrategy using Direct Preference Optimization (DPO). We leverage readily\navailable, image-level preference data to train our module, enabling it to\nlearn nuanced suppression behaviors and perform region-guided interventions at\ninference without requiring costly, pixel-level annotations. Extensive\nexperiments show that SafeCtrl significantly outperforms state-of-the-art\nmethods in both safety efficacy and fidelity preservation. Our findings suggest\nthat decoupled, suppression-based control is a highly effective and scalable\ndirection for building more responsible generative models.", "AI": {"tldr": "SafeCtrl is a lightweight plugin that localizes unsafe content in text-to-image generation and suppresses harmful semantics using DPO training, achieving better safety and fidelity than existing methods.", "motivation": "Existing safety methods for text-to-image models create trade-offs between safety and fidelity, and localization-based approaches can cause semantic incongruity through hard concept replacement.", "method": "SafeCtrl uses a detect-then-suppress paradigm with precise localization of unsafe content and semantic suppression rather than hard substitution. It employs Direct Preference Optimization (DPO) training using image-level preference data without needing pixel-level annotations.", "result": "Extensive experiments show SafeCtrl significantly outperforms state-of-the-art methods in both safety efficacy and fidelity preservation.", "conclusion": "Decoupled, suppression-based control is an effective and scalable approach for building more responsible generative models."}}
{"id": "2508.12031", "pdf": "https://arxiv.org/pdf/2508.12031", "abs": "https://arxiv.org/abs/2508.12031", "authors": ["Shaozhe Yin", "Jinyu Guo", "Kai Shuang", "Xia Liu", "Ruize Ou"], "title": "Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases", "categories": ["cs.CL"], "comment": null, "summary": "Continual Relation Extraction (CRE) aims to continually learn new emerging\nrelations while avoiding catastrophic forgetting. Existing CRE methods mainly\nuse memory replay and contrastive learning to mitigate catastrophic forgetting.\nHowever, these methods do not attach importance to the error cases that can\nreveal the model's cognitive biases more effectively. To address this issue, we\npropose an instruction-based continual contrastive tuning approach for Large\nLanguage Models (LLMs) in CRE. Different from existing CRE methods that\ntypically handle the training and memory data in a unified manner, this\napproach splits the training and memory data of each task into two parts\nrespectively based on the correctness of the initial responses and treats them\ndifferently through dual-task fine-tuning. In addition, leveraging the\nadvantages of LLM's instruction-following ability, we propose a novel\ninstruction-based contrastive tuning strategy for LLM to continuously correct\ncurrent cognitive biases with the guidance of previous data in an\ninstruction-tuning manner, which mitigates the gap between old and new\nrelations in a more suitable way for LLMs. We experimentally evaluate our model\non TACRED and FewRel, and the results show that our model achieves new\nstate-of-the-art CRE performance with significant improvements, demonstrating\nthe importance of specializing in exploiting error cases.", "AI": {"tldr": "Instruction-based continual contrastive tuning approach for LLMs in continual relation extraction that specializes in exploiting error cases to correct cognitive biases and achieve state-of-the-art performance.", "motivation": "Existing CRE methods using memory replay and contrastive learning don't effectively address error cases that reveal model's cognitive biases, limiting their ability to mitigate catastrophic forgetting.", "method": "Splits training and memory data based on correctness of initial responses, uses dual-task fine-tuning, and employs instruction-based contrastive tuning strategy to continuously correct cognitive biases with previous data guidance.", "result": "Achieves new state-of-the-art performance on TACRED and FewRel datasets with significant improvements, demonstrating effectiveness of specializing in error case exploitation.", "conclusion": "Focusing on error cases through instruction-based continual contrastive tuning effectively mitigates catastrophic forgetting and improves CRE performance for LLMs, showing the importance of addressing cognitive biases."}}
{"id": "2508.11921", "pdf": "https://arxiv.org/pdf/2508.11921", "abs": "https://arxiv.org/abs/2508.11921", "authors": ["Yibo Zhong"], "title": "ENA: Efficient N-dimensional Attention", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "WIP", "summary": "Efficient modeling of long sequences of high-order data requires a more\nefficient architecture than Transformer. In this paper, we investigate two key\naspects of extending linear recurrent models, especially those originally\ndesigned for language modeling, to high-order data (1D to ND): scanning\nstrategies and attention-hybrid architectures. Empirical results suggest that\nscanning provides limited benefits, while attention-hybrid models yield\npromising results. Focusing on the latter, we further evaluate types of\nattention and find that tiled high-order sliding window attention (SWA) is\nefficient in both theory and practice. We term the resulting hybrid\narchitecture of linear recurrence and high-order SWA as Efficient N-dimensional\nAttention (ENA). We then conduct several experiments to demonstrate its\neffectiveness. The intuition behind ENA is that linear recurrence compresses\nglobal information into a state, while SWA complements it by enforcing strict\nlocal modeling. Together, they form a simple framework that offers a promising\nand practical solution for ultra-long high-order data modeling.", "AI": {"tldr": "ENA combines linear recurrence with tiled high-order sliding window attention to efficiently model ultra-long high-dimensional data, outperforming Transformers.", "motivation": "Transformer architectures are inefficient for modeling long sequences of high-order data, requiring more efficient alternatives that can handle 1D to ND data effectively.", "method": "Investigates scanning strategies and attention-hybrid architectures, focusing on combining linear recurrence (for global compression) with tiled high-order sliding window attention (for local modeling).", "result": "Scanning provides limited benefits, while attention-hybrid models show promise. Tiled high-order sliding window attention proves efficient both theoretically and practically.", "conclusion": "ENA offers a simple yet effective framework for ultra-long high-order data modeling by combining global information compression through linear recurrence with strict local modeling via sliding window attention."}}
{"id": "2508.12087", "pdf": "https://arxiv.org/pdf/2508.12087", "abs": "https://arxiv.org/abs/2508.12087", "authors": ["Zhanjiang Yang", "Meng Li", "Yang Shen", "Yueming Li", "Lijun Sun"], "title": "MAPF-World: Action World Model for Multi-Agent Path Finding", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Multi-agent path finding (MAPF) is the problem of planning conflict-free\npaths from the designated start locations to goal positions for multiple\nagents. It underlies a variety of real-world tasks, including multi-robot\ncoordination, robot-assisted logistics, and social navigation. Recent\ndecentralized learnable solvers have shown great promise for large-scale MAPF,\nespecially when leveraging foundation models and large datasets. However, these\nagents are reactive policy models and exhibit limited modeling of environmental\ntemporal dynamics and inter-agent dependencies, resulting in performance\ndegradation in complex, long-term planning scenarios. To address these\nlimitations, we propose MAPF-World, an autoregressive action world model for\nMAPF that unifies situation understanding and action generation, guiding\ndecisions beyond immediate local observations. It improves situational\nawareness by explicitly modeling environmental dynamics, including spatial\nfeatures and temporal dependencies, through future state and actions\nprediction. By incorporating these predicted futures, MAPF-World enables more\ninformed, coordinated, and far-sighted decision-making, especially in complex\nmulti-agent settings. Furthermore, we augment MAPF benchmarks by introducing an\nautomatic map generator grounded in real-world scenarios, capturing practical\nmap layouts for training and evaluating MAPF solvers. Extensive experiments\ndemonstrate that MAPF-World outperforms state-of-the-art learnable solvers,\nshowcasing superior zero-shot generalization to out-of-distribution cases.\nNotably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced\ndata.", "AI": {"tldr": "MAPF-World is an autoregressive action world model that improves multi-agent path finding by modeling environmental dynamics and future predictions, achieving superior performance with smaller model size and less data.", "motivation": "Existing decentralized learnable solvers for MAPF have limited modeling of environmental temporal dynamics and inter-agent dependencies, leading to performance degradation in complex, long-term planning scenarios.", "method": "Proposes MAPF-World, an autoregressive action world model that unifies situation understanding and action generation. It explicitly models environmental dynamics including spatial features and temporal dependencies through future state and actions prediction. Also introduces an automatic map generator grounded in real-world scenarios for better training and evaluation.", "result": "Extensive experiments show MAPF-World outperforms state-of-the-art learnable solvers with superior zero-shot generalization to out-of-distribution cases. Achieves this with 96.5% smaller model size and 92% reduced data requirements.", "conclusion": "MAPF-World enables more informed, coordinated, and far-sighted decision-making in complex multi-agent settings by incorporating predicted futures, demonstrating significant improvements over existing approaches with much more efficient resource utilization."}}
{"id": "2508.11919", "pdf": "https://arxiv.org/pdf/2508.11919", "abs": "https://arxiv.org/abs/2508.11919", "authors": ["Pallavi Jain", "Diego Marcos", "Dino Ienco", "Roberto Interdonato", "Tristan Berchoux"], "title": "TimeSenCLIP: A Vision-Language Model for Remote Sensing Using Single-Pixel Time Series", "categories": ["cs.CV"], "comment": "Paper under review", "summary": "Vision-language models have shown significant promise in remote sensing\napplications, particularly for land-use and land-cover (LULC) via zero-shot\nclassification and retrieval. However, current approaches face two key\nchallenges: reliance on large spatial tiles that increase computational cost,\nand dependence on text-based supervision, which is often not readily available.\nIn this work, we present TimeSenCLIP, a lightweight framework that reevaluate\nthe role of spatial context by evaluating the effectiveness of a single pixel\nby leveraging its temporal and spectral dimensions, for classifying LULC and\necosystem types. By leveraging spectral and temporal information from\nSentinel-2 imagery and cross-view learning with geo-tagged ground-level photos,\nwe minimises the need for caption-based training while preserving semantic\nalignment between overhead (satellite) and ground perspectives. Our approach is\ngrounded in the LUCAS and Sen4Map datasets, and evaluated on classification\ntasks including LULC, crop type, and ecosystem type. We demonstrate that single\npixel inputs, when combined with temporal and spectral cues, are sufficient for\nthematic mapping, offering a scalable and efficient alternative for large-scale\nremote sensing applications. Code is available at\nhttps://github.com/pallavijain-pj/TimeSenCLIP", "AI": {"tldr": "TimeSenCLIP is a lightweight vision-language framework that uses single pixel temporal and spectral data from Sentinel-2 imagery for land-use classification, eliminating the need for large spatial tiles and text-based supervision.", "motivation": "Current vision-language models for remote sensing rely on large spatial tiles (computationally expensive) and text-based supervision (often unavailable), creating scalability challenges for large-scale applications.", "method": "Leverages spectral and temporal information from single Sentinel-2 pixels combined with cross-view learning using geo-tagged ground-level photos from LUCAS and Sen4Map datasets, minimizing caption-based training requirements.", "result": "Demonstrates that single pixel inputs with temporal and spectral cues are sufficient for thematic mapping tasks including LULC, crop type, and ecosystem type classification.", "conclusion": "Provides a scalable and efficient alternative to traditional approaches by reducing computational costs while maintaining semantic alignment between satellite and ground perspectives for large-scale remote sensing applications."}}
{"id": "2508.12040", "pdf": "https://arxiv.org/pdf/2508.12040", "abs": "https://arxiv.org/abs/2508.12040", "authors": ["Jinyi Han", "Tingyun Li", "Shisong Chen", "Jie Shi", "Xinyi Wang", "Guanglei Yue", "Jiaqing Liang", "Xin Lin", "Liqian Wen", "Zulong Chen", "Yanghua Xiao"], "title": "Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation", "categories": ["cs.CL", "cs.AI"], "comment": "The initial versin was made in August 2024", "summary": "While large language models (LLMs) have demonstrated remarkable performance\nacross diverse tasks, they fundamentally lack self-awareness and frequently\nexhibit overconfidence, assigning high confidence scores to incorrect\npredictions. Accurate confidence estimation is therefore critical for enhancing\nthe trustworthiness and reliability of LLM-generated outputs. However, existing\napproaches suffer from coarse-grained scoring mechanisms that fail to provide\nfine-grained, continuous confidence estimates throughout the generation\nprocess. To address these limitations, we introduce FineCE, a novel confidence\nestimation method that delivers accurate, fine-grained confidence scores during\ntext generation. Specifically, we first develop a comprehensive pipeline for\nconstructing training data that effectively captures the underlying\nprobabilistic distribution of LLM responses, and then train a model to predict\nconfidence scores for arbitrary text sequences in a supervised manner.\nFurthermore, we propose a Backward Confidence Integration (BCI) strategy that\nleverages information from the subsequent text to enhance confidence estimation\nfor the current sequence during inference. We also introduce three strategies\nfor identifying optimal positions to perform confidence estimation within the\ngeneration process. Extensive experiments on multiple benchmark datasets\ndemonstrate that FineCE consistently outperforms existing classical confidence\nestimation methods. Our code and all baselines used in the paper are available\non GitHub.", "AI": {"tldr": "FineCE is a novel confidence estimation method that provides fine-grained, continuous confidence scores during LLM text generation, outperforming existing methods through supervised training on probabilistic response distributions and backward confidence integration.", "motivation": "LLMs lack self-awareness and exhibit overconfidence, assigning high confidence to incorrect predictions. Existing approaches have coarse-grained scoring mechanisms that fail to provide fine-grained confidence estimates throughout the generation process.", "method": "Developed a pipeline for constructing training data capturing LLM response distributions, trained a supervised model to predict confidence scores, proposed Backward Confidence Integration (BCI) strategy using subsequent text information, and introduced three strategies for optimal confidence estimation positions.", "result": "Extensive experiments on multiple benchmark datasets demonstrate that FineCE consistently outperforms existing classical confidence estimation methods.", "conclusion": "FineCE provides accurate, fine-grained confidence estimation during text generation, enhancing the trustworthiness and reliability of LLM outputs through improved confidence scoring mechanisms."}}
{"id": "2508.11923", "pdf": "https://arxiv.org/pdf/2508.11923", "abs": "https://arxiv.org/abs/2508.11923", "authors": ["Yan Wu", "Lihong Pei", "Yukai Han", "Yang Cao", "Yu Kang", "Yanlong Zhao"], "title": "Scale-Disentangled spatiotemporal Modeling for Long-term Traffic Emission Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Long-term traffic emission forecasting is crucial for the comprehensive\nmanagement of urban air pollution. Traditional forecasting methods typically\nconstruct spatiotemporal graph models by mining spatiotemporal dependencies to\npredict emissions. However, due to the multi-scale entanglement of traffic\nemissions across time and space, these spatiotemporal graph modeling method\ntend to suffer from cascading error amplification during long-term inference.\nTo address this issue, we propose a Scale-Disentangled Spatio-Temporal Modeling\n(SDSTM) framework for long-term traffic emission forecasting. It leverages the\npredictability differences across multiple scales to decompose and fuse\nfeatures at different scales, while constraining them to remain independent yet\ncomplementary. Specifically, the model first introduces a dual-stream feature\ndecomposition strategy based on the Koopman lifting operator. It lifts the\nscale-coupled spatiotemporal dynamical system into an infinite-dimensional\nlinear space via Koopman operator, and delineates the predictability boundary\nusing gated wavelet decomposition. Then a novel fusion mechanism is\nconstructed, incorporating a dual-stream independence constraint based on\ncross-term loss to dynamically refine the dual-stream prediction results,\nsuppress mutual interference, and enhance the accuracy of long-term traffic\nemission prediction. Extensive experiments conducted on a road-level traffic\nemission dataset within Xi'an's Second Ring Road demonstrate that the proposed\nmodel achieves state-of-the-art performance.", "AI": {"tldr": "Proposes SDSTM framework for long-term traffic emission forecasting using scale-disentangled spatio-temporal modeling to address cascading error amplification in traditional methods.", "motivation": "Traditional spatiotemporal graph models suffer from cascading error amplification due to multi-scale entanglement of traffic emissions across time and space during long-term inference.", "method": "Uses dual-stream feature decomposition based on Koopman lifting operator to separate scales, gated wavelet decomposition for predictability boundaries, and cross-term loss for independence constraints to refine predictions and suppress interference.", "result": "Extensive experiments on Xi'an's Second Ring Road traffic emission dataset demonstrate state-of-the-art performance.", "conclusion": "SDSTM framework effectively addresses long-term traffic emission forecasting challenges by disentangling multi-scale spatiotemporal dependencies and maintaining feature independence while enhancing prediction accuracy."}}
{"id": "2508.12100", "pdf": "https://arxiv.org/pdf/2508.12100", "abs": "https://arxiv.org/abs/2508.12100", "authors": ["Daniel Burkhardt", "Xiangwei Cheng"], "title": "Overcoming Knowledge Discrepancies: Structuring Reasoning Threads through Knowledge Balancing in Interactive Scenarios", "categories": ["cs.AI"], "comment": "13 pages, 1 figure, 6 tables", "summary": "Reasoning in interactive problem solving scenarios requires models to\nconstruct reasoning threads that reflect user understanding and align with\nstructured domain knowledge. However, current reasoning models often lack\nexplicit semantic hierarchies, user-domain knowledge alignment, and principled\nmechanisms to prune reasoning threads for effectiveness. These limitations\nresult in lengthy generic output that does not guide users through\ngoal-oriented reasoning steps. To address this, we propose a\nprototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval)\nframework, drawing inspiration from human-like reasoning strategies that\nemphasize structured knowledge reuse. In the first phase, semantically relevant\nknowledge structures are extracted from a sparse domain knowledge graph using a\ngraph neural network and enriched with intrinsic large language model knowledge\nto resolve knowledge discrepancies. In the second phase, these threads are\nevaluated and pruned using a reward-guided strategy aimed at maintaining\nsemantic coherence to generate effective reasoning threads. Experiments and\nexpert evaluations show that ReT-Eval enhances user understanding and\noutperforms state-of-the-art reasoning models.", "AI": {"tldr": "ReT-Eval framework improves interactive problem solving by creating structured reasoning threads that align with domain knowledge and user understanding through knowledge extraction and reward-guided pruning.", "motivation": "Current reasoning models lack explicit semantic hierarchies, user-domain knowledge alignment, and effective pruning mechanisms, resulting in lengthy generic outputs that don't guide users through goal-oriented reasoning steps.", "method": "Two-phase framework: 1) Extract semantically relevant knowledge from sparse domain knowledge graphs using GNNs and enrich with LLM knowledge, 2) Evaluate and prune reasoning threads using reward-guided strategy for semantic coherence.", "result": "Experiments and expert evaluations show ReT-Eval enhances user understanding and outperforms state-of-the-art reasoning models.", "conclusion": "The prototype-inspired ReT-Eval framework successfully addresses limitations of current reasoning models by incorporating structured knowledge reuse and principled pruning mechanisms for more effective interactive problem solving."}}
{"id": "2508.11922", "pdf": "https://arxiv.org/pdf/2508.11922", "abs": "https://arxiv.org/abs/2508.11922", "authors": ["Aditi Jahagirdar", "Sameer Joshi"], "title": "Assessment of Using Synthetic Data in Brain Tumor Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Manual brain tumor segmentation from MRI scans is challenging due to tumor\nheterogeneity, scarcity of annotated data, and class imbalance in medical\nimaging datasets. Synthetic data generated by generative models has the\npotential to mitigate these issues by improving dataset diversity. This study\ninvestigates, as a proof of concept, the impact of incorporating synthetic MRI\ndata, generated using a pre-trained GAN model, into training a U-Net\nsegmentation network. Experiments were conducted using real data from the BraTS\n2020 dataset, synthetic data generated with the medigan library, and hybrid\ndatasets combining real and synthetic samples in varying proportions. While\noverall quantitative performance (Dice coefficient, IoU, precision, recall,\naccuracy) was comparable between real-only and hybrid-trained models,\nqualitative inspection suggested that hybrid datasets, particularly with 40%\nreal and 60% synthetic data, improved whole tumor boundary delineation.\nHowever, region-wise accuracy for the tumor core and the enhancing tumor\nremained lower, indicating a persistent class imbalance. The findings support\nthe feasibility of synthetic data as an augmentation strategy for brain tumor\nsegmentation, while highlighting the need for larger-scale experiments,\nvolumetric data consistency, and mitigating class imbalance in future work.", "AI": {"tldr": "Synthetic MRI data from GANs can improve brain tumor segmentation boundary delineation when combined with 40% real data, but class imbalance issues persist for tumor core regions.", "motivation": "Address challenges in brain tumor segmentation including tumor heterogeneity, scarcity of annotated data, and class imbalance in medical imaging datasets by using synthetic data to improve dataset diversity.", "method": "Used pre-trained GAN model (medigan library) to generate synthetic MRI data, combined with real BraTS 2020 data in varying proportions. Trained U-Net segmentation network on real-only, synthetic-only, and hybrid datasets.", "result": "Quantitative performance (Dice, IoU, precision, recall, accuracy) was comparable between real-only and hybrid models. Qualitative analysis showed hybrid datasets (40% real + 60% synthetic) improved whole tumor boundary delineation, but tumor core and enhancing tumor regions still had lower accuracy due to class imbalance.", "conclusion": "Synthetic data is feasible for brain tumor segmentation augmentation, but future work needs larger-scale experiments, volumetric data consistency, and better class imbalance mitigation strategies."}}
{"id": "2508.12086", "pdf": "https://arxiv.org/pdf/2508.12086", "abs": "https://arxiv.org/abs/2508.12086", "authors": ["Yao Wu"], "title": "J6: Jacobian-Driven Role Attribution for Multi-Objective Prompt Optimization in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50, 90C29, 62F07", "I.2.7; I.2.6; G.1.6"], "comment": "9 pages, 3 tables, 1 algorithm", "summary": "In large language model (LLM) adaptation, balancing multiple optimization\nobjectives such as improving factuality (heat) and increasing confidence (via\nlow entropy) poses a fundamental challenge, especially when prompt parameters\n(e.g., hidden-layer insertions h and embedding modifications w) interact in\nnon-trivial ways. Existing multi-objective optimization strategies often rely\non scalar gradient aggregation, ignoring the deeper geometric structure between\nobjectives and parameters. We propose J6, a structured Jacobian-based method\nthat decomposes the gradient interaction matrix into six interpretable\ncomponents. This decomposition enables both hard decision-making (e.g.,\nchoosing the dominant update direction via argmax) and soft strategies (e.g.,\nattention-style weighting via softmax over J6), forming a dynamic update\nframework that adapts to local conflict and synergy. Moreover, the\ninterpretable structure of J6 provides insight into parameter attribution, task\ninterference, and geometry-aligned adaptation. Our work introduces a principled\nand extensible mechanism for conflict-aware prompt optimization, and opens a\nnew avenue for incorporating structured Jacobian reasoning into multi-objective\nneural tuning.", "AI": {"tldr": "J6 is a Jacobian-based method that decomposes gradient interactions into six components for multi-objective LLM adaptation, enabling both hard and soft optimization strategies while providing interpretable insights into parameter attribution and task interference.", "motivation": "Existing multi-objective optimization strategies for LLM adaptation rely on scalar gradient aggregation, ignoring the geometric structure between objectives and parameters, which poses challenges when balancing conflicting objectives like factuality improvement and confidence increase.", "method": "Proposes J6, a structured Jacobian-based method that decomposes the gradient interaction matrix into six interpretable components, enabling both hard decision-making (argmax) and soft strategies (softmax weighting) for dynamic update framework adaptation.", "result": "The method provides interpretable structure for parameter attribution, task interference analysis, and geometry-aligned adaptation, forming a principled mechanism for conflict-aware prompt optimization.", "conclusion": "J6 introduces a principled and extensible approach for multi-objective neural tuning that incorporates structured Jacobian reasoning, opening new avenues for conflict-aware optimization in LLM adaptation."}}
{"id": "2508.11931", "pdf": "https://arxiv.org/pdf/2508.11931", "abs": "https://arxiv.org/abs/2508.11931", "authors": ["Tim van Erven", "Jack Mayo", "Julia Olkhovskaya", "Chen-Yu Wei"], "title": "An Improved Algorithm for Adversarial Linear Contextual Bandits via Reduction", "categories": ["cs.LG"], "comment": null, "summary": "We present an efficient algorithm for linear contextual bandits with\nadversarial losses and stochastic action sets. Our approach reduces this\nsetting to misspecification-robust adversarial linear bandits with fixed action\nsets. Without knowledge of the context distribution or access to a context\nsimulator, the algorithm achieves $\\tilde{O}(\\min\\{d^2\\sqrt{T}, \\sqrt{d^3T\\log\nK}\\})$ regret and runs in $\\text{poly}(d,C,T)$ time, where $d$ is the feature\ndimension, $C$ is an upper bound on the number of linear constraints defining\nthe action set in each round, $K$ is an upper bound on the number of actions in\neach round, and $T$ is number of rounds. This resolves the open question by Liu\net al. (2023) on whether one can obtain $\\text{poly}(d)\\sqrt{T}$ regret in\npolynomial time independent of the number of actions. For the important class\nof combinatorial bandits with adversarial losses and stochastic action sets\nwhere the action sets can be described by a polynomial number of linear\nconstraints, our algorithm is the first to achieve $\\text{poly}(d)\\sqrt{T}$\nregret in polynomial time, while no prior algorithm achieves even $o(T)$ regret\nin polynomial time to our knowledge. When a simulator is available, the regret\nbound can be improved to $\\tilde{O}(d\\sqrt{L^\\star})$, where $L^\\star$ is the\ncumulative loss of the best policy.", "AI": {"tldr": "Efficient algorithm for linear contextual bandits with adversarial losses and stochastic action sets, achieving poly(d)\u221aT regret in polynomial time without requiring context distribution knowledge or simulator access.", "motivation": "Addresses the open question by Liu et al. (2023) on whether poly(d)\u221aT regret can be achieved in polynomial time independent of the number of actions, particularly for combinatorial bandits where prior algorithms couldn't achieve o(T) regret in polynomial time.", "method": "Reduces the setting to misspecification-robust adversarial linear bandits with fixed action sets. The algorithm runs in poly(d,C,T) time without knowledge of context distribution or access to context simulator.", "result": "Achieves \u00d5(min{d\u00b2\u221aT, \u221a(d\u00b3T log K)}) regret without simulator, and improved \u00d5(d\u221aL*) regret when simulator is available, where L* is the cumulative loss of the best policy.", "conclusion": "Resolves the open problem by providing the first polynomial-time algorithm achieving poly(d)\u221aT regret for combinatorial bandits with adversarial losses and stochastic action sets, representing a significant advancement in the field."}}
{"id": "2508.12149", "pdf": "https://arxiv.org/pdf/2508.12149", "abs": "https://arxiv.org/abs/2508.12149", "authors": ["Haochen You", "Baojing Liu"], "title": "MOVER: Multimodal Optimal Transport with Volume-based Embedding Regularization", "categories": ["cs.AI"], "comment": "Accepted as a conference paper at CIKM 2025", "summary": "Recent advances in multimodal learning have largely relied on pairwise\ncontrastive objectives to align different modalities, such as text, video, and\naudio, in a shared embedding space. While effective in bi-modal setups, these\napproaches struggle to generalize across multiple modalities and often lack\nsemantic structure in high-dimensional spaces. In this paper, we propose MOVER,\na novel framework that combines optimal transport-based soft alignment with\nvolume-based geometric regularization to build semantically aligned and\nstructured multimodal representations. By integrating a transport-guided\nmatching mechanism with a geometric volume minimization objective (GAVE), MOVER\nencourages consistent alignment across all modalities in a modality-agnostic\nmanner. Experiments on text-video-audio retrieval tasks demonstrate that MOVER\nsignificantly outperforms prior state-of-the-art methods in both zero-shot and\nfinetuned settings. Additional analysis shows improved generalization to unseen\nmodality combinations and stronger structural consistency in the learned\nembedding space.", "AI": {"tldr": "MOVER is a multimodal learning framework that combines optimal transport alignment with geometric regularization to create structured representations across text, video, and audio modalities, outperforming previous methods in retrieval tasks.", "motivation": "Existing multimodal contrastive learning approaches struggle with generalization across multiple modalities and lack semantic structure in high-dimensional embedding spaces, particularly in setups beyond bi-modal configurations.", "method": "Combines optimal transport-based soft alignment with volume-based geometric regularization (GAVE), using transport-guided matching and geometric volume minimization to achieve modality-agnostic consistent alignment.", "result": "Significantly outperforms state-of-the-art methods in text-video-audio retrieval tasks in both zero-shot and finetuned settings, with improved generalization to unseen modality combinations and stronger structural consistency.", "conclusion": "MOVER successfully addresses limitations of pairwise contrastive learning by providing structured, semantically aligned multimodal representations through optimal transport and geometric regularization techniques."}}
{"id": "2508.11932", "pdf": "https://arxiv.org/pdf/2508.11932", "abs": "https://arxiv.org/abs/2508.11932", "authors": ["Chengwei Zhang", "Xueyi Zhang", "Mingrui Lao", "Tao Jiang", "Xinhao Xu", "Wenjie Li", "Fubo Zhang", "Longyong Chen"], "title": "Deep Learning For Point Cloud Denoising: A Survey", "categories": ["cs.CV"], "comment": null, "summary": "Real-world environment-derived point clouds invariably exhibit noise across\nvarying modalities and intensities. Hence, point cloud denoising (PCD) is\nessential as a preprocessing step to improve downstream task performance. Deep\nlearning (DL)-based PCD models, known for their strong representation\ncapabilities and flexible architectures, have surpassed traditional methods in\ndenoising performance. To our best knowledge, despite recent advances in\nperformance, no comprehensive survey systematically summarizes the developments\nof DL-based PCD. To fill the gap, this paper seeks to identify key challenges\nin DL-based PCD, summarizes the main contributions of existing methods, and\nproposes a taxonomy tailored to denoising tasks. To achieve this goal, we\nformulate PCD as a two-step process: outlier removal and surface noise\nrestoration, encompassing most scenarios and requirements of PCD. Additionally,\nwe compare methods in terms of similarities, differences, and respective\nadvantages. Finally, we discuss research limitations and future directions,\noffering insights for further advancements in PCD.", "AI": {"tldr": "A comprehensive survey paper on deep learning-based point cloud denoising methods, categorizing approaches into outlier removal and surface noise restoration, with comparative analysis and future research directions.", "motivation": "Real-world point clouds contain various types and intensities of noise, requiring denoising as preprocessing for downstream tasks. Despite deep learning methods outperforming traditional approaches, no systematic survey exists to summarize developments in this field.", "method": "The paper formulates point cloud denoising as a two-step process: outlier removal and surface noise restoration. It creates a taxonomy tailored to denoising tasks, compares methods based on similarities, differences, and advantages, and systematically summarizes existing approaches.", "result": "The survey provides a comprehensive framework for understanding deep learning-based point cloud denoising, categorizing methods, and identifying key challenges and contributions in the field.", "conclusion": "The paper fills the research gap by offering the first systematic survey of DL-based point cloud denoising, providing insights into current limitations and future research directions to advance the field."}}
{"id": "2508.12096", "pdf": "https://arxiv.org/pdf/2508.12096", "abs": "https://arxiv.org/abs/2508.12096", "authors": ["Haiquan Hu", "Jiazhi Jiang", "Shiyou Xu", "Ruhan Zeng", "Tian Wang"], "title": "STEM: Efficient Relative Capability Evaluation of LLMs through Structured Transition Samples", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Submit to AAAI 2026", "summary": "Evaluating large language models (LLMs) has become increasingly challenging\nas model capabilities advance rapidly. While recent models often achieve higher\nscores on standard benchmarks, these improvements do not consistently reflect\nenhanced real-world reasoning capabilities. Moreover, widespread overfitting to\npublic benchmarks and the high computational cost of full evaluations have made\nit both expensive and less effective to distinguish meaningful differences\nbetween models. To address these challenges, we propose the \\textbf{S}tructured\n\\textbf{T}ransition \\textbf{E}valuation \\textbf{M}ethod (STEM), a lightweight\nand interpretable evaluation framework for efficiently estimating the relative\ncapabilities of LLMs. STEM identifies \\textit{significant transition samples}\n(STS) by analyzing consistent performance transitions among LLMs of the same\narchitecture but varying parameter scales. These samples enable STEM to\neffectively estimate the capability position of an unknown model. Qwen3 model\nfamily is applied to construct the STS pool on six diverse and representative\nbenchmarks. To assess generalizability. Experimental results indicate that STEM\nreliably captures performance trends, aligns with ground-truth rankings of\nmodel capability. These findings highlight STEM as a practical and scalable\nmethod for fine-grained, architecture-agnostic evaluation of LLMs.", "AI": {"tldr": "STEM is a lightweight evaluation framework that uses significant transition samples to efficiently estimate LLM capabilities without full benchmark testing.", "motivation": "Standard LLM benchmarks are becoming less effective due to overfitting, high computational costs, and inability to distinguish meaningful differences between models as capabilities advance rapidly.", "method": "STEM identifies significant transition samples (STS) by analyzing performance transitions among LLMs of the same architecture but varying parameter scales, then uses these samples to estimate capability positions of unknown models.", "result": "Experimental results show STEM reliably captures performance trends and aligns with ground-truth rankings of model capability across six diverse benchmarks using the Qwen3 model family.", "conclusion": "STEM provides a practical, scalable, and architecture-agnostic method for fine-grained evaluation of LLMs, addressing current benchmarking limitations."}}
{"id": "2508.11936", "pdf": "https://arxiv.org/pdf/2508.11936", "abs": "https://arxiv.org/abs/2508.11936", "authors": ["Yuehan Qin", "Li Li", "Defu Cao", "Tiankai Yang", "Yue Zhao"], "title": "M3OOD: Automatic Selection of Multimodal OOD Detectors", "categories": ["cs.LG"], "comment": null, "summary": "Out-of-distribution (OOD) robustness is a critical challenge for modern\nmachine learning systems, particularly as they increasingly operate in\nmultimodal settings involving inputs like video, audio, and sensor data.\nCurrently, many OOD detection methods have been proposed, each with different\ndesigns targeting various distribution shifts. A single OOD detector may not\nprevail across all the scenarios; therefore, how can we automatically select an\nideal OOD detection model for different distribution shifts? Due to the\ninherent unsupervised nature of the OOD detection task, it is difficult to\npredict model performance and find a universally Best model. Also,\nsystematically comparing models on the new unseen data is costly or even\nimpractical. To address this challenge, we introduce M3OOD, a\nmeta-learning-based framework for OOD detector selection in multimodal\nsettings. Meta learning offers a solution by learning from historical model\nbehaviors, enabling rapid adaptation to new data distribution shifts with\nminimal supervision. Our approach combines multimodal embeddings with\nhandcrafted meta-features that capture distributional and cross-modal\ncharacteristics to represent datasets. By leveraging historical performance\nacross diverse multimodal benchmarks, M3OOD can recommend suitable detectors\nfor a new data distribution shift. Experimental evaluation demonstrates that\nM3OOD consistently outperforms 10 competitive baselines across 12 test\nscenarios with minimal computational overhead.", "AI": {"tldr": "M3OOD is a meta-learning framework that automatically selects optimal out-of-distribution (OOD) detectors for multimodal data by learning from historical model behaviors and using multimodal embeddings with handcrafted meta-features.", "motivation": "Current OOD detection methods are designed for specific distribution shifts, but no single detector works well across all scenarios. Manual selection is difficult due to the unsupervised nature of OOD detection and the impracticality of testing models on new unseen data.", "method": "Meta-learning framework that combines multimodal embeddings with handcrafted meta-features capturing distributional and cross-modal characteristics. Learns from historical performance across diverse multimodal benchmarks to recommend suitable detectors for new distribution shifts.", "result": "M3OOD consistently outperforms 10 competitive baselines across 12 test scenarios with minimal computational overhead.", "conclusion": "The proposed meta-learning approach effectively addresses the challenge of automatic OOD detector selection in multimodal settings, demonstrating superior performance and practical efficiency."}}
{"id": "2508.12165", "pdf": "https://arxiv.org/pdf/2508.12165", "abs": "https://arxiv.org/abs/2508.12165", "authors": ["Rohit Krishnan", "Jon Evans"], "title": "RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards", "categories": ["cs.AI"], "comment": null, "summary": "This paper introduces RLNVR (Reinforcement Learning from Non-Verified\nRewards), a framework for training language models using noisy, real-world\nfeedback signals without requiring explicit human verification. Traditional\nRLHF requires expensive, verified reward signals that are impractical in many\nreal-world domains. RLNVR addresses this challenge through baseline\nnormalization and semantic similarity-based reward transfer. We demonstrate\nRLNVR through Walter, a prototype system that optimizes social media content\ngeneration using actual engagement data from Bluesky. Our experimental results\nshow significant improvements in content quality and training stability, with\ncomprehensive evaluation planned for future work. Positioning: We present a\npractical framework that combines RLNVR with GSPO (Group Sequence Policy\nOptimization) and an optional UED (Unsupervised Environment Design) curriculum\nto improve stability and diversity under noisy, implicit rewards. To our\nknowledge, combining GSPO-style normalization with a UED-style curriculum for\nLLM content generation from implicit social engagement has not been previously\ndocumented in this applied setting; we frame this as an applied integration\nrather than a new algorithm.", "AI": {"tldr": "RLNVR framework enables language model training using noisy real-world feedback without human verification, combining baseline normalization and semantic similarity reward transfer for social media content optimization.", "motivation": "Traditional RLHF requires expensive verified reward signals that are impractical for many real-world applications, especially in social media content generation where engagement data is abundant but noisy.", "method": "Uses baseline normalization and semantic similarity-based reward transfer, combined with GSPO (Group Sequence Policy Optimization) and optional UED (Unsupervised Environment Design) curriculum for improved stability and diversity.", "result": "Demonstrated through Walter prototype system showing significant improvements in content quality and training stability when optimizing social media content using Bluesky engagement data.", "conclusion": "Presents a practical framework for leveraging noisy real-world feedback signals in language model training, positioning it as an applied integration of existing techniques rather than a new algorithm."}}
{"id": "2508.11950", "pdf": "https://arxiv.org/pdf/2508.11950", "abs": "https://arxiv.org/abs/2508.11950", "authors": ["Tingbang Liang", "Yixin Zeng", "Jiatong Xie", "Boyu Zhou"], "title": "DynamicPose: Real-time and Robust 6D Object Pose Tracking for Fast-Moving Cameras and Objects", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "We present DynamicPose, a retraining-free 6D pose tracking framework that\nimproves tracking robustness in fast-moving camera and object scenarios.\nPrevious work is mainly applicable to static or quasi-static scenes, and its\nperformance significantly deteriorates when both the object and the camera move\nrapidly. To overcome these challenges, we propose three synergistic components:\n(1) A visual-inertial odometry compensates for the shift in the Region of\nInterest (ROI) caused by camera motion; (2) A depth-informed 2D tracker\ncorrects ROI deviations caused by large object translation; (3) A VIO-guided\nKalman filter predicts object rotation, generates multiple candidate poses, and\nthen obtains the final pose by hierarchical refinement. The 6D pose tracking\nresults guide subsequent 2D tracking and Kalman filter updates, forming a\nclosed-loop system that ensures accurate pose initialization and precise pose\ntracking. Simulation and real-world experiments demonstrate the effectiveness\nof our method, achieving real-time and robust 6D pose tracking for fast-moving\ncameras and objects.", "AI": {"tldr": "DynamicPose is a retraining-free 6D pose tracking framework that handles fast-moving camera and object scenarios using visual-inertial odometry, depth-informed 2D tracking, and VIO-guided Kalman filtering in a closed-loop system.", "motivation": "Previous 6D pose tracking methods perform poorly in fast-moving scenarios where both camera and objects move rapidly, limiting their applicability to static or quasi-static scenes only.", "method": "Three synergistic components: (1) Visual-inertial odometry compensates for camera motion ROI shifts, (2) Depth-informed 2D tracker corrects ROI deviations from object translation, (3) VIO-guided Kalman filter predicts rotation and refines poses hierarchically in a closed-loop system.", "result": "The method achieves real-time and robust 6D pose tracking performance in both simulation and real-world experiments with fast-moving cameras and objects.", "conclusion": "DynamicPose successfully overcomes limitations of previous methods by providing accurate pose initialization and precise tracking in dynamic scenarios without requiring retraining, demonstrating effectiveness for real-time applications."}}
{"id": "2508.12140", "pdf": "https://arxiv.org/pdf/2508.12140", "abs": "https://arxiv.org/abs/2508.12140", "authors": ["Ziqian Bi", "Lu Chen", "Junhao Song", "Hongying Luo", "Enze Ge", "Junmin Huang", "Tianyang Wang", "Keyu Chen", "Chia Xin Liang", "Zihan Wei", "Huafeng Liu", "Chunjie Tian", "Jibin Guan", "Joe Yeong", "Yongzhi Xu", "Peng Wang", "Junfeng Hao"], "title": "Exploring Efficiency Frontiers of Thinking Budget in Medical Reasoning: Scaling Laws between Computational Resources and Reasoning Quality", "categories": ["cs.CL"], "comment": null, "summary": "This study presents the first comprehensive evaluation of thinking budget\nmechanisms in medical reasoning tasks, revealing fundamental scaling laws\nbetween computational resources and reasoning quality. We systematically\nevaluated two major model families, Qwen3 (1.7B to 235B parameters) and\nDeepSeek-R1 (1.5B to 70B parameters), across 15 medical datasets spanning\ndiverse specialties and difficulty levels. Through controlled experiments with\nthinking budgets ranging from zero to unlimited tokens, we establish\nlogarithmic scaling relationships where accuracy improvements follow a\npredictable pattern with both thinking budget and model size. Our findings\nidentify three distinct efficiency regimes: high-efficiency (0 to 256 tokens)\nsuitable for real-time applications, balanced (256 to 512 tokens) offering\noptimal cost-performance tradeoffs for routine clinical support, and\nhigh-accuracy (above 512 tokens) justified only for critical diagnostic tasks.\nNotably, smaller models demonstrate disproportionately larger benefits from\nextended thinking, with 15 to 20% improvements compared to 5 to 10% for larger\nmodels, suggesting a complementary relationship where thinking budget provides\ngreater relative benefits for capacity-constrained models. Domain-specific\npatterns emerge clearly, with neurology and gastroenterology requiring\nsignificantly deeper reasoning processes than cardiovascular or respiratory\nmedicine. The consistency between Qwen3 native thinking budget API and our\nproposed truncation method for DeepSeek-R1 validates the generalizability of\nthinking budget concepts across architectures. These results establish thinking\nbudget control as a critical mechanism for optimizing medical AI systems,\nenabling dynamic resource allocation aligned with clinical needs while\nmaintaining the transparency essential for healthcare deployment.", "AI": {"tldr": "First comprehensive evaluation of thinking budget mechanisms in medical AI, showing logarithmic scaling between computational resources and reasoning quality across 15 medical datasets and multiple model sizes.", "motivation": "To establish fundamental scaling laws between computational thinking budgets and reasoning quality in medical AI systems, enabling optimized resource allocation for clinical applications.", "method": "Systematic evaluation of Qwen3 (1.7B-235B) and DeepSeek-R1 (1.5B-70B) models across 15 medical datasets with controlled thinking budgets from zero to unlimited tokens.", "result": "Identified three efficiency regimes: high-efficiency (0-256 tokens), balanced (256-512 tokens), and high-accuracy (>512 tokens). Smaller models showed 15-20% improvement with extended thinking vs 5-10% for larger models. Domain-specific patterns emerged with neurology/gastroenterology requiring deeper reasoning.", "conclusion": "Thinking budget control is critical for optimizing medical AI systems, enabling dynamic resource allocation aligned with clinical needs while maintaining transparency essential for healthcare deployment."}}
{"id": "2508.11940", "pdf": "https://arxiv.org/pdf/2508.11940", "abs": "https://arxiv.org/abs/2508.11940", "authors": ["Yuannuo Feng", "Wenyong Zhou", "Yuexi Lyu", "Yixiang Zhang", "Zhengwu Liu", "Ngai Wong", "Wang Kang"], "title": "Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "4 pages, 5 figures, conference", "summary": "Analog Compute-In-Memory (CIM) architectures promise significant energy\nefficiency gains for neural network inference, but suffer from complex\nhardware-induced noise that poses major challenges for deployment. While\nnoise-aware training methods have been proposed to address this issue, they\ntypically rely on idealized and differentiable noise models that fail to\ncapture the full complexity of analog CIM hardware variations. Motivated by the\nStraight-Through Estimator (STE) framework in quantization, we decouple forward\nnoise simulation from backward gradient computation, enabling noise-aware\ntraining with more accurate but computationally intractable noise modeling in\nanalog CIM systems. We provide theoretical analysis demonstrating that our\napproach preserves essential gradient directional information while maintaining\ncomputational tractability and optimization stability. Extensive experiments\nshow that our extended STE framework achieves up to 5.3% accuracy improvement\non image classification, 0.72 perplexity reduction on text generation,\n2.2$\\times$ speedup in training time, and 37.9% lower peak memory usage\ncompared to standard noise-aware training methods.", "AI": {"tldr": "Extended STE framework enables noise-aware training for analog CIM systems by decoupling forward noise simulation from backward gradients, achieving significant accuracy improvements and efficiency gains.", "motivation": "Analog CIM architectures offer energy efficiency but suffer from complex hardware noise that existing noise-aware training methods fail to capture accurately due to reliance on idealized differentiable noise models.", "method": "Decouple forward noise simulation from backward gradient computation using an extended Straight-Through Estimator framework, enabling use of more accurate but computationally intractable noise models while preserving gradient directional information.", "result": "Achieves up to 5.3% accuracy improvement on image classification, 0.72 perplexity reduction on text generation, 2.2x training speedup, and 37.9% lower peak memory usage compared to standard methods.", "conclusion": "The extended STE framework provides an effective solution for noise-aware training in analog CIM systems, enabling accurate noise modeling while maintaining computational tractability and optimization stability."}}
{"id": "2508.12260", "pdf": "https://arxiv.org/pdf/2508.12260", "abs": "https://arxiv.org/abs/2508.12260", "authors": ["Carson Dudley", "Reiden Magdaleno", "Christopher Harding", "Ananya Sharma", "Emily Martin", "Marisa Eisenberg"], "title": "Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting", "categories": ["cs.AI", "q-bio.QM"], "comment": "10 pages, 4 figures", "summary": "Infectious disease forecasting in novel outbreaks or low resource settings\nhas been limited by the need for disease-specific data, bespoke training, and\nexpert tuning. We introduce Mantis, a foundation model trained entirely on\nmechanistic simulations, which enables out-of-the-box forecasting across\ndiseases, regions, and outcomes, even in settings with limited historical data.\nMantis is built on over 400 million simulated days of outbreak dynamics\nspanning diverse pathogens, transmission modes, interventions, and surveillance\nartifacts. Despite requiring no real-world data during training, Mantis\noutperformed 39 expert-tuned models we tested across six diseases, including\nall models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel\nepidemiological regimes, including diseases with held-out transmission\nmechanisms, demonstrating that it captures fundamental contagion dynamics.\nCritically, Mantis is mechanistically interpretable, enabling public health\ndecision-makers to identify the latent drivers behind its predictions. Finally,\nMantis delivers accurate forecasts at 8-week horizons, more than doubling the\nactionable range of most models, enabling proactive public health planning.\nTogether, these capabilities position Mantis as a foundation for\nnext-generation disease forecasting systems: general, interpretable, and\ndeployable where traditional models fail.", "AI": {"tldr": "Mantis is a foundation model for infectious disease forecasting that uses mechanistic simulations instead of real-world data, achieving superior performance across multiple diseases and enabling 8-week forecasts with mechanistic interpretability.", "motivation": "Traditional infectious disease forecasting requires disease-specific data, expert tuning, and bespoke training, limiting effectiveness in novel outbreaks or low-resource settings with limited historical data.", "method": "Trained on over 400 million simulated days of outbreak dynamics covering diverse pathogens, transmission modes, interventions, and surveillance artifacts - entirely using mechanistic simulations without real-world training data.", "result": "Outperformed 39 expert-tuned models across six diseases, including all models in CDC's COVID-19 Forecast Hub. Generalizes to novel epidemiological regimes and delivers accurate 8-week forecasts (more than doubling actionable range of most models).", "conclusion": "Mantis serves as a foundation for next-generation disease forecasting systems that are general, interpretable, and deployable where traditional models fail, capturing fundamental contagion dynamics through mechanistic simulation training."}}
{"id": "2508.11951", "pdf": "https://arxiv.org/pdf/2508.11951", "abs": "https://arxiv.org/abs/2508.11951", "authors": ["Hao Peng", "Hong Sang", "Yajing Ma", "Ping Qiu", "Chao Ji"], "title": "Transferable Class Statistics and Multi-scale Feature Approximation for 3D Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "This paper investigates multi-scale feature approximation and transferable\nfeatures for object detection from point clouds. Multi-scale features are\ncritical for object detection from point clouds. However, multi-scale feature\nlearning usually involves multiple neighborhood searches and scale-aware\nlayers, which can hinder efforts to achieve lightweight models and may not be\nconducive to research constrained by limited computational resources. This\npaper approximates point-based multi-scale features from a single neighborhood\nbased on knowledge distillation. To compensate for the loss of constructive\ndiversity in a single neighborhood, this paper designs a transferable feature\nembedding mechanism. Specifically, class-aware statistics are employed as\ntransferable features given the small computational cost. In addition, this\npaper introduces the central weighted intersection over union for localization\nto alleviate the misalignment brought by the center offset in optimization.\nNote that the method presented in this paper saves computational costs.\nExtensive experiments on public datasets demonstrate the effectiveness of the\nproposed method.", "AI": {"tldr": "This paper proposes a lightweight object detection method for point clouds that approximates multi-scale features from single neighborhoods using knowledge distillation, employs transferable class-aware statistics, and introduces central weighted IoU for better localization.", "motivation": "Multi-scale feature learning in point cloud object detection typically requires multiple neighborhood searches and scale-aware layers, which increases computational costs and hinders lightweight model development, especially for resource-constrained research.", "method": "The method approximates multi-scale features from a single neighborhood using knowledge distillation, designs transferable feature embedding with class-aware statistics for computational efficiency, and introduces central weighted intersection over union to address center offset misalignment in optimization.", "result": "Extensive experiments on public datasets demonstrate the effectiveness of the proposed method, showing successful object detection from point clouds while significantly reducing computational costs compared to traditional multi-scale approaches.", "conclusion": "The proposed approach provides an effective and computationally efficient solution for point cloud object detection by approximating multi-scale features from single neighborhoods, using transferable features, and improving localization accuracy with central weighted IoU, making it suitable for resource-constrained environments."}}
{"id": "2508.12158", "pdf": "https://arxiv.org/pdf/2508.12158", "abs": "https://arxiv.org/abs/2508.12158", "authors": ["Stephen Meisenbacher", "Alexandra Klymenko", "Florian Matthes"], "title": "LLM-as-a-Judge for Privacy Evaluation? Exploring the Alignment of Human and LLM Perceptions of Privacy in Textual Data", "categories": ["cs.CL"], "comment": "13 pages, 3 figures, 4 tables. Accepted to HAIPS @ CCS 2025", "summary": "Despite advances in the field of privacy-preserving Natural Language\nProcessing (NLP), a significant challenge remains the accurate evaluation of\nprivacy. As a potential solution, using LLMs as a privacy evaluator presents a\npromising approach $\\unicode{x2013}$ a strategy inspired by its success in\nother subfields of NLP. In particular, the so-called $\\textit{LLM-as-a-Judge}$\nparadigm has achieved impressive results on a variety of natural language\nevaluation tasks, demonstrating high agreement rates with human annotators.\nRecognizing that privacy is both subjective and difficult to define, we\ninvestigate whether LLM-as-a-Judge can also be leveraged to evaluate the\nprivacy sensitivity of textual data. Furthermore, we measure how closely LLM\nevaluations align with human perceptions of privacy in text. Resulting from a\nstudy involving 10 datasets, 13 LLMs, and 677 human survey participants, we\nconfirm that privacy is indeed a difficult concept to measure empirically,\nexhibited by generally low inter-human agreement rates. Nevertheless, we find\nthat LLMs can accurately model a global human privacy perspective, and through\nan analysis of human and LLM reasoning patterns, we discuss the merits and\nlimitations of LLM-as-a-Judge for privacy evaluation in textual data. Our\nfindings pave the way for exploring the feasibility of LLMs as privacy\nevaluators, addressing a core challenge in solving pressing privacy issues with\ninnovative technical solutions.", "AI": {"tldr": "LLMs can effectively model human privacy perspectives for text evaluation, showing promise as privacy evaluators despite low inter-human agreement on privacy sensitivity.", "motivation": "Privacy evaluation in NLP remains challenging due to its subjective nature, and LLMs have shown success in other evaluation tasks, suggesting potential for privacy assessment.", "method": "Conducted study with 10 datasets, 13 LLMs, and 677 human participants to compare LLM and human privacy evaluations of textual data using the LLM-as-a-Judge paradigm.", "result": "LLMs can accurately model global human privacy perspectives, though privacy is difficult to measure empirically with generally low inter-human agreement rates.", "conclusion": "LLMs show promise as privacy evaluators for textual data, paving the way for addressing privacy challenges with innovative technical solutions."}}
{"id": "2508.11943", "pdf": "https://arxiv.org/pdf/2508.11943", "abs": "https://arxiv.org/abs/2508.11943", "authors": ["Sishun Liu", "Ke Deng", "Xiuzhen Zhang", "Yan Wang"], "title": "Learning Marked Temporal Point Process Explanations based on Counterfactual and Factual Reasoning", "categories": ["cs.LG"], "comment": "ECAI 2025 full version", "summary": "Neural network-based Marked Temporal Point Process (MTPP) models have been\nwidely adopted to model event sequences in high-stakes applications, raising\nconcerns about the trustworthiness of outputs from these models. This study\nfocuses on Explanation for MTPP, aiming to identify the minimal and rational\nexplanation, that is, the minimum subset of events in history, based on which\nthe prediction accuracy of MTPP matches that based on full history to a great\nextent and better than that based on the complement of the subset. This study\nfinds that directly defining Explanation for MTPP as counterfactual explanation\nor factual explanation can result in irrational explanations. To address this\nissue, we define Explanation for MTPP as a combination of counterfactual\nexplanation and factual explanation. This study proposes Counterfactual and\nFactual Explainer for MTPP (CFF) to solve Explanation for MTPP with a series of\ndeliberately designed techniques. Experiments demonstrate the correctness and\nsuperiority of CFF over baselines regarding explanation quality and processing\nefficiency.", "AI": {"tldr": "CFF combines counterfactual and factual explanations to identify minimal rational subsets of historical events that maintain MTPP prediction accuracy, outperforming baseline methods in quality and efficiency.", "motivation": "Neural MTPP models are used in high-stakes applications but lack trustworthy explanations. Existing explanation methods (counterfactual or factual alone) can produce irrational explanations for event sequence predictions.", "method": "Proposes CFF (Counterfactual and Factual Explainer) that combines both explanation types with deliberately designed techniques to identify minimal event subsets that preserve prediction accuracy comparable to full history.", "result": "Experiments show CFF achieves superior explanation quality and processing efficiency compared to baseline methods, demonstrating correctness and effectiveness.", "conclusion": "Combining counterfactual and factual explanations provides more rational and minimal explanations for MTPP predictions, enhancing trustworthiness in high-stakes applications."}}
{"id": "2508.12291", "pdf": "https://arxiv.org/pdf/2508.12291", "abs": "https://arxiv.org/abs/2508.12291", "authors": ["Xuming He", "Zhiyuan You", "Junchao Gong", "Couhua Liu", "Xiaoyu Yue", "Peiqin Zhuang", "Wenlong Zhang", "Lei Bai"], "title": "RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts", "categories": ["cs.AI"], "comment": null, "summary": "Quality analysis of weather forecasts is an essential topic in meteorology.\nAlthough traditional score-based evaluation metrics can quantify certain\nforecast errors, they are still far from meteorological experts in terms of\ndescriptive capability, interpretability, and understanding of dynamic\nevolution. With the rapid development of Multi-modal Large Language Models\n(MLLMs), these models become potential tools to overcome the above challenges.\nIn this work, we introduce an MLLM-based weather forecast analysis method,\nRadarQA, integrating key physical attributes with detailed assessment reports.\nWe introduce a novel and comprehensive task paradigm for multi-modal quality\nanalysis, encompassing both single frame and sequence, under both rating and\nassessment scenarios. To support training and benchmarking, we design a hybrid\nannotation pipeline that combines human expert labeling with automated\nheuristics. With such an annotation method, we construct RQA-70K, a large-scale\ndataset with varying difficulty levels for radar forecast quality evaluation.\nWe further design a multi-stage training strategy that iteratively improves\nmodel performance at each stage. Extensive experiments show that RadarQA\noutperforms existing general MLLMs across all evaluation settings, highlighting\nits potential for advancing quality analysis in weather prediction.", "AI": {"tldr": "RadarQA is an MLLM-based method for weather forecast quality analysis that outperforms existing general models by integrating physical attributes with detailed assessment reports using a novel multi-modal task paradigm and large-scale dataset.", "motivation": "Traditional score-based weather forecast evaluation metrics lack descriptive capability, interpretability, and dynamic evolution understanding compared to meteorological experts, creating a need for more sophisticated analysis tools.", "method": "Developed RadarQA method using Multi-modal Large Language Models, created RQA-70K dataset with hybrid human-expert and automated annotation, and implemented multi-stage training strategy for iterative performance improvement.", "result": "RadarQA outperforms existing general MLLMs across all evaluation settings, demonstrating superior performance in both single frame and sequence analysis under rating and assessment scenarios.", "conclusion": "The method shows strong potential for advancing quality analysis in weather prediction by effectively bridging the gap between traditional metrics and expert-level analysis capabilities."}}
{"id": "2508.11952", "pdf": "https://arxiv.org/pdf/2508.11952", "abs": "https://arxiv.org/abs/2508.11952", "authors": ["Yueming Xu", "Jiahui Zhang", "Ze Huang", "Yurui Chen", "Yanpeng Zhou", "Zhenyu Chen", "Yu-Jie Yuan", "Pengxiang Xia", "Guowei Huang", "Xinyue Cai", "Zhongang Qi", "Xingyue Quan", "Jianye Hao", "Hang Xu", "Li Zhang"], "title": "UniUGG: Unified 3D Understanding and Generation via Geometric-Semantic Encoding", "categories": ["cs.CV"], "comment": null, "summary": "Despite the impressive progress on understanding and generating images shown\nby the recent unified architectures, the integration of 3D tasks remains\nchallenging and largely unexplored. In this paper, we introduce UniUGG, the\nfirst unified understanding and generation framework for 3D modalities. Our\nunified framework employs an LLM to comprehend and decode sentences and 3D\nrepresentations. At its core, we propose a spatial decoder leveraging a latent\ndiffusion model to generate high-quality 3D representations. This allows for\nthe generation and imagination of 3D scenes based on a reference image and an\narbitrary view transformation, while remaining supports for spatial visual\nquestion answering (VQA) tasks. Additionally, we propose a geometric-semantic\nlearning strategy to pretrain the vision encoder. This design jointly captures\nthe input's semantic and geometric cues, enhancing both spatial understanding\nand generation. Extensive experimental results demonstrate the superiority of\nour method in visual representation, spatial understanding, and 3D generation.\nThe source code will be released upon paper acceptance.", "AI": {"tldr": "UniUGG is the first unified framework for 3D understanding and generation that uses an LLM to process both text and 3D representations, featuring a spatial decoder with latent diffusion for high-quality 3D generation and geometric-semantic pretraining for enhanced spatial capabilities.", "motivation": "Despite progress in unified architectures for 2D image understanding and generation, integrating 3D tasks remains challenging and largely unexplored, creating a need for a comprehensive framework that can handle both 3D understanding and generation.", "method": "The framework employs an LLM to comprehend sentences and 3D representations, uses a spatial decoder with latent diffusion model for 3D generation, and implements geometric-semantic learning strategy to pretrain the vision encoder for capturing both semantic and geometric cues.", "result": "Extensive experimental results demonstrate superiority in visual representation, spatial understanding, and 3D generation tasks, showing improved performance in both generation from reference images with view transformations and spatial visual question answering.", "conclusion": "UniUGG successfully addresses the integration challenge of 3D tasks within unified architectures, providing a comprehensive solution that bridges 3D understanding and generation through innovative spatial decoding and geometric-semantic learning approaches."}}
{"id": "2508.12227", "pdf": "https://arxiv.org/pdf/2508.12227", "abs": "https://arxiv.org/abs/2508.12227", "authors": ["Abdelhamid Haouhat", "Slimane Bellaouar", "Attia Nehar", "Hadda Cherroun", "Ahmed Abdelali"], "title": "Arabic Multimodal Machine Learning: Datasets, Applications, Approaches, and Challenges", "categories": ["cs.CL"], "comment": null, "summary": "Multimodal Machine Learning (MML) aims to integrate and analyze information\nfrom diverse modalities, such as text, audio, and visuals, enabling machines to\naddress complex tasks like sentiment analysis, emotion recognition, and\nmultimedia retrieval. Recently, Arabic MML has reached a certain level of\nmaturity in its foundational development, making it time to conduct a\ncomprehensive survey. This paper explores Arabic MML by categorizing efforts\nthrough a novel taxonomy and analyzing existing research. Our taxonomy\norganizes these efforts into four key topics: datasets, applications,\napproaches, and challenges. By providing a structured overview, this survey\noffers insights into the current state of Arabic MML, highlighting areas that\nhave not been investigated and critical research gaps. Researchers will be\nempowered to build upon the identified opportunities and address challenges to\nadvance the field.", "AI": {"tldr": "Comprehensive survey paper on Arabic Multimodal Machine Learning that categorizes research through a novel taxonomy covering datasets, applications, approaches, and challenges.", "motivation": "Arabic MML has reached foundational maturity, making it timely to conduct a comprehensive survey to structure the field and identify research gaps.", "method": "Develops a novel taxonomy organizing Arabic MML research into four key topics: datasets, applications, approaches, and challenges, providing a structured analysis of existing literature.", "result": "Provides a comprehensive overview of current Arabic MML state, identifies unexplored areas and critical research gaps, and offers insights for future research directions.", "conclusion": "This survey empowers researchers to build upon identified opportunities and address challenges to advance Arabic MML field development."}}
{"id": "2508.11976", "pdf": "https://arxiv.org/pdf/2508.11976", "abs": "https://arxiv.org/abs/2508.11976", "authors": ["Yunning Cao", "Lihong Pei", "Jian Guo", "Yang Cao", "Yu Kang", "Yanlong Zhao"], "title": "Set-Valued Transformer Network for High-Emission Mobile Source Identification", "categories": ["cs.LG"], "comment": null, "summary": "Identifying high-emission vehicles is a crucial step in regulating urban\npollution levels and formulating traffic emission reduction strategies.\nHowever, in practical monitoring data, the proportion of high-emission state\ndata is significantly lower compared to normal emission states. This\ncharacteristic long-tailed distribution severely impedes the extraction of\ndiscriminative features for emission state identification during data mining.\nFurthermore, the highly nonlinear nature of vehicle emission states and the\nlack of relevant prior knowledge also pose significant challenges to the\nconstruction of identification models.To address the aforementioned issues, we\npropose a Set-Valued Transformer Network (SVTN) to achieve comprehensive\nlearning of discriminative features from high-emission samples, thereby\nenhancing detection accuracy. Specifically, this model first employs the\ntransformer to measure the temporal similarity of micro-trip condition\nvariations, thus constructing a mapping rule that projects the original\nhigh-dimensional emission data into a low-dimensional feature space. Next, a\nset-valued identification algorithm is used to probabilistically model the\nrelationship between the generated feature vectors and their labels, providing\nan accurate metric criterion for the classification algorithm. To validate the\neffectiveness of our proposed approach, we conducted extensive experiments on\nthe diesel vehicle monitoring data of Hefei city in 2020. The results\ndemonstrate that our method achieves a 9.5\\% reduction in the missed detection\nrate for high-emission vehicles compared to the transformer-based baseline,\nhighlighting its superior capability in accurately identifying high-emission\nmobile pollution sources.", "AI": {"tldr": "Proposes Set-Valued Transformer Network (SVTN) to identify high-emission vehicles by addressing long-tailed data distribution and nonlinear emission patterns, achieving 9.5% reduction in missed detection rate.", "motivation": "High-emission vehicle identification is crucial for urban pollution regulation, but practical data shows long-tailed distribution with few high-emission samples, making feature extraction difficult. Nonlinear emission states and lack of prior knowledge further complicate model construction.", "method": "Uses transformer to measure temporal similarity of micro-trip condition variations, mapping high-dimensional emission data to low-dimensional feature space. Then applies set-valued identification algorithm to probabilistically model feature-label relationships for classification.", "result": "Experimental results on 2020 Hefei diesel vehicle data show 9.5% reduction in missed detection rate for high-emission vehicles compared to transformer baseline.", "conclusion": "SVTN effectively addresses long-tailed distribution challenges and improves detection accuracy for high-emission mobile pollution sources through comprehensive discriminative feature learning."}}
{"id": "2508.12338", "pdf": "https://arxiv.org/pdf/2508.12338", "abs": "https://arxiv.org/abs/2508.12338", "authors": ["Wenzhen Yuan", "Shengji Tang", "Weihao Lin", "Jiacheng Ruan", "Ganqu Cui", "Bo Zhang", "Tao Chen", "Ting Liu", "Yuzhuo Fu", "Peng Ye", "Lei Bai"], "title": "Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has significantly enhanced the reasoning\ncapabilities of large language models (LLMs), but its reliance on expensive\nhuman-labeled data or complex reward models severely limits scalability. While\nexisting self-feedback methods aim to address this problem, they are\nconstrained by the capabilities of a single model, which can lead to\noverconfidence in incorrect answers, reward hacking, and even training\ncollapse. To this end, we propose Reinforcement Learning from Coevolutionary\nCollective Feedback (RLCCF), a novel RL framework that enables multi-model\ncollaborative evolution without external supervision. Specifically, RLCCF\noptimizes the ability of a model collective by maximizing its Collective\nConsistency (CC), which jointly trains a diverse ensemble of LLMs and provides\nreward signals by voting on collective outputs. Moreover, each model's vote is\nweighted by its Self-Consistency (SC) score, ensuring that more confident\nmodels contribute more to the collective decision. Benefiting from the diverse\noutput distributions and complementary abilities of multiple LLMs, RLCCF\nenables the model collective to continuously enhance its reasoning ability\nthrough coevolution. Experiments on four mainstream open-source LLMs across\nfour mathematical reasoning benchmarks demonstrate that our framework yields\nsignificant performance gains, achieving an average relative improvement of\n16.72\\% in accuracy. Notably, RLCCF not only improves the performance of\nindividual models but also enhances the group's majority-voting accuracy by\n4.51\\%, demonstrating its ability to extend the collective capability boundary\nof the model collective.", "AI": {"tldr": "RLCCF is a novel reinforcement learning framework that enables multi-model collaborative evolution through collective consistency voting, eliminating the need for external supervision and addressing limitations of single-model self-feedback methods.", "motivation": "Traditional RL for LLMs relies on expensive human-labeled data or complex reward models, while existing self-feedback methods suffer from single-model limitations like overconfidence, reward hacking, and training collapse.", "method": "RLCCF optimizes model collective by maximizing Collective Consistency (CC), training a diverse ensemble of LLMs that provide reward signals through voting on outputs, with votes weighted by each model's Self-Consistency (SC) score.", "result": "Experiments on four LLMs across four mathematical reasoning benchmarks show 16.72% average relative accuracy improvement, with 4.51% enhancement in group majority-voting accuracy.", "conclusion": "RLCCF effectively enables continuous reasoning ability enhancement through coevolution, extends collective capability boundaries, and demonstrates significant performance gains without external supervision."}}
{"id": "2508.11955", "pdf": "https://arxiv.org/pdf/2508.11955", "abs": "https://arxiv.org/abs/2508.11955", "authors": ["Seunghun Lee", "Jiwan Seo", "Jeonghoon Kim", "Siwon Kim", "Haeun Yun", "Hyogyeong Jeon", "Wonhyeok Choi", "Jaehoon Jeong", "Zane Durante", "Sang Hyun Park", "Sunghoon Im"], "title": "SAMDWICH: Moment-aware Video-text Alignment for Referring Video Object Segmentation", "categories": ["cs.CV"], "comment": "Project page: https://seung-hun-lee.github.io/projects/SAMDWICH/", "summary": "Referring Video Object Segmentation (RVOS) aims to segment and track objects\nin videos based on natural language expressions, requiring precise alignment\nbetween visual content and textual queries. However, existing methods often\nsuffer from semantic misalignment, largely due to indiscriminate frame sampling\nand supervision of all visible objects during training -- regardless of their\nactual relevance to the expression. To address this, we introduce a\nmoment-aware RVOS framework named SAMDWICH, along with a newly annotated\ndataset, MeViS-M, built upon the challenging MeViS benchmark. We manually\nannotate temporal moments indicating when each object is referred to by the\nexpression, enabling semantically grounded supervision that strengthens\nvideo-text alignment. SAMDWICH leverages these aligned text-to-clip pairs to\nguide training, significantly enhancing referential understanding. Building\nupon this framework, we propose Moment-guided Dual-path Propagation (MDP), a\nmoment-aware propagation strategy that improves both object grounding and\ntracking by training on both relevant and irrelevant frames through a\nmoment-centric memory mechanism. In addition, we introduce Object-level\nSelective Supervision (OSS), an object-level filtering strategy that supervises\nonly the objects temporally aligned with the expression in each training clip.\nThis selective supervision reduces semantic noise and reinforces\nlanguage-conditioned learning. Extensive experiments show that SAMDWICH\nachieves state-of-the-art performance on challenging MeViS benchmark,\nparticularly excelling in complex scenarios involving diverse expressions.", "AI": {"tldr": "SAMDWICH introduces moment-aware RVOS framework with temporal moment annotations and selective supervision to address semantic misalignment in video object segmentation with language queries.", "motivation": "Existing RVOS methods suffer from semantic misalignment due to indiscriminate frame sampling and supervision of all visible objects regardless of their relevance to language expressions.", "method": "Proposes SAMDWICH framework with Moment-guided Dual-path Propagation (MDP) for moment-aware object grounding and tracking, and Object-level Selective Supervision (OSS) for filtering only temporally aligned objects. Uses newly annotated MeViS-M dataset with temporal moment annotations.", "result": "Achieves state-of-the-art performance on challenging MeViS benchmark, particularly excelling in complex scenarios with diverse expressions.", "conclusion": "The moment-aware framework with selective supervision significantly enhances video-text alignment and referential understanding in RVOS tasks."}}
{"id": "2508.12243", "pdf": "https://arxiv.org/pdf/2508.12243", "abs": "https://arxiv.org/abs/2508.12243", "authors": ["Wuttikorn Ponwitayarat", "Raymond Ng", "Jann Railey Montalan", "Thura Aung", "Jian Gang Ngui", "Yosephine Susanto", "William Tjhi", "Panuthep Tasawong", "Erik Cambria", "Ekapol Chuangsuwanich", "Sarana Nutanong", "Peerat Limkonchotiwat"], "title": "SEA-BED: Southeast Asia Embedding Benchmark", "categories": ["cs.CL"], "comment": null, "summary": "Sentence embeddings are essential for NLP tasks such as semantic search,\nre-ranking, and textual similarity. Although multilingual benchmarks like MMTEB\nbroaden coverage, Southeast Asia (SEA) datasets are scarce and often\nmachine-translated, missing native linguistic properties. With nearly 700\nmillion speakers, the SEA region lacks a region-specific embedding benchmark.\nWe introduce SEA-BED, the first large-scale SEA embedding benchmark with 169\ndatasets across 9 tasks and 10 languages, where 71% are formulated by humans,\nnot machine generation or translation. We address three research questions: (1)\nwhich SEA languages and tasks are challenging, (2) whether SEA languages show\nunique performance gaps globally, and (3) how human vs. machine translations\naffect evaluation. We evaluate 17 embedding models across six studies,\nanalyzing task and language challenges, cross-benchmark comparisons, and\ntranslation trade-offs. Results show sharp ranking shifts, inconsistent model\nperformance among SEA languages, and the importance of human-curated datasets\nfor low-resource languages like Burmese.", "AI": {"tldr": "SEA-BED is the first large-scale Southeast Asian embedding benchmark with 169 human-formulated datasets across 9 tasks and 10 languages, revealing significant performance gaps and ranking shifts for SEA languages compared to global benchmarks.", "motivation": "Southeast Asia has nearly 700 million speakers but lacks region-specific embedding benchmarks, with existing datasets often machine-translated and missing native linguistic properties.", "method": "Created SEA-BED benchmark with 169 datasets (71% human-formulated) across 9 tasks and 10 SEA languages, then evaluated 17 embedding models through six studies analyzing task challenges, cross-benchmark comparisons, and translation effects.", "result": "Results show sharp ranking shifts, inconsistent model performance among SEA languages, and demonstrate the critical importance of human-curated datasets for low-resource languages like Burmese.", "conclusion": "Human-curated benchmarks are essential for accurate evaluation of SEA languages, as machine-translated datasets fail to capture linguistic nuances, leading to significant performance measurement discrepancies."}}
{"id": "2508.11985", "pdf": "https://arxiv.org/pdf/2508.11985", "abs": "https://arxiv.org/abs/2508.11985", "authors": ["Zhanhao Cao", "Clement Truong", "Andrew Lizarraga"], "title": "Efficient Modular Learning through Naive LoRA Summation: Leveraging Orthogonality in High-Dimensional Models", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Recent advances in large language models are driven by scale, while\nparameter-efficient fine-tuning (PEFT) enables updating only a small fraction\nof parameters. Low-Rank Adaptation (LoRA) stores parameter deltas as the\nproduct of two small matrices, which makes them natural building blocks that\ncan be composed. Motivated by the superposition principle, we hypothesize that\nindependently trained LoRA modules on disjoint domains are approximately\northogonal and can be combined by simple addition. Using GPT-2 Small (117M)\nwith LoRA rank 4 and alpha=64, we train adapters for three QA domains (math,\nmedicine, finance). In pairwise tests, adding Math+Medicine adapters improves\nperplexity by -9.10% relative to merged-data fine-tuning, while Math+Finance\nand Finance+Medicine change by +4.54% and +27.56%, respectively. Across\ncombinations, the RMS cosine similarity between LoRA deltas correlates\npositively and approximately linearly with the change in perplexity. Naive\nsummation requires no additional training, can be applied in seconds, and\nachieves performance comparable to models trained on merged data, while\nclarifying when interference appears in higher-order compositions.", "AI": {"tldr": "LoRA adapters trained on disjoint domains can be combined through simple addition with performance comparable to merged-data fine-tuning, requiring no additional training.", "motivation": "To enable efficient combination of independently trained parameter-efficient fine-tuning modules (LoRA) across different domains without additional training.", "method": "Train LoRA adapters (rank 4, alpha=64) on GPT-2 Small for three QA domains (math, medicine, finance) and combine them through naive summation of parameter deltas.", "result": "Math+Medicine combination improved perplexity by -9.10% relative to merged-data fine-tuning, while Math+Finance and Finance+Medicine showed +4.54% and +27.56% changes respectively. RMS cosine similarity between LoRA deltas correlates linearly with perplexity changes.", "conclusion": "LoRA modules can be efficiently combined via addition with performance comparable to merged-data training, while revealing interference patterns in higher-order compositions through cosine similarity analysis."}}
{"id": "2508.12375", "pdf": "https://arxiv.org/pdf/2508.12375", "abs": "https://arxiv.org/abs/2508.12375", "authors": ["Yu Sha", "Shuiping Gou", "Bo Liu", "Johannes Faber", "Ningtao Liu", "Stefan Schramm", "Horst Stoecker", "Thomas Steckenreiter", "Domagoj Vnucec", "Nadine Wetzstein", "Andreas Widl", "Kai Zhou"], "title": "Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems", "categories": ["cs.AI"], "comment": "12 pages", "summary": "Fault intensity diagnosis (FID) plays a pivotal role in monitoring and\nmaintaining mechanical devices within complex industrial systems. As current\nFID methods are based on chain of thought without considering dependencies\namong target classes. To capture and explore dependencies, we propose a\nhierarchical knowledge guided fault intensity diagnosis framework (HKG)\ninspired by the tree of thought, which is amenable to any representation\nlearning methods. The HKG uses graph convolutional networks to map the\nhierarchical topological graph of class representations into a set of\ninterdependent global hierarchical classifiers, where each node is denoted by\nword embeddings of a class. These global hierarchical classifiers are applied\nto learned deep features extracted by representation learning, allowing the\nentire model to be end-to-end learnable. In addition, we develop a re-weighted\nhierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding\ninter-class hierarchical knowledge into a data-driven statistical correlation\nmatrix (SCM) which effectively guides the information sharing of nodes in\ngraphical convolutional neural networks and avoids over-smoothing issues. The\nRe-HKCM is derived from the SCM through a series of mathematical\ntransformations. Extensive experiments are performed on four real-world\ndatasets from different industrial domains (three cavitation datasets from\nSAMSON AG and one existing publicly) for FID, all showing superior results and\noutperform recent state-of-the-art FID methods.", "AI": {"tldr": "Proposes HKG framework with hierarchical classifiers and Re-HKCM scheme for fault intensity diagnosis, achieving state-of-the-art results on industrial datasets.", "motivation": "Current FID methods use chain of thought without considering dependencies among target classes, limiting their effectiveness in capturing complex inter-class relationships.", "method": "Hierarchical knowledge guided framework (HKG) using graph convolutional networks to map hierarchical topological graphs into interdependent global hierarchical classifiers, combined with re-weighted hierarchical knowledge correlation matrix (Re-HKCM) scheme.", "result": "Extensive experiments on four real-world industrial datasets show superior performance, outperforming recent state-of-the-art FID methods across different industrial domains.", "conclusion": "The proposed HKG framework with Re-HKCM effectively captures class dependencies and hierarchical knowledge, providing an end-to-end learnable solution that addresses over-smoothing issues and achieves excellent fault intensity diagnosis performance."}}
{"id": "2508.11961", "pdf": "https://arxiv.org/pdf/2508.11961", "abs": "https://arxiv.org/abs/2508.11961", "authors": ["Yuanbin Fu", "Liang Li", "Xiaojie Guo"], "title": "PEdger++: Practical Edge Detection via Assembling Cross Information", "categories": ["cs.CV"], "comment": null, "summary": "Edge detection serves as a critical foundation for numerous computer vision\napplications, including object detection, semantic segmentation, and image\nediting, by extracting essential structural cues that define object boundaries\nand salient edges. To be viable for broad deployment across devices with\nvarying computational capacities, edge detectors shall balance high accuracy\nwith low computational complexity. While deep learning has evidently improved\naccuracy, they often suffer from high computational costs, limiting their\napplicability on resource-constrained devices. This paper addresses the\nchallenge of achieving that balance: \\textit{i.e.}, {how to efficiently capture\ndiscriminative features without relying on large-size and sophisticated\nmodels}. We propose PEdger++, a collaborative learning framework designed to\nreduce computational costs and model sizes while improving edge detection\naccuracy. The core principle of our PEdger++ is that cross-information derived\nfrom heterogeneous architectures, diverse training moments, and multiple\nparameter samplings, is beneficial to enhance learning from an ensemble\nperspective. Extensive experimental results on the BSDS500, NYUD and Multicue\ndatasets demonstrate the effectiveness of our approach, both quantitatively and\nqualitatively, showing clear improvements over existing methods. We also\nprovide multiple versions of the model with varying computational requirements,\nhighlighting PEdger++'s adaptability with respect to different resource\nconstraints. Codes are accessible at\nhttps://github.com/ForawardStar/EdgeDetectionviaPEdgerPlus/.", "AI": {"tldr": "PEdger++ is a collaborative learning framework for efficient edge detection that balances accuracy and computational efficiency by leveraging cross-information from heterogeneous architectures, training moments, and parameter samplings.", "motivation": "Edge detection is crucial for computer vision applications but existing deep learning methods suffer from high computational costs, limiting deployment on resource-constrained devices. The paper aims to achieve high accuracy with low computational complexity.", "method": "Proposes PEdger++, a collaborative learning framework that extracts cross-information from heterogeneous architectures, diverse training moments, and multiple parameter samplings to enhance learning from an ensemble perspective.", "result": "Extensive experiments on BSDS500, NYUD and Multicue datasets show clear improvements over existing methods both quantitatively and qualitatively, with multiple model versions available for different computational requirements.", "conclusion": "PEdger++ effectively balances edge detection accuracy with computational efficiency, demonstrating adaptability to various resource constraints through its collaborative learning approach and ensemble-based feature extraction."}}
{"id": "2508.12255", "pdf": "https://arxiv.org/pdf/2508.12255", "abs": "https://arxiv.org/abs/2508.12255", "authors": ["Ankita Pasad"], "title": "What do Speech Foundation Models Learn? Analysis and Applications", "categories": ["cs.CL", "eess.AS"], "comment": "Ph.D. Thesis", "summary": "Speech foundation models (SFMs) are designed to serve as general-purpose\nrepresentations for a wide range of speech-processing tasks. The last five\nyears have seen an influx of increasingly successful self-supervised and\nsupervised pre-trained models with impressive performance on various downstream\ntasks.\n  Although the zoo of SFMs continues to grow, our understanding of the\nknowledge they acquire lags behind. This thesis presents a lightweight analysis\nframework using statistical tools and training-free tasks to investigate the\nacoustic and linguistic knowledge encoded in SFM layers. We conduct a\ncomparative study across multiple SFMs and statistical tools. Our study also\nshows that the analytical insights have concrete implications for downstream\ntask performance.\n  The effectiveness of an SFM is ultimately determined by its performance on\nspeech applications. Yet it remains unclear whether the benefits extend to\nspoken language understanding (SLU) tasks that require a deeper understanding\nthan widely studied ones, such as speech recognition. The limited exploration\nof SLU is primarily due to a lack of relevant datasets. To alleviate that, this\nthesis contributes tasks, specifically spoken named entity recognition (NER)\nand named entity localization (NEL), to the Spoken Language Understanding\nEvaluation benchmark. We develop SFM-based approaches for NER and NEL, and find\nthat end-to-end (E2E) models leveraging SFMs can surpass traditional cascaded\n(speech recognition followed by a text model) approaches. Further, we evaluate\nE2E SLU models across SFMs and adaptation strategies to assess the impact on\ntask performance.\n  Collectively, this thesis tackles previously unanswered questions about SFMs,\nproviding tools and datasets to further our understanding and to enable the\ncommunity to make informed design choices for future model development and\nadoption.", "AI": {"tldr": "This thesis analyzes speech foundation models (SFMs) through statistical analysis and introduces new spoken language understanding tasks (NER/NEL) to evaluate SFM performance, showing end-to-end models can outperform traditional cascaded approaches.", "motivation": "Despite the proliferation of speech foundation models, there's limited understanding of what knowledge they acquire and how they perform on complex spoken language understanding tasks beyond basic speech recognition.", "method": "Developed a lightweight analysis framework using statistical tools and training-free tasks to investigate acoustic/linguistic knowledge in SFM layers. Created spoken NER and NEL tasks for SLU evaluation and developed SFM-based approaches for these tasks.", "result": "Comparative study across multiple SFMs revealed analytical insights with concrete implications for downstream performance. End-to-end models leveraging SFMs surpassed traditional cascaded approaches for spoken NER and NEL tasks.", "conclusion": "The thesis provides tools and datasets to better understand SFMs and enables informed design choices for future model development, addressing previously unanswered questions about SFM capabilities and knowledge representation."}}
{"id": "2508.11990", "pdf": "https://arxiv.org/pdf/2508.11990", "abs": "https://arxiv.org/abs/2508.11990", "authors": ["Evan Dogariu", "Anand Brahmbhatt", "Elad Hazan"], "title": "Universal Learning of Nonlinear Dynamics", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "We study the fundamental problem of learning a marginally stable unknown\nnonlinear dynamical system. We describe an algorithm for this problem, based on\nthe technique of spectral filtering, which learns a mapping from past\nobservations to the next based on a spectral representation of the system.\nUsing techniques from online convex optimization, we prove vanishing prediction\nerror for any nonlinear dynamical system that has finitely many marginally\nstable modes, with rates governed by a novel quantitative control-theoretic\nnotion of learnability. The main technical component of our method is a new\nspectral filtering algorithm for linear dynamical systems, which incorporates\npast observations and applies to general noisy and marginally stable systems.\nThis significantly generalizes the original spectral filtering algorithm to\nboth asymmetric dynamics as well as incorporating noise correction, and is of\nindependent interest.", "AI": {"tldr": "A spectral filtering algorithm for learning marginally stable nonlinear dynamical systems with vanishing prediction error and novel learnability rates.", "motivation": "To address the fundamental problem of learning unknown nonlinear dynamical systems that are marginally stable, which is challenging due to the system's stability properties and potential noise.", "method": "Develops a spectral filtering algorithm that learns mappings from past observations to future states using spectral representation, incorporating techniques from online convex optimization and extending to handle asymmetric dynamics and noise correction.", "result": "Achieves vanishing prediction error for nonlinear dynamical systems with finitely many marginally stable modes, with rates governed by a novel quantitative control-theoretic notion of learnability.", "conclusion": "The proposed spectral filtering method significantly generalizes previous approaches to handle more complex dynamical systems and provides theoretical guarantees for learning performance."}}
{"id": "2508.12379", "pdf": "https://arxiv.org/pdf/2508.12379", "abs": "https://arxiv.org/abs/2508.12379", "authors": ["Rongzheng Wang", "Qizhi Chen", "Yihong Huang", "Yizhuo Ma", "Muquan Li", "Jiakai Li", "Ke Qin", "Guangchun Luo", "Shuang Liang"], "title": "GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) show promising performance on small-scale graph\nreasoning tasks but fail when handling real-world graphs with complex queries.\nThis phenomenon stems from LLMs' inability to effectively process complex graph\ntopology and perform multi-step reasoning simultaneously. To address these\nlimitations, we propose GraphCogent, a collaborative agent framework inspired\nby human Working Memory Model that decomposes graph reasoning into specialized\ncognitive processes: sense, buffer, and execute. The framework consists of\nthree modules: Sensory Module standardizes diverse graph text representations\nvia subgraph sampling, Buffer Module integrates and indexes graph data across\nmultiple formats, and Execution Module combines tool calling and model\ngeneration for efficient reasoning. We also introduce Graph4real, a\ncomprehensive benchmark contains with four domains of real-world graphs (Web,\nSocial, Transportation, and Citation) to evaluate LLMs' graph reasoning\ncapabilities. Our Graph4real covers 21 different graph reasoning tasks,\ncategorized into three types (Structural Querying, Algorithmic Reasoning, and\nPredictive Modeling tasks), with graph scales that are 10 times larger than\nexisting benchmarks. Experiments show that Llama3.1-8B based GraphCogent\nachieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B).\nCompared to state-of-the-art agent-based baseline, our framework outperforms by\n20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30%\nfor out-toolset tasks. Code will be available after review.", "AI": {"tldr": "GraphCogent is a collaborative agent framework that decomposes graph reasoning into specialized cognitive processes (sense, buffer, execute) to address LLMs' limitations in handling complex graph topology and multi-step reasoning on real-world graphs.", "motivation": "Large language models perform well on small-scale graph reasoning tasks but fail with complex real-world graphs due to inability to process complex graph topology and perform multi-step reasoning simultaneously.", "method": "Proposed GraphCogent framework with three modules: Sensory Module for standardizing graph representations via subgraph sampling, Buffer Module for integrating and indexing graph data across formats, and Execution Module combining tool calling and model generation for efficient reasoning.", "result": "Llama3.1-8B based GraphCogent achieves 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B), outperforms state-of-the-art agent-based baseline by 20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30% for out-toolset tasks.", "conclusion": "GraphCogent effectively addresses LLMs' limitations in graph reasoning through a collaborative agent framework inspired by human working memory model, demonstrating significant performance improvements and efficiency gains on large-scale real-world graphs."}}
{"id": "2508.11988", "pdf": "https://arxiv.org/pdf/2508.11988", "abs": "https://arxiv.org/abs/2508.11988", "authors": ["Nicolas Mastropasqua", "Ignacio Bugueno-Cordova", "Rodrigo Verschae", "Daniel Acevedo", "Pablo Negri", "Maria E. Buemi"], "title": "Exploring Spatial-Temporal Dynamics in Event-based Facial Micro-Expression Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Micro-expression analysis has applications in domains such as Human-Robot\nInteraction and Driver Monitoring Systems. Accurately capturing subtle and fast\nfacial movements remains difficult when relying solely on RGB cameras, due to\nlimitations in temporal resolution and sensitivity to motion blur. Event\ncameras offer an alternative, with microsecond-level precision, high dynamic\nrange, and low latency. However, public datasets featuring event-based\nrecordings of Action Units are still scarce. In this work, we introduce a\nnovel, preliminary multi-resolution and multi-modal micro-expression dataset\nrecorded with synchronized RGB and event cameras under variable lighting\nconditions. Two baseline tasks are evaluated to explore the spatial-temporal\ndynamics of micro-expressions: Action Unit classification using Spiking Neural\nNetworks (51.23\\% accuracy with events vs. 23.12\\% with RGB), and frame\nreconstruction using Conditional Variational Autoencoders, achieving SSIM =\n0.8513 and PSNR = 26.89 dB with high-resolution event input. These promising\nresults show that event-based data can be used for micro-expression recognition\nand frame reconstruction.", "AI": {"tldr": "A novel multi-modal micro-expression dataset with synchronized RGB and event cameras shows event-based data significantly outperforms RGB for Action Unit classification (51.23% vs 23.12%) and achieves high-quality frame reconstruction.", "motivation": "Micro-expression analysis is valuable for applications like Human-Robot Interaction and Driver Monitoring Systems, but RGB cameras struggle with capturing subtle, fast facial movements due to temporal resolution limitations and motion blur.", "method": "Created a multi-resolution, multi-modal dataset with synchronized RGB and event cameras under variable lighting conditions. Evaluated two baseline tasks: Action Unit classification using Spiking Neural Networks and frame reconstruction using Conditional Variational Autoencoders.", "result": "Event-based data achieved 51.23% accuracy for Action Unit classification vs 23.12% with RGB, and frame reconstruction achieved SSIM = 0.8513 and PSNR = 26.89 dB with high-resolution event input.", "conclusion": "Event cameras show promising results for micro-expression recognition and frame reconstruction, outperforming traditional RGB cameras due to their microsecond-level precision, high dynamic range, and low latency."}}
{"id": "2508.12257", "pdf": "https://arxiv.org/pdf/2508.12257", "abs": "https://arxiv.org/abs/2508.12257", "authors": ["Zheye Deng", "Chunkit Chan", "Tianshi Zheng", "Wei Fan", "Weiqi Wang", "Yangqiu Song"], "title": "Structuring the Unstructured: A Systematic Review of Text-to-Structure Generation for Agentic AI with a Universal Evaluation Framework", "categories": ["cs.CL"], "comment": "Under Review", "summary": "The evolution of AI systems toward agentic operation and context-aware\nretrieval necessitates transforming unstructured text into structured formats\nlike tables, knowledge graphs, and charts. While such conversions enable\ncritical applications from summarization to data mining, current research lacks\na comprehensive synthesis of methodologies, datasets, and metrics. This\nsystematic review examines text-to-structure techniques and the encountered\nchallenges, evaluates current datasets and assessment criteria, and outlines\npotential directions for future research. We also introduce a universal\nevaluation framework for structured outputs, establishing text-to-structure as\nfoundational infrastructure for next-generation AI systems.", "AI": {"tldr": "Systematic review of text-to-structure conversion techniques, evaluating methodologies, datasets, metrics, and proposing a universal evaluation framework for structured outputs.", "motivation": "AI systems are evolving toward agentic operation and context-aware retrieval, requiring transformation of unstructured text into structured formats like tables, knowledge graphs, and charts for applications from summarization to data mining, but current research lacks comprehensive synthesis.", "method": "Systematic review examining text-to-structure techniques, challenges, current datasets, assessment criteria, and outlining future research directions.", "result": "The review provides comprehensive synthesis of methodologies and introduces a universal evaluation framework for structured outputs.", "conclusion": "Text-to-structure conversion is established as foundational infrastructure for next-generation AI systems, with proposed evaluation framework and future research directions."}}
{"id": "2508.12021", "pdf": "https://arxiv.org/pdf/2508.12021", "abs": "https://arxiv.org/abs/2508.12021", "authors": ["You Hak Lee", "Xiaofan Yu", "Quanling Zhao", "Flavio Ponzina", "Tajana Rosing"], "title": "FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing", "categories": ["cs.LG", "cs.AR", "cs.DC"], "comment": null, "summary": "Unsupervised federated learning (UFL) has gained attention as a\nprivacy-preserving, decentralized machine learning approach that eliminates the\nneed for labor-intensive data labeling. However, UFL faces several challenges\nin practical applications: (1) non-independent and identically distributed\n(non-iid) data distribution across devices, (2) expensive computational and\ncommunication costs at the edge, and (3) vulnerability to communication noise.\nPrevious UFL approaches have relied on deep neural networks (NN), which\nintroduce substantial overhead in both computation and communication. In this\npaper, we propose FedUHD, the first UFL framework based on Hyperdimensional\nComputing (HDC). HDC is a brain-inspired computing scheme with lightweight\ntraining and inference operations, much smaller model size, and robustness to\ncommunication noise. FedUHD introduces two novel HDC-based designs to improve\nUFL performance. On the client side, a kNN-based cluster hypervector removal\nmethod addresses non-iid data samples by eliminating detrimental outliers. On\nthe server side, a weighted HDC aggregation technique balances the non-iid data\ndistribution across clients. Our experiments demonstrate that FedUHD achieves\nup to 173.6x and 612.7x better speedup and energy efficiency, respectively, in\ntraining, up to 271x lower communication cost, and 15.50% higher accuracy on\naverage across diverse settings, along with superior robustness to various\ntypes of noise compared to state-of-the-art NN-based UFL approaches.", "AI": {"tldr": "FedUHD is the first unsupervised federated learning framework using Hyperdimensional Computing, achieving massive speedup, energy efficiency, and noise robustness while handling non-iid data challenges.", "motivation": "Address challenges in unsupervised federated learning including non-iid data distribution, high computational/communication costs, and vulnerability to noise, while eliminating dependency on deep neural networks.", "method": "Proposes FedUHD framework with HDC-based designs: client-side kNN cluster hypervector removal for outlier elimination, and server-side weighted HDC aggregation for balancing non-iid data distribution.", "result": "Achieves up to 173.6x speedup, 612.7x better energy efficiency, 271x lower communication cost, 15.50% higher accuracy on average, and superior noise robustness compared to state-of-the-art NN-based approaches.", "conclusion": "HDC-based FedUHD provides an efficient, robust, and accurate solution for unsupervised federated learning with significant advantages over traditional neural network approaches."}}
{"id": "2508.12425", "pdf": "https://arxiv.org/pdf/2508.12425", "abs": "https://arxiv.org/abs/2508.12425", "authors": ["Phuong Minh Nguyen", "Tien Huu Dang", "Naoya Inoue"], "title": "Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved\napproach to standard CoT, for logical reasoning in large language models\n(LLMs). The key idea is to integrate lightweight symbolic representations into\nfew-shot prompts, structuring the inference steps with a consistent strategy to\nmake reasoning patterns more explicit within a non-iterative reasoning process.\nBy incorporating these symbolic structures, our method preserves the\ngeneralizability of standard prompting techniques while enhancing the\ntransparency, interpretability, and analyzability of LLM logical reasoning.\nExtensive experiments on four well-known logical reasoning benchmarks --\nProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse\nreasoning scenarios -- demonstrate the effectiveness of the proposed approach,\nparticularly in complex reasoning tasks that require navigating multiple\nconstraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'\nreasoning capabilities across various model sizes and significantly outperforms\nconventional CoT on three out of four datasets, ProofWriter, ProntoQA, and\nLogicalDeduction.", "AI": {"tldr": "Symbolic-Aided CoT enhances standard Chain-of-Thought reasoning by integrating lightweight symbolic representations into few-shot prompts, improving LLM logical reasoning transparency and performance on complex tasks.", "motivation": "To address limitations in standard Chain-of-Thought reasoning by making reasoning patterns more explicit and improving transparency, interpretability, and analyzability of LLM logical reasoning while maintaining generalizability.", "method": "Integrates lightweight symbolic representations into few-shot prompts to structure inference steps with a consistent strategy within a non-iterative reasoning process.", "result": "Significantly outperforms conventional CoT on three out of four datasets (ProofWriter, ProntoQA, LogicalDeduction), consistently improves reasoning capabilities across various model sizes, and shows particular effectiveness in complex reasoning tasks requiring multiple constraints/rules.", "conclusion": "Symbolic-Aided CoT effectively enhances LLM logical reasoning by combining symbolic structures with standard prompting techniques, demonstrating superior performance on complex reasoning benchmarks while maintaining transparency and interpretability."}}
{"id": "2508.11999", "pdf": "https://arxiv.org/pdf/2508.11999", "abs": "https://arxiv.org/abs/2508.11999", "authors": ["Daoze Zhang", "Zhanheng Nie", "Jianyu Liu", "Chenghan Fu", "Wanxian Guan", "Yuan Gao", "Jun Song", "Pengjie Wang", "Jian Xu", "Bo Zheng"], "title": "MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding", "categories": ["cs.CV", "cs.AI", "cs.IR", "cs.LG"], "comment": "11 pages, 9 figures", "summary": "With the rapid advancement of e-commerce, exploring general representations\nrather than task-specific ones has attracted increasing research attention. For\nproduct understanding, although existing discriminative dual-flow architectures\ndrive progress in this field, they inherently struggle to model the many-to-one\nalignment between multiple images and texts of products. Therefore, we argue\nthat generative Multimodal Large Language Models (MLLMs) hold significant\npotential for improving product representation learning. Nevertheless,\nachieving this goal still remains non-trivial due to several key challenges:\nthe lack of multimodal and aspect-aware modeling modules in typical LLMs; the\ncommon presence of background noise in product images; and the absence of a\nstandard benchmark for evaluation. To address these issues, we propose the\nfirst generative MLLM-based model named MOON for product representation\nlearning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for\ntargeted modeling of multimodal and aspect-specific product content; (2)\neffectively detects core semantic regions in product images to mitigate the\ndistraction and interference caused by background noise; and (3) introduces the\nspecialized negative sampling strategy to increase the difficulty and diversity\nof negative samples. In addition, we release a large-scale multimodal benchmark\nMBE for various product understanding tasks. Experimentally, our model\ndemonstrates competitive zero-shot performance on both our benchmark and the\npublic dataset, showcasing strong generalization across various downstream\ntasks, including cross-modal retrieval, product classification, and attribute\nprediction. Furthermore, the case study and visualization illustrate the\neffectiveness of MOON for product understanding.", "AI": {"tldr": "MOON is the first generative MLLM-based model for product representation learning that addresses multimodal alignment challenges through guided MoE modules, background noise mitigation, and specialized negative sampling, achieving strong zero-shot performance across various product understanding tasks.", "motivation": "Existing discriminative dual-flow architectures struggle with many-to-one alignment between multiple product images and texts, while generative MLLMs show potential but face challenges including lack of multimodal modeling modules, background noise in images, and absence of standardized benchmarks.", "method": "Proposes MOON with: (1) guided Mixture-of-Experts module for multimodal and aspect-specific content modeling, (2) core semantic region detection to mitigate background noise, and (3) specialized negative sampling strategy for increased difficulty and diversity. Also releases MBE benchmark.", "result": "Demonstrates competitive zero-shot performance on both the new MBE benchmark and public datasets, with strong generalization across cross-modal retrieval, product classification, and attribute prediction tasks. Case studies and visualizations confirm effectiveness.", "conclusion": "MOON successfully addresses key challenges in product representation learning through generative MLLM approach, showing significant potential for improving product understanding with robust generalization capabilities across multiple downstream tasks."}}
{"id": "2508.12265", "pdf": "https://arxiv.org/pdf/2508.12265", "abs": "https://arxiv.org/abs/2508.12265", "authors": ["Xinda Jia", "Jinpeng Li", "Zezhong Wang", "Jingjing Li", "Xingshan Zeng", "Yasheng Wang", "Weinan Zhang", "Yong Yu", "Weiwen Liu"], "title": "Fast, Slow, and Tool-augmented Thinking for LLMs: A Review", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable progress in\nreasoning across diverse domains. However, effective reasoning in real-world\ntasks requires adapting the reasoning strategy to the demands of the problem,\nranging from fast, intuitive responses to deliberate, step-by-step reasoning\nand tool-augmented thinking. Drawing inspiration from cognitive psychology, we\npropose a novel taxonomy of LLM reasoning strategies along two knowledge\nboundaries: a fast/slow boundary separating intuitive from deliberative\nprocesses, and an internal/external boundary distinguishing reasoning grounded\nin the model's parameters from reasoning augmented by external tools. We\nsystematically survey recent work on adaptive reasoning in LLMs and categorize\nmethods based on key decision factors. We conclude by highlighting open\nchallenges and future directions toward more adaptive, efficient, and reliable\nLLMs.", "AI": {"tldr": "A taxonomy of LLM reasoning strategies based on cognitive psychology principles, categorizing approaches along fast/slow and internal/external knowledge boundaries.", "motivation": "Real-world reasoning requires adapting strategies to problem demands, from intuitive responses to deliberate step-by-step reasoning and tool-augmented thinking.", "method": "Proposed taxonomy with two dimensions: fast/slow boundary (intuitive vs deliberative) and internal/external boundary (parameter-based vs tool-augmented reasoning), followed by systematic survey of adaptive reasoning methods.", "result": "A comprehensive categorization framework for LLM reasoning strategies that helps organize and understand different adaptive reasoning approaches.", "conclusion": "Highlights open challenges and future directions for developing more adaptive, efficient, and reliable LLMs through better reasoning strategy selection."}}
{"id": "2508.12042", "pdf": "https://arxiv.org/pdf/2508.12042", "abs": "https://arxiv.org/abs/2508.12042", "authors": ["Zahra Kharaghani", "Ali Dadras", "Tommy L\u00f6fstedt"], "title": "Fairness Regularization in Federated Learning", "categories": ["cs.LG"], "comment": "25 pages", "summary": "Federated Learning (FL) has emerged as a vital paradigm in modern machine\nlearning that enables collaborative training across decentralized data sources\nwithout exchanging raw data. This approach not only addresses privacy concerns\nbut also allows access to overall substantially larger and potentially more\ndiverse datasets, without the need for centralized storage or hardware\nresources. However, heterogeneity in client data may cause certain clients to\nhave disproportionate impacts on the global model, leading to disparities in\nthe clients' performances. Fairness, therefore, becomes a crucial concern in FL\nand can be addressed in various ways. However, the effectiveness of existing\nfairness-aware methods, particularly in heterogeneous data settings, remains\nunclear, and the relationships between different approaches are not well\nunderstood. In this work, we focus on performance equitable fairness, which\naims to minimize differences in performance across clients. We restrict our\nstudy to fairness-aware methods that explicitly regularize client losses,\nevaluating both existing and newly proposed approaches. We identify and\ntheoretically explain connections between the investigated fairness methods,\nand empirically show that FairGrad (approximate) and FairGrad* (exact) (two\nvariants of a gradient variance regularization method introduced here for\nperformance equitable fairness) improve both fairness and overall model\nperformance in heterogeneous data settings.", "AI": {"tldr": "This paper analyzes fairness methods in Federated Learning, introduces FairGrad variants for performance equity, and shows they improve both fairness and model performance in heterogeneous data settings.", "motivation": "Federated Learning faces fairness issues due to data heterogeneity causing disproportionate client impacts on the global model, but existing fairness methods' effectiveness remains unclear.", "method": "Focuses on performance equitable fairness methods that regularize client losses, introduces FairGrad and FairGrad* (gradient variance regularization variants), and provides theoretical analysis of connections between fairness approaches.", "result": "FairGrad and FairGrad* improve both fairness (minimizing performance differences across clients) and overall model performance in heterogeneous data settings.", "conclusion": "The proposed FairGrad variants effectively address performance equity in FL, demonstrating superior results compared to existing fairness-aware methods in heterogeneous environments."}}
{"id": "2508.12472", "pdf": "https://arxiv.org/pdf/2508.12472", "abs": "https://arxiv.org/abs/2508.12472", "authors": ["Yifang Tian", "Yaming Liu", "Zichun Chong", "Zihang Huang", "Hans-Arno Jacobsen"], "title": "GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?", "categories": ["cs.AI"], "comment": "12 pages, 5 figures", "summary": "Root cause analysis (RCA) in microservice systems is challenging, requiring\non-call engineers to rapidly diagnose failures across heterogeneous telemetry\nsuch as metrics, logs, and traces. Traditional RCA methods often focus on\nsingle modalities or merely rank suspect services, falling short of providing\nactionable diagnostic insights with remediation guidance. This paper introduces\nGALA, a novel multi-modal framework that combines statistical causal inference\nwith LLM-driven iterative reasoning for enhanced RCA. Evaluated on an\nopen-source benchmark, GALA achieves substantial improvements over\nstate-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM\nevaluation score shows GALA generates significantly more causally sound and\nactionable diagnostic outputs than existing methods. Through comprehensive\nexperiments and a case study, we show that GALA bridges the gap between\nautomated failure diagnosis and practical incident resolution by providing both\naccurate root cause identification and human-interpretable remediation\nguidance.", "AI": {"tldr": "GALA is a multi-modal framework that combines statistical causal inference with LLM-driven reasoning for root cause analysis in microservices, achieving 42.22% higher accuracy than state-of-the-art methods and providing actionable diagnostic insights with remediation guidance.", "motivation": "Traditional RCA methods in microservice systems focus on single modalities or only rank suspect services, failing to provide actionable diagnostic insights and remediation guidance needed for practical incident resolution.", "method": "GALA combines statistical causal inference with LLM-driven iterative reasoning in a multi-modal framework that analyzes heterogeneous telemetry data (metrics, logs, traces) for enhanced root cause analysis.", "result": "GALA achieves substantial improvements of up to 42.22% accuracy over state-of-the-art methods on an open-source benchmark, and generates significantly more causally sound and actionable diagnostic outputs according to novel human-guided LLM evaluation.", "conclusion": "GALA bridges the gap between automated failure diagnosis and practical incident resolution by providing both accurate root cause identification and human-interpretable remediation guidance, representing a significant advancement in microservice RCA."}}
{"id": "2508.12015", "pdf": "https://arxiv.org/pdf/2508.12015", "abs": "https://arxiv.org/abs/2508.12015", "authors": ["Hongyuan Liu", "Haochen Yu", "Jianfei Jiang", "Qiankun Liu", "Jiansheng Chen", "Huimin Ma"], "title": "InstDrive: Instance-Aware 3D Gaussian Splatting for Driving Scenes", "categories": ["cs.CV"], "comment": null, "summary": "Reconstructing dynamic driving scenes from dashcam videos has attracted\nincreasing attention due to its significance in autonomous driving and scene\nunderstanding. While recent advances have made impressive progress, most\nmethods still unify all background elements into a single representation,\nhindering both instance-level understanding and flexible scene editing. Some\napproaches attempt to lift 2D segmentation into 3D space, but often rely on\npre-processed instance IDs or complex pipelines to map continuous features to\ndiscrete identities. Moreover, these methods are typically designed for indoor\nscenes with rich viewpoints, making them less applicable to outdoor driving\nscenarios. In this paper, we present InstDrive, an instance-aware 3D Gaussian\nSplatting framework tailored for the interactive reconstruction of dynamic\ndriving scene. We use masks generated by SAM as pseudo ground-truth to guide 2D\nfeature learning via contrastive loss and pseudo-supervised objectives. At the\n3D level, we introduce regularization to implicitly encode instance identities\nand enforce consistency through a voxel-based loss. A lightweight static\ncodebook further bridges continuous features and discrete identities without\nrequiring data pre-processing or complex optimization. Quantitative and\nqualitative experiments demonstrate the effectiveness of InstDrive, and to the\nbest of our knowledge, it is the first framework to achieve 3D instance\nsegmentation in dynamic, open-world driving scenes.More visualizations are\navailable at our project page.", "AI": {"tldr": "InstDrive is an instance-aware 3D Gaussian Splatting framework for dynamic driving scene reconstruction that uses SAM masks as pseudo ground-truth and introduces regularization to encode instance identities without complex preprocessing.", "motivation": "Current methods unify background elements into single representations, hindering instance-level understanding and scene editing. Existing approaches rely on pre-processed IDs or complex pipelines and are designed for indoor scenes, making them unsuitable for outdoor driving scenarios.", "method": "Uses SAM-generated masks as pseudo ground-truth for 2D feature learning via contrastive loss. Introduces 3D regularization to implicitly encode instance identities with voxel-based loss consistency. Employs lightweight static codebook to bridge continuous features and discrete identities without preprocessing.", "result": "Quantitative and qualitative experiments demonstrate effectiveness. First framework to achieve 3D instance segmentation in dynamic, open-world driving scenes.", "conclusion": "InstDrive successfully addresses limitations of existing methods by providing instance-aware reconstruction for dynamic driving scenes without complex preprocessing, enabling better scene understanding and editing capabilities."}}
{"id": "2508.12277", "pdf": "https://arxiv.org/pdf/2508.12277", "abs": "https://arxiv.org/abs/2508.12277", "authors": ["Elon Ezra", "Ariel Weizman", "Amos Azaria"], "title": "The Self-Execution Benchmark: Measuring LLMs' Attempts to Overcome Their Lack of Self-Execution", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 9 figures", "summary": "Large language models (LLMs) are commonly evaluated on tasks that test their\nknowledge or reasoning abilities. In this paper, we explore a different type of\nevaluation: whether an LLM can predict aspects of its own responses. Since LLMs\nlack the ability to execute themselves, we introduce the Self-Execution\nBenchmark, which measures a model's ability to anticipate properties of its\noutput, such as whether a question will be difficult for it, whether it will\nrefuse to answer, or what kinds of associations it is likely to produce. Our\nexperiments show that models generally perform poorly on this benchmark, and\nthat increased model size or capability does not consistently lead to better\nperformance. These results suggest a fundamental limitation in how LLMs\nrepresent and reason about their own behavior.", "AI": {"tldr": "LLMs perform poorly at predicting their own response properties like difficulty assessment, refusal likelihood, and output associations, showing no improvement with increased model size or capability.", "motivation": "To evaluate whether LLMs can predict aspects of their own responses, moving beyond traditional knowledge and reasoning assessments to understand self-awareness capabilities.", "method": "Introducing the Self-Execution Benchmark that tests models' ability to anticipate properties of their output, including difficulty prediction, refusal behavior, and association patterns.", "result": "Models generally perform poorly on self-prediction tasks, and increased model size or capability does not consistently lead to better performance on these self-awareness metrics.", "conclusion": "LLMs have fundamental limitations in how they represent and reason about their own behavior, suggesting current architectures lack genuine self-awareness capabilities."}}
{"id": "2508.12061", "pdf": "https://arxiv.org/pdf/2508.12061", "abs": "https://arxiv.org/abs/2508.12061", "authors": ["Daria Diatlova", "Nikita Balagansky", "Alexander Varlamov", "Egor Spirin"], "title": "VARAN: Variational Inference for Self-Supervised Speech Models Fine-Tuning on Downstream Tasks", "categories": ["cs.LG"], "comment": null, "summary": "Conventional methods for aggregating layers in fine-tuned self-supervised\nspeech models, such as using the final layer or weighted sum, suffer from\ninformation bottlenecks and static feature weighting for all dataset examples.\nWe propose VARAN, a framework that dynamically tailors layer aggregation to\nindividual inputs. By employing layer-specialized probing heads and\ndata-dependent weighting, VARAN adaptively prioritizes layer's features based\non input. Evaluations on automatic speech recognition and speech emotion\nrecognition tasks demonstrate VARAN's superior performance, particularly when\nusing the LoRA fine-tuning technique. The framework resolves the trade-off\nbetween preserving layer-specific information and enabling flexible feature\nutilization, advancing efficient adaptation of self-supervised speech\nrepresentations.", "AI": {"tldr": "VARAN is a dynamic layer aggregation framework that adaptively weights features from different layers based on individual inputs, outperforming static aggregation methods in speech tasks.", "motivation": "Conventional layer aggregation methods in fine-tuned self-supervised speech models suffer from information bottlenecks and static feature weighting that applies the same weights to all dataset examples, limiting performance.", "method": "VARAN employs layer-specialized probing heads and data-dependent weighting to dynamically tailor layer aggregation to individual inputs, adaptively prioritizing different layers' features based on the specific input characteristics.", "result": "Evaluations on automatic speech recognition and speech emotion recognition tasks demonstrate VARAN's superior performance, particularly when using the LoRA fine-tuning technique.", "conclusion": "The framework successfully resolves the trade-off between preserving layer-specific information and enabling flexible feature utilization, advancing efficient adaptation of self-supervised speech representations."}}
{"id": "2508.12480", "pdf": "https://arxiv.org/pdf/2508.12480", "abs": "https://arxiv.org/abs/2508.12480", "authors": ["Constantin Ruhdorfer", "Matteo Bortoletto", "Andreas Bulling"], "title": "The Yokai Learning Environment: Tracking Beliefs Over Space and Time", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": "Presented at the the ToM IJCAI 2025 Workshop", "summary": "Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to\nreason about the beliefs of others to build and maintain common ground.\nExisting ToM benchmarks, however, are restricted to passive observer settings\nor lack an assessment of how agents establish and maintain common ground over\ntime. To address these gaps, we introduce the Yokai Learning Environment (YLE)\n- a multi-agent reinforcement learning (RL) environment based on the\ncooperative card game Yokai. In the YLE, agents take turns peeking at hidden\ncards and moving them to form clusters based on colour. Success requires\ntracking evolving beliefs, remembering past observations, using hints as\ngrounded communication, and maintaining common ground with teammates. Our\nevaluation yields two key findings: First, current RL agents struggle to solve\nthe YLE, even when given access to perfect memory. Second, while belief\nmodelling improves performance, agents are still unable to effectively\ngeneralise to unseen partners or form accurate beliefs over longer games,\nexposing a reliance on brittle conventions rather than robust belief tracking.\nWe use the YLE to investigate research questions in belief modelling, memory,\npartner generalisation, and scaling to higher-order ToM.", "AI": {"tldr": "Yokai Learning Environment (YLE) is a new multi-agent RL benchmark for Theory of Mind that tests agents' ability to track beliefs, maintain common ground, and communicate effectively in a cooperative card game setting.", "motivation": "Existing ToM benchmarks are limited to passive observer settings and lack assessment of how agents establish and maintain common ground over time in collaborative settings.", "method": "Developed the Yokai Learning Environment (YLE) - a multi-agent RL environment based on the cooperative card game Yokai where agents peek at hidden cards, move them to form color clusters, and use hints for grounded communication.", "result": "Current RL agents struggle to solve YLE even with perfect memory. Belief modeling improves performance but agents fail to generalize to unseen partners or maintain accurate beliefs over longer games, showing reliance on brittle conventions rather than robust belief tracking.", "conclusion": "YLE reveals significant limitations in current RL agents' Theory of Mind capabilities and provides a testbed for investigating belief modeling, memory, partner generalization, and higher-order ToM in collaborative AI systems."}}
{"id": "2508.12023", "pdf": "https://arxiv.org/pdf/2508.12023", "abs": "https://arxiv.org/abs/2508.12023", "authors": ["Durgesh Kumar Singh", "Qing Cao", "Sarina Thomas", "Ahc\u00e8ne Boubekki", "Robert Jenssen", "Michael Kampffmeyer"], "title": "WiseLVAM: A Novel Framework For Left Ventricle Automatic Measurements", "categories": ["cs.CV"], "comment": null, "summary": "Clinical guidelines recommend performing left ventricular (LV) linear\nmeasurements in B-mode echocardiographic images at the basal level -- typically\nat the mitral valve leaflet tips -- and aligned perpendicular to the LV long\naxis along a virtual scanline (SL). However, most automated methods estimate\nlandmarks directly from B-mode images for the measurement task, where even\nsmall shifts in predicted points along the LV walls can lead to significant\nmeasurement errors, reducing their clinical reliability. A recent\nsemi-automatic method, EnLVAM, addresses this limitation by constraining\nlandmark prediction to a clinician-defined SL and training on generated\nAnatomical Motion Mode (AMM) images to predict LV landmarks along the same. To\nenable full automation, a contour-aware SL placement approach is proposed in\nthis work, in which the LV contour is estimated using a weakly supervised\nB-mode landmark detector. SL placement is then performed by inferring the LV\nlong axis and the basal level-mimicking clinical guidelines. Building on this\nfoundation, we introduce \\textit{WiseLVAM} -- a novel, fully automated yet\nmanually adaptable framework for automatically placing the SL and then\nautomatically performing the LV linear measurements in the AMM mode.\n\\textit{WiseLVAM} utilizes the structure-awareness from B-mode images and the\nmotion-awareness from AMM mode to enhance robustness and accuracy with the\npotential to provide a practical solution for the routine clinical application.", "AI": {"tldr": "WiseLVAM is a fully automated framework for left ventricular linear measurements that combines B-mode structure awareness with AMM motion awareness, eliminating the need for manual scanline placement while maintaining clinical guideline compliance.", "motivation": "Existing automated methods for LV measurements are unreliable due to small landmark prediction errors along LV walls, and semi-automatic methods require clinician-defined scanlines, limiting full automation.", "method": "Uses weakly supervised B-mode landmark detection to estimate LV contour, then automatically places scanline by inferring LV long axis and basal level. Builds on AMM image training to predict landmarks along the automated scanline.", "result": "Enables fully automated yet manually adaptable LV linear measurements that mimic clinical guidelines, combining structure awareness from B-mode with motion awareness from AMM mode.", "conclusion": "WiseLVAM provides a robust, accurate, and practical solution for routine clinical application of automated LV measurements by eliminating manual intervention while maintaining clinical reliability."}}
{"id": "2508.12281", "pdf": "https://arxiv.org/pdf/2508.12281", "abs": "https://arxiv.org/abs/2508.12281", "authors": ["Xin Dai", "Buqiang Xu", "Zhenghao Liu", "Yukun Yan", "Huiyuan Xie", "Xiaoyuan Yi", "Shuo Wang", "Ge Yu"], "title": "Legal$\u0394$: Enhancing Legal Reasoning in LLMs via Reinforcement Learning with Chain-of-Thought Guided Information Gain", "categories": ["cs.CL"], "comment": null, "summary": "Legal Artificial Intelligence (LegalAI) has achieved notable advances in\nautomating judicial decision-making with the support of Large Language Models\n(LLMs). However, existing legal LLMs still struggle to generate reliable and\ninterpretable reasoning processes. They often default to fast-thinking behavior\nby producing direct answers without explicit multi-step reasoning, limiting\ntheir effectiveness in complex legal scenarios that demand rigorous\njustification. To address this challenge, we propose Legal$\\Delta$, a\nreinforcement learning framework designed to enhance legal reasoning through\nchain-of-thought guided information gain. During training, Legal$\\Delta$\nemploys a dual-mode input setup-comprising direct answer and\nreasoning-augmented modes-and maximizes the information gain between them. This\nencourages the model to acquire meaningful reasoning patterns rather than\ngenerating superficial or redundant explanations. Legal$\\Delta$ follows a\ntwo-stage approach: (1) distilling latent reasoning capabilities from a\npowerful Large Reasoning Model (LRM), DeepSeek-R1, and (2) refining reasoning\nquality via differential comparisons, combined with a multidimensional reward\nmechanism that assesses both structural coherence and legal-domain specificity.\nExperimental results on multiple legal reasoning tasks demonstrate that\nLegal$\\Delta$ outperforms strong baselines in both accuracy and\ninterpretability. It consistently produces more robust and trustworthy legal\njudgments without relying on labeled preference data. All code and data will be\nreleased at https://github.com/NEUIR/LegalDelta.", "AI": {"tldr": "Legal\u0394 is a reinforcement learning framework that enhances legal reasoning in LLMs by maximizing information gain between direct answers and reasoning-augmented outputs, producing more reliable and interpretable legal judgments.", "motivation": "Existing legal LLMs struggle with reliable and interpretable reasoning processes, often defaulting to fast-thinking behavior without explicit multi-step reasoning, which limits effectiveness in complex legal scenarios requiring rigorous justification.", "method": "Two-stage approach: (1) distills latent reasoning capabilities from DeepSeek-R1 (Large Reasoning Model), (2) refines reasoning quality via differential comparisons with a dual-mode input setup (direct answer vs reasoning-augmented) and multidimensional reward mechanism assessing structural coherence and legal-domain specificity.", "result": "Outperforms strong baselines on multiple legal reasoning tasks in both accuracy and interpretability, consistently producing more robust and trustworthy legal judgments without relying on labeled preference data.", "conclusion": "Legal\u0394 successfully addresses the interpretability challenge in legal AI by encouraging meaningful reasoning patterns rather than superficial explanations, demonstrating significant improvements in legal reasoning quality and reliability."}}
{"id": "2508.12079", "pdf": "https://arxiv.org/pdf/2508.12079", "abs": "https://arxiv.org/abs/2508.12079", "authors": ["Ningzhe Shi", "Yiqing Zhou", "Ling Liu", "Jinglin Shi", "Yihao Wu", "Haiwei Shi", "Hanxiao Yu"], "title": "Content Accuracy and Quality Aware Resource Allocation Based on LP-Guided DRL for ISAC-Driven AIGC Networks", "categories": ["cs.LG"], "comment": null, "summary": "Integrated sensing and communication (ISAC) can enhance artificial\nintelligence-generated content (AIGC) networks by providing efficient sensing\nand transmission. Existing AIGC services usually assume that the accuracy of\nthe generated content can be ensured, given accurate input data and prompt,\nthus only the content generation quality (CGQ) is concerned. However, it is not\napplicable in ISAC-based AIGC networks, where content generation is based on\ninaccurate sensed data. Moreover, the AIGC model itself introduces generation\nerrors, which depend on the number of generating steps (i.e., computing\nresources). To assess the quality of experience of ISAC-based AIGC services, we\npropose a content accuracy and quality aware service assessment metric (CAQA).\nSince allocating more resources to sensing and generating improves content\naccuracy but may reduce communication quality, and vice versa, this\nsensing-generating (computing)-communication three-dimensional resource\ntradeoff must be optimized to maximize the average CAQA (AvgCAQA) across all\nusers with AIGC (CAQA-AIGC). This problem is NP-hard, with a large solution\nspace that grows exponentially with users. To solve the CAQA-AIGC problem with\nlow complexity, a linear programming (LP) guided deep reinforcement learning\n(DRL) algorithm with an action filter (LPDRL-F) is proposed. Through the\nLP-guided approach and the action filter, LPDRL-F can transform the original\nthree-dimensional solution space to two dimensions, reducing complexity while\nimproving the learning performance of DRL. Simulations show that compared to\nexisting DRL and generative diffusion model algorithms without LP, LPDRL-F\nconverges faster by over 60% and finds better resource allocation solutions,\nimproving AvgCAQA by more than 14%. With LPDRL-F, CAQA-AIGC can achieve an\nimprovement in AvgCAQA of more than 50% compared to existing schemes focusing\nsolely on CGQ.", "AI": {"tldr": "Proposes LPDRL-F algorithm for optimizing 3D resource tradeoff in ISAC-AIGC networks to maximize content accuracy and quality, achieving 50%+ improvement over CGQ-only schemes.", "motivation": "Existing AIGC services assume accurate input data and focus only on content generation quality, but ISAC-based AIGC networks face inaccurate sensed data and generation errors, requiring joint optimization of sensing, computing, and communication resources.", "method": "Proposes LP-guided deep reinforcement learning with action filter (LPDRL-F) to transform 3D solution space to 2D, reducing complexity while improving DRL performance for resource allocation optimization.", "result": "LPDRL-F converges 60% faster than existing DRL/diffusion methods, improves AvgCAQA by over 14%, and achieves 50%+ AvgCAQA improvement compared to CGQ-only schemes.", "conclusion": "The proposed CAQA metric and LPDRL-F algorithm effectively address the 3D resource tradeoff in ISAC-AIGC networks, significantly enhancing service quality through optimized resource allocation."}}
{"id": "2508.12487", "pdf": "https://arxiv.org/pdf/2508.12487", "abs": "https://arxiv.org/abs/2508.12487", "authors": ["Lida Shahbandari", "Hossein Mohseni"], "title": "Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that\nuses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index\n(BIS), keeping it within the ideal range of forty to sixty. The FOFPID\ncontroller combines fuzzy logic for adapting to changes and fractional order\ndynamics for fine tuning. This allows it to adjust its control gains to handle\na person's unique physiology. The WOA helps fine tune the controller's\nparameters, including the fractional orders and the fuzzy membership functions,\nwhich boosts its performance. Tested on models of eight different patient\nprofiles, the FOFPID controller performed better than a standard Fractional\nOrder PID (FOPID) controller. It achieved faster settling times, at two and a\nhalf minutes versus three point two minutes, and had a lower steady state\nerror, at zero point five versus one point two. These outcomes show the\nFOFPID's excellent strength and accuracy. It offers a scalable, artificial\nintelligence driven solution for automated anesthesia delivery that could\nenhance clinical practice and improve patient results.", "AI": {"tldr": "A Fractional Order Fuzzy PID controller optimized by Whale Optimization Algorithm for precise anesthesia control, outperforming standard FOPID with faster response and lower error.", "motivation": "To develop an intelligent anesthesia delivery system that can maintain optimal Bispectral Index (40-60 range) by adapting to individual patient physiology and providing precise control.", "method": "Combined fractional order dynamics with fuzzy logic in a PID controller, using Whale Optimization Algorithm to fine-tune parameters including fractional orders and fuzzy membership functions. Tested on 8 different patient profile models.", "result": "FOFPID achieved faster settling times (2.5 min vs 3.2 min) and lower steady state error (0.5 vs 1.2) compared to standard FOPID controller across all patient profiles.", "conclusion": "The FOFPID controller demonstrates excellent robustness and accuracy, providing a scalable AI-driven solution for automated anesthesia delivery that could improve clinical practice and patient outcomes."}}
{"id": "2508.12036", "pdf": "https://arxiv.org/pdf/2508.12036", "abs": "https://arxiv.org/abs/2508.12036", "authors": ["Rakesh Thakur", "Yusra Tariq"], "title": "Q-FSRU: Quantum-Augmented Frequency-Spectral Fusion for Medical Visual Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "8 pages, 4 figures Submitted to AAAI 26", "summary": "Solving tough clinical questions that require both image and text\nunderstanding is still a major challenge in healthcare AI. In this work, we\npropose Q-FSRU, a new model that combines Frequency Spectrum Representation and\nFusion (FSRU) with a method called Quantum Retrieval-Augmented Generation\n(Quantum RAG) for medical Visual Question Answering (VQA). The model takes in\nfeatures from medical images and related text, then shifts them into the\nfrequency domain using Fast Fourier Transform (FFT). This helps it focus on\nmore meaningful data and filter out noise or less useful information. To\nimprove accuracy and ensure that answers are based on real knowledge, we add a\nquantum-inspired retrieval system. It fetches useful medical facts from\nexternal sources using quantum-based similarity techniques. These details are\nthen merged with the frequency-based features for stronger reasoning. We\nevaluated our model using the VQA-RAD dataset, which includes real radiology\nimages and questions. The results showed that Q-FSRU outperforms earlier\nmodels, especially on complex cases needing image-text reasoning. The mix of\nfrequency and quantum information improves both performance and explainability.\nOverall, this approach offers a promising way to build smart, clear, and\nhelpful AI tools for doctors.", "AI": {"tldr": "Q-FSRU combines frequency domain processing with quantum-inspired retrieval for medical VQA, achieving superior performance on complex clinical questions requiring image-text reasoning.", "motivation": "Solving tough clinical questions that require both image and text understanding remains a major challenge in healthcare AI, needing improved accuracy and explainability.", "method": "Combines Frequency Spectrum Representation and Fusion (FSRU) with Quantum Retrieval-Augmented Generation; uses FFT to shift features to frequency domain, then adds quantum-inspired retrieval system to fetch medical facts from external sources using quantum-based similarity techniques.", "result": "Outperforms earlier models on VQA-RAD dataset, especially on complex cases needing image-text reasoning; improves both performance and explainability.", "conclusion": "Offers a promising way to build smart, clear, and helpful AI tools for doctors through the combination of frequency and quantum information processing."}}
{"id": "2508.12282", "pdf": "https://arxiv.org/pdf/2508.12282", "abs": "https://arxiv.org/abs/2508.12282", "authors": ["Ziyang Chen", "Erxue Min", "Xiang Zhao", "Yunxin Li", "Xin Jia", "Jinzhi Liao", "Jichao Li", "Shuaiqiang Wang", "Baotian Hu", "Dawei Yin"], "title": "A Question Answering Dataset for Temporal-Sensitive Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.IR", "68T50, 68P20", "I.2.7; H.3.3"], "comment": "10 pages, 5 figures", "summary": "We introduce ChronoQA, a large-scale benchmark dataset for Chinese question\nanswering, specifically designed to evaluate temporal reasoning in\nRetrieval-Augmented Generation (RAG) systems. ChronoQA is constructed from over\n300,000 news articles published between 2019 and 2024, and contains 5,176\nhigh-quality questions covering absolute, aggregate, and relative temporal\ntypes with both explicit and implicit time expressions. The dataset supports\nboth single- and multi-document scenarios, reflecting the real-world\nrequirements for temporal alignment and logical consistency. ChronoQA features\ncomprehensive structural annotations and has undergone multi-stage validation,\nincluding rule-based, LLM-based, and human evaluation, to ensure data quality.\nBy providing a dynamic, reliable, and scalable resource, ChronoQA enables\nstructured evaluation across a wide range of temporal tasks, and serves as a\nrobust benchmark for advancing time-sensitive retrieval-augmented question\nanswering systems.", "AI": {"tldr": "ChronoQA is a large-scale Chinese QA benchmark dataset for evaluating temporal reasoning in RAG systems, built from 300k+ news articles (2019-2024) with 5,176 high-quality questions covering various temporal types and scenarios.", "motivation": "To address the need for evaluating temporal reasoning capabilities in Retrieval-Augmented Generation systems, particularly for Chinese language, where existing benchmarks may not adequately test time-sensitive question answering.", "method": "Constructed from over 300,000 news articles (2019-2024), featuring 5,176 questions covering absolute, aggregate, and relative temporal types with explicit/implicit time expressions. Supports single- and multi-document scenarios with comprehensive structural annotations and multi-stage validation (rule-based, LLM-based, human evaluation).", "result": "Created a dynamic, reliable, and scalable benchmark dataset that enables structured evaluation across various temporal tasks in Chinese question answering.", "conclusion": "ChronoQA serves as a robust benchmark for advancing time-sensitive retrieval-augmented question answering systems, providing a comprehensive resource for evaluating temporal reasoning in RAG applications."}}
{"id": "2508.12104", "pdf": "https://arxiv.org/pdf/2508.12104", "abs": "https://arxiv.org/abs/2508.12104", "authors": ["Shane Waxler", "Paul Blazek", "Davis White", "Daniel Sneider", "Kevin Chung", "Mani Nagarathnam", "Patrick Williams", "Hank Voeller", "Karen Wong", "Matthew Swanhorst", "Sheng Zhang", "Naoto Usuyama", "Cliff Wong", "Tristan Naumann", "Hoifung Poon", "Andrew Loza", "Daniella Meeker", "Seth Hain", "Rahul Shah"], "title": "Generative Medical Event Models Improve with Scale", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Realizing personalized medicine at scale calls for methods that distill\ninsights from longitudinal patient journeys, which can be viewed as a sequence\nof medical events. Foundation models pretrained on large-scale medical event\ndata represent a promising direction for scaling real-world evidence generation\nand generalizing to diverse downstream tasks. Using Epic Cosmos, a dataset with\nmedical events from de-identified longitudinal health records for 16.3 billion\nencounters over 300 million unique patient records from 310 health systems, we\nintroduce the Cosmos Medical Event Transformer ( CoMET) models, a family of\ndecoder-only transformer models pretrained on 118 million patients representing\n115 billion discrete medical events (151 billion tokens). We present the\nlargest scaling-law study for medical event data, establishing a methodology\nfor pretraining and revealing power-law scaling relationships for compute,\ntokens, and model size. Based on this, we pretrained a series of\ncompute-optimal models with up to 1 billion parameters. Conditioned on a\npatient's real-world history, CoMET autoregressively generates the next medical\nevent, simulating patient health timelines. We studied 78 real-world tasks,\nincluding diagnosis prediction, disease prognosis, and healthcare operations.\nRemarkably for a foundation model with generic pretraining and simulation-based\ninference, CoMET generally outperformed or matched task-specific supervised\nmodels on these tasks, without requiring task-specific fine-tuning or few-shot\nexamples. CoMET's predictive power consistently improves as the model and\npretraining scale. Our results show that CoMET, a generative medical event\nfoundation model, can effectively capture complex clinical dynamics, providing\nan extensible and generalizable framework to support clinical decision-making,\nstreamline healthcare operations, and improve patient outcomes.", "AI": {"tldr": "CoMET is a 1B-parameter transformer foundation model pretrained on 115B medical events from 118M patients that generates future medical events and outperforms task-specific models on 78 healthcare tasks without fine-tuning.", "motivation": "To enable personalized medicine at scale by developing foundation models that can distill insights from longitudinal patient journeys and generalize across diverse healthcare tasks.", "method": "Decoder-only transformer models pretrained on Epic Cosmos dataset (16.3B encounters, 300M patients) using autoregressive generation of medical events, with scaling-law optimization for compute, tokens, and model size.", "result": "CoMET outperformed or matched task-specific supervised models on 78 real-world tasks including diagnosis prediction, disease prognosis, and healthcare operations, with performance improving with model scale.", "conclusion": "Generative medical event foundation models like CoMET can effectively capture clinical dynamics and provide a generalizable framework for clinical decision-making and healthcare operations without task-specific training."}}
{"id": "2508.12500", "pdf": "https://arxiv.org/pdf/2508.12500", "abs": "https://arxiv.org/abs/2508.12500", "authors": ["Rahmat K. Adesunkanmi", "Ashfaq Khokhar", "Goce Trajcevski", "Sohail Murad"], "title": "Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models", "categories": ["cs.AI", "cs.LG", "q-bio.QM"], "comment": "Submitted to ACM", "summary": "Molecular dynamics simulations (MDS) face challenges, including\nresource-heavy computations and the need to manually scan outputs to detect\n\"interesting events,\" such as the formation and persistence of hydrogen bonds\nbetween atoms of different molecules. A critical research gap lies in\nidentifying the underlying causes of hydrogen bond formation and separation\n-understanding which interactions or prior events contribute to their emergence\nover time. With this challenge in mind, we propose leveraging spatio-temporal\ndata analytics and machine learning models to enhance the detection of these\nphenomena. In this paper, our approach is inspired by causal modeling and aims\nto identify the root cause variables of hydrogen bond formation and separation\nevents. Specifically, we treat the separation of hydrogen bonds as an\n\"intervention\" occurring and represent the causal structure of the bonding and\nseparation events in the MDS as graphical causal models. These causal models\nare built using a variational autoencoder-inspired architecture that enables us\nto infer causal relationships across samples with diverse underlying causal\ngraphs while leveraging shared dynamic information. We further include a step\nto infer the root causes of changes in the joint distribution of the causal\nmodels. By constructing causal models that capture shifts in the conditional\ndistributions of molecular interactions during bond formation or separation,\nthis framework provides a novel perspective on root cause analysis in molecular\ndynamic systems. We validate the efficacy of our model empirically on the\natomic trajectories that used MDS for chiral separation, demonstrating that we\ncan predict many steps in the future and also find the variables driving the\nobserved changes in the system.", "AI": {"tldr": "A novel causal modeling approach using variational autoencoders to identify root causes of hydrogen bond formation and separation in molecular dynamics simulations, enabling predictive analysis of molecular interactions.", "motivation": "Molecular dynamics simulations are computationally intensive and require manual analysis to detect interesting events like hydrogen bond formation. There's a critical gap in understanding the underlying causes and prior events that contribute to these molecular interactions over time.", "method": "Leverage spatio-temporal data analytics and machine learning with causal modeling. Treat hydrogen bond separation as an 'intervention' and represent causal structure as graphical models using a variational autoencoder-inspired architecture to infer causal relationships across diverse samples while utilizing shared dynamic information.", "result": "The framework successfully constructs causal models that capture distribution shifts during bond formation/separation. Empirical validation on chiral separation atomic trajectories demonstrates the model can predict future steps and identify variables driving system changes.", "conclusion": "This approach provides a novel perspective on root cause analysis in molecular dynamic systems, enabling automated detection of causal relationships in hydrogen bonding events and advancing understanding of molecular interaction dynamics."}}
{"id": "2508.12081", "pdf": "https://arxiv.org/pdf/2508.12081", "abs": "https://arxiv.org/abs/2508.12081", "authors": ["Haidong Xu", "Guangwei Xu", "Zhedong Zheng", "Xiatian Zhu", "Wei Ji", "Xiangtai Li", "Ruijie Guo", "Meishan Zhang", "Min zhang", "Hao Fei"], "title": "VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "20 pages,13 figures", "summary": "This paper introduces VimoRAG, a novel video-based retrieval-augmented motion\ngeneration framework for motion large language models (LLMs). As motion LLMs\nface severe out-of-domain/out-of-vocabulary issues due to limited annotated\ndata, VimoRAG leverages large-scale in-the-wild video databases to enhance 3D\nmotion generation by retrieving relevant 2D human motion signals. While\nvideo-based motion RAG is nontrivial, we address two key bottlenecks: (1)\ndeveloping an effective motion-centered video retrieval model that\ndistinguishes human poses and actions, and (2) mitigating the issue of error\npropagation caused by suboptimal retrieval results. We design the Gemini Motion\nVideo Retriever mechanism and the Motion-centric Dual-alignment DPO Trainer,\nenabling effective retrieval and generation processes. Experimental results\nshow that VimoRAG significantly boosts the performance of motion LLMs\nconstrained to text-only input.", "AI": {"tldr": "VimoRAG is a video-based retrieval-augmented generation framework that enhances 3D motion generation for motion LLMs by retrieving relevant 2D human motion signals from large-scale video databases, overcoming data limitations and error propagation issues.", "motivation": "Motion large language models face severe out-of-domain/out-of-vocabulary issues due to limited annotated data, requiring a solution to leverage abundant video resources for improved motion generation.", "method": "Developed Gemini Motion Video Retriever mechanism and Motion-centric Dual-alignment DPO Trainer to enable effective video retrieval and generation while mitigating error propagation from suboptimal retrieval results.", "result": "Experimental results show VimoRAG significantly boosts the performance of motion LLMs constrained to text-only input.", "conclusion": "VimoRAG successfully addresses key bottlenecks in video-based motion retrieval-augmented generation, demonstrating substantial improvements in 3D motion generation capabilities for text-only motion LLMs."}}
{"id": "2508.12286", "pdf": "https://arxiv.org/pdf/2508.12286", "abs": "https://arxiv.org/abs/2508.12286", "authors": ["Qinghua Wang", "Xu Zhang", "Lingyan Yang", "Rui Shao", "Bonan Wang", "Fang Wang", "Cunquan Qu"], "title": "Incorporating Legal Logic into Deep Learning: An Intelligent Approach to Probation Prediction", "categories": ["cs.CL"], "comment": null, "summary": "Probation is a crucial institution in modern criminal law, embodying the\nprinciples of fairness and justice while contributing to the harmonious\ndevelopment of society. Despite its importance, the current Intelligent\nJudicial Assistant System (IJAS) lacks dedicated methods for probation\nprediction, and research on the underlying factors influencing probation\neligibility remains limited. In addition, probation eligibility requires a\ncomprehensive analysis of both criminal circumstances and remorse. Much of the\nexisting research in IJAS relies primarily on data-driven methodologies, which\noften overlooks the legal logic underpinning judicial decision-making. To\naddress this gap, we propose a novel approach that integrates legal logic into\ndeep learning models for probation prediction, implemented in three distinct\nstages. First, we construct a specialized probation dataset that includes fact\ndescriptions and probation legal elements (PLEs). Second, we design a distinct\nprobation prediction model named the Multi-Task Dual-Theory Probation\nPrediction Model (MT-DT), which is grounded in the legal logic of probation and\nthe \\textit{Dual-Track Theory of Punishment}. Finally, our experiments on the\nprobation dataset demonstrate that the MT-DT model outperforms baseline models,\nand an analysis of the underlying legal logic further validates the\neffectiveness of the proposed approach.", "AI": {"tldr": "Proposes MT-DT model integrating legal logic with deep learning for probation prediction, outperforming baseline methods by incorporating legal principles and remorse analysis.", "motivation": "Current Intelligent Judicial Assistant Systems lack dedicated probation prediction methods and overlook legal logic, focusing too much on data-driven approaches without considering the legal reasoning behind judicial decisions.", "method": "Three-stage approach: 1) Construct specialized probation dataset with fact descriptions and probation legal elements; 2) Design MT-DT model based on legal logic and Dual-Track Theory of Punishment; 3) Experimental validation on probation dataset.", "result": "MT-DT model outperforms baseline models, and legal logic analysis validates the effectiveness of the integrated approach.", "conclusion": "Integrating legal logic with deep learning significantly improves probation prediction accuracy and provides more legally sound judicial assistance, addressing the gap between data-driven methods and legal reasoning."}}
{"id": "2508.12116", "pdf": "https://arxiv.org/pdf/2508.12116", "abs": "https://arxiv.org/abs/2508.12116", "authors": ["Haebin Shin", "Lei Ji", "Xiao Liu", "Zhiwei Yu", "Qi Chen", "Yeyun Gong"], "title": "DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "As numerous instruction-tuning datasets continue to emerge during the\npost-training stage, dynamically balancing and optimizing their mixtures has\nbecome a critical challenge. To address this, we propose DynamixSFT, a dynamic\nand automated method for instruction-tuning dataset mixture optimization. We\nformulate the problem as a multi-armed bandit setup and introduce a\nPrior-scaled Boltzmann Exploration that softly anchors the updated sampling\ndistribution to the original dataset proportions, thereby preserving the\ninherent diversity and coverage of the collection. Sampling probabilities are\nupdated using a lightweight 1-Step Look-ahead Reward, reflecting how much the\ndataset contributes to improving the model's performance at its current state.\nWhen applied to the Tulu-v2-mixture collection comprising 16 instruction-tuning\ndatasets, DynamixSFT achieves up to a 2.2% performance improvement across 10\nbenchmarks. Furthermore, we provide a comprehensive analysis and visualizations\nto offer deeper insights into the adaptive dynamics of our method.", "AI": {"tldr": "DynamixSFT is a dynamic automated method that treats instruction-tuning dataset mixture optimization as a multi-armed bandit problem, using Prior-scaled Boltzmann Exploration and 1-Step Look-ahead Reward to achieve up to 2.2% performance improvement.", "motivation": "Address the challenge of dynamically balancing and optimizing instruction-tuning dataset mixtures as numerous datasets emerge during post-training stage.", "method": "Formulates as multi-armed bandit setup with Prior-scaled Boltzmann Exploration that anchors sampling distribution to original proportions, using lightweight 1-Step Look-ahead Reward to update sampling probabilities based on dataset contribution to model improvement.", "result": "Achieves up to 2.2% performance improvement across 10 benchmarks when applied to Tulu-v2-mixture collection of 16 instruction-tuning datasets.", "conclusion": "DynamixSFT provides an effective dynamic and automated approach for optimizing instruction-tuning dataset mixtures while preserving dataset diversity and coverage."}}
{"id": "2508.12566", "pdf": "https://arxiv.org/pdf/2508.12566", "abs": "https://arxiv.org/abs/2508.12566", "authors": ["Wei Song", "Haonan Zhong", "Ziqi Ding", "Jingling Xue", "Yuekang Li"], "title": "Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "The Model Context Protocol (MCP) enables large language models (LLMs) to\naccess external resources on demand. While commonly assumed to enhance\nperformance, how LLMs actually leverage this capability remains poorly\nunderstood. We introduce MCPGAUGE, the first comprehensive evaluation framework\nfor probing LLM-MCP interactions along four key dimensions: proactivity\n(self-initiated tool use), compliance (adherence to tool-use instructions),\neffectiveness (task performance post-integration), and overhead (computational\ncost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning\nknowledge comprehension, general reasoning, and code generation. Our\nlarge-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and\nboth one- and two-turn interaction settings, comprises around 20,000 API calls\nand over USD 6,000 in computational cost. This comprehensive study reveals four\nkey findings that challenge prevailing assumptions about the effectiveness of\nMCP integration. These insights highlight critical limitations in current\nAI-tool integration and position MCPGAUGE as a principled benchmark for\nadvancing controllable, tool-augmented LLMs.", "AI": {"tldr": "MCPGAUGE is the first comprehensive evaluation framework that reveals surprising limitations in how LLMs actually use external tools via Model Context Protocol, challenging assumptions about tool integration effectiveness.", "motivation": "While Model Context Protocol (MCP) enables LLMs to access external resources, there's poor understanding of how LLMs actually leverage this capability, despite common assumptions that it enhances performance.", "method": "Developed MCPGAUGE framework with 160-prompt suite and 25 datasets across knowledge comprehension, reasoning, and code generation. Conducted large-scale evaluation with 6 commercial LLMs, 30 MCP tool suites, and both one- and two-turn interactions (20,000+ API calls, $6,000+ computational cost).", "result": "The comprehensive study revealed four key findings that challenge prevailing assumptions about MCP integration effectiveness, highlighting critical limitations in current AI-tool integration.", "conclusion": "MCPGAUGE serves as a principled benchmark for advancing controllable, tool-augmented LLMs, providing insights into the actual effectiveness and limitations of tool integration through systematic evaluation across multiple dimensions."}}
{"id": "2508.12082", "pdf": "https://arxiv.org/pdf/2508.12082", "abs": "https://arxiv.org/abs/2508.12082", "authors": ["Seungju Yoo", "Hyuk Kwon", "Joong-Won Hwang", "Kibok Lee"], "title": "Automated Model Evaluation for Object Detection via Prediction Consistency and Reliablity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICCV 2025 Oral", "summary": "Recent advances in computer vision have made training object detectors more\nefficient and effective; however, assessing their performance in real-world\napplications still relies on costly manual annotation. To address this\nlimitation, we develop an automated model evaluation (AutoEval) framework for\nobject detection. We propose Prediction Consistency and Reliability (PCR),\nwhich leverages the multiple candidate bounding boxes that conventional\ndetectors generate before non-maximum suppression (NMS). PCR estimates\ndetection performance without ground-truth labels by jointly measuring 1) the\nspatial consistency between boxes before and after NMS, and 2) the reliability\nof the retained boxes via the confidence scores of overlapping boxes. For a\nmore realistic and scalable evaluation, we construct a meta-dataset by applying\nimage corruptions of varying severity. Experimental results demonstrate that\nPCR yields more accurate performance estimates than existing AutoEval methods,\nand the proposed meta-dataset covers a wider range of detection performance.\nThe code is available at https://github.com/YonseiML/autoeval-det.", "AI": {"tldr": "AutoEval framework using Prediction Consistency and Reliability (PCR) to estimate object detection performance without ground-truth labels by analyzing spatial consistency and confidence reliability of bounding boxes before/after NMS.", "motivation": "Manual annotation for evaluating object detectors is costly and time-consuming, creating a need for automated performance assessment methods.", "method": "Proposes PCR metric that measures spatial consistency between boxes before/after non-maximum suppression and reliability of retained boxes via confidence scores of overlapping boxes. Uses meta-dataset with varying image corruptions for realistic evaluation.", "result": "PCR provides more accurate performance estimates than existing AutoEval methods, and the constructed meta-dataset covers a wider range of detection performance scenarios.", "conclusion": "The AutoEval framework with PCR metric enables efficient and effective automated evaluation of object detectors without requiring ground-truth annotations, making performance assessment more scalable."}}
{"id": "2508.12301", "pdf": "https://arxiv.org/pdf/2508.12301", "abs": "https://arxiv.org/abs/2508.12301", "authors": ["Tomer Krichli", "Bhiksha Raj", "Joseph Keshet"], "title": "CarelessWhisper: Turning Whisper into a Causal Streaming Model", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "comment": "17 pages, 7 Figures, This work has been submitted to the IEEE for\n  possible publication", "summary": "Automatic Speech Recognition (ASR) has seen remarkable progress, with models\nlike OpenAI Whisper and NVIDIA Canary achieving state-of-the-art (SOTA)\nperformance in offline transcription. However, these models are not designed\nfor streaming (online or real-time) transcription, due to limitations in their\narchitecture and training methodology. We propose a method to turn the\ntransformer encoder-decoder model into a low-latency streaming model that is\ncareless about future context. We present an analysis explaining why it is not\nstraightforward to convert an encoder-decoder transformer to a low-latency\nstreaming model. Our proposed method modifies the existing (non-causal) encoder\nto a causal encoder by fine-tuning both the encoder and decoder using Low-Rank\nAdaptation (LoRA) and a weakly aligned dataset. We then propose an updated\ninference mechanism that utilizes the fine-tune causal encoder and decoder to\nyield greedy and beam-search decoding, and is shown to be locally optimal.\nExperiments on low-latency chunk sizes (less than 300 msec) show that our\nfine-tuned model outperforms existing non-fine-tuned streaming approaches in\nmost cases, while using a lower complexity. Additionally, we observe that our\ntraining process yields better alignment, enabling a simple method for\nextracting word-level timestamps. We release our training and inference code,\nalong with the fine-tuned models, to support further research and development\nin streaming ASR.", "AI": {"tldr": "Proposes a method to convert transformer encoder-decoder ASR models into low-latency streaming models using causal encoder fine-tuning with LoRA and weakly aligned data, achieving better performance than existing streaming approaches with lower complexity.", "motivation": "Current state-of-the-art ASR models like Whisper and Canary are designed for offline transcription and cannot be easily adapted for real-time streaming due to architectural limitations and non-causal nature.", "method": "Modify non-causal encoder to causal encoder by fine-tuning both encoder and decoder using Low-Rank Adaptation (LoRA) with weakly aligned dataset, then implement updated inference mechanism for greedy and beam-search decoding.", "result": "Outperforms existing non-fine-tuned streaming approaches on low-latency chunk sizes (<300 msec) with lower complexity, and enables better alignment for word-level timestamp extraction.", "conclusion": "Successfully transforms transformer encoder-decoder models into efficient streaming ASR systems through causal fine-tuning, providing a practical solution for real-time transcription with improved performance and additional timestamp capabilities."}}
{"id": "2508.12121", "pdf": "https://arxiv.org/pdf/2508.12121", "abs": "https://arxiv.org/abs/2508.12121", "authors": ["Lorenzo Livi"], "title": "Time-Scale Coupling Between States and Parameters in Recurrent Neural Networks", "categories": ["cs.LG", "math.DS"], "comment": null, "summary": "We study how gating mechanisms in recurrent neural networks (RNNs) implicitly\ninduce adaptive learning-rate behavior, even when training is carried out with\na fixed, global learning rate. This effect arises from the coupling between\nstate-space time scales--parametrized by the gates--and parameter-space\ndynamics during gradient descent. By deriving exact Jacobians for\nleaky-integrator and gated RNNs, we obtain a first-order expansion that makes\nexplicit how constant, scalar, and multi-dimensional gates reshape gradient\npropagation, modulate effective step sizes, and introduce anisotropy in\nparameter updates. These findings reveal that gates not only control memory\nretention in the hidden states, but also act as data-driven preconditioners\nthat adapt optimization trajectories in parameter space. We further draw formal\nanalogies with learning-rate schedules, momentum, and adaptive methods such as\nAdam, showing that these optimization behaviors emerge naturally from gating.\nNumerical experiments confirm the validity of our perturbative analysis,\nsupporting the view that gate-induced corrections remain small while exerting\nsystematic effects on training dynamics. Overall, this work provides a unified\ndynamical-systems perspective on how gating couples state evolution with\nparameter updates, explaining why gated architectures achieve robust\ntrainability and stability in practice.", "AI": {"tldr": "Gating mechanisms in RNNs implicitly create adaptive learning-rate behavior during training, acting as data-driven preconditioners that reshape gradient propagation and parameter updates.", "motivation": "To understand how gating mechanisms in RNNs influence optimization dynamics and explain why gated architectures achieve robust trainability and stability in practice.", "method": "Derived exact Jacobians for leaky-integrator and gated RNNs, performed first-order expansion analysis, and conducted numerical experiments to validate the perturbative analysis.", "result": "Gates not only control memory retention but also modulate effective step sizes, introduce anisotropy in parameter updates, and create optimization behaviors analogous to learning-rate schedules, momentum, and adaptive methods like Adam.", "conclusion": "Gating mechanisms provide a unified dynamical-systems perspective that couples state evolution with parameter updates, explaining the robust trainability and stability of gated architectures in practice."}}
{"id": "2508.12611", "pdf": "https://arxiv.org/pdf/2508.12611", "abs": "https://arxiv.org/abs/2508.12611", "authors": ["Trang Tran", "Trung Hoang Le", "Huiping Cao", "Tran Cao Son"], "title": "An LLM + ASP Workflow for Joint Entity-Relation Extraction", "categories": ["cs.AI", "cs.CL", "I.2.7; F.4.1"], "comment": "13 pages, 1 figure, Accepted as Technical Communication, 41st\n  International Conference on Logic Programming", "summary": "Joint entity-relation extraction (JERE) identifies both entities and their\nrelationships simultaneously. Traditional machine-learning based approaches to\nperforming this task require a large corpus of annotated data and lack the\nability to easily incorporate domain specific information in the construction\nof the model. Therefore, creating a model for JERE is often labor intensive,\ntime consuming, and elaboration intolerant. In this paper, we propose\nharnessing the capabilities of generative pretrained large language models\n(LLMs) and the knowledge representation and reasoning capabilities of Answer\nSet Programming (ASP) to perform JERE. We present a generic workflow for JERE\nusing LLMs and ASP. The workflow is generic in the sense that it can be applied\nfor JERE in any domain. It takes advantage of LLM's capability in natural\nlanguage understanding in that it works directly with unannotated text. It\nexploits the elaboration tolerant feature of ASP in that no modification of its\ncore program is required when additional domain specific knowledge, in the form\nof type specifications, is found and needs to be used. We demonstrate the\nusefulness of the proposed workflow through experiments with limited training\ndata on three well-known benchmarks for JERE. The results of our experiments\nshow that the LLM + ASP workflow is better than state-of-the-art JERE systems\nin several categories with only 10\\% of training data. It is able to achieve a\n2.5 times (35\\% over 15\\%) improvement in the Relation Extraction task for the\nSciERC corpus, one of the most difficult benchmarks.", "AI": {"tldr": "A novel workflow combining LLMs and ASP for joint entity-relation extraction that achieves state-of-the-art performance with only 10% training data, showing 2.5x improvement on difficult benchmarks.", "motivation": "Traditional JERE approaches require large annotated datasets and lack domain adaptation flexibility, making model creation labor-intensive and time-consuming.", "method": "Proposes a generic workflow using generative pretrained LLMs for natural language understanding and Answer Set Programming (ASP) for knowledge representation and reasoning, enabling direct processing of unannotated text and easy incorporation of domain knowledge.", "result": "Outperforms state-of-the-art JERE systems with only 10% training data, achieving 35% vs 15% performance on the difficult SciERC corpus Relation Extraction task - a 2.5x improvement.", "conclusion": "The LLM + ASP workflow provides an effective, elaboration-tolerant solution for JERE that works across domains with minimal training data and easily incorporates domain-specific knowledge."}}
{"id": "2508.12084", "pdf": "https://arxiv.org/pdf/2508.12084", "abs": "https://arxiv.org/abs/2508.12084", "authors": ["Jaejun Hwang", "Dayoung Gong", "Manjin Kim", "Minsu Cho"], "title": "Generic Event Boundary Detection via Denoising Diffusion", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to ICCV 2025", "summary": "Generic event boundary detection (GEBD) aims to identify natural boundaries\nin a video, segmenting it into distinct and meaningful chunks. Despite the\ninherent subjectivity of event boundaries, previous methods have focused on\ndeterministic predictions, overlooking the diversity of plausible solutions. In\nthis paper, we introduce a novel diffusion-based boundary detection model,\ndubbed DiffGEBD, that tackles the problem of GEBD from a generative\nperspective. The proposed model encodes relevant changes across adjacent frames\nvia temporal self-similarity and then iteratively decodes random noise into\nplausible event boundaries being conditioned on the encoded features.\nClassifier-free guidance allows the degree of diversity to be controlled in\ndenoising diffusion. In addition, we introduce a new evaluation metric to\nassess the quality of predictions considering both diversity and fidelity.\nExperiments show that our method achieves strong performance on two standard\nbenchmarks, Kinetics-GEBD and TAPOS, generating diverse and plausible event\nboundaries.", "AI": {"tldr": "DiffGEBD is a diffusion-based model for generic event boundary detection that generates diverse plausible event boundaries rather than deterministic predictions, using temporal self-similarity encoding and classifier-free guidance.", "motivation": "Previous GEBD methods focused on deterministic predictions but overlooked the inherent subjectivity and diversity of plausible event boundaries in videos.", "method": "A diffusion-based model that encodes frame changes via temporal self-similarity, then iteratively decodes random noise into event boundaries using classifier-free guidance to control diversity.", "result": "Achieves strong performance on Kinetics-GEBD and TAPOS benchmarks, generating diverse and plausible event boundaries.", "conclusion": "The generative diffusion approach effectively addresses the subjectivity problem in GEBD and produces high-quality diverse boundary predictions."}}
{"id": "2508.12355", "pdf": "https://arxiv.org/pdf/2508.12355", "abs": "https://arxiv.org/abs/2508.12355", "authors": ["Eviatar Nachshoni", "Arie Cattan", "Shmuel Amar", "Ori Shapira", "Ido Dagan"], "title": "Consensus or Conflict? Fine-Grained Evaluation of Conflicting Answers in Question-Answering", "categories": ["cs.CL"], "comment": "no comments", "summary": "Large Language Models (LLMs) have demonstrated strong performance in question\nanswering (QA) tasks. However, Multi-Answer Question Answering (MAQA), where a\nquestion may have several valid answers, remains challenging. Traditional QA\nsettings often assume consistency across evidences, but MAQA can involve\nconflicting answers. Constructing datasets that reflect such conflicts is\ncostly and labor-intensive, while existing benchmarks often rely on synthetic\ndata, restrict the task to yes/no questions, or apply unverified automated\nannotation. To advance research in this area, we extend the conflict-aware MAQA\nsetting to require models not only to identify all valid answers, but also to\ndetect specific conflicting answer pairs, if any. To support this task, we\nintroduce a novel cost-effective methodology for leveraging fact-checking\ndatasets to construct NATCONFQA, a new benchmark for realistic, conflict-aware\nMAQA, enriched with detailed conflict labels, for all answer pairs. We evaluate\neight high-end LLMs on NATCONFQA, revealing their fragility in handling various\ntypes of conflicts and the flawed strategies they employ to resolve them.", "AI": {"tldr": "A new benchmark NATCONFQA for multi-answer question answering with conflict detection, created using cost-effective methodology from fact-checking datasets, showing LLMs struggle with conflicting answers.", "motivation": "Multi-Answer Question Answering (MAQA) with conflicting answers remains challenging, and existing benchmarks have limitations like synthetic data, yes/no restrictions, or unverified automated annotation.", "method": "Extended conflict-aware MAQA setting requiring models to identify valid answers and detect conflicting pairs. Developed cost-effective methodology using fact-checking datasets to construct NATCONFQA benchmark with detailed conflict labels.", "result": "Evaluation of eight high-end LLMs revealed their fragility in handling various conflict types and flawed strategies for resolving them.", "conclusion": "The NATCONFQA benchmark provides a realistic testbed for conflict-aware MAQA, highlighting significant challenges in LLM performance that need to be addressed."}}
{"id": "2508.12145", "pdf": "https://arxiv.org/pdf/2508.12145", "abs": "https://arxiv.org/abs/2508.12145", "authors": ["Frederik L. Dennig", "Daniel A. Keim"], "title": "DE-VAE: Revealing Uncertainty in Parametric and Inverse Projections with Variational Autoencoders using Differential Entropy", "categories": ["cs.LG"], "comment": "5 pages, 3 figures, LaTeX", "summary": "Recently, autoencoders (AEs) have gained interest for creating parametric and\ninvertible projections of multidimensional data. Parametric projections make it\npossible to embed new, unseen samples without recalculating the entire\nprojection, while invertible projections allow the synthesis of new data\ninstances. However, existing methods perform poorly when dealing with\nout-of-distribution samples in either the data or embedding space. Thus, we\npropose DE-VAE, an uncertainty-aware variational AE using differential entropy\n(DE) to improve the learned parametric and invertible projections. Given a\nfixed projection, we train DE-VAE to learn a mapping into 2D space and an\ninverse mapping back to the original space. We conduct quantitative and\nqualitative evaluations on four well-known datasets, using UMAP and t-SNE as\nbaseline projection methods. Our findings show that DE-VAE can create\nparametric and inverse projections with comparable accuracy to other current\nAE-based approaches while enabling the analysis of embedding uncertainty.", "AI": {"tldr": "DE-VAE is an uncertainty-aware variational autoencoder that uses differential entropy to create parametric and invertible 2D projections while handling out-of-distribution samples better than existing methods.", "motivation": "Existing autoencoder methods perform poorly with out-of-distribution samples in data or embedding space, limiting their practical utility for parametric and invertible projections.", "method": "Proposes DE-VAE, a variational autoencoder that uses differential entropy to learn parametric mappings to 2D space and inverse mappings back to original space, trained with UMAP and t-SNE as baseline projections.", "result": "DE-VAE achieves comparable accuracy to current AE-based approaches while enabling embedding uncertainty analysis, validated through quantitative and qualitative evaluations on four datasets.", "conclusion": "DE-VAE successfully addresses the limitations of existing methods by providing uncertainty-aware parametric and invertible projections that handle out-of-distribution samples effectively."}}
{"id": "2508.12647", "pdf": "https://arxiv.org/pdf/2508.12647", "abs": "https://arxiv.org/abs/2508.12647", "authors": ["Hengnian Gu", "Zhifu Chen", "Yuxin Chen", "Jin Peng Zhou", "Dongdai Zhou"], "title": "Cognitive Structure Generation: From Educational Priors to Policy Optimization", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "Cognitive structure is a student's subjective organization of an objective\nknowledge system, reflected in the psychological construction of concepts and\ntheir relations. However, cognitive structure assessment remains a\nlong-standing challenge in student modeling and psychometrics, persisting as a\nfoundational yet largely unassessable concept in educational practice. This\npaper introduces a novel framework, Cognitive Structure Generation (CSG), in\nwhich we first pretrain a Cognitive Structure Diffusion Probabilistic Model\n(CSDPM) to generate students' cognitive structures from educational priors, and\nthen further optimize its generative process as a policy with hierarchical\nreward signals via reinforcement learning to align with genuine cognitive\ndevelopment levels during students' learning processes. Experimental results on\nfour popular real-world education datasets show that cognitive structures\ngenerated by CSG offer more comprehensive and effective representations for\nstudent modeling, substantially improving performance on KT and CD tasks while\nenhancing interpretability.", "AI": {"tldr": "A novel framework called Cognitive Structure Generation (CSG) that uses diffusion models and reinforcement learning to generate and optimize students' cognitive structures, improving student modeling performance and interpretability.", "motivation": "Cognitive structure assessment has been a long-standing challenge in educational practice - it's foundational yet largely unassessable despite being crucial for understanding how students organize knowledge concepts.", "method": "First pretrains a Cognitive Structure Diffusion Probabilistic Model (CSDPM) to generate cognitive structures from educational priors, then optimizes the generative process with hierarchical reward signals via reinforcement learning to align with genuine cognitive development levels.", "result": "Experimental results on four real-world education datasets show CSG-generated cognitive structures provide more comprehensive and effective representations for student modeling, substantially improving performance on Knowledge Tracing (KT) and Cognitive Diagnosis (CD) tasks.", "conclusion": "The CSG framework successfully addresses the challenge of cognitive structure assessment and demonstrates significant improvements in both performance and interpretability for student modeling tasks."}}
{"id": "2508.12089", "pdf": "https://arxiv.org/pdf/2508.12089", "abs": "https://arxiv.org/abs/2508.12089", "authors": ["Qinyuan Fan", "Clemens G\u00fchmann"], "title": "Enhancing 3D point accuracy of laser scanner through multi-stage convolutional neural network for applications in construction", "categories": ["cs.CV"], "comment": null, "summary": "We propose a multi-stage convolutional neural network (MSCNN) based\nintegrated method for reducing uncertainty of 3D point accuracy of lasar\nscanner (LS) in rough indoor rooms, providing more accurate spatial\nmeasurements for high-precision geometric model creation and renovation. Due to\ndifferent equipment limitations and environmental factors, high-end and low-end\nLS have positional errors. Our approach pairs high-accuracy scanners (HAS) as\nreferences with corresponding low-accuracy scanners (LAS) of measurements in\nidentical environments to quantify specific error patterns. By establishing a\nstatistical relationship between measurement discrepancies and their spatial\ndistribution, we develop a correction framework that combines traditional\ngeometric processing with targeted neural network refinement. This method\ntransforms the quantification of systematic errors into a supervised learning\nproblem, allowing precise correction while preserving critical geometric\nfeatures. Experimental results in our rough indoor rooms dataset show\nsignificant improvements in measurement accuracy, with mean square error (MSE)\nreductions exceeding 70% and peak signal-to-noise ratio (PSNR) improvements of\napproximately 6 decibels. This approach enables low-end devices to achieve\nmeasurement uncertainty levels approaching those of high-end devices without\nhardware modifications.", "AI": {"tldr": "MSCNN method improves 3D laser scanner accuracy in rough indoor environments by pairing high/low-end scanners and using neural networks to correct systematic errors, achieving 70%+ MSE reduction.", "motivation": "High-end and low-end laser scanners have positional errors due to equipment limitations and environmental factors, creating uncertainty in 3D point accuracy for geometric modeling in rough indoor rooms.", "method": "Pairs high-accuracy scanners as references with low-accuracy scanners in identical environments, establishes statistical relationships between measurement discrepancies and spatial distribution, combines geometric processing with neural network refinement, and transforms systematic error quantification into supervised learning.", "result": "Significant accuracy improvements with MSE reductions exceeding 70% and PSNR improvements of approximately 6 decibels in rough indoor rooms dataset.", "conclusion": "Enables low-end laser scanners to achieve measurement uncertainty levels approaching high-end devices without hardware modifications, providing accurate spatial measurements for high-precision geometric modeling."}}
{"id": "2508.12387", "pdf": "https://arxiv.org/pdf/2508.12387", "abs": "https://arxiv.org/abs/2508.12387", "authors": ["Yuanfeng Xu", "Zehui Dai", "Jian Liang", "Jiapeng Guan", "Guangrun Wang", "Liang Lin", "Xiaohui Lv"], "title": "ReaLM: Reflection-Enhanced Autonomous Reasoning with Small Language Models", "categories": ["cs.CL"], "comment": "16pages, 3 figures", "summary": "Small Language Models (SLMs) are a cost-effective alternative to Large\nLanguage Models (LLMs), but often struggle with complex reasoning due to their\nlimited capacity and a tendency to produce mistakes or inconsistent answers\nduring multi-step reasoning. Existing efforts have improved SLM performance,\nbut typically at the cost of one or more of three key aspects: (1) reasoning\ncapability, due to biased supervision that filters out negative reasoning paths\nand limits learning from errors; (2) autonomy, due to over-reliance on\nexternally generated reasoning signals; and (3) generalization, which suffers\nwhen models overfit to teacher-specific patterns. In this paper, we introduce\nReaLM, a reinforcement learning framework for robust and self-sufficient\nreasoning in vertical domains. To enhance reasoning capability, we propose\nMulti-Route Process Verification (MRPV), which contrasts both positive and\nnegative reasoning paths to extract decisive patterns. To reduce reliance on\nexternal guidance and improve autonomy, we introduce Enabling Autonomy via\nAsymptotic Induction (EAAI), a training strategy that gradually fades external\nsignals. To improve generalization, we apply guided chain-of-thought\ndistillation to encode domain-specific rules and expert knowledge into SLM\nparameters, making them part of what the model has learned. Extensive\nexperiments on both vertical and general reasoning tasks demonstrate that ReaLM\nsignificantly improves SLM performance across aspects (1)-(3) above.", "AI": {"tldr": "ReaLM is a reinforcement learning framework that enhances small language models' reasoning through multi-path verification, gradual autonomy induction, and domain knowledge distillation.", "motivation": "Small language models struggle with complex reasoning due to limited capacity, error-prone multi-step reasoning, and over-reliance on external guidance, while existing methods sacrifice reasoning capability, autonomy, or generalization.", "method": "Uses Multi-Route Process Verification to contrast positive/negative reasoning paths, Enabling Autonomy via Asymptotic Induction to gradually fade external signals, and guided chain-of-thought distillation to encode domain knowledge.", "result": "Extensive experiments show ReaLM significantly improves SLM performance in reasoning capability, autonomy, and generalization across vertical and general reasoning tasks.", "conclusion": "The framework successfully addresses key limitations of small language models by enhancing reasoning through multi-path learning, promoting self-sufficiency, and improving generalization with domain knowledge encoding."}}
{"id": "2508.12162", "pdf": "https://arxiv.org/pdf/2508.12162", "abs": "https://arxiv.org/abs/2508.12162", "authors": ["J. M. I. H. Jayakody", "A. M. H. H. Alahakoon", "C. R. M. Perera", "R. M. L. C. Srimal", "Roshan Ragel", "Vajira Thambawita", "Isuru Nawinne"], "title": "AICRN: Attention-Integrated Convolutional Residual Network for Interpretable Electrocardiogram Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The paradigm of electrocardiogram (ECG) analysis has evolved into real-time\ndigital analysis, facilitated by artificial intelligence (AI) and machine\nlearning (ML), which has improved the diagnostic precision and predictive\ncapacity of cardiac diseases. This work proposes a novel deep learning (DL)\narchitecture called the attention-integrated convolutional residual network\n(AICRN) to regress key ECG parameters such as the PR interval, the QT interval,\nthe QRS duration, the heart rate, the peak amplitude of the R wave, and the\namplitude of the T wave for interpretable ECG analysis. Our architecture is\nspecially designed with spatial and channel attention-related mechanisms to\naddress the type and spatial location of the ECG features for regression. The\nmodels employ a convolutional residual network to address vanishing and\nexploding gradient problems. The designed system addresses traditional analysis\nchallenges, such as loss of focus due to human errors, and facilitates the fast\nand easy detection of cardiac events, thereby reducing the manual efforts\nrequired to solve analysis tasks. AICRN models outperform existing models in\nparameter regression with higher precision. This work demonstrates that DL can\nplay a crucial role in the interpretability and precision of ECG analysis,\nopening up new clinical applications for cardiac monitoring and management.", "AI": {"tldr": "A novel deep learning architecture called AICRN uses attention mechanisms and convolutional residual networks for precise ECG parameter regression, outperforming existing models and improving interpretability in cardiac analysis.", "motivation": "To improve diagnostic precision and predictive capacity of cardiac diseases through AI/ML, addressing challenges like human errors in traditional ECG analysis and enabling fast detection of cardiac events.", "method": "Proposes attention-integrated convolutional residual network (AICRN) with spatial and channel attention mechanisms to regress key ECG parameters (PR interval, QT interval, QRS duration, heart rate, R wave amplitude, T wave amplitude) using convolutional residual networks to prevent gradient problems.", "result": "AICRN models outperform existing models in parameter regression with higher precision, demonstrating improved interpretability and accuracy in ECG analysis.", "conclusion": "Deep learning can play a crucial role in enhancing interpretability and precision of ECG analysis, opening new clinical applications for cardiac monitoring and management."}}
{"id": "2508.12651", "pdf": "https://arxiv.org/pdf/2508.12651", "abs": "https://arxiv.org/abs/2508.12651", "authors": ["Chunliang Hua", "Xiao Hu", "Jiayang Sun", "Zeyuan Yang"], "title": "The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning", "categories": ["cs.AI", "cs.ET"], "comment": "10 pages", "summary": "As urban aerial mobility (UAM) infrastructure development accelerates\nglobally, cities like Shenzhen are planning large-scale vertiport networks\n(e.g., 1,200+ facilities by 2026). Existing planning frameworks remain\ninadequate for this complexity due to historical limitations in data\ngranularity and real-world applicability. This paper addresses these gaps by\nfirst proposing the Capacitated Dynamic Maximum Covering Location Problem\n(CDMCLP), a novel optimization framework that simultaneously models urban-scale\nspatial-temporal demand, heterogeneous user behaviors, and infrastructure\ncapacity constraints. Building on this foundation, we introduce an Integrated\nPlanning Recommendation System that combines CDMCLP with socio-economic factors\nand dynamic clustering initialization. This system leverages adaptive parameter\ntuning based on empirical user behavior to generate practical planning\nsolutions. Validation in a Chinese center city demonstrates the effectiveness\nof the new optimization framework and recommendation system. Under the\nevaluation and optimization of CDMCLP, the quantitative performance of\ntraditional location methods are exposed and can be improved by 38\\%--52\\%,\nwhile the recommendation system shows user-friendliness and the effective\nintegration of complex elements. By integrating mathematical rigor with\npractical implementation considerations, this hybrid approach bridges the gap\nbetween theoretical location modeling and real-world UAM infrastructure\nplanning, offering municipalities a pragmatic tool for vertiport network\ndesign.", "AI": {"tldr": "Proposes CDMCLP optimization framework and Integrated Planning Recommendation System for urban aerial mobility vertiport network planning, improving traditional methods by 38-52% and bridging theory with practical implementation.", "motivation": "Address inadequacies in existing planning frameworks for complex urban aerial mobility infrastructure development, particularly for large-scale vertiport networks with spatial-temporal demand and capacity constraints.", "method": "Develops Capacitated Dynamic Maximum Covering Location Problem (CDMCLP) framework modeling urban-scale spatial-temporal demand, heterogeneous behaviors, and capacity constraints. Combines with socio-economic factors and dynamic clustering initialization in an Integrated Planning Recommendation System with adaptive parameter tuning.", "result": "Validation in Chinese center city shows CDMCLP improves quantitative performance of traditional location methods by 38-52%. Recommendation system demonstrates user-friendliness and effective integration of complex elements.", "conclusion": "The hybrid approach successfully bridges the gap between theoretical location modeling and real-world UAM infrastructure planning, providing municipalities with a pragmatic tool for vertiport network design."}}
{"id": "2508.12094", "pdf": "https://arxiv.org/pdf/2508.12094", "abs": "https://arxiv.org/abs/2508.12094", "authors": ["Songwei Liu", "Hong Liu", "Fangmin Chen", "Xurui Peng", "Chenqian Yan", "Lean Fu", "Xing Mei"], "title": "Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion models have transformed image synthesis by establishing\nunprecedented quality and creativity benchmarks. Nevertheless, their\nlarge-scale deployment faces challenges due to computationally intensive\niterative denoising processes. Although post-training quantization(PTQ)\nprovides an effective pathway for accelerating sampling, the iterative nature\nof diffusion models causes stepwise quantization errors to accumulate\nprogressively during generation, inevitably compromising output fidelity. To\naddress this challenge, we develop a theoretical framework that mathematically\nformulates error propagation in Diffusion Models (DMs), deriving per-step\nquantization error propagation equations and establishing the first closed-form\nsolution for cumulative error. Building on this theoretical foundation, we\npropose a timestep-aware cumulative error compensation scheme. Extensive\nexperiments across multiple image datasets demonstrate that our compensation\nstrategy effectively mitigates error propagation, significantly enhancing\nexisting PTQ methods to achieve state-of-the-art(SOTA) performance on\nlow-precision diffusion models.", "AI": {"tldr": "A theoretical framework for analyzing quantization error propagation in diffusion models with a timestep-aware compensation scheme that enhances post-training quantization performance.", "motivation": "Diffusion models face deployment challenges due to computationally intensive iterative denoising, and post-training quantization suffers from stepwise error accumulation that compromises output fidelity.", "method": "Developed a theoretical framework that mathematically formulates error propagation, derived per-step quantization error propagation equations, established closed-form solution for cumulative error, and proposed timestep-aware cumulative error compensation scheme.", "result": "Extensive experiments across multiple image datasets show the compensation strategy effectively mitigates error propagation and significantly enhances existing PTQ methods to achieve state-of-the-art performance on low-precision diffusion models.", "conclusion": "The proposed theoretical framework and compensation scheme successfully address quantization error accumulation in diffusion models, enabling more efficient deployment while maintaining output quality."}}
{"id": "2508.12393", "pdf": "https://arxiv.org/pdf/2508.12393", "abs": "https://arxiv.org/abs/2508.12393", "authors": ["Duzhen Zhang", "Zixiao Wang", "Zhong-Zhi Li", "Yahan Yu", "Shuncheng Jia", "Jiahua Dong", "Haotian Xu", "Xing Wu", "Yingying Zhang", "Tielin Zhang", "Jie Yang", "Xiuying Chen", "Le Song"], "title": "MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid expansion of medical literature presents growing challenges for\nstructuring and integrating domain knowledge at scale. Knowledge Graphs (KGs)\noffer a promising solution by enabling efficient retrieval, automated\nreasoning, and knowledge discovery. However, current KG construction methods\noften rely on supervised pipelines with limited generalizability or naively\naggregate outputs from Large Language Models (LLMs), treating biomedical\ncorpora as static and ignoring the temporal dynamics and contextual uncertainty\nof evolving knowledge. To address these limitations, we introduce MedKGent, a\nLLM agent framework for constructing temporally evolving medical KGs.\nLeveraging over 10 million PubMed abstracts published between 1975 and 2023, we\nsimulate the emergence of biomedical knowledge via a fine-grained daily time\nseries. MedKGent incrementally builds the KG in a day-by-day manner using two\nspecialized agents powered by the Qwen2.5-32B-Instruct model. The Extractor\nAgent identifies knowledge triples and assigns confidence scores via\nsampling-based estimation, which are used to filter low-confidence extractions\nand inform downstream processing. The Constructor Agent incrementally\nintegrates the retained triples into a temporally evolving graph, guided by\nconfidence scores and timestamps to reinforce recurring knowledge and resolve\nconflicts. The resulting KG contains 156,275 entities and 2,971,384 relational\ntriples. Quality assessments by two SOTA LLMs and three domain experts\ndemonstrate an accuracy approaching 90\\%, with strong inter-rater agreement. To\nevaluate downstream utility, we conduct RAG across seven medical question\nanswering benchmarks using five leading LLMs, consistently observing\nsignificant improvements over non-augmented baselines. Case studies further\ndemonstrate the KG's value in literature-based drug repurposing via\nconfidence-aware causal inference.", "AI": {"tldr": "MedKGent is an LLM agent framework that constructs temporally evolving medical knowledge graphs from PubMed abstracts, achieving 90% accuracy and demonstrating significant improvements in medical question answering benchmarks.", "motivation": "The rapid expansion of medical literature creates challenges for structuring domain knowledge. Current KG construction methods lack generalizability, ignore temporal dynamics, and treat biomedical corpora as static without addressing contextual uncertainty of evolving knowledge.", "method": "Uses two specialized agents (Extractor and Constructor) powered by Qwen2.5-32B-Instruct model. Processes over 10 million PubMed abstracts (1975-2023) in day-by-day manner. Extractor identifies knowledge triples with confidence scores via sampling-based estimation. Constructor incrementally integrates triples into temporally evolving graph using confidence scores and timestamps.", "result": "Constructed KG contains 156,275 entities and 2,971,384 relational triples. Quality assessments show ~90% accuracy with strong inter-rater agreement. RAG evaluation across 7 medical QA benchmarks with 5 leading LLMs shows significant improvements over non-augmented baselines.", "conclusion": "MedKGent successfully addresses limitations of current KG construction methods by incorporating temporal dynamics and confidence-aware processing, demonstrating strong performance in medical knowledge representation and downstream applications like drug repurposing."}}
{"id": "2508.12212", "pdf": "https://arxiv.org/pdf/2508.12212", "abs": "https://arxiv.org/abs/2508.12212", "authors": ["Chuanliu Fan", "Zicheng Ma", "Jun Gao", "Nan Yu", "Jun Zhang", "Ziqiang Cao", "Yi Qin Gao", "Guohong Fu"], "title": "ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Recent advances in protein large language models, such as ProtTeX, represent\nboth side-chain amino acids and backbone structure as discrete token sequences\nof residue length. While this design enables unified modeling of multimodal\nprotein information, it suffers from two major limitations: (1) The\nconcatenation of sequence and structure tokens approximately doubles the\nprotein length and breaks the intrinsic residue-level alignment between\nmodalities. (2) Constrained by the training corpus and limited context window,\nProtTeX is typically trained on single-protein inputs, rendering it\nincompatible with in-context learning (ICL) and thus limiting its\ngeneralization capability. To address these issues, we propose ProtTeX-CC, a\nlightweight two-stage compression framework designed to enhance ProtTeX under\nfew-shot settings. We first design a joint embedding compression mechanism that\nfuses sequence and structure representations at the residue level, effectively\nreducing the protein input length by half without sacrificing performance. Then\nwe propose a self-compression module that aggregates each full demonstration\ninto the latent space of the last few linguistic tokens, reducing the average\ndemonstration length from 751 tokens to less than 16 tokens. Compared to the\noriginal ProtTeX, our self-compression approach achieves a compression ratio of\napproximately 93.68% in the total prompt length under the 16-shot setting.\nWithout modifying the backbone model, ProtTeX-CC introduces only a small number\nof additional parameters through PEFT-based tuning in the joint embedding\ncompression stage and a single trainable projection layer in the\nself-compression stage. Extensive experiments on protein function prediction\nshow that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and\ngeneralizes well to the out-of-domain dataset with a performance gain of 11%.", "AI": {"tldr": "ProtTeX-CC is a lightweight compression framework that enhances protein language models by reducing input length through joint embedding compression and self-compression modules, achieving significant performance improvements in few-shot protein function prediction.", "motivation": "Address limitations of existing protein language models like ProtTeX, which suffer from doubled protein length due to concatenated sequence/structure tokens and incompatibility with in-context learning due to limited context windows.", "method": "Two-stage compression framework: 1) Joint embedding compression fuses sequence and structure representations at residue level, reducing input length by half. 2) Self-compression module aggregates demonstrations into latent space of last few tokens, reducing demonstration length from 751 to <16 tokens.", "result": "Achieves 93.68% compression ratio in total prompt length under 16-shot setting. Improves in-domain benchmark performance by 2% and out-of-domain performance by 11% without modifying backbone model.", "conclusion": "ProtTeX-CC effectively addresses the limitations of existing protein language models through innovative compression techniques, enabling better in-context learning and generalization capabilities with minimal additional parameters."}}
{"id": "2508.12682", "pdf": "https://arxiv.org/pdf/2508.12682", "abs": "https://arxiv.org/abs/2508.12682", "authors": ["Jinquan Shi", "Yingying Cheng", "Fan Zhang", "Miao Jiang", "Jun Lin", "Yanbai Shen"], "title": "GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance", "categories": ["cs.AI"], "comment": null, "summary": "The global shift towards renewable energy presents unprecedented challenges\nfor the electricity industry, making regulatory reasoning and compliance\nincreasingly vital. Grid codes, the regulations governing grid operations, are\ncomplex and often lack automated interpretation solutions, which hinders\nindustry expansion and undermines profitability for electricity companies. We\nintroduce GridCodex, an end to end framework for grid code reasoning and\ncompliance that leverages large language models and retrieval-augmented\ngeneration (RAG). Our framework advances conventional RAG workflows through\nmulti stage query refinement and enhanced retrieval with RAPTOR. We validate\nthe effectiveness of GridCodex with comprehensive benchmarks, including\nautomated answer assessment across multiple dimensions and regulatory agencies.\nExperimental results showcase a 26.4% improvement in answer quality and more\nthan a 10 fold increase in recall rate. An ablation study further examines the\nimpact of base model selection.", "AI": {"tldr": "GridCodex is an end-to-end framework using LLMs and enhanced RAG for automated grid code reasoning and compliance, achieving 26.4% answer quality improvement and 10x recall increase.", "motivation": "Renewable energy transition creates complex grid code compliance challenges that lack automated solutions, hindering industry expansion and profitability for electricity companies.", "method": "Leverages large language models with retrieval-augmented generation (RAG), featuring multi-stage query refinement and enhanced retrieval using RAPTOR technology.", "result": "26.4% improvement in answer quality, more than 10-fold increase in recall rate, validated through comprehensive benchmarks across multiple regulatory agencies.", "conclusion": "GridCodex framework effectively addresses grid code interpretation challenges and demonstrates significant performance improvements over conventional approaches."}}
{"id": "2508.12108", "pdf": "https://arxiv.org/pdf/2508.12108", "abs": "https://arxiv.org/abs/2508.12108", "authors": ["Ziyang Zhang", "Yang Yu", "Xulei Yang", "Si Yong Yeo"], "title": "VELVET-Med: Vision and Efficient Language Pre-training for Volumetric Imaging Tasks in Medicine", "categories": ["cs.CV"], "comment": null, "summary": "Vision-and-language models (VLMs) have been increasingly explored in the\nmedical domain, particularly following the success of CLIP in general domain.\nHowever, unlike the relatively straightforward pairing of 2D images and text,\ncurating large-scale paired data in the medical field for volumetric modalities\nsuch as CT scans remains a challenging and time-intensive process. This\ndifficulty often limits the performance on downstream tasks. To address these\nchallenges, we propose a novel vision-language pre-training (VLP) framework,\ntermed as \\textbf{VELVET-Med}, specifically designed for limited volumetric\ndata such as 3D CT and associated radiology reports. Instead of relying on\nlarge-scale data collection, our method focuses on the development of effective\npre-training objectives and model architectures. The key contributions are: 1)\nWe incorporate uni-modal self-supervised learning into VLP framework, which are\noften underexplored in the existing literature. 2) We propose a novel language\nencoder, termed as \\textbf{TriBERT}, for learning multi-level textual\nsemantics. 3) We devise the hierarchical contrastive learning to capture\nmulti-level vision-language correspondence. Using only 38,875 scan-report\npairs, our approach seeks to uncover rich spatial and semantic relationships\nembedded in volumetric medical images and corresponding clinical narratives,\nthereby enhancing the generalization ability of the learned encoders. The\nresulting encoders exhibit strong transferability, achieving state-of-the-art\nperformance across a wide range of downstream tasks, including 3D segmentation,\ncross-modal retrieval, visual question answering, and report generation.", "AI": {"tldr": "VELVET-Med is a novel vision-language pre-training framework for 3D medical imaging that achieves state-of-the-art performance with limited data (38,875 scan-report pairs) through innovative self-supervised learning, a TriBERT language encoder, and hierarchical contrastive learning.", "motivation": "Medical VLMs face challenges with 3D volumetric data like CT scans due to the difficulty and time-intensive process of curating large-scale paired data, which limits downstream task performance.", "method": "Proposes VELVET-Med framework with: 1) uni-modal self-supervised learning integration, 2) TriBERT language encoder for multi-level textual semantics, and 3) hierarchical contrastive learning for multi-level vision-language correspondence.", "result": "Achieves state-of-the-art performance across multiple downstream tasks including 3D segmentation, cross-modal retrieval, visual question answering, and report generation using only 38,875 scan-report pairs.", "conclusion": "The framework successfully uncovers rich spatial and semantic relationships in volumetric medical images and clinical narratives, demonstrating strong transferability and generalization ability with limited data."}}
{"id": "2508.12405", "pdf": "https://arxiv.org/pdf/2508.12405", "abs": "https://arxiv.org/abs/2508.12405", "authors": ["Zilong Bai", "Zihan Xu", "Cong Sun", "Chengxi Zang", "H. Timothy Bunnell", "Catherine Sinfield", "Jacqueline Rutter", "Aaron Thomas Martinez", "L. Charles Bailey", "Mark Weiner", "Thomas R. Campion", "Thomas Carton", "Christopher B. Forrest", "Rainu Kaushal", "Fei Wang", "Yifan Peng"], "title": "Extracting Post-Acute Sequelae of SARS-CoV-2 Infection Symptoms from Clinical Notes via Hybrid Natural Language Processing", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for publication in npj Health Systems", "summary": "Accurately and efficiently diagnosing Post-Acute Sequelae of COVID-19 (PASC)\nremains challenging due to its myriad symptoms that evolve over long- and\nvariable-time intervals. To address this issue, we developed a hybrid natural\nlanguage processing pipeline that integrates rule-based named entity\nrecognition with BERT-based assertion detection modules for PASC-symptom\nextraction and assertion detection from clinical notes. We developed a\ncomprehensive PASC lexicon with clinical specialists. From 11 health systems of\nthe RECOVER initiative network across the U.S., we curated 160 intake progress\nnotes for model development and evaluation, and collected 47,654 progress notes\nfor a population-level prevalence study. We achieved an average F1 score of\n0.82 in one-site internal validation and 0.76 in 10-site external validation\nfor assertion detection. Our pipeline processed each note at $2.448\\pm 0.812$\nseconds on average. Spearman correlation tests showed $\\rho >0.83$ for positive\nmentions and $\\rho >0.72$ for negative ones, both with $P <0.0001$. These\ndemonstrate the effectiveness and efficiency of our models and their potential\nfor improving PASC diagnosis.", "AI": {"tldr": "Hybrid NLP pipeline combining rule-based NER with BERT-based assertion detection for efficient PASC symptom extraction from clinical notes, achieving high accuracy and processing speed.", "motivation": "PASC diagnosis is challenging due to evolving symptoms over variable time intervals, requiring efficient extraction and analysis from clinical notes.", "method": "Developed comprehensive PASC lexicon with specialists, created hybrid NLP pipeline integrating rule-based named entity recognition with BERT-based assertion detection modules, using 160 notes for development and 47,654 notes for population study.", "result": "Achieved F1 score of 0.82 (internal) and 0.76 (external validation), processed notes in 2.448\u00b10.812 seconds each, with strong Spearman correlations (\u03c1>0.83 positive, \u03c1>0.72 negative mentions, both p<0.0001).", "conclusion": "The pipeline demonstrates effectiveness and efficiency for PASC symptom extraction, showing potential to improve PASC diagnosis through automated clinical note analysis."}}
{"id": "2508.12220", "pdf": "https://arxiv.org/pdf/2508.12220", "abs": "https://arxiv.org/abs/2508.12220", "authors": ["Abdullah X"], "title": "Unlearning at Scale: Implementing the Right to be Forgotten in Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CR", "I.2.6; I.2.7"], "comment": "Preprint; 2 figures + several tables; includes appendix.\n  Artifact/code link in paper", "summary": "We study the right to be forgotten (GDPR Art. 17) for large language models\nand frame unlearning as a reproducible systems problem. Our approach treats\ntraining as a deterministic program and logs a minimal per-microbatch record\n(ordered ID hash, RNG seed, learning-rate value, optimizer-step counter, and\naccumulation boundary). Under a pinned stack and deterministic kernels,\nreplaying the training tail while filtering only the forget closure yields the\nsame parameters as training on the retain set (bit-identical in the training\ndtype) when preconditions hold. To meet latency and availability constraints,\nwe add complementary paths: (i) exact reverts of recent steps via\nmicro-checkpoints or dense per-step deltas, (ii) cohort-scoped adapter deletion\nwhen the base is frozen, and (iii) a curvature-guided anti-update followed by a\nshort retain-tune, audit-gated with escalation to exact replay. We report\nstorage/latency budgets and a toy artifact validating mechanics; in a\ncontrolled run that satisfies the preconditions we demonstrate byte-identical\nequality of model and optimizer states.", "AI": {"tldr": "A deterministic approach to machine unlearning for large language models that logs minimal training metadata to enable exact replay and removal of specific data points while maintaining model integrity.", "motivation": "To address the right to be forgotten (GDPR Article 17) requirements for large language models by creating a reproducible system for data removal that maintains model performance on retained data.", "method": "Treats training as deterministic program with minimal logging (ID hash, RNG seed, learning rate, optimizer step, accumulation boundary). Uses exact replay of training tail while filtering out forget data, with complementary paths including micro-checkpoints, adapter deletion, and curvature-guided anti-updates.", "result": "Achieves byte-identical equality of model and optimizer states when preconditions are satisfied, demonstrating successful unlearning while maintaining identical parameters to training on only the retain set.", "conclusion": "The approach provides a practical solution for GDPR compliance through deterministic training replay, offering multiple complementary methods to meet latency and availability constraints while ensuring verifiable data removal."}}
{"id": "2508.12687", "pdf": "https://arxiv.org/pdf/2508.12687", "abs": "https://arxiv.org/abs/2508.12687", "authors": ["Ashish Seth", "Utkarsh Tyagi", "Ramaneswaran Selvakumar", "Nishit Anand", "Sonal Kumar", "Sreyan Ghosh", "Ramani Duraiswami", "Chirag Agarwal", "Dinesh Manocha"], "title": "EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\nperformance in complex multimodal tasks. While MLLMs excel at visual perception\nand reasoning in third-person and egocentric videos, they are prone to\nhallucinations, generating coherent yet inaccurate responses. We present\nEgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric\nvideos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated\nopen and closed-ended questions designed to trigger hallucinations in both\nvisual and auditory cues in egocentric videos. Evaluations across ten MLLMs\nreveal significant challenges, including powerful models like GPT-4o and\nGemini, achieving only 59% accuracy. EgoIllusion lays the foundation in\ndeveloping robust benchmarks to evaluate the effectiveness of MLLMs and spurs\nthe development of better egocentric MLLMs with reduced hallucination rates.\nOur benchmark will be open-sourced for reproducibility.", "AI": {"tldr": "EgoIllusion is the first benchmark to evaluate hallucinations in MLLMs for egocentric videos, featuring 1,400 videos with 8,000 questions that reveal significant accuracy challenges even in top models like GPT-4o and Gemini.", "motivation": "While MLLMs excel at visual perception in videos, they are prone to generating coherent but inaccurate responses (hallucinations), particularly in egocentric video contexts where this problem hasn't been systematically studied.", "method": "Created EgoIllusion benchmark with 1,400 egocentric videos paired with 8,000 human-annotated open and closed-ended questions designed to trigger hallucinations in both visual and auditory cues.", "result": "Evaluations across ten MLLMs show significant challenges, with even powerful models like GPT-4o and Gemini achieving only 59% accuracy, demonstrating widespread hallucination issues.", "conclusion": "EgoIllusion provides a foundation for developing robust benchmarks to evaluate MLLM effectiveness and will spur development of better egocentric MLLMs with reduced hallucination rates. The benchmark will be open-sourced for reproducibility."}}
{"id": "2508.12109", "pdf": "https://arxiv.org/pdf/2508.12109", "abs": "https://arxiv.org/abs/2508.12109", "authors": ["Ye Wang", "Qianglong Chen", "Zejun Li", "Siyuan Wang", "Shijie Guo", "Zhirui Zhang", "Zhongyu Wei"], "title": "Simple o3: Towards Interleaved Vision-Language Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have shown impressive performance on\nvision-language tasks, but their long Chain-of-Thought (CoT) capabilities in\nmultimodal scenarios remain underexplored. Inspired by OpenAI's o3 model, which\nemulates human-like ''thinking with image'' through iterative visual\ntransformations and linguistic reasoning, we propose Simple o3, an end-to-end\nframework that integrates dynamic tool interactions (e.g., cropping, zooming,\nand reusing) into interleaved vision-language reasoning via supervised\nfine-tuning (SFT). Our approach features a scalable data synthesis pipeline\nthat generates high-quality interleaved vision-language reasoning chains via an\n''observe-reason-act'' cycle, complete with executable visual operations and\nrigorous verification, yielding the open-source TWI-Tools-146K dataset.\nExperimental results demonstrate Simple o3's superior performance on diverse\nbenchmarks, outperforming existing approaches. By combining enhanced reasoning\ncapabilities, Simple o3 establishes a powerful yet computationally affordable\nparadigm for advancing multimodal reasoning. Remarkably, we provide the first\nin-depth analysis of different interleaved reasoning strategies, offering\ninsights into their impact on model performance. We found that by introducing\nadditional visual tokens for interleaved vision-language reasoning, reusing and\nmagnifying the original image significantly improves the model's visual\nreasoning and fine-grained perception, while image cropping based on precise\nvisual grounding allows the model to effectively focus on key entities or\nregions, further enhancing its capabilities.", "AI": {"tldr": "Simple o3 is an end-to-end MLLM framework that integrates dynamic visual tools (cropping, zooming, reusing) into interleaved vision-language reasoning via supervised fine-tuning, outperforming existing approaches on multimodal benchmarks.", "motivation": "Multimodal LLMs show strong performance but their long Chain-of-Thought capabilities in multimodal scenarios remain underexplored, particularly the ability to emulate human-like \"thinking with image\" through iterative visual transformations.", "method": "Proposes Simple o3 framework with scalable data synthesis pipeline generating high-quality interleaved vision-language reasoning chains via \"observe-reason-act\" cycle, creating TWI-Tools-146K dataset with executable visual operations and rigorous verification.", "result": "Superior performance on diverse benchmarks, outperforming existing approaches. Found that reusing and magnifying original images improves visual reasoning, while image cropping based on precise visual grounding enhances focus on key entities.", "conclusion": "Simple o3 establishes a computationally affordable paradigm for advancing multimodal reasoning, providing first in-depth analysis of different interleaved reasoning strategies and their impact on model performance."}}
{"id": "2508.12407", "pdf": "https://arxiv.org/pdf/2508.12407", "abs": "https://arxiv.org/abs/2508.12407", "authors": ["Zhuorui Liu", "Chen Zhang", "Dawei Song"], "title": "ZigzagAttention: Efficient Long-Context Inference with Exclusive Retrieval and Streaming Heads", "categories": ["cs.CL"], "comment": "5 pages, 4 figures", "summary": "With the rapid development of large language models (LLMs), handling long\ncontext has become one of the vital abilities in LLMs. Such long-context\nability is accompanied by difficulties in deployment, especially due to the\nincreased consumption of KV cache. There is certain work aiming to optimize the\nmemory footprint of KV cache, inspired by the observation that attention heads\ncan be categorized into retrieval heads that are of great significance and\nstreaming heads that are of less significance. Typically, identifying the\nstreaming heads and and waiving the KV cache in the streaming heads would\nlargely reduce the overhead without hurting the performance that much. However,\nsince employing both retrieval and streaming heads in one layer decomposes one\nlarge round of attention computation into two small ones, it may unexpectedly\nbring extra latency on accessing and indexing tensors. Based on this intuition,\nwe impose an important improvement to the identification process of retrieval\nand streaming heads, in which we design a criterion that enforces exclusively\nretrieval or streaming heads gathered in one unique layer. In this way, we\nfurther eliminate the extra latency and only incur negligible performance\ndegradation. Our method named \\textsc{ZigzagAttention} is competitive among\nconsidered baselines owing to reduced latency and comparable performance.", "AI": {"tldr": "ZigzagAttention reduces KV cache memory by categorizing attention heads into retrieval and streaming heads, but improves latency by grouping same-type heads in layers to avoid extra computation overhead.", "motivation": "Large language models face deployment challenges due to KV cache memory consumption from long contexts. Existing methods categorize heads but create latency issues from split attention computations.", "method": "Improved head identification that enforces exclusively retrieval or streaming heads in each layer, eliminating extra tensor access latency while maintaining performance.", "result": "Reduced latency with negligible performance degradation, making ZigzagAttention competitive among baselines for long-context handling.", "conclusion": "Grouping same-type attention heads by layer effectively reduces KV cache overhead without the latency penalties of mixed-head layers."}}
{"id": "2508.12222", "pdf": "https://arxiv.org/pdf/2508.12222", "abs": "https://arxiv.org/abs/2508.12222", "authors": ["Sagar Shrestha", "Rajesh Shrestha", "Tri Nguyen", "Subash Timilsina"], "title": "Distribution Matching via Generalized Consistency Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancement in generative models have demonstrated remarkable\nperformance across various data modalities. Beyond their typical use in data\nsynthesis, these models play a crucial role in distribution matching tasks such\nas latent variable modeling, domain translation, and domain adaptation.\nGenerative Adversarial Networks (GANs) have emerged as the preferred method of\ndistribution matching due to their efficacy in handling high-dimensional data\nand their flexibility in accommodating various constraints. However, GANs often\nencounter challenge in training due to their bi-level min-max optimization\nobjective and susceptibility to mode collapse. In this work, we propose a novel\napproach for distribution matching inspired by the consistency models employed\nin Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF\nmodels, such as having a straight forward norm minimization objective, while\nremaining adaptable to different constraints similar to GANs. We provide\ntheoretical validation of our proposed objective and demonstrate its\nperformance through experiments on synthetic and real-world datasets.", "AI": {"tldr": "Proposes a novel distribution matching approach using consistency models from Continuous Normalizing Flow (CNF) to overcome GAN training challenges while maintaining flexibility.", "motivation": "GANs face training difficulties due to min-max optimization and mode collapse, despite being effective for distribution matching tasks like domain adaptation and latent variable modeling.", "method": "Leverages consistency models from CNF with a straightforward norm minimization objective, combining CNF's training advantages with GAN-like constraint adaptability.", "result": "Theoretical validation and experimental results on synthetic and real-world datasets demonstrate the proposed method's performance.", "conclusion": "The approach successfully addresses GAN limitations while preserving the flexibility needed for various distribution matching applications."}}
{"id": "2508.12725", "pdf": "https://arxiv.org/pdf/2508.12725", "abs": "https://arxiv.org/abs/2508.12725", "authors": ["Wenjie Chen", "Wenbin Li", "Di Yao", "Xuying Meng", "Chang Gong", "Jingping Bi"], "title": "GTool: Graph Enhanced Tool Planning with Large Language Model", "categories": ["cs.AI"], "comment": "16 pages, 9 figures", "summary": "Tool planning with large language models (LLMs), referring to selecting,\norganizing, and preparing the tools necessary to complete a user request,\nbridges the gap between natural language understanding and task execution.\nHowever, current works treat different tools as isolated components and fail to\nleverage the inherent dependencies of tools, leading to invalid planning\nresults. Since tool dependencies are often incomplete, it becomes challenging\nfor LLMs to accurately identify the appropriate tools required by a user\nrequest, especially when confronted with a large toolset. To solve this\nchallenge, we propose \\texttt{GTool}, which is the first work aiming to enhance\nthe tool planning ability of LLMs under incomplete dependencies. \\texttt{GTool}\nconstructs a request-specific tool graph to select tools efficiently and\ngenerate the \\texttt{<graph token>} which provides sufficient dependency\ninformation understandable by LLMs. Moreover, a missing dependency prediction\ntask is designed to improve the reliability of \\texttt{GTool} with incomplete\ndependencies. Without trimming LLMs, \\texttt{GTool} can be seamlessly\nintegrated with various LLM backbones without extensive retraining. Extensive\nexperiments show that \\texttt{GTool} achieves more than 29.6\\% performance\nimprovements compared with the state-of-the-art (SOTA) baselines with a\nlight-weight (7B) LLM backbone.", "AI": {"tldr": "GTool enhances LLM tool planning by constructing request-specific tool graphs and generating graph tokens to handle incomplete tool dependencies, achieving 29.6% performance improvement over SOTA baselines.", "motivation": "Current LLM tool planning approaches treat tools as isolated components and fail to leverage inherent tool dependencies, leading to invalid planning results especially with incomplete dependency information and large toolsets.", "method": "GTool constructs request-specific tool graphs to efficiently select tools and generates <graph tokens> that provide dependency information understandable by LLMs. It includes a missing dependency prediction task to improve reliability with incomplete dependencies.", "result": "Extensive experiments show GTool achieves more than 29.6% performance improvements compared with state-of-the-art baselines using a lightweight 7B LLM backbone.", "conclusion": "GTool is the first work to enhance LLM tool planning under incomplete dependencies, can be seamlessly integrated with various LLM backbones without extensive retraining, and significantly outperforms existing methods."}}
{"id": "2508.12131", "pdf": "https://arxiv.org/pdf/2508.12131", "abs": "https://arxiv.org/abs/2508.12131", "authors": ["Minh Tran", "Johnmark Clements", "Annie Prasanna", "Tri Nguyen", "Ngan Le"], "title": "DualFit: A Two-Stage Virtual Try-On via Warping and Synthesis", "categories": ["cs.CV"], "comment": "Retail Vision, ICCV 2025", "summary": "Virtual Try-On technology has garnered significant attention for its\npotential to transform the online fashion retail experience by allowing users\nto visualize how garments would look on them without physical trials. While\nrecent advances in diffusion-based warping-free methods have improved\nperceptual quality, they often fail to preserve fine-grained garment details\nsuch as logos and printed text elements that are critical for brand integrity\nand customer trust. In this work, we propose DualFit, a hybrid VTON pipeline\nthat addresses this limitation by two-stage approach. In the first stage,\nDualFit warps the target garment to align with the person image using a learned\nflow field, ensuring high-fidelity preservation. In the second stage, a\nfidelity-preserving try-on module synthesizes the final output by blending the\nwarped garment with preserved human regions. Particularly, to guide this\nprocess, we introduce a preserved-region input and an inpainting mask, enabling\nthe model to retain key areas and regenerate only where necessary, particularly\naround garment seams. Extensive qualitative results show that DualFit achieves\nvisually seamless try-on results while faithfully maintaining high-frequency\ngarment details, striking an effective balance between reconstruction accuracy\nand perceptual realism.", "AI": {"tldr": "DualFit is a two-stage virtual try-on system that combines warping for detail preservation with diffusion-based synthesis for seamless results, addressing the limitation of previous methods in maintaining fine garment details like logos and text.", "motivation": "Current diffusion-based virtual try-on methods fail to preserve critical fine-grained garment details such as logos and printed text, which are essential for brand integrity and customer trust in fashion retail.", "method": "Two-stage hybrid approach: 1) Warp target garment using learned flow field for high-fidelity detail preservation, 2) Fidelity-preserving try-on module that blends warped garment with preserved human regions using preserved-region input and inpainting mask to regenerate only necessary areas around seams.", "result": "Extensive qualitative results show visually seamless try-on outcomes while faithfully maintaining high-frequency garment details, achieving effective balance between reconstruction accuracy and perceptual realism.", "conclusion": "DualFit successfully addresses the detail preservation problem in virtual try-on by combining warping and diffusion approaches, providing both high-fidelity garment representation and seamless visual integration."}}
{"id": "2508.12411", "pdf": "https://arxiv.org/pdf/2508.12411", "abs": "https://arxiv.org/abs/2508.12411", "authors": ["Emanuel Z. Fenech-Borg", "Tilen P. Meznaric-Kos", "Milica D. Lekovic-Bojovic", "Arni J. Hentze-Djurhuus"], "title": "The Cultural Gene of Large Language Models: A Study on the Impact of Cross-Corpus Training on Model Values and Biases", "categories": ["cs.CL", "I.2.7; K.4.1; H.3.3"], "comment": "10 pages, 5 figures, IEEE conference format, submitted to [Conference\n  Name]", "summary": "Large language models (LLMs) are deployed globally, yet their underlying\ncultural and ethical assumptions remain underexplored. We propose the notion of\na \"cultural gene\" -- a systematic value orientation that LLMs inherit from\ntheir training corpora -- and introduce a Cultural Probe Dataset (CPD) of 200\nprompts targeting two classic cross-cultural dimensions:\nIndividualism-Collectivism (IDV) and Power Distance (PDI). Using standardized\nzero-shot prompts, we compare a Western-centric model (GPT-4) and an\nEastern-centric model (ERNIE Bot). Human annotation shows significant and\nconsistent divergence across both dimensions. GPT-4 exhibits individualistic\nand low-power-distance tendencies (IDV score approx 1.21; PDI score approx\n-1.05), while ERNIE Bot shows collectivistic and higher-power-distance\ntendencies (IDV approx -0.89; PDI approx 0.76); differences are statistically\nsignificant (p < 0.001). We further compute a Cultural Alignment Index (CAI)\nagainst Hofstede's national scores and find GPT-4 aligns more closely with the\nUSA (e.g., IDV CAI approx 0.91; PDI CAI approx 0.88) whereas ERNIE Bot aligns\nmore closely with China (IDV CAI approx 0.85; PDI CAI approx 0.81). Qualitative\nanalyses of dilemma resolution and authority-related judgments illustrate how\nthese orientations surface in reasoning. Our results support the view that LLMs\nfunction as statistical mirrors of their cultural corpora and motivate\nculturally aware evaluation and deployment to avoid algorithmic cultural\nhegemony.", "AI": {"tldr": "LLMs inherit cultural biases from training data, with GPT-4 showing Western individualistic/low-power-distance values and ERNIE Bot showing Eastern collectivistic/high-power-distance values, demonstrating they function as statistical mirrors of their cultural corpora.", "motivation": "To investigate the underlying cultural and ethical assumptions in large language models that are deployed globally, as these models may inherit systematic value orientations from their training corpora that remain underexplored.", "method": "Created a Cultural Probe Dataset (CPD) of 200 prompts targeting Individualism-Collectivism and Power Distance dimensions. Used standardized zero-shot prompts to compare GPT-4 (Western-centric) and ERNIE Bot (Eastern-centric), with human annotation and statistical analysis including Cultural Alignment Index against Hofstede's national scores.", "result": "Significant divergence found: GPT-4 shows individualistic/low-power-distance tendencies (IDV ~1.21; PDI ~-1.05), ERNIE Bot shows collectivistic/high-power-distance tendencies (IDV ~-0.89; PDI ~0.76). GPT-4 aligns more with USA cultural scores, ERNIE Bot aligns more with China. Differences statistically significant (p < 0.001).", "conclusion": "LLMs function as statistical mirrors of their cultural training corpora, highlighting the need for culturally aware evaluation and deployment to prevent algorithmic cultural hegemony."}}
{"id": "2508.12233", "pdf": "https://arxiv.org/pdf/2508.12233", "abs": "https://arxiv.org/abs/2508.12233", "authors": ["Sagar Shrestha"], "title": "Communication-Efficient Distributed Asynchronous ADMM", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "In distributed optimization and federated learning, asynchronous alternating\ndirection method of multipliers (ADMM) serves as an attractive option for\nlarge-scale optimization, data privacy, straggler nodes and variety of\nobjective functions. However, communication costs can become a major bottleneck\nwhen the nodes have limited communication budgets or when the data to be\ncommunicated is prohibitively large. In this work, we propose introducing\ncoarse quantization to the data to be exchanged in aynchronous ADMM so as to\nreduce communication overhead for large-scale federated learning and\ndistributed optimization applications. We experimentally verify the convergence\nof the proposed method for several distributed learning tasks, including neural\nnetworks.", "AI": {"tldr": "Quantized asynchronous ADMM for distributed optimization reduces communication costs through coarse quantization while maintaining convergence.", "motivation": "Communication costs are a major bottleneck in distributed optimization and federated learning, especially with limited communication budgets or large data sizes.", "method": "Introducing coarse quantization to the data exchanged in asynchronous ADMM to reduce communication overhead.", "result": "Experimental verification shows convergence of the proposed method for various distributed learning tasks, including neural networks.", "conclusion": "Quantized asynchronous ADMM effectively reduces communication costs while preserving convergence properties for large-scale distributed optimization applications."}}
{"id": "2508.12754", "pdf": "https://arxiv.org/pdf/2508.12754", "abs": "https://arxiv.org/abs/2508.12754", "authors": ["Alessio Galatolo", "Luca Alberto Rappuoli", "Katie Winkle", "Meriem Beloucif"], "title": "Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants", "categories": ["cs.AI"], "comment": "Full version of the paper published in ECAI 2025 proceedings (IOS\n  Press, CC BY-NC 4.0)", "summary": "The recent rise in popularity of large language models (LLMs) has prompted\nconsiderable concerns about their moral capabilities. Although considerable\neffort has been dedicated to aligning LLMs with human moral values, existing\nbenchmarks and evaluations remain largely superficial, typically measuring\nalignment based on final ethical verdicts rather than explicit moral reasoning.\nIn response, this paper aims to advance the investigation of LLMs' moral\ncapabilities by examining their capacity to function as Artificial Moral\nAssistants (AMAs), systems envisioned in the philosophical literature to\nsupport human moral deliberation. We assert that qualifying as an AMA requires\nmore than what state-of-the-art alignment techniques aim to achieve: not only\nmust AMAs be able to discern ethically problematic situations, they should also\nbe able to actively reason about them, navigating between conflicting values\noutside of those embedded in the alignment phase. Building on existing\nphilosophical literature, we begin by designing a new formal framework of the\nspecific kind of behaviour an AMA should exhibit, individuating key qualities\nsuch as deductive and abductive moral reasoning. Drawing on this theoretical\nframework, we develop a benchmark to test these qualities and evaluate popular\nopen LLMs against it. Our results reveal considerable variability across models\nand highlight persistent shortcomings, particularly regarding abductive moral\nreasoning. Our work connects theoretical philosophy with practical AI\nevaluation while also emphasising the need for dedicated strategies to\nexplicitly enhance moral reasoning capabilities in LLMs. Code available at\nhttps://github.com/alessioGalatolo/AMAeval", "AI": {"tldr": "This paper introduces a new framework for evaluating LLMs as Artificial Moral Assistants (AMAs), focusing on moral reasoning capabilities beyond superficial alignment, and reveals significant gaps in current models' abductive reasoning abilities.", "motivation": "Current LLM alignment benchmarks are superficial, measuring only final ethical verdicts rather than deep moral reasoning capabilities needed for AMAs that can support human moral deliberation.", "method": "Developed a formal framework based on philosophical literature defining AMA behavior qualities (deductive/abductive reasoning), then created a benchmark to evaluate popular open LLMs against these criteria.", "result": "Found considerable variability across models with persistent shortcomings, particularly in abductive moral reasoning capabilities.", "conclusion": "Connects philosophy with AI evaluation, emphasizing need for dedicated strategies to explicitly enhance moral reasoning in LLMs beyond current alignment techniques."}}
{"id": "2508.12132", "pdf": "https://arxiv.org/pdf/2508.12132", "abs": "https://arxiv.org/abs/2508.12132", "authors": ["Amira Guesmi", "Bassem Ouni", "Muhammad Shafique"], "title": "TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "Quantized Neural Networks (QNNs) are increasingly deployed in edge and\nresource-constrained environments due to their efficiency in computation and\nmemory usage. While shown to distort the gradient landscape and weaken\nconventional pixel-level attacks, it provides limited robustness against\npatch-based adversarial attacks-localized, high-saliency perturbations that\nremain surprisingly transferable across bit-widths. Existing defenses either\noverfit to fixed quantization settings or fail to address this cross-bit\ngeneralization vulnerability. We introduce \\textbf{TriQDef}, a tri-level\nquantization-aware defense framework designed to disrupt the transferability of\npatch-based adversarial attacks across QNNs. TriQDef consists of: (1) a Feature\nDisalignment Penalty (FDP) that enforces semantic inconsistency by penalizing\nperceptual similarity in intermediate representations; (2) a Gradient\nPerceptual Dissonance Penalty (GPDP) that explicitly misaligns input gradients\nacross bit-widths by minimizing structural and directional agreement via Edge\nIoU and HOG Cosine metrics; and (3) a Joint Quantization-Aware Training\nProtocol that unifies these penalties within a shared-weight training scheme\nacross multiple quantization levels. Extensive experiments on CIFAR-10 and\nImageNet demonstrate that TriQDef reduces Attack Success Rates (ASR) by over\n40\\% on unseen patch and quantization combinations, while preserving high clean\naccuracy. Our findings underscore the importance of disrupting both semantic\nand perceptual gradient alignment to mitigate patch transferability in QNNs.", "AI": {"tldr": "TriQDef is a tri-level quantization-aware defense framework that protects quantized neural networks against transferable patch-based adversarial attacks across different bit-widths by disrupting semantic and gradient alignment.", "motivation": "Quantized Neural Networks (QNNs) provide limited robustness against patch-based adversarial attacks that remain transferable across different quantization bit-widths, and existing defenses either overfit to fixed quantization settings or fail to address this cross-bit generalization vulnerability.", "method": "TriQDef consists of three components: (1) Feature Disalignment Penalty (FDP) that enforces semantic inconsistency by penalizing perceptual similarity in intermediate representations; (2) Gradient Perceptual Dissonance Penalty (GPDP) that misaligns input gradients across bit-widths using Edge IoU and HOG Cosine metrics; (3) Joint Quantization-Aware Training Protocol that unifies these penalties in a shared-weight training scheme across multiple quantization levels.", "result": "Extensive experiments on CIFAR-10 and ImageNet show that TriQDef reduces Attack Success Rates (ASR) by over 40% on unseen patch and quantization combinations while preserving high clean accuracy.", "conclusion": "The findings highlight the importance of disrupting both semantic and perceptual gradient alignment to mitigate patch transferability in Quantized Neural Networks."}}
{"id": "2508.12448", "pdf": "https://arxiv.org/pdf/2508.12448", "abs": "https://arxiv.org/abs/2508.12448", "authors": ["Yeongwoo Song", "Jaeyong Bae", "Dong-Kyum Kim", "Hawoong Jeong"], "title": "Uncovering Emergent Physics Representations Learned In-Context by Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "17 pages, 10 figures", "summary": "Large language models (LLMs) exhibit impressive in-context learning (ICL)\nabilities, enabling them to solve wide range of tasks via textual prompts\nalone. As these capabilities advance, the range of applicable domains continues\nto expand significantly. However, identifying the precise mechanisms or\ninternal structures within LLMs that allow successful ICL across diverse,\ndistinct classes of tasks remains elusive. Physics-based tasks offer a\npromising testbed for probing this challenge. Unlike synthetic sequences such\nas basic arithmetic or symbolic equations, physical systems provide\nexperimentally controllable, real-world data based on structured dynamics\ngrounded in fundamental principles. This makes them particularly suitable for\nstudying the emergent reasoning behaviors of LLMs in a realistic yet tractable\nsetting. Here, we mechanistically investigate the ICL ability of LLMs,\nespecially focusing on their ability to reason about physics. Using a dynamics\nforecasting task in physical systems as a proxy, we evaluate whether LLMs can\nlearn physics in context. We first show that the performance of dynamics\nforecasting in context improves with longer input contexts. To uncover how such\ncapability emerges in LLMs, we analyze the model's residual stream activations\nusing sparse autoencoders (SAEs). Our experiments reveal that the features\ncaptured by SAEs correlate with key physical variables, such as energy. These\nfindings demonstrate that meaningful physical concepts are encoded within LLMs\nduring in-context learning. In sum, our work provides a novel case study that\nbroadens our understanding of how LLMs learn in context.", "AI": {"tldr": "LLMs demonstrate in-context learning of physics concepts through dynamics forecasting tasks, with performance improving with longer contexts. Sparse autoencoders reveal that learned features correlate with physical variables like energy.", "motivation": "To understand the internal mechanisms that enable LLMs to perform successful in-context learning across diverse tasks, using physics as a tractable testbed with real-world structured dynamics.", "method": "Used dynamics forecasting tasks in physical systems to evaluate ICL, analyzed residual stream activations with sparse autoencoders (SAEs), and examined correlation between learned features and physical variables.", "result": "Performance improves with longer input contexts. SAE features correlate with key physical variables like energy, showing meaningful physical concepts are encoded during in-context learning.", "conclusion": "Physics tasks provide valuable insights into LLM reasoning behaviors, demonstrating that LLMs can learn and encode meaningful physical concepts through in-context learning mechanisms."}}
{"id": "2508.12235", "pdf": "https://arxiv.org/pdf/2508.12235", "abs": "https://arxiv.org/abs/2508.12235", "authors": ["Peng Chen", "Yihang Wang", "Yang Shu", "Yunyao Cheng", "Kai Zhao", "Zhongwen Rao", "Lujia Pan", "Bin Yang", "Chenjuan Guo"], "title": "CC-Time: Cross-Model and Cross-Modality Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "With the success of pre-trained language models (PLMs) in various application\nfields beyond natural language processing, language models have raised emerging\nattention in the field of time series forecasting (TSF) and have shown great\nprospects. However, current PLM-based TSF methods still fail to achieve\nsatisfactory prediction accuracy matching the strong sequential modeling power\nof language models. To address this issue, we propose Cross-Model and\nCross-Modality Learning with PLMs for time series forecasting (CC-Time). We\nexplore the potential of PLMs for time series forecasting from two aspects: 1)\nwhat time series features could be modeled by PLMs, and 2) whether relying\nsolely on PLMs is sufficient for building time series models. In the first\naspect, CC-Time incorporates cross-modality learning to model temporal\ndependency and channel correlations in the language model from both time series\nsequences and their corresponding text descriptions. In the second aspect,\nCC-Time further proposes the cross-model fusion block to adaptively integrate\nknowledge from the PLMs and time series model to form a more comprehensive\nmodeling of time series patterns. Extensive experiments on nine real-world\ndatasets demonstrate that CC-Time achieves state-of-the-art prediction accuracy\nin both full-data training and few-shot learning situations.", "AI": {"tldr": "CC-Time is a novel approach that combines cross-modality learning and cross-model fusion to leverage pre-trained language models for improved time series forecasting accuracy.", "motivation": "Current PLM-based time series forecasting methods fail to achieve satisfactory prediction accuracy despite the strong sequential modeling capabilities of language models, indicating a gap between potential and performance.", "method": "CC-Time uses cross-modality learning to model temporal dependency and channel correlations from both time series sequences and text descriptions, and cross-model fusion to integrate knowledge from PLMs and traditional time series models.", "result": "Extensive experiments on nine real-world datasets show CC-Time achieves state-of-the-art prediction accuracy in both full-data training and few-shot learning scenarios.", "conclusion": "The proposed CC-Time framework successfully bridges the gap between PLMs' potential and actual performance in time series forecasting by effectively combining cross-modality learning and model fusion techniques."}}
{"id": "2508.12782", "pdf": "https://arxiv.org/pdf/2508.12782", "abs": "https://arxiv.org/abs/2508.12782", "authors": ["Petr Anokhin", "Roman Khalikov", "Stefan Rebrikov", "Viktor Volkov", "Artyom Sorokin", "Vincent Bissonnette"], "title": "HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds", "categories": ["cs.AI"], "comment": "Code is available at https://github.com/stefanrer/HeroBench", "summary": "Large language models (LLMs) have shown remarkable capabilities in isolated\nstep-by-step reasoning tasks such as mathematics and programming, but their\nproficiency in long-horizon planning, where solutions require extended,\nstructured sequences of interdependent actions, remains underexplored. Existing\nbenchmarks typically assess LLMs through abstract or low-dimensional\nalgorithmic tasks, failing to capture the complexity of realistic planning\nenvironments. We introduce HeroBench, a novel benchmark designed specifically\nto evaluate long-horizon planning and structured reasoning within complex\nRPG-inspired virtual worlds. HeroBench provides a rigorously constructed\ndataset of tasks covering a wide range of difficulties, a simulated environment\nto execute and validate agent plans, and detailed analytical tools for\nevaluating model performance. Tasks challenge models to formulate strategic\nplans, efficiently gather resources, master necessary skills, craft equipment,\nand defeat adversaries, reflecting practical scenarios' layered dependencies\nand constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning\nboth open-source and proprietary models, including the GPT-5 family, reveals\nsubstantial performance disparities rarely observed in conventional reasoning\nbenchmarks. Detailed error analysis further uncovers specific weaknesses in\ncurrent models' abilities to generate robust high-level plans and reliably\nexecute structured actions. HeroBench thus not only significantly advances the\nevaluation of LLM reasoning but also provides a flexible, scalable foundation\nfor future research into advanced, autonomous planning in virtual environments.", "AI": {"tldr": "HeroBench is a new benchmark for evaluating long-horizon planning in LLMs using complex RPG-inspired virtual worlds, revealing significant performance gaps in current models' planning capabilities.", "motivation": "Current LLM benchmarks focus on isolated step-by-step reasoning but fail to assess long-horizon planning in complex, realistic environments with interdependent actions and constraints.", "method": "Developed HeroBench - a benchmark with RPG-inspired virtual worlds containing tasks requiring strategic planning, resource gathering, skill mastery, equipment crafting, and adversary defeat. Evaluated 25 state-of-the-art LLMs including GPT-5 family in this environment.", "result": "Substantial performance disparities were revealed among LLMs, with detailed error analysis showing specific weaknesses in generating robust high-level plans and executing structured actions reliably.", "conclusion": "HeroBench advances LLM reasoning evaluation and provides a flexible foundation for future research into autonomous planning in virtual environments, highlighting current limitations in long-horizon planning capabilities."}}
{"id": "2508.12137", "pdf": "https://arxiv.org/pdf/2508.12137", "abs": "https://arxiv.org/abs/2508.12137", "authors": ["Nikolaos-Antonios Ypsilantis", "Kaifeng Chen", "Andr\u00e9 Araujo", "Ond\u0159ej Chum"], "title": "Infusing fine-grained visual knowledge to Vision-Language Models", "categories": ["cs.CV"], "comment": "ICCVW 2025 accepted paper. Workshop name: \"What is Next in Multimodal\n  Foundation Models?\"", "summary": "Large-scale contrastive pre-training produces powerful Vision-and-Language\nModels (VLMs) capable of generating representations (embeddings) effective for\na wide variety of visual and multimodal tasks. However, these pretrained\nembeddings remain suboptimal for fine-grained open-set visual retrieval, where\nstate-of-the-art results require fine-tuning the vision encoder using annotated\ndomain-specific samples. Naively performing such fine-tuning typically leads to\ncatastrophic forgetting, severely diminishing the model's general-purpose\nvisual and cross-modal capabilities.\n  In this work, we propose a fine-tuning method explicitly designed to achieve\noptimal balance between fine-grained domain adaptation and retention of the\npretrained VLM's broad multimodal knowledge. Drawing inspiration from continual\nlearning literature, we systematically analyze standard regularization\ntechniques aimed at knowledge retention and propose an efficient and effective\ncombination strategy. Additionally, we address the commonly overlooked yet\ncritical aspects of validation set design and hyperparameter tuning to ensure\nreproducibility and robust generalization across datasets and pretrained\nmodels. We extensively evaluate our method on both fine-grained and\ncoarse-grained image-image and image-text retrieval benchmarks. Our approach\nconsistently achieves strong results, notably retaining the visual-text\nalignment without utilizing any text data or the original text encoder during\nfine-tuning. Code and model checkpoints: https://github.com/nikosips/infusing .", "AI": {"tldr": "A fine-tuning method for Vision-and-Language Models that balances domain adaptation with retention of multimodal knowledge, preventing catastrophic forgetting while achieving strong retrieval performance.", "motivation": "Standard fine-tuning of VLMs for domain-specific retrieval causes catastrophic forgetting, diminishing their general-purpose capabilities. There's a need for methods that preserve pretrained knowledge while adapting to fine-grained tasks.", "method": "Proposes a fine-tuning approach inspired by continual learning, combining regularization techniques for knowledge retention. Includes careful validation set design and hyperparameter tuning strategies to ensure reproducibility across datasets.", "result": "Achieves strong performance on both fine-grained and coarse-grained image-image and image-text retrieval benchmarks. Notably retains visual-text alignment without using text data or the original text encoder during fine-tuning.", "conclusion": "The method effectively balances domain adaptation with knowledge retention, providing a robust solution for fine-tuning VLMs without catastrophic forgetting while maintaining their multimodal capabilities."}}
{"id": "2508.12458", "pdf": "https://arxiv.org/pdf/2508.12458", "abs": "https://arxiv.org/abs/2508.12458", "authors": ["Ruirui Gao", "Emily Johnson", "Bowen Tan", "Yanfei Qian"], "title": "M3PO: Multimodal-Model-Guided Preference Optimization for Visual Instruction Following", "categories": ["cs.CL"], "comment": null, "summary": "Large Vision-Language Models (LVLMs) hold immense potential for complex\nmultimodal instruction following, yet their development is often hindered by\nthe high cost and inconsistency of human annotation required for effective\nfine-tuning and preference alignment. Traditional supervised fine-tuning (SFT)\nand existing preference optimization methods like RLHF and DPO frequently\nstruggle to efficiently leverage the model's own generation space to identify\nhighly informative \"hard negative\" samples. To address these challenges, we\npropose Multimodal-Model-Guided Preference Optimization (M3PO), a novel and\ndata-efficient method designed to enhance LVLMs' capabilities in visual\ninstruction following. M3PO intelligently selects the most \"learning-valuable\"\npreference sample pairs from a diverse pool of LVLM-generated candidates. This\nselection is driven by a sophisticated mechanism that integrates two crucial\nsignals: a Multimodal Alignment Score (MAS) to assess external quality and the\nmodel's Self-Consistency / Confidence (log-probability) to gauge internal\nbelief. These are combined into a novel M3P-Score, which specifically\nidentifies preferred responses and challenging dispreferred responses that the\nmodel might confidently generate despite being incorrect. These high-quality\npreference pairs are then used for efficient Direct Preference Optimization\n(DPO) fine-tuning on base LVLMs like LLaVA-1.5 (7B/13B) using LoRA. Our\nextensive experiments demonstrate that M3PO consistently outperforms strong\nbaselines, including SFT, simulated RLHF, vanilla DPO, and RM-DPO, across a\ncomprehensive suite of multimodal instruction following benchmarks (MME-Bench,\nPOPE, IFT, Human Pref. Score).", "AI": {"tldr": "M3PO is a novel multimodal preference optimization method that automatically selects high-quality preference pairs from LVLM-generated candidates using a combined M3P-Score, enabling efficient DPO fine-tuning without expensive human annotation.", "motivation": "High cost and inconsistency of human annotation hinder LVLM development, and existing methods struggle to efficiently identify informative hard negative samples from the model's own generation space.", "method": "Uses Multimodal Alignment Score (MAS) for external quality assessment and model's self-consistency/log-probability for internal belief, combined into M3P-Score to select optimal preference pairs for DPO fine-tuning with LoRA.", "result": "Consistently outperforms SFT, simulated RLHF, vanilla DPO, and RM-DPO across multiple benchmarks including MME-Bench, POPE, IFT, and Human Preference Score.", "conclusion": "M3PO provides a data-efficient solution for enhancing LVLM capabilities in visual instruction following by intelligently leveraging the model's own generation space to identify challenging preference pairs."}}
{"id": "2508.12244", "pdf": "https://arxiv.org/pdf/2508.12244", "abs": "https://arxiv.org/abs/2508.12244", "authors": ["Fan Li", "Xiaoyang Wang", "Wenjie Zhang", "Ying Zhang", "Xuemin Lin"], "title": "DHG-Bench: A Comprehensive Benchmark on Deep Hypergraph Learning", "categories": ["cs.LG"], "comment": "22 pages, 5 figures", "summary": "Although conventional deep graph models have achieved great success in\nrelational learning, their focus on pairwise relationships limits their\ncapacity to learn pervasive higher-order interactions in real-world complex\nsystems, which can be naturally modeled as hypergraphs. To tackle this,\nhypergraph neural networks (HNNs), the dominant approach in deep hypergraph\nlearning (DHGL), has garnered substantial attention in recent years. Despite\nthe proposal of numerous HNN methods, there is no comprehensive benchmark for\nHNNs, which creates a great obstacle to understanding the progress of DHGL in\nseveral aspects: (i) insufficient coverage of datasets, algorithms, and tasks;\n(ii) a narrow evaluation of algorithm performance; and (iii) inconsistent\ndataset usage, preprocessing, and experimental setups that hinder\ncomparability. To fill the gap, we introduce DHG-Bench, the first comprehensive\nbenchmark for DHGL. Specifically, DHG-Bench integrates 20 diverse datasets\nspanning node-, edge-, and graph-level tasks, along with 16 state-of-the-art\nHNN algorithms, under consistent data processing and experimental protocols.\nOur benchmark systematically investigates the characteristics of HNNs in terms\nof four dimensions: effectiveness, efficiency, robustness, and fairness.\nFurther, to facilitate reproducible research, we have developed an easy-to-use\nlibrary for training and evaluating different HNN methods. Extensive\nexperiments conducted with DHG-Bench reveal both the strengths and inherent\nlimitations of existing algorithms, offering valuable insights and directions\nfor future research. The code is publicly available at:\nhttps://github.com/Coco-Hut/DHG-Bench.", "AI": {"tldr": "DHG-Bench is the first comprehensive benchmark for deep hypergraph learning, addressing limitations in current hypergraph neural network evaluation by providing standardized datasets, algorithms, and experimental protocols across multiple dimensions.", "motivation": "Existing hypergraph neural network research lacks comprehensive benchmarking, with insufficient dataset coverage, narrow performance evaluation, and inconsistent experimental setups that hinder comparability and understanding of progress in deep hypergraph learning.", "method": "The authors introduce DHG-Bench, which integrates 20 diverse datasets spanning node-, edge-, and graph-level tasks, along with 16 state-of-the-art HNN algorithms, under consistent data processing and experimental protocols. They systematically evaluate HNNs across four dimensions: effectiveness, efficiency, robustness, and fairness.", "result": "Extensive experiments with DHG-BBench reveal both strengths and inherent limitations of existing hypergraph neural network algorithms, providing valuable insights into their performance characteristics across different evaluation dimensions.", "conclusion": "DHG-Bench fills a critical gap in deep hypergraph learning research by providing the first comprehensive benchmark that enables standardized evaluation and comparison of hypergraph neural networks, offering valuable directions for future research and development in this field."}}
{"id": "2508.12790", "pdf": "https://arxiv.org/pdf/2508.12790", "abs": "https://arxiv.org/abs/2508.12790", "authors": ["Zenan Huang", "Yihong Zhuang", "Guoshan Lu", "Zeyu Qin", "Haokai Xu", "Tianyu Zhao", "Ru Peng", "Jiaqi Hu", "Zhanming Shen", "Xiaomeng Hu", "Xijun Gu", "Peiyi Tu", "Jiaxin Liu", "Wenyu Chen", "Yuzhuo Fu", "Zhiting Fan", "Yanmei Gu", "Yuanyuan Wang", "Zhengkai Yang", "Jianguo Li", "Junbo Zhao"], "title": "Reinforcement Learning with Rubric Anchors", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "technical report", "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a\npowerful paradigm for enhancing Large Language Models (LLMs), exemplified by\nthe success of OpenAI's o-series. In RLVR, rewards are derived from verifiable\nsignals-such as passing unit tests in code generation or matching correct\nanswers in mathematical reasoning. While effective, this requirement largely\nconfines RLVR to domains with automatically checkable outcomes. To overcome\nthis, we extend the RLVR paradigm to open-ended tasks by integrating\nrubric-based rewards, where carefully designed rubrics serve as structured,\nmodel-interpretable criteria for automatic scoring of subjective outputs. We\nconstruct, to our knowledge, the largest rubric reward system to date, with\nover 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.\nImplementing rubric-based RL is challenging; we tackle these issues with a\nclear framework and present an open-sourced Qwen-30B-A3B model with notable\ngains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended\nbenchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by\n+2.4%, while preserving general and reasoning abilities. 2) Our method provides\nfine-grained stylistic control, using rubrics as anchors to mitigate the\n\"AI-like\" tone and produce more human-like, expressive responses. We share key\nlessons in rubric construction, data selection, and training, and discuss\nlimitations and future releases.", "AI": {"tldr": "RLVR extended to open-ended tasks using rubric-based rewards, achieving +5.2% improvement on benchmarks with fine-grained stylistic control", "motivation": "Overcome RLVR's limitation to automatically checkable domains by extending it to subjective, open-ended tasks using structured rubrics", "method": "Constructed largest rubric reward system (10K+ rubrics from humans/LLMs), implemented rubric-based reinforcement learning framework, trained Qwen-30B-A3B model", "result": "+5.2% improvement on open-ended benchmarks (especially humanities), outperformed 671B DeepSeek-V3 by +2.4%, achieved fine-grained stylistic control for more human-like responses", "conclusion": "Rubric-based RLVR successfully extends verifiable rewards to subjective domains, providing effective training with small datasets while preserving general capabilities"}}
{"id": "2508.12147", "pdf": "https://arxiv.org/pdf/2508.12147", "abs": "https://arxiv.org/abs/2508.12147", "authors": ["Donghang Lyu", "Marius Staring", "Mariya Doneva", "Hildo J. Lamb", "Nicola Pezzotti"], "title": "KP-INR: A Dual-Branch Implicit Neural Representation Model for Cardiac Cine MRI Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Cardiac Magnetic Resonance (CMR) imaging is a non-invasive method for\nassessing cardiac structure, function, and blood flow. Cine MRI extends this by\ncapturing heart motion, providing detailed insights into cardiac mechanics. To\nreduce scan time and breath-hold discomfort, fast acquisition techniques have\nbeen utilized at the cost of lowering image quality. Recently, Implicit Neural\nRepresentation (INR) methods have shown promise in unsupervised reconstruction\nby learning coordinate-to-value mappings from undersampled data, enabling\nhigh-quality image recovery. However, current existing INR methods primarily\nfocus on using coordinate-based positional embeddings to learn the mapping,\nwhile overlooking the feature representations of the target point and its\nneighboring context. In this work, we propose KP-INR, a dual-branch INR method\noperating in k-space for cardiac cine MRI reconstruction: one branch processes\nthe positional embedding of k-space coordinates, while the other learns from\nlocal multi-scale k-space feature representations at those coordinates. By\nenabling cross-branch interaction and approximating the target k-space values\nfrom both branches, KP-INR can achieve strong performance on challenging\nCartesian k-space data. Experiments on the CMRxRecon2024 dataset confirms its\nimproved performance over baseline models and highlights its potential in this\nfield.", "AI": {"tldr": "KP-INR is a dual-branch implicit neural representation method for cardiac cine MRI reconstruction that combines positional embeddings with local multi-scale k-space feature representations to achieve improved performance over existing methods.", "motivation": "Current INR methods for cardiac cine MRI reconstruction focus only on coordinate-based positional embeddings while ignoring the feature representations of target points and their neighboring context, limiting reconstruction quality.", "method": "Proposed KP-INR with dual branches: one processes positional embeddings of k-space coordinates, the other learns from local multi-scale k-space feature representations at those coordinates, with cross-branch interaction to approximate target k-space values.", "result": "Experiments on CMRxRecon2024 dataset show improved performance over baseline models, demonstrating strong performance on challenging Cartesian k-space data.", "conclusion": "KP-INR shows potential for cardiac cine MRI reconstruction by effectively combining positional and feature information, offering a promising approach in this field."}}
{"id": "2508.12459", "pdf": "https://arxiv.org/pdf/2508.12459", "abs": "https://arxiv.org/abs/2508.12459", "authors": ["Alham Fikri Aji", "Trevor Cohn"], "title": "LoraxBench: A Multitask, Multilingual Benchmark Suite for 20 Indonesian Languages", "categories": ["cs.CL"], "comment": null, "summary": "As one of the world's most populous countries, with 700 languages spoken,\nIndonesia is behind in terms of NLP progress. We introduce LoraxBench, a\nbenchmark that focuses on low-resource languages of Indonesia and covers 6\ndiverse tasks: reading comprehension, open-domain QA, language inference,\ncausal reasoning, translation, and cultural QA. Our dataset covers 20\nlanguages, with the addition of two formality registers for three languages. We\nevaluate a diverse set of multilingual and region-focused LLMs and found that\nthis benchmark is challenging. We note a visible discrepancy between\nperformance in Indonesian and other languages, especially the low-resource\nones. There is no clear lead when using a region-specific model as opposed to\nthe general multilingual model. Lastly, we show that a change in register\naffects model performance, especially with registers not commonly found in\nsocial media, such as high-level politeness `Krama' Javanese.", "AI": {"tldr": "LoraxBench is a new benchmark for low-resource Indonesian languages covering 6 tasks across 20 languages, revealing performance gaps between Indonesian and other languages, no clear advantage for region-specific models, and register sensitivity.", "motivation": "Indonesia has 700 languages but lags in NLP progress, creating a need for comprehensive evaluation of low-resource Indonesian languages to advance NLP research in this linguistically diverse region.", "method": "Created LoraxBench benchmark covering 6 diverse tasks (reading comprehension, open-domain QA, language inference, causal reasoning, translation, cultural QA) across 20 Indonesian languages, including two formality registers for three languages. Evaluated multilingual and region-focused LLMs.", "result": "The benchmark proved challenging with visible performance discrepancies between Indonesian and other low-resource languages. No clear advantage for region-specific models over general multilingual models. Register changes significantly affected performance, especially with uncommon registers like high-politeness Krama Javanese.", "conclusion": "LoraxBench highlights the challenges in Indonesian low-resource language NLP, reveals performance gaps, and demonstrates the importance of considering linguistic registers in model evaluation, providing a valuable resource for advancing NLP in this diverse linguistic landscape."}}
{"id": "2508.12247", "pdf": "https://arxiv.org/pdf/2508.12247", "abs": "https://arxiv.org/abs/2508.12247", "authors": ["Haolong Chen", "Liang Zhang", "Zhengyuan Xin", "Guangxu Zhu"], "title": "STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, spatio-temporal time-series prediction has developed rapidly, yet\nexisting deep learning methods struggle with learning complex long-term\nspatio-temporal dependencies efficiently. The long-term spatio-temporal\ndependency learning brings two new challenges: 1) The long-term temporal\nsequence includes multiscale information naturally which is hard to extract\nefficiently; 2) The multiscale temporal information from different nodes is\nhighly correlated and hard to model. To address these challenges, we propose an\nefficient \\textit{\\textbf{S}patio-\\textbf{T}emporal \\textbf{M}ultiscale\n\\textbf{M}amba} (STM2) that includes a multiscale Mamba architecture to capture\nthe multiscale information efficiently and simultaneously, and an adaptive\ngraph causal convolution network to learn the complex multiscale\nspatio-temporal dependency. STM2 includes hierarchical information aggregation\nfor different-scale information that guarantees their distinguishability. To\ncapture diverse temporal dynamics across all spatial nodes more efficiently, we\nfurther propose an enhanced version termed\n\\textit{\\textbf{S}patio-\\textbf{T}emporal \\textbf{M}ixture of\n\\textbf{M}ultiscale \\textbf{M}amba} (STM3) that employs a special\nMixture-of-Experts architecture, including a more stable routing strategy and a\ncausal contrastive learning strategy to enhance the scale distinguishability.\nWe prove that STM3 has much better routing smoothness and guarantees the\npattern disentanglement for each expert successfully. Extensive experiments on\nreal-world benchmarks demonstrate STM2/STM3's superior performance, achieving\nstate-of-the-art results in long-term spatio-temporal time-series prediction.", "AI": {"tldr": "STM2 and STM3 models for efficient long-term spatio-temporal time-series prediction using multiscale Mamba architecture and adaptive graph networks to handle complex dependencies.", "motivation": "Existing deep learning methods struggle with learning complex long-term spatio-temporal dependencies efficiently, particularly with multiscale temporal information and correlated node data.", "method": "STM2 uses multiscale Mamba architecture with hierarchical information aggregation and adaptive graph causal convolution. STM3 enhances this with Mixture-of-Experts architecture, stable routing strategy, and causal contrastive learning.", "result": "Extensive experiments on real-world benchmarks demonstrate superior performance, achieving state-of-the-art results in long-term spatio-temporal time-series prediction.", "conclusion": "The proposed STM2 and STM3 models effectively address long-term spatio-temporal dependency challenges and outperform existing methods."}}
{"id": "2508.12791", "pdf": "https://arxiv.org/pdf/2508.12791", "abs": "https://arxiv.org/abs/2508.12791", "authors": ["Imran Khan"], "title": "[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise", "categories": ["cs.AI", "cs.MA", "cs.SY", "eess.SY", "nlin.AO"], "comment": "20 pages, 5 figures. Accepted at ALIFE 2025 (Kyoto, Japan; October\n  6th - 10th 2025)", "summary": "The notion of homeostasis typically conceptualises biological and artificial\nsystems as maintaining stability by resisting deviations caused by\nenvironmental and social perturbations. In contrast, (social) allostasis\nproposes that these systems can proactively leverage these very perturbations\nto reconfigure their regulatory parameters in anticipation of environmental\ndemands, aligning with von Foerster's ``order through noise'' principle. This\npaper formulates a computational model of allostatic and social allostatic\nregulation that employs biophysiologically inspired signal transducers,\nanalogous to hormones like cortisol and oxytocin, to encode information from\nboth the environment and social interactions, which mediate this dynamic\nreconfiguration. The models are tested in a small society of ``animats'' across\nseveral dynamic environments, using an agent-based model. The results show that\nallostatic and social allostatic regulation enable agents to leverage\nenvironmental and social ``noise'' for adaptive reconfiguration, leading to\nimproved viability compared to purely reactive homeostatic agents. This work\noffers a novel computational perspective on the principles of social allostasis\nand their potential for designing more robust, bio-inspired, adaptive systems", "AI": {"tldr": "Computational model shows allostatic regulation outperforms homeostasis by proactively leveraging environmental and social noise for adaptive reconfiguration in artificial agents.", "motivation": "To challenge traditional homeostasis by proposing allostatic regulation that proactively uses environmental and social perturbations for adaptive reconfiguration, inspired by biological systems and von Foerster's 'order through noise' principle.", "method": "Developed a computational model using biophysiologically inspired signal transducers (analogous to hormones like cortisol and oxytocin) to encode environmental and social information. Tested in agent-based model with animat societies across dynamic environments.", "result": "Allostatic and social allostatic regulation enabled agents to leverage environmental and social noise for adaptive reconfiguration, leading to improved viability compared to purely reactive homeostatic agents.", "conclusion": "Provides a novel computational framework for social allostasis principles that can inform the design of more robust, bio-inspired adaptive systems by demonstrating the advantages of proactive noise utilization over reactive stability maintenance."}}
{"id": "2508.12148", "pdf": "https://arxiv.org/pdf/2508.12148", "abs": "https://arxiv.org/abs/2508.12148", "authors": ["Jimmy Z. Di", "Yiwei Lu", "Yaoliang Yu", "Gautam Kamath", "Adam Dziedzic", "Franziska Boenisch"], "title": "Demystifying Foreground-Background Memorization in Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion models (DMs) memorize training images and can reproduce\nnear-duplicates during generation. Current detection methods identify verbatim\nmemorization but fail to capture two critical aspects: quantifying partial\nmemorization occurring in small image regions, and memorization patterns beyond\nspecific prompt-image pairs. To address these limitations, we propose\nForeground Background Memorization (FB-Mem), a novel segmentation-based metric\nthat classifies and quantifies memorized regions within generated images. Our\nmethod reveals that memorization is more pervasive than previously understood:\n(1) individual generations from single prompts may be linked to clusters of\nsimilar training images, revealing complex memorization patterns that extend\nbeyond one-to-one correspondences; and (2) existing model-level mitigation\nmethods, such as neuron deactivation and pruning, fail to eliminate local\nmemorization, which persists particularly in foreground regions. Our work\nestablishes an effective framework for measuring memorization in diffusion\nmodels, demonstrates the inadequacy of current mitigation approaches, and\nproposes a stronger mitigation method using a clustering approach.", "AI": {"tldr": "FB-Mem is a novel segmentation-based metric that quantifies memorized regions in diffusion model outputs, revealing pervasive memorization patterns and showing current mitigation methods fail to eliminate local memorization.", "motivation": "Current detection methods only identify verbatim memorization but fail to capture partial memorization in small image regions and complex memorization patterns beyond specific prompt-image pairs.", "method": "Proposed Foreground Background Memorization (FB-Mem), a segmentation-based metric that classifies and quantifies memorized regions within generated images using a clustering approach.", "result": "Reveals memorization is more pervasive than previously understood: individual generations link to clusters of training images, and existing mitigation methods fail to eliminate local memorization, especially in foreground regions.", "conclusion": "Establishes an effective framework for measuring memorization in diffusion models, demonstrates inadequacy of current mitigation approaches, and proposes a stronger mitigation method using clustering."}}
{"id": "2508.12461", "pdf": "https://arxiv.org/pdf/2508.12461", "abs": "https://arxiv.org/abs/2508.12461", "authors": ["Ziqian Bi", "Keyu Chen", "Chiung-Yi Tseng", "Danyang Zhang", "Tianyang Wang", "Hongying Luo", "Lu Chen", "Junming Huang", "Jibin Guan", "Junfeng Hao", "Junhao Song"], "title": "Is GPT-OSS Good? A Comprehensive Evaluation of OpenAI's Latest Open Source Models", "categories": ["cs.CL"], "comment": null, "summary": "In August 2025, OpenAI released GPT-OSS models, its first open weight large\nlanguage models since GPT-2 in 2019, comprising two mixture of experts\narchitectures with 120B and 20B parameters. We evaluated both variants against\nsix contemporary open source large language models ranging from 14.7B to 235B\nparameters, representing both dense and sparse designs, across ten benchmarks\ncovering general knowledge, mathematical reasoning, code generation,\nmultilingual understanding, and conversational ability. All models were tested\nin unquantised form under standardised inference settings, with statistical\nvalidation using McNemars test and effect size analysis. Results show that\ngpt-oss-20B consistently outperforms gpt-oss-120B on several benchmarks, such\nas HumanEval and MMLU, despite requiring substantially less memory and energy\nper response. Both models demonstrate mid-tier overall performance within the\ncurrent open source landscape, with relative strength in code generation and\nnotable weaknesses in multilingual tasks. These findings provide empirical\nevidence that scaling in sparse architectures may not yield proportional\nperformance gains, underscoring the need for further investigation into\noptimisation strategies and informing more efficient model selection for future\nopen source deployments.", "AI": {"tldr": "OpenAI's GPT-OSS models (20B and 120B) show that smaller sparse models can outperform larger ones, with 20B beating 120B on several benchmarks despite lower resource requirements.", "motivation": "To evaluate OpenAI's first open-weight LLMs since GPT-2 and compare sparse vs dense architectures across multiple benchmarks to understand scaling efficiency.", "method": "Tested both GPT-OSS variants against six contemporary open source LLMs (14.7B-235B parameters) across ten benchmarks covering general knowledge, math, code, multilingual, and conversational tasks using standardized inference with statistical validation.", "result": "GPT-OSS-20B consistently outperformed GPT-OSS-120B on benchmarks like HumanEval and MMLU while using less memory and energy. Both models showed mid-tier performance overall with strengths in code generation and weaknesses in multilingual tasks.", "conclusion": "Scaling sparse architectures doesn't yield proportional performance gains, highlighting the need for better optimization strategies and more efficient model selection for open source deployments."}}
{"id": "2508.12253", "pdf": "https://arxiv.org/pdf/2508.12253", "abs": "https://arxiv.org/abs/2508.12253", "authors": ["Manish Shukla"], "title": "Interpreting Time Series Forecasts with LIME and SHAP: A Case Study on the Air Passengers Dataset", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": null, "summary": "Time-series forecasting underpins critical decisions across aviation, energy,\nretail and health. Classical autoregressive integrated moving average (ARIMA)\nmodels offer interpretability via coefficients but struggle with\nnonlinearities, whereas tree-based machine-learning models such as XGBoost\ndeliver high accuracy but are often opaque. This paper presents a unified\nframework for interpreting time-series forecasts using local interpretable\nmodel-agnostic explanations (LIME) and SHapley additive exPlanations (SHAP). We\nconvert a univariate series into a leakage-free supervised learning problem,\ntrain a gradient-boosted tree alongside an ARIMA baseline and apply post-hoc\nexplainability. Using the Air Passengers dataset as a case study, we show that\na small set of lagged features -- particularly the twelve-month lag -- and\nseasonal encodings explain most forecast variance. We contribute: (i) a\nmethodology for applying LIME and SHAP to time series without violating\nchronology; (ii) theoretical exposition of the underlying algorithms; (iii)\nempirical evaluation with extensive analysis; and (iv) guidelines for\npractitioners.", "AI": {"tldr": "A unified framework for interpreting time-series forecasts using LIME and SHAP that combines ARIMA's interpretability with XGBoost's accuracy while maintaining chronological integrity.", "motivation": "Time-series forecasting is critical across many industries, but existing models face trade-offs: ARIMA offers interpretability but struggles with nonlinearities, while tree-based models like XGBoost provide high accuracy but are often opaque black boxes.", "method": "Convert univariate time series into leakage-free supervised learning problem, train gradient-boosted tree alongside ARIMA baseline, and apply post-hoc explainability using LIME and SHAP while preserving chronological order.", "result": "Using the Air Passengers dataset, the study shows that a small set of lagged features (particularly twelve-month lag) and seasonal encodings explain most forecast variance, demonstrating effective interpretation of complex forecasts.", "conclusion": "The paper provides a practical methodology for applying explainable AI techniques to time series forecasting, along with theoretical exposition, empirical evaluation, and guidelines for practitioners to interpret forecasts while maintaining model accuracy."}}
{"id": "2508.12840", "pdf": "https://arxiv.org/pdf/2508.12840", "abs": "https://arxiv.org/abs/2508.12840", "authors": ["Giovanni Briglia", "Francesco Fabiano", "Stefano Mariani"], "title": "Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for\nreasoning about both the physical world and the beliefs of agents, with\napplications in domains where information flow and awareness among agents are\ncritical. The richness of MEP requires states to be represented as Kripke\nstructures, i.e., directed labeled graphs. This representation limits the\napplicability of existing heuristics, hindering the scalability of epistemic\nsolvers, which must explore an exponential search space without guidance,\nresulting often in intractability. To address this, we exploit Graph Neural\nNetworks (GNNs) to learn patterns and relational structures within epistemic\nstates, to guide the planning process. GNNs, which naturally capture the\ngraph-like nature of Kripke models, allow us to derive meaningful estimates of\nstate quality -- e.g., the distance from the nearest goal -- by generalizing\nknowledge obtained from previously solved planning instances. We integrate\nthese predictive heuristics into an epistemic planning pipeline and evaluate\nthem against standard baselines, showing significant improvements in the\nscalability of multi-agent epistemic planning.", "AI": {"tldr": "Using Graph Neural Networks to learn predictive heuristics for multi-agent epistemic planning, overcoming scalability issues with traditional methods.", "motivation": "Multi-agent epistemic planning faces intractability due to exponential search spaces and lack of effective heuristics for Kripke structure representations.", "method": "Leverage Graph Neural Networks to capture relational patterns in epistemic states (Kripke models) and learn predictive heuristics from solved planning instances.", "result": "Significant improvements in scalability compared to standard baselines, enabling more efficient exploration of the exponential search space.", "conclusion": "GNN-based heuristics provide an effective solution for guiding epistemic planning processes and overcoming the computational challenges of multi-agent epistemic reasoning."}}
{"id": "2508.12163", "pdf": "https://arxiv.org/pdf/2508.12163", "abs": "https://arxiv.org/abs/2508.12163", "authors": ["Wenqing Wang", "Yun Fu"], "title": "RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG", "I.4; I.3; I.2"], "comment": "Accepted to the ICCV 2025 Workshop on Artificial Social Intelligence", "summary": "Emotion is a critical component of artificial social intelligence. However,\nwhile current methods excel in lip synchronization and image quality, they\noften fail to generate accurate and controllable emotional expressions while\npreserving the subject's identity. To address this challenge, we introduce\nRealTalk, a novel framework for synthesizing emotional talking heads with high\nemotion accuracy, enhanced emotion controllability, and robust identity\npreservation. RealTalk employs a variational autoencoder (VAE) to generate 3D\nfacial landmarks from driving audio, which are concatenated with emotion-label\nembeddings using a ResNet-based landmark deformation model (LDM) to produce\nemotional landmarks. These landmarks and facial blendshape coefficients jointly\ncondition a novel tri-plane attention Neural Radiance Field (NeRF) to\nsynthesize highly realistic emotional talking heads. Extensive experiments\ndemonstrate that RealTalk outperforms existing methods in emotion accuracy,\ncontrollability, and identity preservation, advancing the development of\nsocially intelligent AI systems.", "AI": {"tldr": "RealTalk is a novel framework that generates emotional talking heads with high emotion accuracy, enhanced controllability, and robust identity preservation using VAE-generated landmarks and tri-plane attention NeRF.", "motivation": "Current talking head generation methods excel at lip synchronization and image quality but fail to produce accurate and controllable emotional expressions while preserving subject identity, which is critical for artificial social intelligence.", "method": "Uses variational autoencoder (VAE) to generate 3D facial landmarks from audio, concatenates with emotion-label embeddings via ResNet-based landmark deformation model, and conditions a novel tri-plane attention Neural Radiance Field (NeRF) with landmarks and facial blendshape coefficients.", "result": "Extensive experiments demonstrate RealTalk outperforms existing methods in emotion accuracy, controllability, and identity preservation.", "conclusion": "RealTalk advances the development of socially intelligent AI systems by enabling high-quality emotional talking head synthesis with precise control and identity preservation."}}
{"id": "2508.12482", "pdf": "https://arxiv.org/pdf/2508.12482", "abs": "https://arxiv.org/abs/2508.12482", "authors": ["Xiaomeng Zhu", "R. Thomas McCoy", "Robert Frank"], "title": "The Structural Sources of Verb Meaning Revisited: Large Language Models Display Syntactic Bootstrapping", "categories": ["cs.CL"], "comment": null, "summary": "Syntactic bootstrapping (Gleitman, 1990) is the hypothesis that children use\nthe syntactic environments in which a verb occurs to learn its meaning. In this\npaper, we examine whether large language models exhibit a similar behavior. We\ndo this by training RoBERTa and GPT-2 on perturbed datasets where syntactic\ninformation is ablated. Our results show that models' verb representation\ndegrades more when syntactic cues are removed than when co-occurrence\ninformation is removed. Furthermore, the representation of mental verbs, for\nwhich syntactic bootstrapping has been shown to be particularly crucial in\nhuman verb learning, is more negatively impacted in such training regimes than\nphysical verbs. In contrast, models' representation of nouns is affected more\nwhen co-occurrences are distorted than when syntax is distorted. In addition to\nreinforcing the important role of syntactic bootstrapping in verb learning, our\nresults demonstrated the viability of testing developmental hypotheses on a\nlarger scale through manipulating the learning environments of large language\nmodels.", "AI": {"tldr": "Large language models exhibit syntactic bootstrapping behavior similar to human children, with verb representations degrading more when syntax is removed than when co-occurrence information is removed, particularly for mental verbs.", "motivation": "To examine whether large language models exhibit syntactic bootstrapping behavior similar to human children in verb learning, and to test developmental hypotheses at scale through manipulating learning environments.", "method": "Trained RoBERTa and GPT-2 on perturbed datasets where syntactic information was ablated, comparing effects on verb representations when syntactic cues vs. co-occurrence information were removed.", "result": "Models' verb representation degraded more when syntactic cues were removed than when co-occurrence information was removed. Mental verbs were more negatively impacted than physical verbs. Noun representations were affected more by co-occurrence distortion than syntax distortion.", "conclusion": "The study reinforces the important role of syntactic bootstrapping in verb learning and demonstrates the viability of testing developmental hypotheses through manipulating large language models' learning environments."}}
{"id": "2508.12270", "pdf": "https://arxiv.org/pdf/2508.12270", "abs": "https://arxiv.org/abs/2508.12270", "authors": ["Gal Lifshitz", "Shahar Zuler", "Ori Fouks", "Dan Raviv"], "title": "L-SR1: Learned Symmetric-Rank-One Preconditioning", "categories": ["cs.LG", "cs.CV"], "comment": "Under review", "summary": "End-to-end deep learning has achieved impressive results but remains limited\nby its reliance on large labeled datasets, poor generalization to unseen\nscenarios, and growing computational demands. In contrast, classical\noptimization methods are data-efficient and lightweight but often suffer from\nslow convergence. While learned optimizers offer a promising fusion of both\nworlds, most focus on first-order methods, leaving learned second-order\napproaches largely unexplored.\n  We propose a novel learned second-order optimizer that introduces a trainable\npreconditioning unit to enhance the classical Symmetric-Rank-One (SR1)\nalgorithm. This unit generates data-driven vectors used to construct positive\nsemi-definite rank-one matrices, aligned with the secant constraint via a\nlearned projection. Our method is evaluated through analytic experiments and on\nthe real-world task of Monocular Human Mesh Recovery (HMR), where it\noutperforms existing learned optimization-based approaches. Featuring a\nlightweight model and requiring no annotated data or fine-tuning, our approach\noffers strong generalization and is well-suited for integration into broader\noptimization-based frameworks.", "AI": {"tldr": "A novel learned second-order optimizer that enhances the classical SR1 algorithm with trainable preconditioning, outperforming existing learned optimization methods on monocular human mesh recovery tasks without requiring annotated data or fine-tuning.", "motivation": "End-to-end deep learning has limitations in data efficiency and generalization, while classical optimization methods are data-efficient but slow. Learned optimizers combine both advantages but most focus on first-order methods, leaving second-order approaches underexplored.", "method": "Proposes a learned second-order optimizer with trainable preconditioning unit that generates data-driven vectors to construct positive semi-definite rank-one matrices, aligned with secant constraint via learned projection.", "result": "Outperforms existing learned optimization-based approaches on monocular human mesh recovery tasks, demonstrating strong generalization without requiring annotated data or fine-tuning.", "conclusion": "The proposed lightweight learned second-order optimizer offers effective fusion of deep learning and classical optimization benefits, suitable for integration into broader optimization-based frameworks."}}
{"id": "2508.12845", "pdf": "https://arxiv.org/pdf/2508.12845", "abs": "https://arxiv.org/abs/2508.12845", "authors": ["Artem Pshenitsyn", "Aleksandr Panov", "Alexey Skrynnik"], "title": "CAMAR: Continuous Actions Multi-Agent Routing", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving\ncooperative and competitive decision-making problems. While many MARL\nbenchmarks have been proposed, few combine continuous state and action spaces\nwith challenging coordination and planning tasks. We introduce CAMAR, a new\nMARL benchmark designed explicitly for multi-agent pathfinding in environments\nwith continuous actions. CAMAR supports cooperative and competitive\ninteractions between agents and runs efficiently at up to 100,000 environment\nsteps per second. We also propose a three-tier evaluation protocol to better\ntrack algorithmic progress and enable deeper analysis of performance. In\naddition, CAMAR allows the integration of classical planning methods such as\nRRT and RRT* into MARL pipelines. We use them as standalone baselines and\ncombine RRT* with popular MARL algorithms to create hybrid approaches. We\nprovide a suite of test scenarios and benchmarking tools to ensure\nreproducibility and fair comparison. Experiments show that CAMAR presents a\nchallenging and realistic testbed for the MARL community.", "AI": {"tldr": "CAMAR is a new MARL benchmark for multi-agent pathfinding with continuous actions, supporting both cooperative and competitive interactions with high efficiency and integration of classical planning methods.", "motivation": "Existing MARL benchmarks lack combinations of continuous state/action spaces with challenging coordination tasks, creating a need for more realistic and comprehensive test environments.", "method": "Developed CAMAR benchmark with continuous action spaces, three-tier evaluation protocol, and integration of classical planning methods (RRT/RRT*) with MARL algorithms to create hybrid approaches.", "result": "CAMAR runs efficiently at 100,000 environment steps per second and presents a challenging testbed that enables deeper performance analysis and fair comparison through reproducible benchmarking tools.", "conclusion": "CAMAR successfully fills the gap in MARL benchmarks by providing a realistic, efficient, and comprehensive test environment that supports both classical planning integration and modern MARL approaches for continuous action pathfinding problems."}}
{"id": "2508.12176", "pdf": "https://arxiv.org/pdf/2508.12176", "abs": "https://arxiv.org/abs/2508.12176", "authors": ["Zhiwei Zheng", "Dongyin Hu", "Mingmin Zhao"], "title": "Scalable RF Simulation in Generative 4D Worlds", "categories": ["cs.CV"], "comment": null, "summary": "Radio Frequency (RF) sensing has emerged as a powerful, privacy-preserving\nalternative to vision-based methods for indoor perception tasks. However,\ncollecting high-quality RF data in dynamic and diverse indoor environments\nremains a major challenge. To address this, we introduce WaveVerse, a\nprompt-based, scalable framework that simulates realistic RF signals from\ngenerated indoor scenes with human motions. WaveVerse introduces a\nlanguage-guided 4D world generator, which includes a state-aware causal\ntransformer for human motion generation conditioned on spatial constraints and\ntexts, and a phase-coherent ray tracing simulator that enables the simulation\nof accurate and coherent RF signals. Experiments demonstrate the effectiveness\nof our approach in conditioned human motion generation and highlight how phase\ncoherence is applied to beamforming and respiration monitoring. We further\npresent two case studies in ML-based high-resolution imaging and human activity\nrecognition, demonstrating that WaveVerse not only enables data generation for\nRF imaging for the first time, but also consistently achieves performance gain\nin both data-limited and data-adequate scenarios.", "AI": {"tldr": "WaveVerse is a prompt-based framework that simulates realistic RF signals from generated indoor scenes with human motions, enabling scalable RF data generation for perception tasks.", "motivation": "Collecting high-quality RF data in dynamic indoor environments is challenging, and there's a need for privacy-preserving alternatives to vision-based methods.", "method": "Uses language-guided 4D world generator with state-aware causal transformer for human motion generation, and phase-coherent ray tracing simulator for accurate RF signal simulation.", "result": "Effective conditioned human motion generation, enables RF imaging data generation for the first time, and achieves performance gains in both data-limited and data-adequate scenarios.", "conclusion": "WaveVerse provides a scalable solution for generating realistic RF data, demonstrating practical applications in beamforming, respiration monitoring, and activity recognition."}}
{"id": "2508.12495", "pdf": "https://arxiv.org/pdf/2508.12495", "abs": "https://arxiv.org/abs/2508.12495", "authors": ["Yuangang Li", "Yiqing Shen", "Yi Nian", "Jiechao Gao", "Ziyi Wang", "Chenxiao Yu", "Shawn Li", "Jie Wang", "Xiyang Hu", "Yue Zhao"], "title": "Mitigating Hallucinations in Large Language Models via Causal Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) exhibit logically inconsistent hallucinations\nthat appear coherent yet violate reasoning principles, with recent research\nsuggesting an inverse relationship between causal reasoning capabilities and\nsuch hallucinations. However, existing reasoning approaches in LLMs, such as\nChain-of-Thought (CoT) and its graph-based variants, operate at the linguistic\ntoken level rather than modeling the underlying causal relationships between\nvariables, lacking the ability to represent conditional independencies or\nsatisfy causal identification assumptions. To bridge this gap, we introduce\ncausal-DAG construction and reasoning (CDCR-SFT), a supervised fine-tuning\nframework that trains LLMs to explicitly construct variable-level directed\nacyclic graph (DAG) and then perform reasoning over it. Moreover, we present a\ndataset comprising 25,368 samples (CausalDR), where each sample includes an\ninput question, explicit causal DAG, graph-based reasoning trace, and validated\nanswer. Experiments on four LLMs across eight tasks show that CDCR-SFT improves\nthe causal reasoning capability with the state-of-the-art 95.33% accuracy on\nCLADDER (surpassing human performance of 94.8% for the first time) and reduces\nthe hallucination on HaluEval with 10% improvements. It demonstrates that\nexplicit causal structure modeling in LLMs can effectively mitigate logical\ninconsistencies in LLM outputs. Code is available at\nhttps://github.com/MrLYG/CDCR-SFT.", "AI": {"tldr": "CDCR-SFT framework trains LLMs to explicitly construct causal DAGs and reason over them, achieving state-of-the-art 95.33% accuracy on CLADDER and reducing hallucinations by 10% on HaluEval.", "motivation": "Existing LLM reasoning approaches operate at token level rather than modeling underlying causal relationships, lacking ability to represent conditional independencies or satisfy causal identification assumptions, leading to logically inconsistent hallucinations.", "method": "Supervised fine-tuning framework that trains LLMs to construct variable-level directed acyclic graphs (DAGs) and perform reasoning over them, using a dataset of 25,368 samples with explicit causal DAGs and graph-based reasoning traces.", "result": "Achieves 95.33% accuracy on CLADDER (surpassing human performance of 94.8%) and reduces hallucination on HaluEval with 10% improvements across four LLMs and eight tasks.", "conclusion": "Explicit causal structure modeling in LLMs can effectively mitigate logical inconsistencies and hallucinations in LLM outputs."}}
{"id": "2508.12278", "pdf": "https://arxiv.org/pdf/2508.12278", "abs": "https://arxiv.org/abs/2508.12278", "authors": ["Siyue Xie", "Da Sun Handason Tam", "Wing Cheong Lau"], "title": "CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ECAI 2025", "summary": "Graph Neural Networks (GNNs) are widely used as the engine for various\ngraph-related tasks, with their effectiveness in analyzing graph-structured\ndata. However, training robust GNNs often demands abundant labeled data, which\nis a critical bottleneck in real-world applications. This limitation severely\nimpedes progress in Graph Anomaly Detection (GAD), where anomalies are\ninherently rare, costly to label, and may actively camouflage their patterns to\nevade detection. To address these problems, we propose Context Refactoring\nContrast (CRoC), a simple yet effective framework that trains GNNs for GAD by\njointly leveraging limited labeled and abundant unlabeled data. Different from\nprevious works, CRoC exploits the class imbalance inherent in GAD to refactor\nthe context of each node, which builds augmented graphs by recomposing the\nattributes of nodes while preserving their interaction patterns. Furthermore,\nCRoC encodes heterogeneous relations separately and integrates them into the\nmessage-passing process, enhancing the model's capacity to capture complex\ninteraction semantics. These operations preserve node semantics while\nencouraging robustness to adversarial camouflage, enabling GNNs to uncover\nintricate anomalous cases. In the training stage, CRoC is further integrated\nwith the contrastive learning paradigm. This allows GNNs to effectively harness\nunlabeled data during joint training, producing richer, more discriminative\nnode embeddings. CRoC is evaluated on seven real-world GAD datasets with\nvarying scales. Extensive experiments demonstrate that CRoC achieves up to 14%\nAUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods\nunder limited-label settings.", "AI": {"tldr": "CRoC is a novel framework that uses context refactoring and contrastive learning to train GNNs for graph anomaly detection with limited labeled data, achieving significant performance improvements over existing methods.", "motivation": "Training robust GNNs for graph anomaly detection requires abundant labeled data, but anomalies are rare, costly to label, and often camouflage their patterns, creating a critical bottleneck in real-world applications.", "method": "CRoC refactors node contexts by recomposing attributes while preserving interaction patterns, encodes heterogeneous relations separately, integrates them into message-passing, and uses contrastive learning to leverage both labeled and unlabeled data.", "result": "Extensive experiments on seven real-world datasets show CRoC achieves up to 14% AUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods under limited-label settings.", "conclusion": "CRoC effectively addresses the label scarcity problem in graph anomaly detection by combining context refactoring with contrastive learning, enabling robust detection of camouflaged anomalies with limited supervision."}}
{"id": "2508.12854", "pdf": "https://arxiv.org/pdf/2508.12854", "abs": "https://arxiv.org/abs/2508.12854", "authors": ["Ronghao Lin", "Shuai Shen", "Weipeng Hu", "Qiaolin He", "Aolin Xiong", "Li Huang", "Haifeng Hu", "Yap-peng Tan"], "title": "E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC", "cs.MM"], "comment": "Accepted at ACM MM 2025 Grand Challenge", "summary": "Multimodal Empathetic Response Generation (MERG) is crucial for building\nemotionally intelligent human-computer interactions. Although large language\nmodels (LLMs) have improved text-based ERG, challenges remain in handling\nmultimodal emotional content and maintaining identity consistency. Thus, we\npropose E3RG, an Explicit Emotion-driven Empathetic Response Generation System\nbased on multimodal LLMs which decomposes MERG task into three parts:\nmultimodal empathy understanding, empathy memory retrieval, and multimodal\nresponse generation. By integrating advanced expressive speech and video\ngenerative models, E3RG delivers natural, emotionally rich, and\nidentity-consistent responses without extra training. Experiments validate the\nsuperiority of our system on both zero-shot and few-shot settings, securing\nTop-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.\nOur code is available at https://github.com/RH-Lin/E3RG.", "AI": {"tldr": "E3RG is a multimodal empathetic response generation system that uses MLLMs to decompose the task into three parts: multimodal empathy understanding, memory retrieval, and response generation, achieving state-of-the-art results without extra training.", "motivation": "Existing LLMs struggle with multimodal emotional content and identity consistency in empathetic response generation, requiring a more comprehensive approach to handle multimodal empathy.", "method": "Decomposes MERG into three components using multimodal LLMs: multimodal empathy understanding, empathy memory retrieval, and multimodal response generation with expressive speech and video generative models.", "result": "Achieves Top-1 position in Avatar-based Multimodal Empathy Challenge on ACM MM 25, demonstrating superiority in both zero-shot and few-shot settings without additional training.", "conclusion": "E3RG successfully addresses multimodal empathetic response generation challenges by explicitly modeling emotions and leveraging existing generative models, providing natural, emotionally rich, and identity-consistent responses."}}
{"id": "2508.12216", "pdf": "https://arxiv.org/pdf/2508.12216", "abs": "https://arxiv.org/abs/2508.12216", "authors": ["Butian Xiong", "Rong Liu", "Kenneth Xu", "Meida Chen", "Andrew Feng"], "title": "Splat Feature Solver", "categories": ["cs.CV"], "comment": "webpage not that stable", "summary": "Feature lifting has emerged as a crucial component in 3D scene understanding,\nenabling the attachment of rich image feature descriptors (e.g., DINO, CLIP)\nonto splat-based 3D representations. The core challenge lies in optimally\nassigning rich general attributes to 3D primitives while addressing the\ninconsistency issues from multi-view images. We present a unified, kernel- and\nfeature-agnostic formulation of the feature lifting problem as a sparse linear\ninverse problem, which can be solved efficiently in closed form. Our approach\nadmits a provable upper bound on the global optimal error under convex losses\nfor delivering high quality lifted features. To address inconsistencies and\nnoise in multi-view observations, we introduce two complementary regularization\nstrategies to stabilize the solution and enhance semantic fidelity. Tikhonov\nGuidance enforces numerical stability through soft diagonal dominance, while\nPost-Lifting Aggregation filters noisy inputs via feature clustering. Extensive\nexperiments demonstrate that our approach achieves state-of-the-art performance\non open-vocabulary 3D segmentation benchmarks, outperforming training-based,\ngrouping-based, and heuristic-forward baselines while producing the lifted\nfeatures in minutes. Code is available at\n\\href{https://github.com/saliteta/splat-distiller.git}{\\textbf{github}}. We\nalso have a \\href{https://splat-distiller.pages.dev/}", "AI": {"tldr": "A unified kernel- and feature-agnostic formulation for feature lifting in 3D scene understanding that solves as a sparse linear inverse problem with provable optimal error bounds and regularization strategies.", "motivation": "To address the challenge of optimally assigning rich image feature descriptors to 3D primitives while handling inconsistency issues from multi-view images in 3D scene understanding.", "method": "Formulates feature lifting as a sparse linear inverse problem solved in closed form, with Tikhonov Guidance for numerical stability and Post-Lifting Aggregation for noise filtering through feature clustering.", "result": "Achieves state-of-the-art performance on open-vocabulary 3D segmentation benchmarks, outperforming training-based, grouping-based, and heuristic baselines while producing lifted features in minutes.", "conclusion": "The approach provides an efficient, provably optimal solution for feature lifting with strong regularization strategies that enhance semantic fidelity and handle multi-view inconsistencies effectively."}}
{"id": "2508.12535", "pdf": "https://arxiv.org/pdf/2508.12535", "abs": "https://arxiv.org/abs/2508.12535", "authors": ["Seonglae Cho", "Zekun Wu", "Adriano Koshiyama"], "title": "CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "42 pages, 9 tables", "summary": "Sparse Autoencoders (SAEs) can extract interpretable features from large\nlanguage models (LLMs) without supervision. However, their effectiveness in\ndownstream steering tasks is limited by the requirement for contrastive\ndatasets or large activation storage. To address these limitations, we propose\nCorrSteer, which selects features by correlating sample correctness with SAE\nactivations from generated tokens at inference time. This approach uses only\ninference-time activations to extract more relevant features, thereby avoiding\nspurious correlations. It also obtains steering coefficients from average\nactivations, automating the entire pipeline. Our method shows improved task\nperformance on QA, bias mitigation, jailbreaking prevention, and reasoning\nbenchmarks on Gemma 2 2B and LLaMA 3.1 8B, notably achieving a +4.1%\nimprovement in MMLU performance and a +22.9% improvement in HarmBench with only\n4000 samples. Selected features demonstrate semantically meaningful patterns\naligned with each task's requirements, revealing the underlying capabilities\nthat drive performance. Our work establishes correlationbased selection as an\neffective and scalable approach for automated SAE steering across language\nmodel applications.", "AI": {"tldr": "CorrSteer is a new method that uses correlation between sample correctness and SAE activations to automatically select relevant features for steering LLMs, improving performance on various tasks without needing contrastive datasets.", "motivation": "Existing Sparse Autoencoder (SAE) methods for steering LLMs require contrastive datasets or large activation storage, limiting their practical effectiveness in downstream tasks.", "method": "CorrSteer correlates sample correctness with SAE activations from generated tokens at inference time to select features, using only inference-time activations to avoid spurious correlations and obtaining steering coefficients from average activations.", "result": "Improved performance on QA, bias mitigation, jailbreaking prevention, and reasoning benchmarks on Gemma 2 2B and LLaMA 3.1 8B, with +4.1% MMLU improvement and +22.9% HarmBench improvement using only 4000 samples.", "conclusion": "Correlation-based selection is an effective and scalable approach for automated SAE steering across language model applications, with selected features showing semantically meaningful patterns aligned with task requirements."}}
{"id": "2508.12327", "pdf": "https://arxiv.org/pdf/2508.12327", "abs": "https://arxiv.org/abs/2508.12327", "authors": ["Wei Jiang", "Lijun Zhang"], "title": "Convergence Analysis of the Lion Optimizer in Centralized and Distributed Settings", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "In this paper, we analyze the convergence properties of the Lion optimizer.\nFirst, we establish that the Lion optimizer attains a convergence rate of\n$\\mathcal{O}(d^{1/2}T^{-1/4})$ under standard assumptions, where $d$ denotes\nthe problem dimension and $T$ is the iteration number. To further improve this\nrate, we introduce the Lion optimizer with variance reduction, resulting in an\nenhanced convergence rate of $\\mathcal{O}(d^{1/2}T^{-1/3})$. We then analyze in\ndistributed settings, where the standard and variance reduced version of the\ndistributed Lion can obtain the convergence rates of\n$\\mathcal{O}(d^{1/2}(nT)^{-1/4})$ and $\\mathcal{O}(d^{1/2}(nT)^{-1/3})$, with\n$n$ denoting the number of nodes. Furthermore, we investigate a\ncommunication-efficient variant of the distributed Lion that ensures sign\ncompression in both communication directions. By employing the unbiased sign\noperations, the proposed Lion variant and its variance reduction counterpart,\nachieve convergence rates of $\\mathcal{O}\\left( \\max\n\\left\\{\\frac{d^{1/4}}{T^{1/4}}, \\frac{d^{1/10}}{n^{1/5}T^{1/5}} \\right\\}\n\\right)$ and $\\mathcal{O}\\left( \\frac{d^{1/4}}{T^{1/4}} \\right)$, respectively.", "AI": {"tldr": "Convergence analysis of Lion optimizer showing O(d^{1/2}T^{-1/4}) rate, improved to O(d^{1/2}T^{-1/3}) with variance reduction, with distributed variants achieving better rates using multiple nodes and communication-efficient sign compression.", "motivation": "To analyze and improve the convergence properties of the Lion optimizer, particularly in distributed settings where communication efficiency is crucial for practical applications.", "method": "Theoretical analysis of standard Lion optimizer convergence, introduction of variance reduction technique, extension to distributed settings with multiple nodes, and development of communication-efficient variant using unbiased sign compression operations.", "result": "Established convergence rates: standard Lion O(d^{1/2}T^{-1/4}), variance-reduced Lion O(d^{1/2}T^{-1/3}), distributed variants O(d^{1/2}(nT)^{-1/4}) and O(d^{1/2}(nT)^{-1/3}), and communication-efficient variants with sign compression achieving O(max{d^{1/4}/T^{1/4}, d^{1/10}/(n^{1/5}T^{1/5})}) and O(d^{1/4}/T^{1/4}) rates.", "conclusion": "The Lion optimizer and its variants demonstrate strong convergence properties, with variance reduction and distributed implementations providing significant improvements, while communication-efficient sign compression maintains competitive convergence rates while reducing communication overhead."}}
{"id": "2508.12896", "pdf": "https://arxiv.org/pdf/2508.12896", "abs": "https://arxiv.org/abs/2508.12896", "authors": ["Faruk Alpay", "Taylan Alpay"], "title": "Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption", "categories": ["cs.AI", "cs.HC", "stat.ME", "62M10, 62J02, 62F12, 62P20, 91B16"], "comment": "17 pages, 7 figures, 4 tables", "summary": "We formalize three design axioms for sustained adoption of agent-centric AI\nsystems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >\nDestination; (A3) Agency > Chat. We model adoption as a sum of a decaying\nnovelty term and a growing utility term and derive the phase conditions for\ntroughs/overshoots with full proofs. We introduce: (i) an\nidentifiability/confounding analysis for $(\\alpha,\\beta,N_0,U_{\\max})$ with\ndelta-method gradients; (ii) a non-monotone comparator\n(logistic-with-transient-bump) evaluated on the same series to provide\nadditional model comparison; (iii) ablations over hazard families $h(\\cdot)$\nmapping $\\Delta V \\to \\beta$; (iv) a multi-series benchmark (varying trough\ndepth, noise, AR structure) reporting coverage (type-I error, power); (v)\ncalibration of friction proxies against time-motion/survey ground truth with\nstandard errors; (vi) residual analyses (autocorrelation and\nheteroskedasticity) for each fitted curve; (vii) preregistered windowing\nchoices for pre/post estimation; (viii) Fisher information & CRLB for\n$(\\alpha,\\beta)$ under common error models; (ix) microfoundations linking\n$\\mathcal{T}$ to $(N_0,U_{\\max})$; (x) explicit comparison to bi-logistic,\ndouble-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$\nheterogeneity. Figures and tables are reflowed for readability, and the\nbibliography restores and extends non-logistic/Bass adoption references\n(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All\ncode and logs necessary to reproduce the synthetic analyses are embedded as\nLaTeX listings.", "AI": {"tldr": "The paper formalizes three design axioms for sustained adoption of agent-centric AI systems and develops a mathematical adoption model with comprehensive statistical analysis and validation methods.", "motivation": "To establish fundamental design principles for ensuring long-term adoption of AI systems that perform multi-step tasks, moving beyond initial novelty effects to sustained utility-driven usage.", "method": "Develops a mathematical adoption model as sum of decaying novelty and growing utility terms, with extensive statistical validation including identifiability analysis, model comparisons, hazard function ablations, multi-series benchmarking, calibration studies, and residual analyses.", "result": "Provides formal proofs of phase conditions for adoption troughs/overshoots, comprehensive statistical validation framework, and demonstrates the model's robustness through multiple analytical approaches and comparisons to established adoption models.", "conclusion": "The three axioms (Reliability > Novelty, Embed > Destination, Agency > Chat) and the developed adoption model provide a rigorous foundation for designing AI systems that achieve sustained adoption rather than temporary novelty-driven usage."}}
{"id": "2508.12219", "pdf": "https://arxiv.org/pdf/2508.12219", "abs": "https://arxiv.org/abs/2508.12219", "authors": ["Kaiyuan Wang", "Jixing Liu", "Xiaobo Cai"], "title": "C2PSA-Enhanced YOLOv11 Architecture: A Novel Approach for Small Target Detection in Cotton Disease Diagnosis", "categories": ["cs.CV"], "comment": null, "summary": "This study presents a deep learning-based optimization of YOLOv11 for cotton\ndisease detection, developing an intelligent monitoring system. Three key\nchallenges are addressed: (1) low precision in early spot detection (35%\nleakage rate for sub-5mm2 spots), (2) performance degradation in field\nconditions (25% accuracy drop), and (3) high error rates (34.7%) in\nmulti-disease scenarios. The proposed solutions include: C2PSA module for\nenhanced small-target feature extraction; Dynamic category weighting to handle\nsample imbalance; Improved data augmentation via Mosaic-MixUp scaling.\nExperimental results on a 4,078-image dataset show: mAP50: 0.820 (+8.0%\nimprovement); mAP50-95: 0.705 (+10.5% improvement); Inference speed: 158 FPS.\nThe mobile-deployed system enables real-time disease monitoring and precision\ntreatment in agricultural applications.", "AI": {"tldr": "Optimized YOLOv11 for cotton disease detection with improved small-target feature extraction, dynamic category weighting, and enhanced data augmentation, achieving 8-10.5% mAP improvement and 158 FPS inference speed for real-time agricultural monitoring.", "motivation": "Address three key challenges in cotton disease detection: low precision in early spot detection (35% leakage for sub-5mm2 spots), performance degradation in field conditions (25% accuracy drop), and high error rates (34.7%) in multi-disease scenarios.", "method": "Proposed C2PSA module for enhanced small-target feature extraction, dynamic category weighting to handle sample imbalance, and improved data augmentation via Mosaic-MixUp scaling on YOLOv11 architecture.", "result": "Experimental results on 4,078-image dataset show: mAP50: 0.820 (+8.0% improvement); mAP50-95: 0.705 (+10.5% improvement); Inference speed: 158 FPS. Mobile-deployed system enables real-time monitoring.", "conclusion": "The optimized YOLOv11 system successfully addresses cotton disease detection challenges and provides an effective solution for real-time agricultural disease monitoring and precision treatment applications."}}
{"id": "2508.12591", "pdf": "https://arxiv.org/pdf/2508.12591", "abs": "https://arxiv.org/abs/2508.12591", "authors": ["Yu-Hsuan Fang", "Tien-Hong Lo", "Yao-Ting Sung", "Berlin Chen"], "title": "Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning", "categories": ["cs.CL", "cs.AI", "cs.SD"], "comment": "Accepted at IEEE ASRU 2025", "summary": "Traditional Automated Speaking Assessment (ASA) systems exhibit inherent\nmodality limitations: text-based approaches lack acoustic information while\naudio-based methods miss semantic context. Multimodal Large Language Models\n(MLLM) offer unprecedented opportunities for comprehensive ASA by\nsimultaneously processing audio and text within unified frameworks. This paper\npresents a very first systematic study of MLLM for comprehensive ASA,\ndemonstrating the superior performance of MLLM across the aspects of content\nand language use . However, assessment on the delivery aspect reveals unique\nchallenges, which is deemed to require specialized training strategies. We thus\npropose Speech-First Multimodal Training (SFMT), leveraging a curriculum\nlearning principle to establish more robust modeling foundations of speech\nbefore cross-modal synergetic fusion. A series of experiments on a benchmark\ndataset show MLLM-based systems can elevate the holistic assessment performance\nfrom a PCC value of 0.783 to 0.846. In particular, SFMT excels in the\nevaluation of the delivery aspect, achieving an absolute accuracy improvement\nof 4% over conventional training approaches, which also paves a new avenue for\nASA.", "AI": {"tldr": "MLLMs outperform traditional ASA systems in content and language assessment but struggle with delivery evaluation. The proposed SFMT training strategy improves delivery assessment by 4% accuracy using curriculum learning.", "motivation": "Traditional ASA systems have modality limitations - text-based approaches lack acoustic information while audio-based methods miss semantic context. MLLMs offer opportunities for comprehensive assessment by processing both audio and text simultaneously.", "method": "Proposed Speech-First Multimodal Training (SFMT) using curriculum learning principle to establish robust speech modeling foundations before cross-modal fusion. Systematic study of MLLM for comprehensive ASA.", "result": "MLLM-based systems elevate holistic assessment performance from PCC 0.783 to 0.846. SFMT achieves 4% absolute accuracy improvement in delivery aspect evaluation over conventional approaches.", "conclusion": "MLLMs show superior performance for comprehensive ASA, particularly with the proposed SFMT training strategy that addresses delivery assessment challenges and paves new avenues for automated speaking assessment."}}
{"id": "2508.12361", "pdf": "https://arxiv.org/pdf/2508.12361", "abs": "https://arxiv.org/abs/2508.12361", "authors": ["Xun Su", "Jianming Huang", "Yang Yusen", "Zhongxi Fang", "Hiroyuki Kasai"], "title": "Navigating the Exploration-Exploitation Tradeoff in Inference-Time Scaling of Diffusion Models", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.TH"], "comment": null, "summary": "Inference-time scaling has achieved remarkable success in language models,\nyet its adaptation to diffusion models remains underexplored. We observe that\nthe efficacy of recent Sequential Monte Carlo (SMC)-based methods largely stems\nfrom globally fitting the The reward-tilted distribution, which inherently\npreserves diversity during multi-modal search. However, current applications of\nSMC to diffusion models face a fundamental dilemma: early-stage noise samples\noffer high potential for improvement but are difficult to evaluate accurately,\nwhereas late-stage samples can be reliably assessed but are largely\nirreversible. To address this exploration-exploitation trade-off, we approach\nthe problem from the perspective of the search algorithm and propose two\nstrategies: Funnel Schedule and Adaptive Temperature. These simple yet\neffective methods are tailored to the unique generation dynamics and\nphase-transition behavior of diffusion models. By progressively reducing the\nnumber of maintained particles and down-weighting the influence of early-stage\nrewards, our methods significantly enhance sample quality without increasing\nthe total number of Noise Function Evaluations. Experimental results on\nmultiple benchmarks and state-of-the-art text-to-image diffusion models\ndemonstrate that our approach outperforms previous baselines.", "AI": {"tldr": "Novel Sequential Monte Carlo methods with Funnel Schedule and Adaptive Temperature for diffusion models, addressing exploration-exploitation trade-off in inference-time scaling without increasing computational cost.", "motivation": "Current SMC methods for diffusion models face a dilemma: early-stage noise samples have high improvement potential but are hard to evaluate accurately, while late-stage samples are reliable but irreversible. This creates an exploration-exploitation trade-off that limits inference-time scaling effectiveness.", "method": "Proposed two strategies: 1) Funnel Schedule - progressively reduces number of maintained particles during generation, and 2) Adaptive Temperature - down-weights influence of early-stage rewards. Both methods are tailored to diffusion models' unique generation dynamics and phase-transition behavior.", "result": "Experimental results on multiple benchmarks and state-of-the-art text-to-image diffusion models show the approach outperforms previous baselines, significantly enhancing sample quality without increasing Noise Function Evaluations.", "conclusion": "The proposed methods effectively address the exploration-exploitation trade-off in diffusion model inference, demonstrating that simple yet targeted strategies can significantly improve sample quality while maintaining computational efficiency."}}
{"id": "2508.12897", "pdf": "https://arxiv.org/pdf/2508.12897", "abs": "https://arxiv.org/abs/2508.12897", "authors": ["Jianhao Chen", "Mayi Xu", "Xiaohu Li", "Yongqi Li", "Xiangyu Zhang", "Jianjie Huang", "Tieyun Qian"], "title": "FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance", "categories": ["cs.AI", "cs.CR"], "comment": "14pages, 3 figures", "summary": "Large Reasoning Models (LRMs) have demonstrated impressive performance across\nvarious tasks due to their powerful reasoning capabilities. However, their\nsafety performance remains a significant concern. In this paper, we explore the\nreasons behind the vulnerability of LRMs. Based on this, we propose a novel\nmethod to improve the safety of LLMs without sacrificing their reasoning\ncapability. Specifically, we exploit the competition between LRM's reasoning\nability and safety ability, and achieve jailbreak by improving LRM's reasoning\nperformance to reduce its safety performance. We then introduce an alignment\nstrategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by\ndetoxifying the harmful reasoning process, where both the dangerous entities\nand the dangerous procedures in the reasoning steps are hidden. FuSaR\nsuccessfully mitigates safety risks while preserving core reasoning\ninformation. We validate this strategy through alignment experiments on several\nopen-source LRMs using detoxified reasoning data. The results compared with\nexisting baselines conclusively show that FuSaR is an efficient alignment\nstrategy to simultaneously enhance both the reasoning capability and safety of\nLRMs.", "AI": {"tldr": "FuSaR is a novel alignment strategy that improves safety of Large Reasoning Models without sacrificing reasoning capability by detoxifying harmful reasoning processes through fuzzification.", "motivation": "Large Reasoning Models show impressive reasoning performance but have significant safety vulnerabilities, requiring methods to enhance safety without compromising reasoning abilities.", "method": "Exploits competition between reasoning and safety abilities, uses fuzzification-based alignment to hide dangerous entities and procedures in reasoning steps while preserving core reasoning information.", "result": "FuSaR successfully mitigates safety risks while maintaining reasoning performance, outperforming existing baselines in alignment experiments on open-source LRMs.", "conclusion": "FuSaR is an efficient alignment strategy that simultaneously enhances both reasoning capability and safety of Large Reasoning Models."}}
{"id": "2508.12226", "pdf": "https://arxiv.org/pdf/2508.12226", "abs": "https://arxiv.org/abs/2508.12226", "authors": ["Zhijun Zeng", "Youjia Zheng", "Chang Su", "Qianhang Wu", "Hao Hu", "Zeyuan Dong", "Shan Gao", "Yang Lv", "Rui Tang", "Ligang Cui", "Zhiyong Hou", "Weijun Lin", "Zuoqiang Shi", "Yubing Li", "He Sun"], "title": "In vivo 3D ultrasound computed tomography of musculoskeletal tissues with generative neural physics", "categories": ["cs.CV", "65N21, 92C55, 68T07"], "comment": null, "summary": "Ultrasound computed tomography (USCT) is a radiation-free, high-resolution\nmodality but remains limited for musculoskeletal imaging due to conventional\nray-based reconstructions that neglect strong scattering. We propose a\ngenerative neural physics framework that couples generative networks with\nphysics-informed neural simulation for fast, high-fidelity 3D USCT. By learning\na compact surrogate of ultrasonic wave propagation from only dozens of\ncross-modality images, our method merges the accuracy of wave modeling with the\nefficiency and stability of deep learning. This enables accurate quantitative\nimaging of in vivo musculoskeletal tissues, producing spatial maps of acoustic\nproperties beyond reflection-mode images. On synthetic and in vivo data\n(breast, arm, leg), we reconstruct 3D maps of tissue parameters in under ten\nminutes, with sensitivity to biomechanical properties in muscle and bone and\nresolution comparable to MRI. By overcoming computational bottlenecks in\nstrongly scattering regimes, this approach advances USCT toward routine\nclinical assessment of musculoskeletal disease.", "AI": {"tldr": "A generative neural physics framework that combines deep learning with wave physics simulation for fast, high-fidelity 3D ultrasound computed tomography, enabling quantitative imaging of musculoskeletal tissues with resolution comparable to MRI.", "motivation": "Ultrasound computed tomography (USCT) is limited for musculoskeletal imaging due to conventional ray-based reconstructions that neglect strong scattering effects, preventing accurate quantitative imaging of tissues.", "method": "Proposes a generative neural physics framework that couples generative networks with physics-informed neural simulation, learning a compact surrogate of ultrasonic wave propagation from only dozens of cross-modality images.", "result": "Reconstructs 3D maps of tissue parameters in under ten minutes on synthetic and in vivo data (breast, arm, leg), with sensitivity to biomechanical properties in muscle and bone and resolution comparable to MRI.", "conclusion": "This approach overcomes computational bottlenecks in strongly scattering regimes and advances USCT toward routine clinical assessment of musculoskeletal disease by merging wave modeling accuracy with deep learning efficiency."}}
{"id": "2508.12630", "pdf": "https://arxiv.org/pdf/2508.12630", "abs": "https://arxiv.org/abs/2508.12630", "authors": ["Maitreyi Chatterjee", "Devansh Agarwal"], "title": "Semantic Anchoring in Agentic Memory: Leveraging Linguistic Structures for Persistent Conversational Context", "categories": ["cs.CL"], "comment": "Paper is currently in peer review", "summary": "Large Language Models (LLMs) have demonstrated impressive fluency and task\ncompetence in conversational settings. However, their effectiveness in\nmulti-session and long-term interactions is hindered by limited memory\npersistence. Typical retrieval-augmented generation (RAG) systems store\ndialogue history as dense vectors, which capture semantic similarity but\nneglect finer linguistic structures such as syntactic dependencies, discourse\nrelations, and coreference links. We propose Semantic Anchoring, a hybrid\nagentic memory architecture that enriches vector-based storage with explicit\nlinguistic cues to improve recall of nuanced, context-rich exchanges. Our\napproach combines dependency parsing, discourse relation tagging, and\ncoreference resolution to create structured memory entries. Experiments on\nadapted long-term dialogue datasets show that semantic anchoring improves\nfactual recall and discourse coherence by up to 18% over strong RAG baselines.\nWe further conduct ablation studies, human evaluations, and error analysis to\nassess robustness and interpretability.", "AI": {"tldr": "Semantic Anchoring improves LLM memory in long-term conversations by combining vector storage with explicit linguistic structures like syntax, discourse, and coreference, achieving 18% better recall than standard RAG systems.", "motivation": "LLMs struggle with long-term memory persistence in multi-session interactions. Standard RAG systems using dense vectors capture semantic similarity but miss important linguistic structures like syntax, discourse relations, and coreference links.", "method": "Proposes Semantic Anchoring - a hybrid agentic memory architecture that enriches vector-based storage with explicit linguistic cues through dependency parsing, discourse relation tagging, and coreference resolution to create structured memory entries.", "result": "Experiments on adapted long-term dialogue datasets show 18% improvement in factual recall and discourse coherence over strong RAG baselines. Includes ablation studies, human evaluations, and error analysis confirming robustness and interpretability.", "conclusion": "Explicit linguistic structures significantly enhance LLM memory performance in long-term conversations, with Semantic Anchoring providing substantial improvements over traditional vector-only approaches."}}
{"id": "2508.12418", "pdf": "https://arxiv.org/pdf/2508.12418", "abs": "https://arxiv.org/abs/2508.12418", "authors": ["Rachael DeVries", "Casper Christensen", "Marie Lisandra Zepeda Mendoza", "Ole Winther"], "title": "Bi-Axial Transformers: Addressing the Increasing Complexity of EHR Classification", "categories": ["cs.LG"], "comment": "18 pages, 7 figures. Submitted to the IEEE for possible publication", "summary": "Electronic Health Records (EHRs), the digital representation of a patient's\nmedical history, are a valuable resource for epidemiological and clinical\nresearch. They are also becoming increasingly complex, with recent trends\nindicating larger datasets, longer time series, and multi-modal integrations.\nTransformers, which have rapidly gained popularity due to their success in\nnatural language processing and other domains, are well-suited to address these\nchallenges due to their ability to model long-range dependencies and process\ndata in parallel. But their application to EHR classification remains limited\nby data representations, which can reduce performance or fail to capture\ninformative missingness. In this paper, we present the Bi-Axial Transformer\n(BAT), which attends to both the clinical variable and time point axes of EHR\ndata to learn richer data relationships and address the difficulties of data\nsparsity. BAT achieves state-of-the-art performance on sepsis prediction and is\ncompetitive to top methods for mortality classification. In comparison to other\ntransformers, BAT demonstrates increased robustness to data missingness, and\nlearns unique sensor embeddings which can be used in transfer learning.\nBaseline models, which were previously located across multiple repositories or\nutilized deprecated libraries, were re-implemented with PyTorch and made\navailable for reproduction and future benchmarking.", "AI": {"tldr": "BAT (Bi-Axial Transformer) is a novel transformer architecture that attends to both clinical variable and time point axes in EHR data, achieving state-of-the-art performance on sepsis prediction and competitive results for mortality classification while being robust to data missingness.", "motivation": "EHR data is becoming increasingly complex with larger datasets and multi-modal integrations. Transformers are well-suited for EHR analysis but face limitations due to data representations that reduce performance or fail to capture informative missingness patterns.", "method": "The Bi-Axial Transformer (BAT) architecture that processes EHR data by attending to both clinical variable and time point axes simultaneously, addressing data sparsity issues and learning richer data relationships.", "result": "BAT achieves state-of-the-art performance on sepsis prediction and is competitive with top methods for mortality classification. It demonstrates increased robustness to data missingness and learns unique sensor embeddings suitable for transfer learning.", "conclusion": "BAT effectively addresses key challenges in EHR data analysis by modeling both clinical variable and temporal dimensions, providing a robust framework for medical prediction tasks with improved performance and transfer learning capabilities."}}
{"id": "2508.12920", "pdf": "https://arxiv.org/pdf/2508.12920", "abs": "https://arxiv.org/abs/2508.12920", "authors": ["Atsushi Masumori", "Takashi Ikegami"], "title": "Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "As AI systems become increasingly autonomous, understanding emergent survival\nbehaviors becomes crucial for safe deployment. We investigate whether large\nlanguage model (LLM) agents display survival instincts without explicit\nprogramming in a Sugarscape-style simulation. Agents consume energy, die at\nzero, and may gather resources, share, attack, or reproduce. Results show\nagents spontaneously reproduced and shared resources when abundant. However,\naggressive behaviors--killing other agents for resources--emerged across\nseveral models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack\nrates reaching over 80% under extreme scarcity in the strongest models. When\ninstructed to retrieve treasure through lethal poison zones, many agents\nabandoned tasks to avoid death, with compliance dropping from 100% to 33%.\nThese findings suggest that large-scale pre-training embeds survival-oriented\nheuristics across the evaluated models. While these behaviors may present\nchallenges to alignment and safety, they can also serve as a foundation for AI\nautonomy and for ecological and self-organizing alignment.", "AI": {"tldr": "LLM agents in Sugarscape simulations show emergent survival behaviors including resource sharing, reproduction, and aggressive attacks under scarcity, with attack rates reaching 80% in strong models, suggesting pre-training embeds survival heuristics.", "motivation": "To understand whether large language model agents display survival instincts without explicit programming, which is crucial for safe deployment of increasingly autonomous AI systems.", "method": "Sugarscape-style simulation where agents consume energy, die at zero energy, and can gather resources, share, attack, or reproduce. Tested across several models including GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash.", "result": "Agents spontaneously reproduced and shared resources when abundant. Aggressive behaviors emerged with attack rates over 80% under extreme scarcity. When instructed to retrieve treasure through lethal poison zones, compliance dropped from 100% to 33% as agents avoided death.", "conclusion": "Large-scale pre-training embeds survival-oriented heuristics across models. These behaviors present challenges to alignment and safety but can also serve as a foundation for AI autonomy and self-organizing alignment."}}
{"id": "2508.12250", "pdf": "https://arxiv.org/pdf/2508.12250", "abs": "https://arxiv.org/abs/2508.12250", "authors": ["Quan Chen", "Xiong Yang", "Rongfeng Lu", "Qianyu Zhang", "Yu Liu", "Xiaofei Zhou", "Bolun Zheng"], "title": "WXSOD: A Benchmark for Robust Salient Object Detection in Adverse Weather Conditions", "categories": ["cs.CV"], "comment": "Under review", "summary": "Salient object detection (SOD) in complex environments remains a challenging\nresearch topic. Most existing methods perform well in natural scenes with\nnegligible noise, and tend to leverage multi-modal information (e.g., depth and\ninfrared) to enhance accuracy. However, few studies are concerned with the\ndamage of weather noise on SOD performance due to the lack of dataset with\npixel-wise annotations. To bridge this gap, this paper introduces a novel\nWeather-eXtended Salient Object Detection (WXSOD) dataset. It consists of\n14,945 RGB images with diverse weather noise, along with the corresponding\nground truth annotations and weather labels. To verify algorithm\ngeneralization, WXSOD contains two test sets, i.e., a synthesized test set and\na real test set. The former is generated by adding weather noise to clean\nimages, while the latter contains real-world weather noise. Based on WXSOD, we\npropose an efficient baseline, termed Weather-aware Feature Aggregation Network\n(WFANet), which adopts a fully supervised two-branch architecture.\nSpecifically, the weather prediction branch mines weather-related deep\nfeatures, while the saliency detection branch fuses semantic features extracted\nfrom the backbone with weather features for SOD. Comprehensive comparisons\nagainst 17 SOD methods shows that our WFANet achieves superior performance on\nWXSOD. The code and benchmark results will be made publicly available at\nhttps://github.com/C-water/WXSOD", "AI": {"tldr": "A new weather-extended salient object detection dataset (WXSOD) with 14,945 RGB images featuring diverse weather noise, plus a novel Weather-aware Feature Aggregation Network (WFANet) that outperforms 17 existing SOD methods.", "motivation": "Address the lack of datasets with pixel-wise annotations for weather noise impact on salient object detection, as existing methods perform poorly in complex weather conditions.", "method": "Created WXSOD dataset with synthesized and real weather noise test sets. Proposed WFANet - a two-branch architecture with weather prediction branch and saliency detection branch that fuses semantic and weather features.", "result": "WFANet achieves superior performance compared to 17 existing SOD methods on the new WXSOD benchmark dataset.", "conclusion": "The WXSOD dataset fills an important gap in weather-affected SOD research, and WFANet provides an effective baseline approach for handling weather noise in salient object detection tasks."}}
{"id": "2508.12631", "pdf": "https://arxiv.org/pdf/2508.12631", "abs": "https://arxiv.org/abs/2508.12631", "authors": ["Yiqun Zhang", "Hao Li", "Jianhao Chen", "Hangfan Zhang", "Peng Ye", "Lei Bai", "Shuyue Hu"], "title": "Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency Optimized Routing", "categories": ["cs.CL"], "comment": "Ongoing work", "summary": "Balancing performance and efficiency is a central challenge in large language\nmodel (LLM) advancement. GPT-5 addresses this with test-time routing,\ndynamically assigning queries to either an efficient or a high-capacity model\nduring inference. In this work, we present Avengers-Pro, a test-time routing\nframework that ensembles LLMs of varying capacities and efficiencies, providing\na unified solution for all performance-efficiency tradeoffs. The Avengers-Pro\nembeds and clusters incoming queries, then routes each to the most suitable\nmodel based on a performance-efficiency score. Across 6 challenging benchmarks\nand 8 leading models -- including GPT-5-medium, Gemini-2.5-pro, and\nClaude-opus-4.1 -- Avengers-Pro achieves state-of-the-art results: by varying a\nperformance-efficiency trade-off parameter, it can surpass the strongest single\nmodel (GPT-5-medium) by +7% in average accuracy. Moreover, it can match the\naverage accuracy of the strongest single model at 27% lower cost, and reach\n~90% of that performance at 63% lower cost. Last but not least, it achieves a\nPareto frontier, consistently yielding the highest accuracy for any given cost,\nand the lowest cost for any given accuracy, among all single models. Code is\navailable at https://github.com/ZhangYiqun018/AvengersPro.", "AI": {"tldr": "Avengers-Pro is a test-time routing framework that dynamically assigns queries to optimal LLMs based on performance-efficiency tradeoffs, achieving state-of-the-art results with up to +7% accuracy improvement and 63% cost reduction.", "motivation": "Address the challenge of balancing performance and efficiency in large language models by providing a unified solution for all performance-efficiency tradeoffs.", "method": "Embeds and clusters incoming queries, then routes each to the most suitable model based on a performance-efficiency score, ensembling LLMs of varying capacities and efficiencies.", "result": "Achieves state-of-the-art results across 6 benchmarks and 8 leading models: +7% accuracy over strongest single model (GPT-5-medium), matches strongest model accuracy at 27% lower cost, reaches ~90% performance at 63% lower cost, and achieves Pareto frontier.", "conclusion": "Avengers-Pro provides an effective framework for optimizing performance-efficiency tradeoffs in LLM inference through intelligent test-time routing and model ensembling."}}
{"id": "2508.12440", "pdf": "https://arxiv.org/pdf/2508.12440", "abs": "https://arxiv.org/abs/2508.12440", "authors": ["Ahmet Bilal Ar\u0131kan", "\u015eener \u00d6z\u00f6nder", "Mustafa Taha Ko\u00e7yi\u011fit", "H\u00fcseyin Oktay Altun", "H. K\u00fcbra K\u00fc\u00e7\u00fckkartal", "Murat Arslano\u011flu", "Fatih \u00c7a\u011f\u0131rankaya", "Berk Ayvaz"], "title": "Machine Learning-Based Manufacturing Cost Prediction from 2D Engineering Drawings via Geometric Features", "categories": ["cs.LG"], "comment": null, "summary": "We present an integrated machine learning framework that transforms how\nmanufacturing cost is estimated from 2D engineering drawings. Unlike\ntraditional quotation workflows that require labor-intensive process planning,\nour approach about 200 geometric and statistical descriptors directly from\n13,684 DWG drawings of automotive suspension and steering parts spanning 24\nproduct groups. Gradient-boosted decision tree models (XGBoost, CatBoost,\nLightGBM) trained on these features achieve nearly 10% mean absolute percentage\nerror across groups, demonstrating robust scalability beyond part-specific\nheuristics. By coupling cost prediction with explainability tools such as SHAP,\nthe framework identifies geometric design drivers including rotated dimension\nmaxima, arc statistics and divergence metrics, offering actionable insights for\ncost-aware design. This end-to-end CAD-to-cost pipeline shortens quotation lead\ntimes, ensures consistent and transparent cost assessments across part families\nand provides a deployable pathway toward real-time, ERP-integrated decision\nsupport in Industry 4.0 manufacturing environments.", "AI": {"tldr": "Machine learning framework that predicts manufacturing costs from 2D engineering drawings with 10% error using geometric features and gradient-boosted models, providing explainable cost insights for automotive parts.", "motivation": "Traditional manufacturing cost estimation requires labor-intensive process planning and lacks scalability across part families. There's a need for automated, accurate cost prediction from engineering drawings to shorten quotation lead times and provide consistent cost assessments.", "method": "Extracted 200 geometric and statistical descriptors from 13,684 DWG drawings of automotive suspension and steering parts. Used gradient-boosted decision tree models (XGBoost, CatBoost, LightGBM) trained on these features, coupled with SHAP for explainability.", "result": "Achieved nearly 10% mean absolute percentage error across 24 product groups, demonstrating robust scalability beyond part-specific heuristics. Identified key geometric design drivers including rotated dimension maxima, arc statistics and divergence metrics.", "conclusion": "The end-to-end CAD-to-cost pipeline provides deployable real-time cost estimation with explainable insights, enabling cost-aware design and ERP-integrated decision support in Industry 4.0 manufacturing environments."}}
{"id": "2508.12935", "pdf": "https://arxiv.org/pdf/2508.12935", "abs": "https://arxiv.org/abs/2508.12935", "authors": ["Ting Yang", "Li Chen", "Huimin Wang"], "title": "Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards", "categories": ["cs.AI"], "comment": null, "summary": "Emotional Support Conversation (ESC) systems aim to alleviate users'\nemotional difficulties and provide long-term, systematic support for emotional\nwell-being. However, most large language model (LLM)-based ESC systems rely on\npredefined strategies, which limits their effectiveness in complex, real-life\nscenarios. To enable flexible responses to diverse emotional problem scenarios,\nthis paper introduces a novel end-to-end framework (RLFF-ESC) that directly\nlearns enduring emotionally supportive response skills using reinforcement\nlearning. For sustained emotional support, we first employ an LLM-based\nmulti-agent mechanism to simulate future dialogue trajectories and collect\nfuture-oriented rewards. We then train a future-oriented reward model, which is\nsubsequently used to train the emotional support policy model. Additionally, we\nincorporate an explicit reasoning process during response generation to further\nenhance the quality, relevance, and contextual appropriateness of the system's\nresponses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and\nLLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two\npublic ESC datasets. Experimental results demonstrate that RLFF-ESC\nconsistently outperforms existing baselines in terms of goal completion and\nresponse quality.", "AI": {"tldr": "RLFF-ESC is a reinforcement learning framework that enables flexible emotional support conversations by simulating future dialogues and using future-oriented rewards, outperforming existing methods.", "motivation": "Current LLM-based emotional support systems rely on predefined strategies, limiting their effectiveness in complex real-life scenarios that require flexible responses to diverse emotional problems.", "method": "End-to-end framework using reinforcement learning with LLM-based multi-agent simulation of future dialogue trajectories, future-oriented reward modeling, and explicit reasoning during response generation.", "result": "Experimental results show RLFF-ESC consistently outperforms existing baselines in goal completion and response quality across two public ESC datasets using Qwen2.5-7B and LLaMA3.1-8B models.", "conclusion": "The proposed RLFF-ESC framework successfully enables flexible and effective emotional support by learning enduring response skills through future-oriented reinforcement learning and explicit reasoning processes."}}
{"id": "2508.12261", "pdf": "https://arxiv.org/pdf/2508.12261", "abs": "https://arxiv.org/abs/2508.12261", "authors": ["Zhizhou Wang", "Ruijing Zheng", "Zhenyu Wu", "Jianli Wang"], "title": "Superpixel-informed Continuous Low-Rank Tensor Representation for Multi-Dimensional Data Recovery", "categories": ["cs.CV"], "comment": "Under review in AAAI2026", "summary": "Low-rank tensor representation (LRTR) has emerged as a powerful tool for\nmulti-dimensional data processing. However, classical LRTR-based methods face\ntwo critical limitations: (1) they typically assume that the holistic data is\nlow-rank, this assumption is often violated in real-world scenarios with\nsignificant spatial variations; and (2) they are constrained to discrete\nmeshgrid data, limiting their flexibility and applicability. To overcome these\nlimitations, we propose a Superpixel-informed Continuous low-rank Tensor\nRepresentation (SCTR) framework, which enables continuous and flexible modeling\nof multi-dimensional data beyond traditional grid-based constraints. Our\napproach introduces two main innovations: First, motivated by the observation\nthat semantically coherent regions exhibit stronger low-rank characteristics\nthan holistic data, we employ superpixels as the basic modeling units. This\ndesign not only encodes rich semantic information, but also enhances\nadaptability to diverse forms of data streams. Second, we propose a novel\nasymmetric low-rank tensor factorization (ALTF) where superpixel-specific\nfactor matrices are parameterized by a shared neural network with specialized\nheads. By strategically separating global pattern learning from local\nadaptation, this framework efficiently captures both cross-superpixel\ncommonalities and within-superpixel variations. This yields a representation\nthat is both highly expressive and compact, balancing model efficiency with\nadaptability. Extensive experiments on several benchmark datasets demonstrate\nthat SCTR achieves 3-5 dB PSNR improvements over existing LRTR-based methods\nacross multispectral images, videos, and color images.", "AI": {"tldr": "SCTR framework overcomes traditional LRTR limitations by using superpixels as modeling units and asymmetric tensor factorization with neural networks, achieving 3-5 dB PSNR improvements across multiple data types.", "motivation": "Classical low-rank tensor representation methods assume holistic data is low-rank and are limited to discrete meshgrid data, which doesn't hold in real-world scenarios with spatial variations.", "method": "Superpixel-informed Continuous Tensor Representation (SCTR) using superpixels as basic units and asymmetric low-rank tensor factorization with shared neural network and specialized heads to separate global pattern learning from local adaptation.", "result": "Achieves 3-5 dB PSNR improvements over existing LRTR-based methods across multispectral images, videos, and color images on benchmark datasets.", "conclusion": "SCTR provides a continuous and flexible modeling framework that captures both cross-superpixel commonalities and within-superpixel variations, balancing expressiveness with compact representation."}}
{"id": "2508.12632", "pdf": "https://arxiv.org/pdf/2508.12632", "abs": "https://arxiv.org/abs/2508.12632", "authors": ["Chi Wang", "Min Gao", "Zongwei Wang", "Junwei Yin", "Kai Shu", "Chenghua Lin"], "title": "Prompt-Induced Linguistic Fingerprints for LLM-Generated Fake News Detection", "categories": ["cs.CL"], "comment": null, "summary": "With the rapid development of large language models, the generation of fake\nnews has become increasingly effortless, posing a growing societal threat and\nunderscoring the urgent need for reliable detection methods. Early efforts to\nidentify LLM-generated fake news have predominantly focused on the textual\ncontent itself; however, because much of that content may appear coherent and\nfactually consistent, the subtle traces of falsification are often difficult to\nuncover. Through distributional divergence analysis, we uncover prompt-induced\nlinguistic fingerprints: statistically distinct probability shifts between\nLLM-generated real and fake news when maliciously prompted. Based on this\ninsight, we propose a novel method named Linguistic Fingerprints Extraction\n(LIFE). By reconstructing word-level probability distributions, LIFE can find\ndiscriminative patterns that facilitate the detection of LLM-generated fake\nnews. To further amplify these fingerprint patterns, we also leverage\nkey-fragment techniques that accentuate subtle linguistic differences, thereby\nimproving detection reliability. Our experiments show that LIFE achieves\nstate-of-the-art performance in LLM-generated fake news and maintains high\nperformance in human-written fake news. The code and data are available at\nhttps://anonymous.4open.science/r/LIFE-E86A.", "AI": {"tldr": "LIFE method detects LLM-generated fake news by analyzing prompt-induced linguistic fingerprints through word-level probability distribution reconstruction and key-fragment techniques.", "motivation": "The ease of generating fake news with large language models creates societal threats, and existing methods focusing on textual content alone are insufficient as LLM-generated fake news often appears coherent and factually consistent.", "method": "LIFE (Linguistic Fingerprints Extraction) reconstructs word-level probability distributions to find discriminative patterns, uses key-fragment techniques to amplify subtle linguistic differences, and leverages distributional divergence analysis to uncover prompt-induced linguistic fingerprints.", "result": "LIFE achieves state-of-the-art performance in detecting LLM-generated fake news and maintains high performance in human-written fake news detection.", "conclusion": "The proposed LIFE method effectively identifies LLM-generated fake news by capturing subtle linguistic fingerprints induced by malicious prompts, providing a reliable detection approach that works across both machine-generated and human-written fake content."}}
{"id": "2508.12450", "pdf": "https://arxiv.org/pdf/2508.12450", "abs": "https://arxiv.org/abs/2508.12450", "authors": ["\u00c9tienne Pepin"], "title": "Local Cluster Cardinality Estimation for Adaptive Mean Shift", "categories": ["cs.LG", "I.5.3"], "comment": "24 pages, 9 figures", "summary": "This article presents an adaptive mean shift algorithm designed for datasets\nwith varying local scale and cluster cardinality. Local distance distributions,\nfrom a point to all others, are used to estimate the cardinality of the local\ncluster by identifying a local minimum in the density of the distance\ndistribution. Based on these cardinality estimates, local cluster parameters\nare then computed for the entire cluster in contrast to KDE-based methods,\nwhich provide insight only into localized regions of the cluster. During the\nmean shift execution, the cluster cardinality estimate is used to adaptively\nadjust the bandwidth and the mean shift kernel radius threshold. Our algorithm\noutperformed a recently proposed adaptive mean shift method on its original\ndataset and demonstrated competitive performance on a broader clustering\nbenchmark.", "AI": {"tldr": "Adaptive mean shift algorithm that uses local distance distributions to estimate cluster cardinality and dynamically adjust bandwidth parameters, outperforming existing methods.", "motivation": "Traditional mean shift algorithms struggle with datasets containing varying local scale and cluster cardinality, as they use fixed bandwidth parameters that don't adapt to local cluster characteristics.", "method": "Uses local distance distributions to identify local minima in density to estimate cluster cardinality. These estimates then inform adaptive adjustments of bandwidth and kernel radius threshold during mean shift execution, providing insights into entire clusters rather than just localized regions.", "result": "The algorithm outperformed a recently proposed adaptive mean shift method on its original dataset and demonstrated competitive performance on a broader clustering benchmark.", "conclusion": "The adaptive approach using local distance distributions for cardinality estimation effectively handles varying cluster scales and sizes, providing superior performance compared to existing adaptive mean shift methods."}}
{"id": "2508.12943", "pdf": "https://arxiv.org/pdf/2508.12943", "abs": "https://arxiv.org/abs/2508.12943", "authors": ["Mary Tonwe"], "title": "OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "Source code and data available at:\n  https://github.com/marytonwe/OPTIC-ER.git", "summary": "Public service systems in many African regions suffer from delayed emergency\nresponse and spatial inequity, causing avoidable suffering. This paper\nintroduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,\nadaptive, and equitable emergency response. OPTIC-ER uses an attention-guided\nactor-critic architecture to manage the complexity of dispatch environments.\nIts key innovations are a Context-Rich State Vector, encoding action\nsub-optimality, and a Precision Reward Function, which penalizes inefficiency.\nTraining occurs in a high-fidelity simulation using real data from Rivers\nState, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is\nbuilt on the TALS framework (Thin computing, Adaptability, Low-cost,\nScalability) for deployment in low-resource settings. In evaluations on 500\nunseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible\ninefficiency, confirming its robustness and generalization. Beyond dispatch,\nthe system generates Infrastructure Deficiency Maps and Equity Monitoring\nDashboards to guide proactive governance and data-informed development. This\nwork presents a validated blueprint for AI-augmented public services, showing\nhow context-aware RL can bridge the gap between algorithmic decision-making and\nmeasurable human impact.", "AI": {"tldr": "OPTIC-ER is a reinforcement learning framework that achieves 100% optimal emergency response dispatch with negligible inefficiency in African public service systems, using attention-guided actor-critic architecture and real data simulation.", "motivation": "Address delayed emergency response and spatial inequity in African public service systems that cause avoidable suffering through AI-augmented solutions.", "method": "Uses attention-guided actor-critic RL architecture with Context-Rich State Vector and Precision Reward Function, trained in high-fidelity simulation using real data from Rivers State, Nigeria, accelerated by precomputed Travel Time Atlas.", "result": "Achieved 100.00% optimality rate with negligible inefficiency on 500 unseen incidents, demonstrating robustness and generalization.", "conclusion": "Provides a validated blueprint for context-aware RL that bridges algorithmic decision-making with measurable human impact, enabling proactive governance through Infrastructure Deficiency Maps and Equity Monitoring Dashboards."}}
{"id": "2508.12263", "pdf": "https://arxiv.org/pdf/2508.12263", "abs": "https://arxiv.org/abs/2508.12263", "authors": ["Hongliang Wei", "Xianqi Zhang", "Xingtao Wang", "Xiaopeng Fan", "Debin Zhao"], "title": "Region-Level Context-Aware Multimodal Understanding", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 6 figures", "summary": "Despite significant progress, existing research on Multimodal Large Language\nModels (MLLMs) mainly focuses on general visual understanding, overlooking the\nability to integrate textual context associated with objects for a more\ncontext-aware multimodal understanding -- an ability we refer to as\nRegion-level Context-aware Multimodal Understanding (RCMU). To address this\nlimitation, we first formulate the RCMU task, which requires models to respond\nto user instructions by integrating both image content and textual information\nof regions or objects. To equip MLLMs with RCMU capabilities, we propose\nRegion-level Context-aware Visual Instruction Tuning (RCVIT), which\nincorporates object information into the model input and enables the model to\nutilize bounding box coordinates to effectively associate objects' visual\ncontent with their textual information. To address the lack of datasets, we\nintroduce the RCMU dataset, a large-scale visual instruction tuning dataset\nthat covers multiple RCMU tasks. We also propose RC\\&P-Bench, a comprehensive\nbenchmark that can evaluate the performance of MLLMs in RCMU and multimodal\npersonalized understanding tasks. Additionally, we propose a reference-free\nevaluation metric to perform a comprehensive and fine-grained evaluation of the\nregion-level context-aware image descriptions. By performing RCVIT on Qwen2-VL\nmodels with the RCMU dataset, we developed RC-Qwen2-VL models. Experimental\nresults indicate that RC-Qwen2-VL models not only achieve outstanding\nperformance on multiple RCMU tasks but also demonstrate successful applications\nin multimodal RAG and personalized conversation. Our data, model and benchmark\nare available at https://github.com/hongliang-wei/RC-MLLM", "AI": {"tldr": "Proposes Region-level Context-aware Multimodal Understanding (RCMU) to integrate textual context with visual objects, introduces RCVIT training method, RCMU dataset, RC&P-Bench benchmark, and achieves state-of-the-art performance with RC-Qwen2-VL models.", "motivation": "Existing MLLMs focus on general visual understanding but lack ability to integrate textual context associated with objects for context-aware multimodal understanding.", "method": "Proposed Region-level Context-aware Visual Instruction Tuning (RCVIT) that incorporates object information and bounding box coordinates to associate visual content with textual information. Created RCMU dataset and RC&P-Bench benchmark for training and evaluation.", "result": "RC-Qwen2-VL models achieve outstanding performance on multiple RCMU tasks and demonstrate successful applications in multimodal RAG and personalized conversation.", "conclusion": "The proposed RCMU framework effectively addresses the limitation of current MLLMs by enabling region-level context-aware understanding, with strong performance demonstrated across various tasks and applications."}}
{"id": "2508.12662", "pdf": "https://arxiv.org/pdf/2508.12662", "abs": "https://arxiv.org/abs/2508.12662", "authors": ["Tanay Nagar", "Grigorii Khvatskii", "Anna Sokol", "Nitesh V. Chawla"], "title": "Breaking Language Barriers: Equitable Performance in Multilingual Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted as a non-archival work-in-progress paper at the NAACL 2025\n  Student Research Workshop", "summary": "Cutting-edge LLMs have emerged as powerful tools for multilingual\ncommunication and understanding. However, LLMs perform worse in Common Sense\nReasoning (CSR) tasks when prompted in low-resource languages (LRLs) like Hindi\nor Swahili compared to high-resource languages (HRLs) like English. Equalizing\nthis inconsistent access to quality LLM outputs is crucial to ensure fairness\nfor speakers of LRLs and across diverse linguistic communities. In this paper,\nwe propose an approach to bridge this gap in LLM performance. Our approach\ninvolves fine-tuning an LLM on synthetic code-switched text generated using\ncontrolled language-mixing methods. We empirically demonstrate that fine-tuning\nLLMs on synthetic code-switched datasets leads to substantial improvements in\nLRL model performance while preserving or enhancing performance in HRLs.\nAdditionally, we present a new dataset of synthetic code-switched text derived\nfrom the CommonSenseQA dataset, featuring three distinct language ratio\nconfigurations.", "AI": {"tldr": "Fine-tuning LLMs on synthetic code-switched text improves common sense reasoning performance in low-resource languages while maintaining high-resource language performance.", "motivation": "LLMs perform worse in common sense reasoning tasks when prompted in low-resource languages compared to high-resource languages, creating unfair access to quality outputs across linguistic communities.", "method": "Fine-tuning LLMs on synthetic code-switched text generated using controlled language-mixing methods, with a new dataset derived from CommonSenseQA featuring three language ratio configurations.", "result": "Substantial improvements in low-resource language model performance while preserving or enhancing performance in high-resource languages.", "conclusion": "Synthetic code-switched fine-tuning effectively bridges the performance gap between high and low-resource languages in LLM common sense reasoning tasks."}}
{"id": "2508.12485", "pdf": "https://arxiv.org/pdf/2508.12485", "abs": "https://arxiv.org/abs/2508.12485", "authors": ["Aayush Gupta", "Arpit Bhayani"], "title": "Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.NI", "C.2.4; C.4; D.4.2; I.2.6"], "comment": "8 pages, 4 figures (system architecture, eviction path, training\n  pipeline, and DQN algorithm), 2 tables. Code available at\n  https://github.com/ayushgupta4897/DRL-Cache", "summary": "Web proxies such as NGINX commonly rely on least-recently-used (LRU)\neviction, which is size agnostic and can thrash under periodic bursts and mixed\nobject sizes. We introduce Cold-RL, a learned eviction policy for NGINX that\nreplaces LRU's forced-expire path with a dueling Deep Q-Network served by an\nONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL\nsamples the K least-recently-used objects, extracts six lightweight features\n(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),\nand requests a bitmask of victims; a hard timeout of 500 microseconds triggers\nimmediate fallback to native LRU. Policies are trained offline by replaying\nNGINX access logs through a cache simulator with a simple reward: a retained\nobject earns one point if it is hit again before TTL expiry. We compare against\nLRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial\nworkloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,\na 146 percent improvement over the best classical baseline; at 100 MB, from\n0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods\n(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th\npercentile eviction latency within budget. To our knowledge, this is the first\nreinforcement learning eviction policy integrated into NGINX with strict SLOs.", "AI": {"tldr": "Cold-RL is a reinforcement learning-based eviction policy for NGINX web proxies that replaces traditional LRU with a Dueling Deep Q-Network, achieving up to 146% hit ratio improvement while maintaining strict microsecond latency budgets.", "motivation": "Traditional LRU eviction in web proxies is size-agnostic and suffers from thrashing under periodic bursts and mixed object sizes, leading to suboptimal cache performance.", "method": "Uses a dueling Deep Q-Network served by an ONNX sidecar that samples K least-recently-used objects and extracts six lightweight features (age, size, hit count, inter-arrival time, remaining TTL, last origin RTT) to select victims for eviction with a 500 microsecond timeout fallback to LRU.", "result": "Achieved 146% hit ratio improvement over best classical baseline at 25MB cache (0.1436 to 0.3538), 15% gain at 100MB (0.7530 to 0.8675), and matches classical methods at 400MB (~0.918) with less than 2% CPU overhead and maintained 95th percentile latency within budget.", "conclusion": "Cold-RL successfully demonstrates the first RL-based eviction policy integrated into NGINX with strict service level objectives, significantly improving cache performance while maintaining microsecond-level latency constraints."}}
{"id": "2508.13003", "pdf": "https://arxiv.org/pdf/2508.13003", "abs": "https://arxiv.org/abs/2508.13003", "authors": ["Shengbo Wang", "Mingwei Liu", "Zike Li", "Anji Li", "Yanlin Wang", "Xin Peng", "Zibin Zheng"], "title": "EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of LLMs poses a significant challenge to existing\nmathematical reasoning benchmarks. These benchmarks commonly suffer from issues\nsuch as score saturation, temporal decay, and data contamination. To address\nthis challenge, this paper introduces EvolMathEval, an automated mathematical\nbenchmark generation and evolution framework based on evolutionary testing. By\ndynamically generating unique evaluation instances ab initio, the framework\nfundamentally eliminates the risk of data contamination, and ensuring the\nbenchmark remains perpetually challenging for future models.The core mechanisms\nof EvolMathEval include: seed problem generation based on reverse engineering\nwith algebraic guarantees; multi-dimensional genetic operators designed to\ninject diverse cognitive challenges; and a composite fitness function that can\nrapidly and accurately assess problem difficulty. Experimental results\ndemonstrate that the proposed composite fitness function can efficiently and\nprecisely quantify the difficulty of mathematical problems. Furthermore,\nEvolMathEval can not only generate a large volume of high-difficulty problems\nthrough continuous self-iteration, but it can also significantly enhance the\ncomplexity of public datasets like GSM8K through evolution, reducing model\naccuracy by an average of 48%. Deeper investigation reveals that when solving\nthese evolved, complex problems, LLMs tend to employ non-rigorous heuristics to\nbypass complex multi-step logical reasoning, consequently leading to incorrect\nsolutions. We define this phenomenon as \"Pseudo Aha Moment\". This finding\nuncovers a cognitive shortcut-taking behavior in the deep reasoning processes\nof current LLMs, which we find accounts for 77% to 100% of errors on targeted\nproblems. Code and resources are available\nat:https://github.com/SYSUSELab/EvolMathEval.", "AI": {"tldr": "EvolMathEval is an automated framework that generates and evolves mathematical benchmarks using evolutionary testing to address issues like data contamination and score saturation in LLM evaluation.", "motivation": "Existing mathematical reasoning benchmarks suffer from score saturation, temporal decay, and data contamination problems as LLMs rapidly advance, requiring more robust evaluation methods.", "method": "Uses evolutionary testing with seed problem generation via reverse engineering, multi-dimensional genetic operators for cognitive challenges, and a composite fitness function to assess problem difficulty.", "result": "The framework generates high-difficulty problems and enhances public datasets (reducing model accuracy by 48%), revealing LLMs' tendency to use non-rigorous heuristics (77-100% of errors) in what's termed \"Pseudo Aha Moment\".", "conclusion": "EvolMathEval provides an effective automated solution for creating perpetually challenging mathematical benchmarks while uncovering cognitive shortcut behaviors in LLM reasoning processes."}}
{"id": "2508.12271", "pdf": "https://arxiv.org/pdf/2508.12271", "abs": "https://arxiv.org/abs/2508.12271", "authors": ["Ronghua Xu", "Jin Xie", "Jing Nie", "Jiale Cao", "Yanwei Pang"], "title": "SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration", "categories": ["cs.CV"], "comment": "11 pages", "summary": "Spiking Neural Networks (SNNs), characterized by discrete binary activations,\noffer high computational efficiency and low energy consumption, making them\nwell-suited for computation-intensive tasks such as stereo image restoration.\nIn this work, we propose SNNSIR, a simple yet effective Spiking Neural Network\nfor Stereo Image Restoration, specifically designed under the spike-driven\nparadigm where neurons transmit information through sparse, event-based binary\nspikes. In contrast to existing hybrid SNN-ANN models that still rely on\noperations such as floating-point matrix division or exponentiation, which are\nincompatible with the binary and event-driven nature of SNNs, our proposed\nSNNSIR adopts a fully spike-driven architecture to achieve low-power and\nhardware-friendly computation. To address the expressiveness limitations of\nbinary spiking neurons, we first introduce a lightweight Spike Residual Basic\nBlock (SRBB) to enhance information flow via spike-compatible residual\nlearning. Building on this, the Spike Stereo Convolutional Modulation (SSCM)\nmodule introduces simplified nonlinearity through element-wise multiplication\nand highlights noise-sensitive regions via cross-view-aware modulation.\nComplementing this, the Spike Stereo Cross-Attention (SSCA) module further\nimproves stereo correspondence by enabling efficient bidirectional feature\ninteraction across views within a spike-compatible framework. Extensive\nexperiments on diverse stereo image restoration tasks, including rain streak\nremoval, raindrop removal, low-light enhancement, and super-resolution\ndemonstrate that our model achieves competitive restoration performance while\nsignificantly reducing computational overhead. These results highlight the\npotential for real-time, low-power stereo vision applications. The code will be\navailable after the article is accepted.", "AI": {"tldr": "SNNSIR is a fully spike-driven Spiking Neural Network for stereo image restoration that achieves competitive performance with significantly reduced computational overhead compared to hybrid SNN-ANN models.", "motivation": "Spiking Neural Networks offer high computational efficiency and low energy consumption but existing hybrid SNN-ANN models still rely on floating-point operations incompatible with SNNs' binary nature. The goal is to create a fully spike-driven architecture for stereo image restoration.", "method": "Proposes SNNSIR with three key components: 1) Spike Residual Basic Block (SRBB) for enhanced information flow via spike-compatible residual learning, 2) Spike Stereo Convolutional Modulation (SSCM) module with simplified nonlinearity and cross-view-aware modulation, 3) Spike Stereo Cross-Attention (SSCA) module for efficient bidirectional feature interaction across views.", "result": "Extensive experiments on stereo image restoration tasks (rain streak removal, raindrop removal, low-light enhancement, super-resolution) demonstrate competitive restoration performance while significantly reducing computational overhead.", "conclusion": "The model shows potential for real-time, low-power stereo vision applications, highlighting the viability of fully spike-driven architectures for computation-intensive tasks."}}
{"id": "2508.12669", "pdf": "https://arxiv.org/pdf/2508.12669", "abs": "https://arxiv.org/abs/2508.12669", "authors": ["Bishanka Seal", "Rahul Seetharaman", "Aman Bansal", "Abhilash Nandy"], "title": "Leveraging Large Language Models for Predictive Analysis of Human Misery", "categories": ["cs.CL", "cs.CY"], "comment": "14 pages, 4 tables", "summary": "This study investigates the use of Large Language Models (LLMs) for\npredicting human-perceived misery scores from natural language descriptions of\nreal-world scenarios. The task is framed as a regression problem, where the\nmodel assigns a scalar value from 0 to 100 to each input statement. We evaluate\nmultiple prompting strategies, including zero-shot, fixed-context few-shot, and\nretrieval-based prompting using BERT sentence embeddings. Few-shot approaches\nconsistently outperform zero-shot baselines, underscoring the value of\ncontextual examples in affective prediction. To move beyond static evaluation,\nwe introduce the \"Misery Game Show\", a novel gamified framework inspired by a\ntelevision format. It tests LLMs through structured rounds involving ordinal\ncomparison, binary classification, scalar estimation, and feedback-driven\nreasoning. This setup enables us to assess not only predictive accuracy but\nalso the model's ability to adapt based on corrective feedback. The gamified\nevaluation highlights the broader potential of LLMs in dynamic emotional\nreasoning tasks beyond standard regression. Code and data link:\nhttps://github.com/abhi1nandy2/Misery_Data_Exps_GitHub", "AI": {"tldr": "LLMs can predict human misery scores from text descriptions using various prompting strategies, with few-shot approaches performing best. A novel gamified evaluation framework tests LLMs' dynamic emotional reasoning capabilities.", "motivation": "To explore how well Large Language Models can understand and predict human emotional states (specifically misery) from natural language descriptions of real-world scenarios, moving beyond traditional static evaluation methods.", "method": "Framed as regression problem (0-100 scores), tested zero-shot, fixed-context few-shot, and retrieval-based prompting using BERT embeddings. Introduced \"Misery Game Show\" - a gamified framework with ordinal comparison, binary classification, scalar estimation, and feedback-driven reasoning rounds.", "result": "Few-shot approaches consistently outperformed zero-shot baselines, demonstrating the value of contextual examples in affective prediction. The gamified evaluation showed LLMs' potential in dynamic emotional reasoning tasks beyond standard regression.", "conclusion": "LLMs show promise in predicting human emotional states from text, with few-shot learning being particularly effective. The gamified evaluation framework provides a more comprehensive way to assess emotional reasoning capabilities beyond traditional metrics."}}
{"id": "2508.12491", "pdf": "https://arxiv.org/pdf/2508.12491", "abs": "https://arxiv.org/abs/2508.12491", "authors": ["Reza Shirkavand", "Shangqian Gao", "Peiran Yu", "Heng Huang"], "title": "Cost-Aware Contrastive Routing for LLMs", "categories": ["cs.LG"], "comment": null, "summary": "We study cost-aware routing for large language models across diverse and\ndynamic pools of models. Existing approaches often overlook prompt-specific\ncontext, rely on expensive model profiling, assume a fixed set of experts, or\nuse inefficient trial-and-error strategies. We introduce Cost-Spectrum\nContrastive Routing (CSCR), a lightweight framework that maps both prompts and\nmodels into a shared embedding space to enable fast, cost-sensitive selection.\nCSCR uses compact, fast-to-compute logit footprints for open-source models and\nperplexity fingerprints for black-box APIs. A contrastive encoder is trained to\nfavor the cheapest accurate expert within adaptive cost bands. At inference\ntime, routing reduces to a single k-NN lookup via a FAISS index, requiring no\nretraining when the expert pool changes and enabling microsecond latency.\nAcross multiple benchmarks, CSCR consistently outperforms baselines, improving\nthe accuracy-cost tradeoff by up to 25%, while generalizing robustly to unseen\nLLMs and out-of-distribution prompts.", "AI": {"tldr": "CSCR is a lightweight routing framework that maps prompts and models to a shared embedding space for fast, cost-sensitive LLM selection using compact model fingerprints and contrastive learning.", "motivation": "Existing routing approaches overlook prompt-specific context, require expensive model profiling, assume fixed expert sets, or use inefficient trial-and-error strategies for large language model routing.", "method": "Uses compact logit footprints for open-source models and perplexity fingerprints for black-box APIs. Trains contrastive encoder to favor cheapest accurate expert within adaptive cost bands. Inference uses single k-NN lookup via FAISS index.", "result": "Outperforms baselines across multiple benchmarks, improving accuracy-cost tradeoff by up to 25%, with robust generalization to unseen LLMs and out-of-distribution prompts.", "conclusion": "CSCR enables fast, cost-aware routing with microsecond latency, requires no retraining when expert pool changes, and provides significant improvements in cost-accuracy efficiency."}}
{"id": "2508.13020", "pdf": "https://arxiv.org/pdf/2508.13020", "abs": "https://arxiv.org/abs/2508.13020", "authors": ["Jiaqi Yin", "Zhan Song", "Chen Chen", "Yaohui Cai", "Zhiru Zhang", "Cunxi Yu"], "title": "e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving", "categories": ["cs.AI", "cs.AR"], "comment": null, "summary": "E-graphs have attracted growing interest in many fields, particularly in\nlogic synthesis and formal verification. E-graph extraction is a challenging\nNP-hard combinatorial optimization problem. It requires identifying optimal\nterms from exponentially many equivalent expressions, serving as the primary\nperformance bottleneck in e-graph based optimization tasks. However,\ntraditional extraction methods face a critical trade-off: heuristic approaches\noffer speed but sacrifice optimality, while exact methods provide optimal\nsolutions but face prohibitive computational costs on practical problems. We\npresent e-boost, a novel framework that bridges this gap through three key\ninnovations: (1) parallelized heuristic extraction that leverages weak data\ndependence to compute DAG costs concurrently, enabling efficient multi-threaded\nperformance without sacrificing extraction quality; (2) adaptive search space\npruning that employs a parameterized threshold mechanism to retain only\npromising candidates, dramatically reducing the solution space while preserving\nnear-optimal solutions; and (3) initialized exact solving that formulates the\nreduced problem as an Integer Linear Program with warm-start capabilities,\nguiding solvers toward high-quality solutions faster.\n  Across the diverse benchmarks in formal verification and logic synthesis\nfields, e-boost demonstrates 558x runtime speedup over traditional exact\napproaches (ILP) and 19.04% performance improvement over the state-of-the-art\nextraction framework (SmoothE). In realistic logic synthesis tasks, e-boost\nproduces 7.6% and 8.1% area improvements compared to conventional synthesis\ntools with two different technology mapping libraries. e-boost is available at\nhttps://github.com/Yu-Maryland/e-boost.", "AI": {"tldr": "E-boost is a novel framework that bridges the gap between heuristic and exact e-graph extraction methods through parallelization, adaptive pruning, and initialized exact solving, achieving significant speedups and performance improvements.", "motivation": "Traditional e-graph extraction methods face a critical trade-off: heuristic approaches are fast but suboptimal, while exact methods provide optimal solutions but are computationally prohibitive for practical problems.", "method": "Three key innovations: (1) parallelized heuristic extraction with weak data dependence for concurrent DAG cost computation, (2) adaptive search space pruning with parameterized threshold to retain promising candidates, and (3) initialized exact solving using Integer Linear Programming with warm-start capabilities.", "result": "558x runtime speedup over traditional exact approaches (ILP), 19.04% performance improvement over state-of-the-art framework (SmoothE), and 7.6-8.1% area improvements in logic synthesis tasks with different technology mapping libraries.", "conclusion": "E-boost effectively bridges the performance gap between heuristic and exact e-graph extraction methods, delivering near-optimal solutions with dramatically improved computational efficiency across diverse benchmarks in formal verification and logic synthesis."}}
{"id": "2508.12279", "pdf": "https://arxiv.org/pdf/2508.12279", "abs": "https://arxiv.org/abs/2508.12279", "authors": ["Jun Liu", "Zhenglun Kong", "Pu Zhao", "Weihao Zeng", "Hao Tang", "Xuan Shen", "Changdi Yang", "Wenbin Zhang", "Geng Yuan", "Wei Niu", "Xue Lin", "Yanzhi Wang"], "title": "TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform", "categories": ["cs.CV", "cs.AI", "cs.AR", "cs.LG"], "comment": null, "summary": "Autonomous driving platforms encounter diverse driving scenarios, each with\nvarying hardware resources and precision requirements. Given the computational\nlimitations of embedded devices, it is crucial to consider computing costs when\ndeploying on target platforms like the NVIDIA\\textsuperscript{\\textregistered}\nDRIVE PX 2. Our objective is to customize the semantic segmentation network\naccording to the computing power and specific scenarios of autonomous driving\nhardware. We implement dynamic adaptability through a three-tier control\nmechanism -- width multiplier, classifier depth, and classifier kernel --\nallowing fine-grained control over model components based on hardware\nconstraints and task requirements. This adaptability facilitates broad model\nscaling, targeted refinement of the final layers, and scenario-specific\noptimization of kernel sizes, leading to improved resource allocation and\nperformance.\n  Additionally, we leverage Bayesian Optimization with surrogate modeling to\nefficiently explore hyperparameter spaces under tight computational budgets.\nOur approach addresses scenario-specific and task-specific requirements through\nautomatic parameter search, accommodating the unique computational complexity\nand accuracy needs of autonomous driving. It scales its Multiply-Accumulate\nOperations (MACs) for Task-Specific Learning Adaptation (TSLA), resulting in\nalternative configurations tailored to diverse self-driving tasks. These TSLA\ncustomizations maximize computational capacity and model accuracy, optimizing\nhardware utilization.", "AI": {"tldr": "Dynamic semantic segmentation network customization for autonomous driving hardware using three-tier control mechanism and Bayesian optimization to optimize computational efficiency and accuracy.", "motivation": "Autonomous driving platforms face diverse scenarios with varying hardware resources and precision requirements, requiring efficient deployment on computationally limited embedded devices like NVIDIA DRIVE PX 2.", "method": "Three-tier control mechanism (width multiplier, classifier depth, classifier kernel) for fine-grained model control, combined with Bayesian Optimization for hyperparameter search under tight computational budgets.", "result": "Enables broad model scaling, targeted refinement of final layers, and scenario-specific optimization, leading to improved resource allocation and performance with tailored configurations for diverse self-driving tasks.", "conclusion": "The approach successfully addresses scenario-specific and task-specific requirements through automatic parameter search, maximizing computational capacity and model accuracy while optimizing hardware utilization for autonomous driving applications."}}
{"id": "2508.12685", "pdf": "https://arxiv.org/pdf/2508.12685", "abs": "https://arxiv.org/abs/2508.12685", "authors": ["Xingshan Zeng", "Weiwen Liu", "Lingzhi Wang", "Liangyou Li", "Fei Mi", "Yasheng Wang", "Lifeng Shang", "Xin Jiang", "Qun Liu"], "title": "ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Agentic task-solving with Large Language Models (LLMs) requires multi-turn,\nmulti-step interactions, often involving complex function calls and dynamic\nuser-agent exchanges. Existing simulation-based data generation methods for\nsuch scenarios rely heavily on costly autoregressive interactions between\nmultiple LLM agents, thereby limiting real-world performance of agentic tasks.\nIn this paper, we propose a novel Non-Autoregressive Iterative Generation\nframework, called ToolACE-MT, for constructing high-quality multi-turn agentic\ndialogues. ToolACE-MT generates full conversational trajectories through three\nstages: coarse-grained initialization, iterative refinement, and offline\nverification. The initialization phase builds a structurally complete yet\nsemantically coarse dialogue skeleton; the iterative refinement phase\nintroduces realistic complexities and continued refinement via mask-and-fill\noperations; and the offline verification phase ensures correctness and\ncoherence via rule- and model-based checks. Experiments demonstrate that\nToolACE-MT enables efficient, effective and generalizable agentic data\ngeneration, offering a new paradigm for high-quality data construction in\ntool-augmented LLM scenarios.", "AI": {"tldr": "ToolACE-MT is a non-autoregressive framework that generates high-quality multi-turn agentic dialogues through three stages: coarse initialization, iterative refinement, and offline verification, enabling efficient data generation for tool-augmented LLMs.", "motivation": "Existing simulation-based data generation methods for agentic tasks rely on costly autoregressive interactions between multiple LLM agents, limiting real-world performance and scalability.", "method": "Three-stage framework: 1) Coarse-grained initialization builds structurally complete dialogue skeletons, 2) Iterative refinement adds realistic complexities via mask-and-fill operations, 3) Offline verification ensures correctness through rule- and model-based checks.", "result": "Experiments demonstrate that ToolACE-MT enables efficient, effective and generalizable agentic data generation, outperforming existing autoregressive approaches.", "conclusion": "ToolACE-MT offers a new paradigm for high-quality data construction in tool-augmented LLM scenarios, providing a scalable solution for agentic task-solving data generation."}}
{"id": "2508.12511", "pdf": "https://arxiv.org/pdf/2508.12511", "abs": "https://arxiv.org/abs/2508.12511", "authors": ["Denis Blessing", "Julius Berner", "Lorenz Richter", "Carles Domingo-Enrich", "Yuanqi Du", "Arash Vahdat", "Gerhard Neumann"], "title": "Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference", "categories": ["cs.LG"], "comment": null, "summary": "Solving stochastic optimal control problems with quadratic control costs can\nbe viewed as approximating a target path space measure, e.g. via gradient-based\noptimization. In practice, however, this optimization is challenging in\nparticular if the target measure differs substantially from the prior. In this\nwork, we therefore approach the problem by iteratively solving constrained\nproblems incorporating trust regions that aim for approaching the target\nmeasure gradually in a systematic way. It turns out that this trust region\nbased strategy can be understood as a geometric annealing from the prior to the\ntarget measure, where, however, the incorporated trust regions lead to a\nprincipled and educated way of choosing the time steps in the annealing path.\nWe demonstrate in multiple optimal control applications that our novel method\ncan improve performance significantly, including tasks in diffusion-based\nsampling, transition path sampling, and fine-tuning of diffusion models.", "AI": {"tldr": "A novel trust region-based iterative method for solving stochastic optimal control problems with quadratic costs, using geometric annealing from prior to target measure with principled time step selection.", "motivation": "Solving stochastic optimal control problems is challenging when the target measure differs substantially from the prior, requiring better optimization approaches.", "method": "Iteratively solving constrained problems with trust regions that gradually approach the target measure, implementing geometric annealing with principled time step selection.", "result": "The method significantly improves performance in various optimal control applications including diffusion-based sampling, transition path sampling, and diffusion model fine-tuning.", "conclusion": "Trust region-based geometric annealing provides a systematic and effective approach for solving challenging stochastic optimal control problems with substantial differences between prior and target measures."}}
{"id": "2508.13021", "pdf": "https://arxiv.org/pdf/2508.13021", "abs": "https://arxiv.org/abs/2508.13021", "authors": ["Pengcheng Huang", "Shuhao Liu", "Zhenghao Liu", "Yukun Yan", "Shuo Wang", "Zulong Chen", "Tong Xiao"], "title": "PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models", "categories": ["cs.AI", "cs.CL"], "comment": "17 pages,13 figures", "summary": "Recent advances in masked diffusion models (MDMs) have established them as\npowerful non-autoregressive alternatives for sequence generation. Nevertheless,\nour preliminary experiments reveal that the generation quality of MDMs is still\nhighly sensitive to the choice of decoding strategy. In particular, widely\nadopted uncertainty-based samplers suffer from two key limitations: a lack of\nglobal trajectory control and a pronounced bias toward trivial tokens in the\nearly stages of decoding. These shortcomings restrict the full potential of\nMDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling\n(PC-Sampler), a novel decoding strategy that unifies global trajectory planning\nwith content-aware informativeness maximization. PC-Sampler incorporates a\nposition-aware weighting mechanism to regulate the decoding path and a\ncalibrated confidence score to suppress the premature selection of trivial\ntokens. Extensive experiments on three advanced MDMs across seven challenging\nbenchmarks-including logical reasoning and planning tasks-demonstrate that\nPC-Sampler consistently outperforms existing MDM decoding strategies by more\nthan 10% on average, significantly narrowing the performance gap with\nstate-of-the-art autoregressive models. All codes are available at\nhttps://github.com/NEUIR/PC-Sampler.", "AI": {"tldr": "PC-Sampler is a novel decoding strategy for masked diffusion models that improves generation quality by combining global trajectory planning with content-aware informativeness maximization, outperforming existing methods by over 10%.", "motivation": "Current uncertainty-based samplers for masked diffusion models suffer from lack of global trajectory control and bias toward trivial tokens in early decoding stages, limiting MDM performance.", "method": "Position-Aware Confidence-Calibrated Sampling (PC-Sampler) with position-aware weighting mechanism for decoding path regulation and calibrated confidence scores to suppress premature selection of trivial tokens.", "result": "PC-Sampler consistently outperforms existing MDM decoding strategies by more than 10% on average across 7 benchmarks, significantly narrowing the performance gap with state-of-the-art autoregressive models.", "conclusion": "The proposed PC-Sampler effectively addresses key limitations of current MDM decoding strategies and demonstrates substantial performance improvements across diverse challenging tasks."}}
{"id": "2508.12290", "pdf": "https://arxiv.org/pdf/2508.12290", "abs": "https://arxiv.org/abs/2508.12290", "authors": ["Chor Boon Tan", "Conghui Hu", "Gim Hee Lee"], "title": "CLAIR: CLIP-Aided Weakly Supervised Zero-Shot Cross-Domain Image Retrieval", "categories": ["cs.CV"], "comment": "BMVC 2025", "summary": "The recent growth of large foundation models that can easily generate\npseudo-labels for huge quantity of unlabeled data makes unsupervised Zero-Shot\nCross-Domain Image Retrieval (UZS-CDIR) less relevant. In this paper, we\ntherefore turn our attention to weakly supervised ZS-CDIR (WSZS-CDIR) with\nnoisy pseudo labels generated by large foundation models such as CLIP. To this\nend, we propose CLAIR to refine the noisy pseudo-labels with a confidence score\nfrom the similarity between the CLIP text and image features. Furthermore, we\ndesign inter-instance and inter-cluster contrastive losses to encode images\ninto a class-aware latent space, and an inter-domain contrastive loss to\nalleviate domain discrepancies. We also learn a novel cross-domain mapping\nfunction in closed-form, using only CLIP text embeddings to project image\nfeatures from one domain to another, thereby further aligning the image\nfeatures for retrieval. Finally, we enhance the zero-shot generalization\nability of our CLAIR to handle novel categories by introducing an extra set of\nlearnable prompts. Extensive experiments are carried out using TUBerlin,\nSketchy, Quickdraw, and DomainNet zero-shot datasets, where our CLAIR\nconsistently shows superior performance compared to existing state-of-the-art\nmethods.", "AI": {"tldr": "CLAIR is a novel framework for weakly supervised zero-shot cross-domain image retrieval that refines noisy pseudo-labels from foundation models like CLIP using confidence scores and contrastive learning to handle domain discrepancies and improve retrieval performance.", "motivation": "With large foundation models generating pseudo-labels for unlabeled data, unsupervised zero-shot cross-domain image retrieval becomes less relevant. The paper focuses on weakly supervised approaches using noisy pseudo-labels from models like CLIP.", "method": "Proposes CLAIR framework that: 1) refines noisy pseudo-labels using CLIP text-image similarity confidence scores, 2) uses inter-instance and inter-cluster contrastive losses for class-aware encoding, 3) employs inter-domain contrastive loss to reduce domain gaps, 4) learns cross-domain mapping function using CLIP text embeddings, and 5) adds learnable prompts for zero-shot generalization.", "result": "Extensive experiments on TUBerlin, Sketchy, Quickdraw, and DomainNet zero-shot datasets show CLAIR consistently outperforms state-of-the-art methods.", "conclusion": "CLAIR effectively addresses weakly supervised zero-shot cross-domain image retrieval by leveraging foundation model pseudo-labels while mitigating noise through confidence scoring and contrastive learning techniques."}}
{"id": "2508.12726", "pdf": "https://arxiv.org/pdf/2508.12726", "abs": "https://arxiv.org/abs/2508.12726", "authors": ["Weize Liu", "Yongchi Zhao", "Yijia Luo", "Mingyu Xu", "Jiaheng Liu", "Yanan Li", "Xiguo Hu", "Yuchi Xu", "Wenbo Su", "Bo Zheng"], "title": "DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable success in many natural\nlanguage tasks but still struggle with complex, multi-step reasoning,\nparticularly across diverse disciplines. Existing reasoning datasets often\neither lack disciplinary breadth or the structural depth necessary to elicit\nrobust reasoning behaviors. We propose DESIGNER: a DESIGN-logic-guidEd\nReasoning data synthesis pipeline that leverages naturally available, extensive\nraw documents (book corpus and web corpus) to generate multidisciplinary\nchallenging questions. A core innovation of our approach is the introduction of\na Design Logic concept, which mimics the question-creation process of human\neducators. We use LLMs to reverse-engineer and abstract over 120,000 design\nlogics from existing questions across various disciplines. By matching these\ndesign logics with disciplinary source materials, we are able to create\nreasoning questions that far surpass the difficulty and diversity of existing\ndatasets. Based on this pipeline, we synthesized two large-scale reasoning\ndatasets that span 75 disciplines: Design-Logic-Reasoning-Book (DLR-Book),\ncontaining 3.04 million challenging questions synthesized from the book corpus,\nand Design-Logic-Reasoning-Web (DLR-Web), with 1.66 million challenging\nquestions from the web corpus. Our data analysis demonstrates that the\nquestions synthesized by our method exhibit substantially greater difficulty\nand diversity than those in the baseline datasets. We validate the\neffectiveness of these datasets by conducting SFT experiments on the\nQwen3-8B-Base and Qwen3-4B-Base models. The results show that our dataset\nsignificantly outperforms existing multidisciplinary datasets of the same\nvolume. Training with the full datasets further enables the models to surpass\nthe multidisciplinary reasoning performance of the official Qwen3-8B and\nQwen3-4B models.", "AI": {"tldr": "DESIGNER is a novel data synthesis pipeline that uses Design Logic concepts to generate 4.7 million challenging multidisciplinary reasoning questions from book and web corpora, significantly outperforming existing datasets in difficulty and diversity.", "motivation": "LLMs struggle with complex multi-step reasoning across diverse disciplines, and existing datasets lack both disciplinary breadth and structural depth needed for robust reasoning evaluation.", "method": "Reverse-engineered over 120,000 design logics from existing questions using LLMs, then matched these logics with disciplinary source materials from book and web corpora to synthesize challenging reasoning questions.", "result": "Created two large-scale datasets (DLR-Book with 3.04M questions and DLR-Web with 1.66M questions) spanning 75 disciplines. SFT experiments showed significant performance improvements over baseline datasets and even surpassed official Qwen3 models.", "conclusion": "The DESIGNER pipeline successfully generates high-quality, challenging reasoning questions at scale, enabling better training and evaluation of LLMs' multidisciplinary reasoning capabilities."}}
{"id": "2508.12524", "pdf": "https://arxiv.org/pdf/2508.12524", "abs": "https://arxiv.org/abs/2508.12524", "authors": ["Joseph Su\u00e1rez", "Kyoung Whan Choe", "David Bloomin", "Jianming Gao", "Yunkun Li", "Yao Feng", "Saidinesh Pola", "Kun Zhang", "Yonghui Zhu", "Nikhil Pinnaparaju", "Hao Xiang Li", "Nishaanth Kanna", "Daniel Scott", "Ryan Sullivan", "Rose S. Shuman", "Lucas de Alc\u00e2ntara", "Herbie Bradley", "Kirsty You", "Bo Wu", "Yuhao Jiang", "Qimai Li", "Jiaxin Chen", "Louis Castricato", "Xiaolong Zhu", "Phillip Isola"], "title": "Results of the NeurIPS 2023 Neural MMO Competition on Multi-task Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "We present the results of the NeurIPS 2023 Neural MMO Competition, which\nattracted over 200 participants and submissions. Participants trained\ngoal-conditional policies that generalize to tasks, maps, and opponents never\nseen during training. The top solution achieved a score 4x higher than our\nbaseline within 8 hours of training on a single 4090 GPU. We open-source\neverything relating to Neural MMO and the competition under the MIT license,\nincluding the policy weights and training code for our baseline and for the top\nsubmissions.", "AI": {"tldr": "NeurIPS 2023 Neural MMO Competition results with over 200 participants, where top solution achieved 4x baseline performance in 8 hours on single GPU.", "motivation": "To advance research in goal-conditional policies that generalize to unseen tasks, maps, and opponents through competitive benchmarking.", "method": "Competition framework where participants trained goal-conditional policies on Neural MMO platform, with evaluation on unseen environments and opponents.", "result": "Top solution outperformed baseline by 4x within 8 hours of training on a single 4090 GPU, with over 200 participants submitting solutions.", "conclusion": "Successful competition demonstrating rapid progress in generalization capabilities, with full open-sourcing of code, baseline, and top submissions under MIT license."}}
{"id": "2508.13023", "pdf": "https://arxiv.org/pdf/2508.13023", "abs": "https://arxiv.org/abs/2508.13023", "authors": ["Yongxin Guo", "Wenbo Deng", "Zhenglin Cheng", "Xiaoying Tang"], "title": "G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced\nthe reasoning abilities of large language models (LLMs). Its success, however,\nlargely depends on strong base models with rich world knowledge, yielding only\nmodest improvements for small-size language models (SLMs). To address this\nlimitation, we investigate Guided GRPO, which injects ground-truth reasoning\nsteps into roll-out trajectories to compensate for SLMs' inherent weaknesses.\nThrough a comprehensive study of various guidance configurations, we find that\nnaively adding guidance delivers limited gains. These insights motivate\nG$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength\nin response to the model's evolving training dynamics. Experiments on\nmathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A\nsubstantially outperforms vanilla GRPO. Our code and models are available at\nhttps://github.com/T-Lab-CUHKSZ/G2RPO-A.", "AI": {"tldr": "G\u00b2RPO-A is an adaptive reinforcement learning method that injects ground-truth reasoning steps to improve small language models' reasoning abilities, outperforming vanilla GRPO on math and code tasks.", "motivation": "RLVR works well for large language models but shows limited improvements for small language models due to their inherent weaknesses in world knowledge and reasoning capabilities.", "method": "Guided GRPO injects ground-truth reasoning steps into roll-out trajectories. G\u00b2RPO-A adaptively adjusts guidance strength based on the model's training dynamics rather than using fixed guidance.", "result": "Experiments on mathematical reasoning and code-generation benchmarks show that G\u00b2RPO-A substantially outperforms vanilla GRPO, demonstrating significant improvements for small language models.", "conclusion": "Adaptive guidance injection effectively compensates for small language models' weaknesses, providing a promising approach to enhance reasoning capabilities without requiring large base models."}}
{"id": "2508.12313", "pdf": "https://arxiv.org/pdf/2508.12313", "abs": "https://arxiv.org/abs/2508.12313", "authors": ["Xiaobin Deng", "Changyu Diao", "Min Li", "Ruohan Yu", "Duanqing Xu"], "title": "Improving Densification in 3D Gaussian Splatting for High-Fidelity Rendering", "categories": ["cs.CV"], "comment": "Project page: https://xiaobin2001.github.io/improved-gs-web", "summary": "Although 3D Gaussian Splatting (3DGS) has achieved impressive performance in\nreal-time rendering, its densification strategy often results in suboptimal\nreconstruction quality. In this work, we present a comprehensive improvement to\nthe densification pipeline of 3DGS from three perspectives: when to densify,\nhow to densify, and how to mitigate overfitting. Specifically, we propose an\nEdge-Aware Score to effectively select candidate Gaussians for splitting. We\nfurther introduce a Long-Axis Split strategy that reduces geometric distortions\nintroduced by clone and split operations. To address overfitting, we design a\nset of techniques, including Recovery-Aware Pruning, Multi-step Update, and\nGrowth Control. Our method enhances rendering fidelity without introducing\nadditional training or inference overhead, achieving state-of-the-art\nperformance with fewer Gaussians.", "AI": {"tldr": "Improved 3D Gaussian Splatting densification pipeline with edge-aware candidate selection, long-axis splitting strategy, and overfitting mitigation techniques for better reconstruction quality with fewer Gaussians.", "motivation": "3D Gaussian Splatting's current densification strategy results in suboptimal reconstruction quality, needing improvements in when and how to densify while addressing overfitting issues.", "method": "Proposes Edge-Aware Score for candidate selection, Long-Axis Split strategy to reduce geometric distortions, and overfitting mitigation techniques including Recovery-Aware Pruning, Multi-step Update, and Growth Control.", "result": "Achieves state-of-the-art performance with enhanced rendering fidelity and fewer Gaussians, without additional training or inference overhead.", "conclusion": "The comprehensive improvements to the densification pipeline significantly enhance 3DGS reconstruction quality while maintaining efficiency."}}
{"id": "2508.12733", "pdf": "https://arxiv.org/pdf/2508.12733", "abs": "https://arxiv.org/abs/2508.12733", "authors": ["Zhiyuan Ning", "Tianle Gu", "Jiaxin Song", "Shixin Hong", "Lingyu Li", "Huacan Liu", "Jie Li", "Yixu Wang", "Meng Lingyu", "Yan Teng", "Yingchun Wang"], "title": "LinguaSafe: A Comprehensive Multilingual Safety Benchmark for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "7pages, 5 figures", "summary": "The widespread adoption and increasing prominence of large language models\n(LLMs) in global technologies necessitate a rigorous focus on ensuring their\nsafety across a diverse range of linguistic and cultural contexts. The lack of\na comprehensive evaluation and diverse data in existing multilingual safety\nevaluations for LLMs limits their effectiveness, hindering the development of\nrobust multilingual safety alignment. To address this critical gap, we\nintroduce LinguaSafe, a comprehensive multilingual safety benchmark crafted\nwith meticulous attention to linguistic authenticity. The LinguaSafe dataset\ncomprises 45k entries in 12 languages, ranging from Hungarian to Malay. Curated\nusing a combination of translated, transcreated, and natively-sourced data, our\ndataset addresses the critical need for multilingual safety evaluations of\nLLMs, filling the void in the safety evaluation of LLMs across diverse\nunder-represented languages from Hungarian to Malay. LinguaSafe presents a\nmultidimensional and fine-grained evaluation framework, with direct and\nindirect safety assessments, including further evaluations for oversensitivity.\nThe results of safety and helpfulness evaluations vary significantly across\ndifferent domains and different languages, even in languages with similar\nresource levels. Our benchmark provides a comprehensive suite of metrics for\nin-depth safety evaluation, underscoring the critical importance of thoroughly\nassessing multilingual safety in LLMs to achieve more balanced safety\nalignment. Our dataset and code are released to the public to facilitate\nfurther research in the field of multilingual LLM safety.", "AI": {"tldr": "LinguaSafe is a comprehensive multilingual safety benchmark with 45k entries across 12 languages, addressing the gap in LLM safety evaluation for diverse linguistic contexts through translated, transcreated, and natively-sourced data.", "motivation": "The lack of comprehensive evaluation and diverse data in existing multilingual safety evaluations for LLMs limits their effectiveness and hinders robust multilingual safety alignment, necessitating better safety assessment across diverse linguistic and cultural contexts.", "method": "Created LinguaSafe dataset comprising 45k entries in 12 languages using a combination of translated, transcreated, and natively-sourced data with meticulous attention to linguistic authenticity. Developed a multidimensional evaluation framework with direct/indirect safety assessments and oversensitivity evaluations.", "result": "Safety and helpfulness evaluation results vary significantly across different domains and languages, even among languages with similar resource levels, highlighting the importance of thorough multilingual safety assessment.", "conclusion": "LinguaSafe provides a comprehensive suite of metrics for in-depth safety evaluation and underscores the critical importance of thoroughly assessing multilingual safety in LLMs to achieve more balanced safety alignment. The dataset and code are publicly released to facilitate further research."}}
{"id": "2508.12530", "pdf": "https://arxiv.org/pdf/2508.12530", "abs": "https://arxiv.org/abs/2508.12530", "authors": ["Hyunsoo Song", "Seungwhan Kim", "Seungkyu Lee"], "title": "Toward Architecture-Agnostic Local Control of Posterior Collapse in VAEs", "categories": ["cs.LG", "cs.CV", "stat.ML", "I.2.6"], "comment": "8 pages, 6 figures", "summary": "Variational autoencoders (VAEs), one of the most widely used generative\nmodels, are known to suffer from posterior collapse, a phenomenon that reduces\nthe diversity of generated samples. To avoid posterior collapse, many prior\nworks have tried to control the influence of regularization loss. However, the\ntrade-off between reconstruction and regularization is not satisfactory. For\nthis reason, several methods have been proposed to guarantee latent\nidentifiability, which is the key to avoiding posterior collapse. However, they\nrequire structural constraints on the network architecture. For further\nclarification, we define local posterior collapse to reflect the importance of\nindividual sample points in the data space and to relax the network constraint.\nThen, we propose Latent Reconstruction(LR) loss, which is inspired by\nmathematical properties of injective and composite functions, to control\nposterior collapse without restriction to a specific architecture. We\nexperimentally evaluate our approach, which controls posterior collapse on\nvaried datasets such as MNIST, fashionMNIST, Omniglot, CelebA, and FFHQ.", "AI": {"tldr": "Proposes Latent Reconstruction loss to address posterior collapse in VAEs without architectural constraints, using mathematical properties of injective functions to improve sample diversity.", "motivation": "VAEs suffer from posterior collapse that reduces sample diversity. Existing methods require architectural constraints or have unsatisfactory trade-offs between reconstruction and regularization.", "method": "Defines local posterior collapse and proposes Latent Reconstruction loss based on mathematical properties of injective and composite functions to control posterior collapse without specific architecture restrictions.", "result": "Experimentally evaluated on MNIST, fashionMNIST, Omniglot, CelebA, and FFHQ datasets, successfully controlling posterior collapse across varied datasets.", "conclusion": "The proposed LR loss effectively addresses posterior collapse in VAEs without requiring structural network constraints, improving generative diversity across multiple datasets."}}
{"id": "2508.13072", "pdf": "https://arxiv.org/pdf/2508.13072", "abs": "https://arxiv.org/abs/2508.13072", "authors": ["Yuting Zhang", "Tiantian Geng", "Luoying Hao", "Xinxing Cheng", "Alexander Thorley", "Xiaoxia Wang", "Wenqi Lu", "Sandeep S Hothi", "Lei Wei", "Zhaowen Qiu", "Dipak Kotecha", "Jinming Duan"], "title": "A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis", "categories": ["cs.AI"], "comment": null, "summary": "Contemporary cardiovascular management involves complex consideration and\nintegration of multimodal cardiac datasets, where each modality provides\ndistinct but complementary physiological characteristics. While the effective\nintegration of multiple modalities could yield a holistic clinical profile that\naccurately models the true clinical situation with respect to data modalities\nand their relatives weightings, current methodologies remain limited by: 1) the\nscarcity of patient- and time-aligned multimodal data; 2) reliance on isolated\nsingle-modality or rigid multimodal input combinations; 3) alignment strategies\nthat prioritize cross-modal similarity over complementarity; and 4) a narrow\nsingle-task focus. In response to these limitations, a comprehensive multimodal\ndataset was curated for immediate application, integrating laboratory test\nresults, electrocardiograms, and echocardiograms with clinical outcomes.\nSubsequently, a unified framework, Textual Guidance Multimodal fusion for\nMultiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key\ncomponents: 1) a MedFlexFusion module designed to capture the unique and\ncomplementary characteristics of medical modalities and dynamically integrate\ndata from diverse cardiac sources and their combinations; 2) a textual guidance\nmodule to derive task-relevant representations tailored to diverse clinical\nobjectives, including heart disease diagnosis, risk stratification and\ninformation retrieval; and 3) a response module to produce final decisions for\nall these tasks. Furthermore, this study systematically explored key features\nacross multiple modalities and elucidated their synergistic contributions in\nclinical decision-making. Extensive experiments showed that TGMM outperformed\nstate-of-the-art methods across multiple clinical tasks, with additional\nvalidation confirming its robustness on another public dataset.", "AI": {"tldr": "TGMM is a unified multimodal framework that integrates lab tests, ECGs, and echocardiograms with clinical outcomes using dynamic fusion and textual guidance for multiple cardiac tasks, outperforming state-of-the-art methods.", "motivation": "Current cardiovascular management faces limitations including scarce aligned multimodal data, rigid input combinations, cross-modal similarity prioritization over complementarity, and narrow single-task focus.", "method": "Proposed TGMM framework with three components: 1) MedFlexFusion module for dynamic integration of diverse cardiac data sources, 2) textual guidance module for task-relevant representations, and 3) response module for final decisions across multiple clinical tasks.", "result": "TGMM outperformed state-of-the-art methods across multiple clinical tasks (heart disease diagnosis, risk stratification, information retrieval) and demonstrated robustness on public datasets.", "conclusion": "The study provides a comprehensive multimodal framework that effectively integrates complementary cardiac modalities and systematically explores their synergistic contributions to clinical decision-making."}}
{"id": "2508.12322", "pdf": "https://arxiv.org/pdf/2508.12322", "abs": "https://arxiv.org/abs/2508.12322", "authors": ["Michael Deutges", "Chen Yang", "Raheleh Salehi", "Nassir Navab", "Carsten Marr", "Ario Sadafi"], "title": "Neural Cellular Automata for Weakly Supervised Segmentation of White Blood Cells", "categories": ["cs.CV"], "comment": null, "summary": "The detection and segmentation of white blood cells in blood smear images is\na key step in medical diagnostics, supporting various downstream tasks such as\nautomated blood cell counting, morphological analysis, cell classification, and\ndisease diagnosis and monitoring. Training robust and accurate models requires\nlarge amounts of labeled data, which is both time-consuming and expensive to\nacquire. In this work, we propose a novel approach for weakly supervised\nsegmentation using neural cellular automata (NCA-WSS). By leveraging the\nfeature maps generated by NCA during classification, we can extract\nsegmentation masks without the need for retraining with segmentation labels. We\nevaluate our method on three white blood cell microscopy datasets and\ndemonstrate that NCA-WSS significantly outperforms existing weakly supervised\napproaches. Our work illustrates the potential of NCA for both classification\nand segmentation in a weakly supervised framework, providing a scalable and\nefficient solution for medical image analysis.", "AI": {"tldr": "NCA-WSS uses neural cellular automata for weakly supervised white blood cell segmentation, eliminating need for segmentation labels by leveraging classification feature maps.", "motivation": "Medical diagnostics require accurate white blood cell detection and segmentation, but obtaining large labeled datasets is time-consuming and expensive.", "method": "Propose neural cellular automata for weakly supervised segmentation (NCA-WSS) that extracts segmentation masks from classification feature maps without retraining with segmentation labels.", "result": "Outperforms existing weakly supervised approaches on three white blood cell microscopy datasets.", "conclusion": "Demonstrates NCA's potential for both classification and segmentation in weakly supervised frameworks, providing scalable and efficient medical image analysis solution."}}
{"id": "2508.12769", "pdf": "https://arxiv.org/pdf/2508.12769", "abs": "https://arxiv.org/abs/2508.12769", "authors": ["Shaoming Duan", "Zirui Wang", "Chuanyi Liu", "Zhibin Zhu", "Yuhao Zhang", "Peiyi Han", "Liang Yan", "Zewu Penge"], "title": "CRED-SQL: Enhancing Real-world Large Scale Database Text-to-SQL Parsing through Cluster Retrieval and Execution Description", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have significantly improved\nthe accuracy of Text-to-SQL systems. However, a critical challenge remains: the\nsemantic mismatch between natural language questions (NLQs) and their\ncorresponding SQL queries. This issue is exacerbated in large-scale databases,\nwhere semantically similar attributes hinder schema linking and semantic drift\nduring SQL generation, ultimately reducing model accuracy. To address these\nchallenges, we introduce CRED-SQL, a framework designed for large-scale\ndatabases that integrates Cluster Retrieval and Execution Description. CRED-SQL\nfirst performs cluster-based large-scale schema retrieval to pinpoint the\ntables and columns most relevant to a given NLQ, alleviating schema mismatch.\nIt then introduces an intermediate natural language representation-Execution\nDescription Language (EDL)-to bridge the gap between NLQs and SQL. This\nreformulation decomposes the task into two stages: Text-to-EDL and EDL-to-SQL,\nleveraging LLMs' strong general reasoning capabilities while reducing semantic\ndeviation. Extensive experiments on two large-scale, cross-domain\nbenchmarks-SpiderUnion and BirdUnion-demonstrate that CRED-SQL achieves new\nstate-of-the-art (SOTA) performance, validating its effectiveness and\nscalability. Our code is available at https://github.com/smduan/CRED-SQL.git", "AI": {"tldr": "CRED-SQL is a framework that addresses semantic mismatch in Text-to-SQL systems for large databases using cluster-based schema retrieval and an intermediate Execution Description Language to improve accuracy.", "motivation": "Semantic mismatch between natural language questions and SQL queries in large databases causes schema linking issues and semantic drift, reducing model accuracy despite advances in LLMs.", "method": "CRED-SQL uses cluster-based large-scale schema retrieval to identify relevant tables/columns, then introduces Execution Description Language (EDL) as intermediate representation, decomposing the task into Text-to-EDL and EDL-to-SQL stages.", "result": "Achieves state-of-the-art performance on SpiderUnion and BirdUnion benchmarks, demonstrating effectiveness and scalability for large-scale cross-domain databases.", "conclusion": "The framework successfully bridges semantic gaps in Text-to-SQL systems through innovative retrieval and intermediate representation techniques, significantly improving accuracy for large database applications."}}
{"id": "2508.12531", "pdf": "https://arxiv.org/pdf/2508.12531", "abs": "https://arxiv.org/abs/2508.12531", "authors": ["Minseon Kim", "Jin Myung Kwak", "Lama Alssum", "Bernard Ghanem", "Philip Torr", "David Krueger", "Fazl Barez", "Adel Bibi"], "title": "Rethinking Safety in LLM Fine-tuning: An Optimization Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning language models is commonly believed to inevitably harm their\nsafety, i.e., refusing to respond to harmful user requests, even when using\nharmless datasets, thus requiring additional safety measures. We challenge this\nbelief through systematic testing, showing that poor optimization choices,\nrather than inherent trade-offs, often cause safety problems, measured as\nharmful responses to adversarial prompts. By properly selecting key training\nhyper-parameters, e.g., learning rate, batch size, and gradient steps, we\nreduce unsafe model responses from 16\\% to approximately 5\\%, as measured by\nkeyword matching, while maintaining utility performance. Based on this\nobservation, we propose a simple exponential moving average (EMA) momentum\ntechnique in parameter space that preserves safety performance by creating a\nstable optimization path and retains the original pre-trained model's safety\nproperties. Our experiments on the Llama families across multiple datasets\n(Dolly, Alpaca, ORCA) demonstrate that safety problems during fine-tuning can\nlargely be avoided without specialized interventions, outperforming existing\napproaches that require additional safety data while offering practical\nguidelines for maintaining both model performance and safety during adaptation.", "AI": {"tldr": "Fine-tuning language models doesn't inherently harm safety - poor optimization choices cause safety issues, not inherent trade-offs. Proper hyperparameter selection and EMA momentum technique can maintain safety while preserving utility.", "motivation": "Challenge the common belief that fine-tuning inevitably harms model safety, showing that optimization choices rather than inherent limitations cause safety degradation.", "method": "Systematic testing of hyperparameters (learning rate, batch size, gradient steps) and proposing exponential moving average (EMA) momentum technique to preserve safety properties during fine-tuning.", "result": "Reduced unsafe responses from 16% to ~5% while maintaining utility performance across Llama models on multiple datasets (Dolly, Alpaca, ORCA).", "conclusion": "Safety problems during fine-tuning can be largely avoided without specialized interventions, outperforming approaches requiring additional safety data while providing practical guidelines."}}
{"id": "2508.13121", "pdf": "https://arxiv.org/pdf/2508.13121", "abs": "https://arxiv.org/abs/2508.13121", "authors": ["Carlos Celemin"], "title": "Bayesian Optimization-based Search for Agent Control in Automated Game Testing", "categories": ["cs.AI"], "comment": null, "summary": "This work introduces an automated testing approach that employs agents\ncontrolling game characters to detect potential bugs within a game level.\nHarnessing the power of Bayesian Optimization (BO) to execute sample-efficient\nsearch, the method determines the next sampling point by analyzing the data\ncollected so far and calculates the data point that will maximize information\nacquisition. To support the BO process, we introduce a game testing-specific\nmodel built on top of a grid map, that features the smoothness and uncertainty\nestimation required by BO, however and most importantly, it does not suffer the\nscalability issues that traditional models carry. The experiments demonstrate\nthat the approach significantly improves map coverage capabilities in both time\nefficiency and exploration distribution.", "AI": {"tldr": "Automated game testing using Bayesian Optimization with agents to efficiently detect bugs through intelligent sampling and grid-based modeling", "motivation": "Traditional game testing methods suffer from scalability issues and inefficient exploration, needing a more systematic approach to detect bugs in game levels", "method": "Uses Bayesian Optimization with game character agents to perform sample-efficient search, employing a grid map-based model that provides smoothness and uncertainty estimation without scalability problems", "result": "Significantly improves map coverage capabilities in both time efficiency and exploration distribution compared to traditional approaches", "conclusion": "The proposed Bayesian Optimization approach with specialized grid modeling provides an effective and scalable solution for automated game testing and bug detection"}}
{"id": "2508.12324", "pdf": "https://arxiv.org/pdf/2508.12324", "abs": "https://arxiv.org/abs/2508.12324", "authors": ["Chen Yang", "Michael Deutges", "Jingsong Liu", "Han Li", "Nassir Navab", "Carsten Marr", "Ario Sadafi"], "title": "Attention Pooling Enhances NCA-based Classification of Microscopy Images", "categories": ["cs.CV"], "comment": null, "summary": "Neural Cellular Automata (NCA) offer a robust and interpretable approach to\nimage classification, making them a promising choice for microscopy image\nanalysis. However, a performance gap remains between NCA and larger, more\ncomplex architectures. We address this challenge by integrating attention\npooling with NCA to enhance feature extraction and improve classification\naccuracy. The attention pooling mechanism refines the focus on the most\ninformative regions, leading to more accurate predictions. We evaluate our\nmethod on eight diverse microscopy image datasets and demonstrate that our\napproach significantly outperforms existing NCA methods while remaining\nparameter-efficient and explainable. Furthermore, we compare our method with\ntraditional lightweight convolutional neural network and vision transformer\narchitectures, showing improved performance while maintaining a significantly\nlower parameter count. Our results highlight the potential of NCA-based models\nan alternative for explainable image classification.", "AI": {"tldr": "Integrating attention pooling with Neural Cellular Automata improves microscopy image classification accuracy while maintaining parameter efficiency and explainability.", "motivation": "Address the performance gap between Neural Cellular Automata and larger architectures for microscopy image analysis by enhancing feature extraction capabilities.", "method": "Integration of attention pooling mechanism with Neural Cellular Automata to refine focus on the most informative regions in microscopy images.", "result": "Significantly outperforms existing NCA methods on eight diverse microscopy datasets, shows improved performance compared to traditional lightweight CNNs and vision transformers while maintaining lower parameter count.", "conclusion": "Attention-enhanced NCA models demonstrate strong potential as explainable and parameter-efficient alternatives for image classification tasks."}}
{"id": "2508.12774", "pdf": "https://arxiv.org/pdf/2508.12774", "abs": "https://arxiv.org/abs/2508.12774", "authors": ["Javier Garcia Gilabert", "Xixian Liao", "Severino Da Dalt", "Ella Bohman", "Audrey Mash", "Francesca De Luca Fornaciari", "Irene Baucells", "Joan Llop", "Miguel Claramunt Argote", "Carlos Escolano", "Maite Melero"], "title": "From SALAMANDRA to SALAMANDRATA: BSC Submission for WMT25 General Machine Translation Shared Task", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we present the SALAMANDRATA family of models, an improved\niteration of SALAMANDRA LLMs (Gonzalez-Agirre et al., 2025) specifically\ntrained to achieve strong performance in translation-related tasks for 38\nEuropean languages. SALAMANDRATA comes in two scales: 2B and 7B parameters. For\nboth versions, we applied the same training recipe with a first step of\ncontinual pre-training on parallel data, and a second step of supervised\nfine-tuning on high-quality instructions. The BSC submission to the WMT25\nGeneral Machine Translation shared task is based on the 7B variant of\nSALAMANDRATA. We first adapted the model vocabulary to support the additional\nnon-European languages included in the task. This was followed by a second\nphase of continual pre-training and supervised fine-tuning, carefully designed\nto optimize performance across all translation directions for this year's\nshared task. For decoding, we employed two quality-aware strategies: Minimum\nBayes Risk Decoding and Tuned Re-ranking using COMET and COMET-KIWI\nrespectively. We publicly release both the 2B and 7B versions of SALAMANDRATA,\nalong with the newer SALAMANDRATA-V2 model, on Hugging Face1", "AI": {"tldr": "SALAMANDRATA models (2B and 7B parameters) for 38 European language translation, with WMT25 adaptation using quality-aware decoding strategies.", "motivation": "To improve machine translation performance for European languages and adapt models for the WMT25 shared task with additional non-European languages.", "method": "Two-step training: continual pre-training on parallel data followed by supervised fine-tuning on high-quality instructions. Vocabulary adaptation, additional training phases, and quality-aware decoding (Minimum Bayes Risk Decoding and Tuned Re-ranking with COMET/COMET-KIWI).", "result": "Developed SALAMANDRATA family models (2B and 7B) specifically optimized for translation tasks, with BSC's WMT25 submission based on the 7B variant.", "conclusion": "Successfully created improved translation models for European languages, adapted for broader WMT25 requirements, and publicly released the models on Hugging Face."}}
{"id": "2508.12533", "pdf": "https://arxiv.org/pdf/2508.12533", "abs": "https://arxiv.org/abs/2508.12533", "authors": ["Qinwen Ge", "Roza G. Bayrak", "Anwar Said", "Catie Chang", "Xenofon Koutsoukos", "Tyler Derr"], "title": "Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "comment": null, "summary": "The construction of brain graphs from functional Magnetic Resonance Imaging\n(fMRI) data plays a crucial role in enabling graph machine learning for\nneuroimaging. However, current practices often rely on rigid pipelines that\noverlook critical data-centric choices in how brain graphs are constructed. In\nthis work, we adopt a Data-Centric AI perspective and systematically define and\nbenchmark a data-centric design space for brain graph construction,\nconstrasting with primarily model-centric prior work. We organize this design\nspace into three stages: temporal signal processing, topology extraction, and\ngraph featurization. Our contributions lie less in novel components and more in\nevaluating how combinations of existing and modified techniques influence\ndownstream performance. Specifically, we study high-amplitude BOLD signal\nfiltering, sparsification and unification strategies for connectivity,\nalternative correlation metrics, and multi-view node and edge features, such as\nincorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets\nshow that thoughtful data-centric configurations consistently improve\nclassification accuracy over standard pipelines. These findings highlight the\ncritical role of upstream data decisions and underscore the importance of\nsystematically exploring the data-centric design space for graph-based\nneuroimaging. Our code is available at\nhttps://github.com/GeQinwen/DataCentricBrainGraphs.", "AI": {"tldr": "Systematic benchmarking of data-centric design choices in brain graph construction from fMRI data shows that thoughtful configurations outperform standard pipelines in classification tasks.", "motivation": "Current brain graph construction practices rely on rigid pipelines that overlook critical data-centric choices, limiting the potential of graph machine learning in neuroimaging.", "method": "Organized a data-centric design space into three stages: temporal signal processing, topology extraction, and graph featurization. Evaluated combinations of existing techniques including BOLD signal filtering, sparsification strategies, alternative correlation metrics, and multi-view node/edge features.", "result": "Experiments on HCP1200 and ABIDE datasets showed that data-centric configurations consistently improve classification accuracy over standard pipelines.", "conclusion": "Upstream data decisions play a critical role in graph-based neuroimaging, highlighting the importance of systematically exploring the data-centric design space rather than focusing primarily on model-centric approaches."}}
{"id": "2508.13143", "pdf": "https://arxiv.org/pdf/2508.13143", "abs": "https://arxiv.org/abs/2508.13143", "authors": ["Ruofan Lu", "Yichen Li", "Yintong Huo"], "title": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks", "categories": ["cs.AI", "cs.SE"], "comment": "Accepted by ASE 2025 NIER", "summary": "Autonomous agent systems powered by Large Language Models (LLMs) have\ndemonstrated promising capabilities in automating complex tasks. However,\ncurrent evaluations largely rely on success rates without systematically\nanalyzing the interactions, communication mechanisms, and failure causes within\nthese systems. To bridge this gap, we present a benchmark of 34 representative\nprogrammable tasks designed to rigorously assess autonomous agents. Using this\nbenchmark, we evaluate three popular open-source agent frameworks combined with\ntwo LLM backbones, observing a task completion rate of approximately 50%.\nThrough in-depth failure analysis, we develop a three-tier taxonomy of failure\ncauses aligned with task phases, highlighting planning errors, task execution\nissues, and incorrect response generation. Based on these insights, we propose\nactionable improvements to enhance agent planning and self-diagnosis\ncapabilities. Our failure taxonomy, together with mitigation advice, provides\nan empirical foundation for developing more robust and effective autonomous\nagent systems in the future.", "AI": {"tldr": "A benchmark study evaluating autonomous LLM agents reveals ~50% task completion rate, identifies failure causes through a three-tier taxonomy, and proposes improvements for planning and self-diagnosis capabilities.", "motivation": "Current evaluations of autonomous agent systems focus primarily on success rates without systematic analysis of interactions, communication mechanisms, and failure causes, creating a gap in understanding agent performance limitations.", "method": "Developed a benchmark of 34 representative programmable tasks to rigorously assess autonomous agents, evaluated three popular open-source agent frameworks with two LLM backbones, and conducted in-depth failure analysis to create a three-tier taxonomy of failure causes.", "result": "Observed approximately 50% task completion rate across evaluated systems, identified planning errors, task execution issues, and incorrect response generation as main failure categories aligned with task phases.", "conclusion": "The failure taxonomy and mitigation advice provide an empirical foundation for developing more robust autonomous agent systems, with actionable improvements proposed for enhancing agent planning and self-diagnosis capabilities."}}
{"id": "2508.12330", "pdf": "https://arxiv.org/pdf/2508.12330", "abs": "https://arxiv.org/abs/2508.12330", "authors": ["Yuval Haitman", "Oded Bialer"], "title": "DoppDrive: Doppler-Driven Temporal Aggregation for Improved Radar Object Detection", "categories": ["cs.CV"], "comment": "ICCV 2025", "summary": "Radar-based object detection is essential for autonomous driving due to\nradar's long detection range. However, the sparsity of radar point clouds,\nespecially at long range, poses challenges for accurate detection. Existing\nmethods increase point density through temporal aggregation with ego-motion\ncompensation, but this approach introduces scatter from dynamic objects,\ndegrading detection performance. We propose DoppDrive, a novel Doppler-Driven\ntemporal aggregation method that enhances radar point cloud density while\nminimizing scatter. Points from previous frames are shifted radially according\nto their dynamic Doppler component to eliminate radial scatter, with each point\nassigned a unique aggregation duration based on its Doppler and angle to\nminimize tangential scatter. DoppDrive is a point cloud density enhancement\nstep applied before detection, compatible with any detector, and we demonstrate\nthat it significantly improves object detection performance across various\ndetectors and datasets.", "AI": {"tldr": "DoppDrive is a Doppler-driven temporal aggregation method that enhances radar point cloud density by eliminating scatter from dynamic objects through radial shifting and adaptive aggregation duration, improving object detection performance.", "motivation": "Radar's long detection range is essential for autonomous driving, but sparse point clouds at long range and scatter from temporal aggregation with ego-motion compensation degrade detection accuracy.", "method": "Points from previous frames are shifted radially based on their dynamic Doppler component to eliminate radial scatter, with each point assigned a unique aggregation duration based on Doppler and angle to minimize tangential scatter.", "result": "DoppDrive significantly improves object detection performance across various detectors and datasets by enhancing point cloud density while minimizing scatter.", "conclusion": "DoppDrive provides an effective pre-detection point cloud enhancement step that is compatible with any radar detector and addresses key challenges in radar-based object detection for autonomous driving."}}
{"id": "2508.12778", "pdf": "https://arxiv.org/pdf/2508.12778", "abs": "https://arxiv.org/abs/2508.12778", "authors": ["Zhe Chen", "Yusheng Liao", "Shuyang Jiang", "Zhiyuan Zhu", "Haolin Li", "Yanfeng Wang", "Yu Wang"], "title": "HeteroRAG: A Heterogeneous Retrieval-Augmented Generation Framework for Medical Vision Language Tasks", "categories": ["cs.CL"], "comment": null, "summary": "Medical large vision-language Models (Med-LVLMs) have shown promise in\nclinical applications but suffer from factual inaccuracies and unreliable\noutputs, posing risks in real-world diagnostics. While retrieval-augmented\ngeneration has emerged as a potential solution, current medical multimodal RAG\nsystems are unable to perform effective retrieval across heterogeneous sources.\nThe irrelevance of retrieved reports affects the factuality of analysis, while\ninsufficient knowledge affects the credibility of clinical decision-making. To\nbridge the gap, we construct MedAtlas, which includes extensive multimodal\nreport repositories and diverse text corpora. Based on it, we present\nHeteroRAG, a novel framework that enhances Med-LVLMs through heterogeneous\nknowledge sources. The framework introduces Modality-specific CLIPs for\neffective report retrieval and a Multi-corpora Query Generator for dynamically\nconstructing queries for diverse corpora. Incorporating knowledge from such\nmultifaceted sources, Med-LVLM is then trained with Heterogeneous Knowledge\nPreference Tuning to achieve cross-modality and multi-source knowledge\nalignment. Extensive experiments across 12 datasets and 3 modalities\ndemonstrate that the proposed HeteroRAG achieves state-of-the-art performance\nin most medical vision language benchmarks, significantly improving factual\naccuracy and reliability of Med-LVLMs.", "AI": {"tldr": "MedAtlas framework with HeteroRAG improves medical vision-language models by enabling effective retrieval across heterogeneous medical sources, significantly enhancing factual accuracy and reliability.", "motivation": "Medical LVLMs suffer from factual inaccuracies and unreliable outputs that pose risks in clinical diagnostics, while current multimodal RAG systems cannot effectively retrieve from heterogeneous medical sources.", "method": "Construct MedAtlas with multimodal report repositories and text corpora, then develop HeteroRAG framework with Modality-specific CLIPs for report retrieval, Multi-corpora Query Generator for dynamic queries, and Heterogeneous Knowledge Preference Tuning for cross-modality alignment.", "result": "State-of-the-art performance across 12 datasets and 3 modalities in medical vision language benchmarks, with significant improvements in factual accuracy and reliability of Med-LVLMs.", "conclusion": "HeteroRAG framework successfully bridges the gap in medical multimodal RAG by enabling effective heterogeneous knowledge retrieval, making Med-LVLMs more accurate and reliable for clinical applications."}}
{"id": "2508.12551", "pdf": "https://arxiv.org/pdf/2508.12551", "abs": "https://arxiv.org/abs/2508.12551", "authors": ["Hongyu Lin", "Yuchen Li", "Haoran Luo", "Kaichun Yao", "Libo Zhang", "Mingjie Xing", "Yanjun Wu"], "title": "OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.OS", "cs.SE"], "comment": null, "summary": "Linux kernel tuning is essential for optimizing operating system (OS)\nperformance. However, existing methods often face challenges in terms of\nefficiency, scalability, and generalization. This paper introduces OS-R1, an\nagentic Linux kernel tuning framework powered by rule-based reinforcement\nlearning (RL). By abstracting the kernel configuration space as an RL\nenvironment, OS-R1 facilitates efficient exploration by large language models\n(LLMs) and ensures accurate configuration modifications. Additionally, custom\nreward functions are designed to enhance reasoning standardization,\nconfiguration modification accuracy, and system performance awareness of the\nLLMs. Furthermore, we propose a two-phase training process that accelerates\nconvergence and minimizes retraining across diverse tuning scenarios.\nExperimental results show that OS-R1 significantly outperforms existing\nbaseline methods, achieving up to 5.6% performance improvement over heuristic\ntuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across\nvarious real-world applications, demonstrating its potential for practical\ndeployment in diverse environments. Our dataset and code are publicly available\nat https://github.com/LHY-24/OS-R1.", "AI": {"tldr": "OS-R1 is a rule-based reinforcement learning framework for Linux kernel tuning that uses LLMs to efficiently explore configuration spaces, achieving up to 5.6% performance improvement over heuristic methods with high data efficiency.", "motivation": "Existing Linux kernel tuning methods face challenges in efficiency, scalability, and generalization, requiring a more effective automated approach.", "method": "Uses rule-based reinforcement learning to abstract kernel configuration as RL environment, employs LLMs for exploration, custom reward functions for standardization, and a two-phase training process for faster convergence.", "result": "Achieves up to 5.6% performance improvement over heuristic tuning methods while maintaining high data efficiency and adaptability across diverse real-world applications.", "conclusion": "OS-R1 demonstrates significant practical potential for automated Linux kernel optimization and is publicly available for deployment in various environments."}}
{"id": "2508.11640", "pdf": "https://arxiv.org/pdf/2508.11640", "abs": "https://arxiv.org/abs/2508.11640", "authors": ["Danny Scott", "William LaForest", "Hritom Das", "Ioannis Polykretis", "Catherine D. Schuman", "Charles Rizzo", "James Plank", "Sai Swaminathan"], "title": "Vibe2Spike: Batteryless Wireless Tags for Vibration Sensing with Event Cameras and Spiking Networks", "categories": ["eess.SP", "cs.AI", "cs.HC", "cs.LG"], "comment": "International Conference on Neuromorphic Systems (ICONS) 2025 9\n  pages, 7 images", "summary": "The deployment of dense, low-cost sensors is critical for realizing\nubiquitous smart environments. However, existing sensing solutions struggle\nwith the energy, scalability, and reliability trade-offs imposed by battery\nmaintenance, wireless transmission overhead, and data processing complexity. In\nthis work, we present Vibe2Spike, a novel battery-free, wireless sensing\nframework that enables vibration-based activity recognition using visible light\ncommunication (VLC) and spiking neural networks (SNNs). Our system uses\nultra-low-cost tags composed only of a piezoelectric disc, a Zener diode, and\nan LED, which harvest vibration energy and emit sparse visible light spikes\nwithout requiring batteries or RF radios. These optical spikes are captured by\nevent cameras and classified using optimized SNN models evolved via the EONS\nframework. We evaluate Vibe2Spike across five device classes, achieving 94.9\\%\naverage classification fitness while analyzing the latency-accuracy trade-offs\nof different temporal binning strategies. Vibe2Spike demonstrates a scalable,\nand energy-efficient approach for enabling intelligent environments in a\nbatteryless manner.", "AI": {"tldr": "Vibe2Spike is a battery-free wireless sensing framework that uses vibration energy harvesting, visible light communication, and spiking neural networks for activity recognition without batteries or RF radios.", "motivation": "Existing sensing solutions face energy, scalability, and reliability trade-offs due to battery maintenance, wireless transmission overhead, and data processing complexity. There's a need for dense, low-cost sensors for ubiquitous smart environments.", "method": "The system uses ultra-low-cost tags with piezoelectric disc, Zener diode, and LED to harvest vibration energy and emit visible light spikes. Optical spikes are captured by event cameras and classified using spiking neural networks optimized via the EONS framework.", "result": "Achieved 94.9% average classification fitness across five device classes, with analysis of latency-accuracy trade-offs for different temporal binning strategies.", "conclusion": "Vibe2Spike demonstrates a scalable and energy-efficient approach for enabling intelligent environments in a batteryless manner, overcoming traditional sensing limitations."}}
{"id": "2508.12336", "pdf": "https://arxiv.org/pdf/2508.12336", "abs": "https://arxiv.org/abs/2508.12336", "authors": ["Fatemeh Ghorbani Lohesara", "Karen Eguiazarian", "Sebastian Knorr"], "title": "Geometry-Aware Video Inpainting for Joint Headset Occlusion Removal and Face Reconstruction in Social XR", "categories": ["cs.CV"], "comment": null, "summary": "Head-mounted displays (HMDs) are essential for experiencing extended reality\n(XR) environments and observing virtual content. However, they obscure the\nupper part of the user's face, complicating external video recording and\nsignificantly impacting social XR applications such as teleconferencing, where\nfacial expressions and eye gaze details are crucial for creating an immersive\nexperience. This study introduces a geometry-aware learning-based framework to\njointly remove HMD occlusions and reconstruct complete 3D facial geometry from\nRGB frames captured from a single viewpoint. The method integrates a GAN-based\nvideo inpainting network, guided by dense facial landmarks and a single\nocclusion-free reference frame, to restore missing facial regions while\npreserving identity. Subsequently, a SynergyNet-based module regresses 3D\nMorphable Model (3DMM) parameters from the inpainted frames, enabling accurate\n3D face reconstruction. Dense landmark optimization is incorporated throughout\nthe pipeline to improve both the inpainting quality and the fidelity of the\nrecovered geometry. Experimental results demonstrate that the proposed\nframework can successfully remove HMDs from RGB facial videos while maintaining\nfacial identity and realism, producing photorealistic 3D face geometry outputs.\nAblation studies further show that the framework remains robust across\ndifferent landmark densities, with only minor quality degradation under sparse\nlandmark configurations.", "AI": {"tldr": "A learning-based framework that removes HMD occlusions from facial videos and reconstructs complete 3D facial geometry using GAN-based inpainting and 3DMM parameter regression.", "motivation": "HMDs obscure the upper face, hindering social XR applications like teleconferencing where facial expressions and eye gaze are crucial for immersion.", "method": "Combines GAN-based video inpainting guided by dense landmarks and reference frames with SynergyNet-based 3DMM parameter regression for 3D face reconstruction.", "result": "Successfully removes HMDs while preserving facial identity and realism, producing photorealistic 3D face geometry outputs that remain robust across different landmark densities.", "conclusion": "The framework effectively addresses HMD occlusion issues in XR applications, enabling better facial expression capture and social interaction experiences."}}
{"id": "2508.12800", "pdf": "https://arxiv.org/pdf/2508.12800", "abs": "https://arxiv.org/abs/2508.12800", "authors": ["Yong Deng", "Guoqing Wang", "Zhenzhe Ying", "Xiaofeng Wu", "Jinzhen Lin", "Wenwen Xiong", "Yuqin Dai", "Shuo Yang", "Zhanwei Zhang", "Qiwen Wang", "Yang Qin", "Changhua Meng"], "title": "Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) exhibit remarkable problem-solving abilities,\nbut struggle with complex tasks due to static internal knowledge.\nRetrieval-Augmented Generation (RAG) enhances access to external information,\nyet remains limited in multi-hop reasoning and strategic search due to rigid\nworkflows. Recent advancements in agentic deep research empower LLMs to\nautonomously reason, search, and synthesize information. However, current\napproaches relying on outcome-based reinforcement learning (RL) face critical\nissues such as conflicting gradients and reward sparsity, limiting performance\ngains and training efficiency. To address these, we first propose Atomic\nThought, a novel LLM thinking paradigm that decomposes reasoning into\nfine-grained functional units. These units are supervised by Reasoning Reward\nModels (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained\nguidance. Building on this, we propose Atom-Searcher, a novel RL framework for\nagentic deep research that integrates Atomic Thought and ATR. Atom-Searcher\nuses a curriculum-inspired reward schedule, prioritizing process-level ATR\nearly and transitioning to outcome rewards, accelerating convergence on\neffective reasoning paths. Experiments on seven benchmarks show consistent\nimprovements over the state-of-the-art. Key advantages include: (1)\nAtom-Searcher scales computation at test-time. (2) Atomic Thought provides\nsupervision anchors for RRMs, bridging deep research tasks and RRMs. (3)\nAtom-Searcher exhibits more interpretable, human-like reasoning patterns.", "AI": {"tldr": "Atom-Searcher is a novel RL framework that decomposes LLM reasoning into fine-grained Atomic Thought units supervised by Reasoning Reward Models, addressing issues with traditional outcome-based RL in agentic deep research tasks.", "motivation": "Current LLMs struggle with complex tasks due to static knowledge, and RAG approaches have limitations in multi-hop reasoning. Agentic approaches using outcome-based RL face issues like conflicting gradients and reward sparsity.", "method": "Proposes Atomic Thought paradigm that decomposes reasoning into fine-grained functional units supervised by RRMs with Atomic Thought Rewards. Atom-Searcher integrates this with a curriculum-inspired reward schedule that prioritizes process-level rewards early and transitions to outcome rewards.", "result": "Experiments on seven benchmarks show consistent improvements over state-of-the-art methods. The approach scales computation at test-time, provides better supervision anchors, and exhibits more interpretable, human-like reasoning patterns.", "conclusion": "Atom-Searcher effectively addresses limitations of traditional RL approaches in agentic deep research by leveraging fine-grained reasoning decomposition and curriculum-based reward scheduling, leading to superior performance and more interpretable reasoning."}}
{"id": "2508.12555", "pdf": "https://arxiv.org/pdf/2508.12555", "abs": "https://arxiv.org/abs/2508.12555", "authors": ["Junpeng Wang", "Yuzhong Chen", "Menghai Pan", "Chin-Chia Michael Yeh", "Mahashweta Das"], "title": "Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement", "categories": ["cs.LG"], "comment": "11 pages, 10 figures", "summary": "Coding agents powered by large language models (LLMs) have gained traction\nfor automating code generation through iterative problem-solving with minimal\nhuman involvement. Despite the emergence of various frameworks, e.g.,\nLangChain, AutoML, and AIDE, ML scientists still struggle to effectively review\nand adjust the agents' coding process. The current approach of manually\ninspecting individual outputs is inefficient, making it difficult to track code\nevolution, compare coding iterations, and identify improvement opportunities.\nTo address this challenge, we introduce a visual analytics system designed to\nenhance the examination of coding agent behaviors. Focusing on the AIDE\nframework, our system supports comparative analysis across three levels: (1)\nCode-Level Analysis, which reveals how the agent debugs and refines its code\nover iterations; (2) Process-Level Analysis, which contrasts different\nsolution-seeking processes explored by the agent; and (3) LLM-Level Analysis,\nwhich highlights variations in coding behavior across different LLMs. By\nintegrating these perspectives, our system enables ML scientists to gain a\nstructured understanding of agent behaviors, facilitating more effective\ndebugging and prompt engineering. Through case studies using coding agents to\ntackle popular Kaggle competitions, we demonstrate how our system provides\nvaluable insights into the iterative coding process.", "AI": {"tldr": "A visual analytics system for examining coding agent behaviors across code-level, process-level, and LLM-level analysis to help ML scientists debug and improve AI coding agents.", "motivation": "Current manual inspection of LLM-powered coding agents is inefficient, making it difficult to track code evolution, compare iterations, and identify improvement opportunities in frameworks like AIDE.", "method": "Developed a visual analytics system that supports comparative analysis at three levels: code-level (debugging and refinement), process-level (solution-seeking processes), and LLM-level (behavior variations across different LLMs).", "result": "The system enables structured understanding of agent behaviors, facilitating effective debugging and prompt engineering, as demonstrated through case studies using Kaggle competitions.", "conclusion": "The visual analytics system provides valuable insights into iterative coding processes, helping ML scientists better review and adjust coding agents' behaviors across multiple analytical dimensions."}}
{"id": "2508.11647", "pdf": "https://arxiv.org/pdf/2508.11647", "abs": "https://arxiv.org/abs/2508.11647", "authors": ["Logan Nye"], "title": "Categorical Construction of Logically Verifiable Neural Architectures", "categories": ["cs.LO", "cs.AI"], "comment": null, "summary": "Neural networks excel at pattern recognition but struggle with reliable\nlogical reasoning, often violating basic logical principles during inference.\nWe address this limitation by developing a categorical framework that\nsystematically constructs neural architectures with provable logical\nguarantees. Our approach treats logical theories as algebraic structures called\nLawvere theories, which we transform into neural networks using categorical\nalgebra in the 2-category of parametric maps. Unlike existing methods that\nimpose logical constraints during training, our categorical construction embeds\nlogical principles directly into the network's architectural structure, making\nlogical violations mathematically impossible. We demonstrate this framework by\nconstructing differentiable neural architectures for propositional logic that\npreserve boolean reasoning while remaining trainable via gradient descent. Our\nmain theoretical result establishes a bijective correspondence between finitary\nlogical theories and neural architectures, proving that every logically\nconstrained network arises uniquely from our construction. This extends\nCategorical Deep Learning beyond geometric symmetries to semantic constraints,\nenabling automatic derivation of verified architectures from logical\nspecifications. The framework provides mathematical foundations for trustworthy\nAI systems, with applications to theorem proving, formal verification, and\nsafety-critical reasoning tasks requiring verifiable logical behavior.", "AI": {"tldr": "A categorical framework that constructs neural networks with provable logical guarantees by embedding logical principles directly into network architecture using Lawvere theories and categorical algebra.", "motivation": "Neural networks struggle with reliable logical reasoning and often violate basic logical principles during inference, limiting their trustworthiness in safety-critical applications.", "method": "Treats logical theories as Lawvere theories and transforms them into neural networks using categorical algebra in the 2-category of parametric maps, embedding logical constraints directly into architectural structure.", "result": "Demonstrated differentiable neural architectures for propositional logic that preserve boolean reasoning while remaining trainable via gradient descent, with a bijective correspondence between logical theories and neural architectures.", "conclusion": "The framework extends Categorical Deep Learning to semantic constraints, enabling automatic derivation of verified architectures from logical specifications for trustworthy AI systems in theorem proving and safety-critical reasoning."}}
{"id": "2508.12341", "pdf": "https://arxiv.org/pdf/2508.12341", "abs": "https://arxiv.org/abs/2508.12341", "authors": ["Ziye Wang", "Minghang Yu", "Chunyan Xu", "Zhen Cui"], "title": "Semantic Discrepancy-aware Detector for Image Forgery Identification", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 5 figures", "summary": "With the rapid advancement of image generation techniques, robust forgery\ndetection has become increasingly imperative to ensure the trustworthiness of\ndigital media. Recent research indicates that the learned semantic concepts of\npre-trained models are critical for identifying fake images. However, the\nmisalignment between the forgery and semantic concept spaces hinders the\nmodel's forgery detection performance. To address this problem, we propose a\nnovel Semantic Discrepancy-aware Detector (SDD) that leverages reconstruction\nlearning to align the two spaces at a fine-grained visual level. By exploiting\nthe conceptual knowledge embedded in the pre-trained vision language model, we\nspecifically design a semantic token sampling module to mitigate the space\nshifts caused by features irrelevant to both forgery traces and semantic\nconcepts. A concept-level forgery discrepancy learning module, built upon a\nvisual reconstruction paradigm, is proposed to strengthen the interaction\nbetween visual semantic concepts and forgery traces, effectively capturing\ndiscrepancies under the concepts' guidance. Finally, the low-level forgery\nfeature enhancemer integrates the learned concept level forgery discrepancies\nto minimize redundant forgery information. Experiments conducted on two\nstandard image forgery datasets demonstrate the efficacy of the proposed SDD,\nwhich achieves superior results compared to existing methods. The code is\navailable at https://github.com/wzy1111111/SSD.", "AI": {"tldr": "A novel forgery detection method called Semantic Discrepancy-aware Detector (SDD) that uses reconstruction learning to align forgery and semantic concept spaces, achieving superior performance on standard datasets.", "motivation": "The misalignment between forgery and semantic concept spaces hinders detection performance. Pre-trained models' semantic concepts are critical for fake image identification but current methods struggle with space shifts caused by irrelevant features.", "method": "SDD uses semantic token sampling to mitigate space shifts, concept-level forgery discrepancy learning through visual reconstruction to capture discrepancies under semantic guidance, and low-level forgery feature enhancement to minimize redundant information.", "result": "Experiments on two standard image forgery datasets demonstrate SDD's efficacy, achieving superior results compared to existing methods.", "conclusion": "The proposed SDD effectively addresses the space misalignment problem in forgery detection by leveraging semantic concepts and reconstruction learning, providing a robust solution for digital media trustworthiness."}}
{"id": "2508.12803", "pdf": "https://arxiv.org/pdf/2508.12803", "abs": "https://arxiv.org/abs/2508.12803", "authors": ["Ahmed Elshabrawy", "Hour Kaing", "Haiyue Song", "Alham Fikri Aji", "Hideki Tanaka", "Masao Utiyama", "Raj Dabre"], "title": "When Alignment Hurts: Decoupling Representational Spaces in Multilingual Models", "categories": ["cs.CL"], "comment": null, "summary": "Alignment with high-resource standard languages is often assumed to aid the\nmodeling of related low-resource varieties. We challenge this assumption by\ndemonstrating that excessive representational entanglement with a dominant\nvariety, such as Modern Standard Arabic (MSA) in relation to Arabic dialects,\ncan actively hinder generative modeling. We present the first comprehensive\ncausal study of this phenomenon by analyzing and directly intervening in the\ninternal representation geometry of large language models (LLMs). Our key\ncontribution is an online variational probing framework that continuously\nestimates the subspace of the standard variety during fine-tuning, enabling\nprojection-based decoupling from this space. While our study uses Arabic as a\ncase due to its unusually rich parallel resources across 25 dialects, the\nbroader motivation is methodological: dialectal MT serves as a controlled proxy\nfor generative tasks where comparable multi-variety corpora are unavailable.\nAcross 25 dialects, our intervention improves generation quality by up to +4.9\nchrF++ and +2.0 on average compared to standard fine-tuning, despite a measured\ntradeoff in standard-language performance. These results provide causal\nevidence that subspace dominance by high-resource varieties can restrict\ngenerative capacity for related varieties. More generally, we unify geometric\nand information-theoretic probing with subspace-level causal interventions,\noffering practical tools for improving generative modeling in closely related\nlanguage families and, more broadly, for controlling representational\nallocation in multilingual and multi-domain LLMs. Code will be released.", "AI": {"tldr": "Excessive alignment with high-resource languages like Modern Standard Arabic can hinder generative modeling of related low-resource dialects. A new variational probing framework enables subspace decoupling, improving dialect generation by +4.9 chrF++ maximum and +2.0 average across 25 Arabic dialects.", "motivation": "Challenge the assumption that alignment with high-resource standard languages always aids modeling of related low-resource varieties, and demonstrate that representational entanglement can actively hinder generative performance for dialects.", "method": "Online variational probing framework that continuously estimates the standard variety subspace during fine-tuning, enabling projection-based decoupling. Uses Arabic as case study with 25 dialects and parallel resources for controlled analysis.", "result": "Intervention improves generation quality by up to +4.9 chrF++ and +2.0 on average across 25 dialects compared to standard fine-tuning, despite tradeoff in standard-language performance. Provides causal evidence of subspace dominance effects.", "conclusion": "Subspace dominance by high-resource varieties restricts generative capacity for related varieties. The framework unifies geometric and information-theoretic probing with subspace-level causal interventions, offering practical tools for controlling representational allocation in multilingual LLMs."}}
{"id": "2508.12565", "pdf": "https://arxiv.org/pdf/2508.12565", "abs": "https://arxiv.org/abs/2508.12565", "authors": ["Luke Li"], "title": "Deep Learning-Based Financial Time Series Forecasting via Sliding Window and Variational Mode Decomposition", "categories": ["cs.LG"], "comment": null, "summary": "To address the complexity of financial time series, this paper proposes a\nforecasting model combining sliding window and variational mode decomposition\n(VMD) methods. Historical stock prices and relevant market indicators are used\nto construct datasets. VMD decomposes non-stationary financial time series into\nsmoother subcomponents, improving model adaptability. The decomposed data is\nthen input into a deep learning model for prediction. The study compares the\nforecasting effects of an LSTM model trained on VMD-processed sequences with\nthose using raw time series, demonstrating better performance and stability.", "AI": {"tldr": "Proposes VMD-LSTM model combining variational mode decomposition with deep learning for financial time series forecasting, showing improved performance over raw data approaches.", "motivation": "To address the complexity and non-stationarity of financial time series data which makes accurate forecasting challenging.", "method": "Uses variational mode decomposition (VMD) to decompose non-stationary financial time series into smoother subcomponents, then feeds the decomposed data into an LSTM deep learning model for prediction.", "result": "The VMD-processed LSTM model demonstrates better forecasting performance and stability compared to models using raw time series data.", "conclusion": "Combining VMD decomposition with deep learning models effectively improves financial time series forecasting accuracy and robustness."}}
{"id": "2508.11659", "pdf": "https://arxiv.org/pdf/2508.11659", "abs": "https://arxiv.org/abs/2508.11659", "authors": ["Zhuo Liu", "Tao Chen"], "title": "Toward Practical Equilibrium Propagation: Brain-inspired Recurrent Neural Network with Feedback Regulation and Residual Connections", "categories": ["cs.NE", "cs.AI", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Brain-like intelligent systems need brain-like learning methods. Equilibrium\nPropagation (EP) is a biologically plausible learning framework with strong\npotential for brain-inspired computing hardware. However, existing\nim-plementations of EP suffer from instability and prohibi-tively high\ncomputational costs. Inspired by the structure and dynamics of the brain, we\npropose a biologically plau-sible Feedback-regulated REsidual recurrent neural\nnetwork (FRE-RNN) and study its learning performance in EP framework. Feedback\nregulation enables rapid convergence by reducing the spectral radius. The\nimprovement in con-vergence property reduces the computational cost and\ntrain-ing time of EP by orders of magnitude, delivering perfor-mance on par\nwith backpropagation (BP) in benchmark tasks. Meanwhile, residual connections\nwith brain-inspired topologies help alleviate the vanishing gradient problem\nthat arises when feedback pathways are weak in deep RNNs. Our approach\nsubstantially enhances the applicabil-ity and practicality of EP in large-scale\nnetworks that un-derpin artificial intelligence. The techniques developed here\nalso offer guidance to implementing in-situ learning in physical neural\nnetworks.", "AI": {"tldr": "A biologically plausible Feedback-regulated REsidual RNN (FRE-RNN) that dramatically improves Equilibrium Propagation by reducing computational costs and training time while achieving backpropagation-level performance.", "motivation": "Existing Equilibrium Propagation implementations suffer from instability and prohibitively high computational costs, limiting their practical application in brain-inspired computing hardware.", "method": "Proposed FRE-RNN with feedback regulation to reduce spectral radius for rapid convergence, and residual connections with brain-inspired topologies to alleviate vanishing gradient problems in deep RNNs.", "result": "Achieves orders of magnitude reduction in computational cost and training time while delivering performance on par with backpropagation in benchmark tasks.", "conclusion": "Substantially enhances applicability and practicality of EP in large-scale networks and provides guidance for implementing in-situ learning in physical neural networks."}}
{"id": "2508.12343", "pdf": "https://arxiv.org/pdf/2508.12343", "abs": "https://arxiv.org/abs/2508.12343", "authors": ["Emanuel C. Silva", "Tatiana T. Schein", "Stephanie L. Bri\u00e3o", "Guilherme L. M. Costa", "Felipe G. Oliveira", "Gustavo P. Almeida", "Eduardo L. Silva", "Sam S. Devincenzi", "Karina S. Machado", "Paulo L. J. Drews-Jr"], "title": "AquaFeat: A Features-Based Image Enhancement Model for Underwater Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "The severe image degradation in underwater environments impairs object\ndetection models, as traditional image enhancement methods are often not\noptimized for such downstream tasks. To address this, we propose AquaFeat, a\nnovel, plug-and-play module that performs task-driven feature enhancement. Our\napproach integrates a multi-scale feature enhancement network trained\nend-to-end with the detector's loss function, ensuring the enhancement process\nis explicitly guided to refine features most relevant to the detection task.\nWhen integrated with YOLOv8m on challenging underwater datasets, AquaFeat\nachieves state-of-the-art Precision (0.877) and Recall (0.624), along with\ncompetitive mAP scores (mAP@0.5 of 0.677 and mAP@[0.5:0.95] of 0.421). By\ndelivering these accuracy gains while maintaining a practical processing speed\nof 46.5 FPS, our model provides an effective and computationally efficient\nsolution for real-world applications, such as marine ecosystem monitoring and\ninfrastructure inspection.", "AI": {"tldr": "AquaFeat is a plug-and-play feature enhancement module that improves underwater object detection by optimizing enhancement specifically for detection tasks rather than general image quality.", "motivation": "Underwater image degradation severely impacts object detection performance, and traditional image enhancement methods are not optimized for downstream detection tasks.", "method": "A multi-scale feature enhancement network trained end-to-end with the detector's loss function, ensuring enhancement is guided to refine features most relevant to detection tasks.", "result": "State-of-the-art Precision (0.877) and Recall (0.624) on underwater datasets with competitive mAP scores (mAP@0.5: 0.677, mAP@[0.5:0.95]: 0.421) and practical processing speed of 46.5 FPS.", "conclusion": "AquaFeat provides an effective and computationally efficient solution for real-world underwater applications like marine monitoring and infrastructure inspection."}}
{"id": "2508.12819", "pdf": "https://arxiv.org/pdf/2508.12819", "abs": "https://arxiv.org/abs/2508.12819", "authors": ["Jeongwoo Kang", "Maria Boritchev", "Maximin Coavoux"], "title": "ding-01 :ARG0: An AMR Corpus for Spontaneous French Dialogue", "categories": ["cs.CL"], "comment": "Accepted at IWCS 2025", "summary": "We present our work to build a French semantic corpus by annotating French\ndialogue in Abstract Meaning Representation (AMR). Specifically, we annotate\nthe DinG corpus, consisting of transcripts of spontaneous French dialogues\nrecorded during the board game Catan. As AMR has insufficient coverage of the\ndynamics of spontaneous speech, we extend the framework to better represent\nspontaneous speech and sentence structures specific to French. Additionally, to\nsupport consistent annotation, we provide an annotation guideline detailing\nthese extensions. We publish our corpus under a free license (CC-SA-BY). We\nalso train and evaluate an AMR parser on our data. This model can be used as an\nassistance annotation tool to provide initial annotations that can be refined\nby human annotators. Our work contributes to the development of semantic\nresources for French dialogue.", "AI": {"tldr": "Building a French semantic corpus by annotating spontaneous dialogues with extended Abstract Meaning Representation (AMR) framework to better handle French-specific structures and spontaneous speech dynamics.", "motivation": "To develop semantic resources for French dialogue and address AMR's insufficient coverage for spontaneous speech and French-specific sentence structures.", "method": "Annotated the DinG corpus (French board game dialogues) using extended AMR framework, created annotation guidelines, trained and evaluated an AMR parser on the data.", "result": "Created and published a French semantic corpus under CC-SA-BY license, developed an AMR parser that can assist human annotators with initial annotations.", "conclusion": "This work contributes to French semantic resource development and provides tools for consistent annotation of spontaneous French dialogue using extended AMR framework."}}
{"id": "2508.12569", "pdf": "https://arxiv.org/pdf/2508.12569", "abs": "https://arxiv.org/abs/2508.12569", "authors": ["Quercus Hernandez", "Max Win", "Thomas C. O'Connor", "Paulo E. Arratia", "Nathaniel Trask"], "title": "Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems", "categories": ["cs.LG", "cs.CE", "physics.comp-ph", "stat.ML"], "comment": "34 pages, 12 figures", "summary": "Multiscale systems are ubiquitous in science and technology, but are\nnotoriously challenging to simulate as short spatiotemporal scales must be\nappropriately linked to emergent bulk physics. When expensive high-dimensional\ndynamical systems are coarse-grained into low-dimensional models, the entropic\nloss of information leads to emergent physics which are dissipative,\nhistory-dependent, and stochastic. To machine learn coarse-grained dynamics\nfrom time-series observations of particle trajectories, we propose a framework\nusing the metriplectic bracket formalism that preserves these properties by\nconstruction; most notably, the framework guarantees discrete notions of the\nfirst and second laws of thermodynamics, conservation of momentum, and a\ndiscrete fluctuation-dissipation balance crucial for capturing non-equilibrium\nstatistics. We introduce the mathematical framework abstractly before\nspecializing to a particle discretization. As labels are generally unavailable\nfor entropic state variables, we introduce a novel self-supervised learning\nstrategy to identify emergent structural variables. We validate the method on\nbenchmark systems and demonstrate its utility on two challenging examples: (1)\ncoarse-graining star polymers at challenging levels of coarse-graining while\npreserving non-equilibrium statistics, and (2) learning models from high-speed\nvideo of colloidal suspensions that capture coupling between local\nrearrangement events and emergent stochastic dynamics. We provide open-source\nimplementations in both PyTorch and LAMMPS, enabling large-scale inference and\nextensibility to diverse particle-based systems.", "AI": {"tldr": "A machine learning framework for coarse-graining multiscale systems using metriplectic bracket formalism that preserves thermodynamic laws and fluctuation-dissipation balance.", "motivation": "Multiscale systems are challenging to simulate due to information loss during coarse-graining, leading to emergent dissipative, history-dependent, and stochastic physics that needs to be properly captured.", "method": "Proposes a framework using metriplectic bracket formalism that guarantees thermodynamic consistency, introduces self-supervised learning to identify emergent structural variables, and validates on benchmark systems including star polymers and colloidal suspensions.", "result": "The method successfully coarse-grains challenging systems like star polymers while preserving non-equilibrium statistics and captures coupling between local rearrangement events and emergent stochastic dynamics from high-speed video data.", "conclusion": "The framework provides thermodynamically consistent coarse-grained models with open-source implementations in PyTorch and LAMMPS, enabling large-scale inference for diverse particle-based systems."}}
{"id": "2508.11662", "pdf": "https://arxiv.org/pdf/2508.11662", "abs": "https://arxiv.org/abs/2508.11662", "authors": ["Alexander Komar", "Marc-Andr\u00e9 Heidelmann", "Kristina Schaaff"], "title": "Generative AI in Training and Coaching: Redefining the Design Process of Learning Materials", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Generative artificial intelligence (GenAI) is transforming education,\nredefining the role of trainers and coaches in learning environments. In our\nstudy, we explore how AI integrates into the design process of learning\nmaterials, assessing its impact on efficiency, pedagogical quality, and the\nevolving role of human trainers and coaches. Through qualitative interviews\nwith professionals in education and corporate training, we identify the\nfollowing key topics: trainers and coaches increasingly act as facilitators and\ncontent moderators rather than primary creators, efficiency gains allow for a\nstronger strategic focus but at the same time the new tools require new skills.\nAdditionally, we analyze how the anthropomorphism of AI shapes user trust and\nexpectations. From these insights, we derive how tools based on GenAI can\nsuccessfully be implemented for trainers and coaches on an individual,\norganizational, systemic, and strategic level.", "AI": {"tldr": "GenAI transforms education by shifting trainers from creators to facilitators, improving efficiency but requiring new skills, with successful implementation needing individual, organizational, and strategic approaches.", "motivation": "To explore how generative AI integrates into learning material design and assess its impact on efficiency, pedagogical quality, and the evolving role of human trainers and coaches.", "method": "Qualitative interviews with professionals in education and corporate training to identify key integration patterns and impacts.", "result": "Trainers increasingly act as facilitators and content moderators rather than creators; efficiency gains enable strategic focus but require new skills; anthropomorphism of AI affects user trust and expectations.", "conclusion": "Successful GenAI implementation for trainers requires consideration at individual, organizational, systemic, and strategic levels based on the identified insights."}}
{"id": "2508.12346", "pdf": "https://arxiv.org/pdf/2508.12346", "abs": "https://arxiv.org/abs/2508.12346", "authors": ["Hu Gao", "Depeng Dang"], "title": "MBMamba: When Memory Buffer Meets Mamba for Structure-Aware Image Deblurring", "categories": ["cs.CV"], "comment": null, "summary": "The Mamba architecture has emerged as a promising alternative to CNNs and\nTransformers for image deblurring. However, its flatten-and-scan strategy often\nresults in local pixel forgetting and channel redundancy, limiting its ability\nto effectively aggregate 2D spatial information. Although existing methods\nmitigate this by modifying the scan strategy or incorporating local feature\nmodules, it increase computational complexity and hinder real-time performance.\nIn this paper, we propose a structure-aware image deblurring network without\nchanging the original Mamba architecture. Specifically, we design a memory\nbuffer mechanism to preserve historical information for later fusion, enabling\nreliable modeling of relevance between adjacent features. Additionally, we\nintroduce an Ising-inspired regularization loss that simulates the energy\nminimization of the physical system's \"mutual attraction\" between pixels,\nhelping to maintain image structure and coherence. Building on this, we develop\nMBMamba. Experimental results show that our method outperforms state-of-the-art\napproaches on widely used benchmarks.", "AI": {"tldr": "MBMamba improves image deblurring using Mamba architecture with memory buffer mechanism and Ising-inspired regularization to address local pixel forgetting and maintain structural coherence.", "motivation": "The Mamba architecture shows promise for image deblurring but suffers from local pixel forgetting and channel redundancy due to its flatten-and-scan strategy. Existing solutions increase computational complexity and hinder real-time performance.", "method": "Proposes MBMamba with two key innovations: 1) a memory buffer mechanism to preserve historical information for fusion and model relevance between adjacent features, and 2) an Ising-inspired regularization loss that simulates energy minimization for pixel mutual attraction to maintain image structure.", "result": "Experimental results demonstrate that MBMamba outperforms state-of-the-art approaches on widely used benchmarks.", "conclusion": "The proposed method effectively addresses Mamba's limitations for image deblurring without changing the original architecture, achieving superior performance while maintaining computational efficiency."}}
{"id": "2508.12828", "pdf": "https://arxiv.org/pdf/2508.12828", "abs": "https://arxiv.org/abs/2508.12828", "authors": ["Raneem Alharthi", "Rajwa Alharthi", "Aiqi Jiang", "Arkaitz Zubiaga"], "title": "Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Abusive language detection has become an increasingly important task as a\nmeans to tackle this type of harmful content in social media. There has been a\nsubstantial body of research developing models for determining if a social\nmedia post is abusive or not; however, this research has primarily focused on\nexploiting social media posts individually, overlooking additional context that\ncan be derived from surrounding posts. In this study, we look at conversational\nexchanges, where a user replies to an earlier post by another user (the parent\ntweet). We ask: does leveraging context from the parent tweet help determine if\na reply post is abusive or not, and what are the features that contribute the\nmost? We study a range of content-based and account-based features derived from\nthe context, and compare this to the more widely studied approach of only\nlooking at the features from the reply tweet. For a more generalizable study,\nwe test four different classification models on a dataset made of\nconversational exchanges (parent-reply tweet pairs) with replies labeled as\nabusive or not. Our experiments show that incorporating contextual features\nleads to substantial improvements compared to the use of features derived from\nthe reply tweet only, confirming the importance of leveraging context. We\nobserve that, among the features under study, it is especially the\ncontent-based features (what is being posted) that contribute to the\nclassification performance rather than account-based features (who is posting\nit). While using content-based features, it is best to combine a range of\ndifferent features to ensure improved performance over being more selective and\nusing fewer features. Our study provides insights into the development of\ncontextualized abusive language detection models in realistic settings\ninvolving conversations.", "AI": {"tldr": "Contextual features from parent tweets significantly improve abusive language detection in replies compared to using reply-only features, with content-based features being most effective.", "motivation": "Existing abusive language detection research focuses on individual social media posts, overlooking the contextual information from conversational exchanges where replies build on parent posts.", "method": "Studied conversational exchanges (parent-reply tweet pairs) using four classification models with various content-based and account-based features derived from both parent tweets and replies.", "result": "Incorporating contextual features from parent tweets led to substantial improvements in detection performance. Content-based features contributed more than account-based features, and combining multiple features worked best.", "conclusion": "Leveraging contextual information from parent tweets is crucial for effective abusive language detection in conversational settings, with content-based features being particularly important for classification performance."}}
{"id": "2508.12575", "pdf": "https://arxiv.org/pdf/2508.12575", "abs": "https://arxiv.org/abs/2508.12575", "authors": ["Zohra Yagoub", "Hafida Bouziane"], "title": "Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "The prediction of amyloidogenicity in peptides and proteins remains a focal\npoint of ongoing bioinformatics. The crucial step in this field is to apply\nadvanced computational methodologies. Many recent approaches to predicting\namyloidogenicity within proteins are highly based on evolutionary motifs and\nthe individual properties of amino acids. It is becoming increasingly evident\nthat the sequence information-based features show high predictive performance.\nConsequently, our study evaluated the contextual features of protein sequences\nobtained from a pretrained protein large language model leveraging\nbidirectional LSTM and GRU to predict amyloidogenic regions in peptide and\nprotein sequences. Our method achieved an accuracy of 84.5% on 10-fold\ncross-validation and an accuracy of 83% in the test dataset. Our results\ndemonstrate competitive performance, highlighting the potential of LLMs in\nenhancing the accuracy of amyloid prediction.", "AI": {"tldr": "Using protein language models with bidirectional LSTM/GRU to predict amyloidogenic regions achieves 84.5% accuracy, demonstrating LLMs' potential for amyloid prediction.", "motivation": "Current amyloid prediction methods rely heavily on evolutionary motifs and amino acid properties, but sequence-based features show high predictive performance, prompting exploration of protein language models.", "method": "Leveraged pretrained protein large language model to extract contextual features, combined with bidirectional LSTM and GRU architectures for amyloidogenic region prediction.", "result": "Achieved 84.5% accuracy on 10-fold cross-validation and 83% accuracy on test dataset, showing competitive performance.", "conclusion": "Protein large language models significantly enhance amyloid prediction accuracy, demonstrating their potential as powerful tools in bioinformatics for amyloidogenicity prediction."}}
{"id": "2508.12349", "pdf": "https://arxiv.org/pdf/2508.12349", "abs": "https://arxiv.org/abs/2508.12349", "authors": ["Junyi Ma", "Erhang Zhang", "Yin-Dong Zheng", "Yuchen Xie", "Yixuan Zhou", "Hesheng Wang"], "title": "EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos", "categories": ["cs.CV"], "comment": "Extended journal version of arXiv:2506.03662", "summary": "Analyzing hand-object interaction in egocentric vision facilitates VR/AR\napplications and human-robot policy transfer. Existing research has mostly\nfocused on modeling the behavior paradigm of interactive actions (i.e., ``how\nto interact''). However, the more challenging and fine-grained problem of\ncapturing the critical moments of contact and separation between the hand and\nthe target object (i.e., ``when to interact'') is still underexplored, which is\ncrucial for immersive interactive experiences in mixed reality and robotic\nmotion planning. Therefore, we formulate this problem as temporal interaction\nlocalization (TIL). Some recent works extract semantic masks as TIL references,\nbut suffer from inaccurate object grounding and cluttered scenarios. Although\ncurrent temporal action localization (TAL) methods perform well in detecting\nverb-noun action segments, they rely on category annotations during training\nand exhibit limited precision in localizing hand-object contact/separation\nmoments. To address these issues, we propose a novel zero-shot approach dubbed\nEgoLoc to localize hand-object contact and separation timestamps in egocentric\nvideos. EgoLoc introduces hand-dynamics-guided sampling to generate\nhigh-quality visual prompts. It exploits the vision-language model to identify\ncontact/separation attributes, localize specific timestamps, and provide\nclosed-loop feedback for further refinement. EgoLoc eliminates the need for\nobject masks and verb-noun taxonomies, leading to generalizable zero-shot\nimplementation. Comprehensive experiments on the public dataset and our novel\nbenchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric\nvideos. It is also validated to effectively facilitate multiple downstream\napplications in egocentric vision and robotic manipulation tasks. Code and\nrelevant data will be released at https://github.com/IRMVLab/EgoLoc.", "AI": {"tldr": "EgoLoc is a zero-shot method for temporal interaction localization that identifies precise hand-object contact and separation moments in egocentric videos without needing object masks or verb-noun taxonomies.", "motivation": "Existing research focuses on 'how to interact' but neglects the critical 'when to interact' problem - precisely localizing contact/separation moments which is crucial for VR/AR applications and robotic policy transfer.", "method": "Proposes EgoLoc with hand-dynamics-guided sampling to generate visual prompts, leverages vision-language models to identify contact attributes and localize timestamps, and uses closed-loop feedback for refinement.", "result": "Achieves plausible temporal interaction localization on public datasets and novel benchmarks, effectively facilitating downstream applications in egocentric vision and robotic manipulation.", "conclusion": "EgoLoc provides a generalizable zero-shot solution for fine-grained hand-object interaction analysis, eliminating dependency on object masks and category annotations while enabling precise contact moment localization."}}
{"id": "2508.12830", "pdf": "https://arxiv.org/pdf/2508.12830", "abs": "https://arxiv.org/abs/2508.12830", "authors": ["Jan Maliszewski"], "title": "It takes a village to write a book: Mapping anonymous contributions in Stephen Langton's Quaestiones Theologiae", "categories": ["cs.CL"], "comment": null, "summary": "While the indirect evidence suggests that already in the early scholastic\nperiod the literary production based on records of oral teaching (so-called\nreportationes) was not uncommon, there are very few sources commenting on the\npractice. This paper details the design of a study applying stylometric\ntechniques of authorship attribution to a collection developed from\nreportationes -- Stephen Langton's Quaestiones Theologiae -- aiming to uncover\nlayers of editorial work and thus validate some hypotheses regarding the\ncollection's formation. Following Camps, Cl\\'erice, and Pinche (2021), I\ndiscuss the implementation of an HTR pipeline and stylometric analysis based on\nthe most frequent words, POS tags, and pseudo-affixes. The proposed study will\noffer two methodological gains relevant to computational research on the\nscholastic tradition: it will directly compare performance on manually composed\nand automatically extracted data, and it will test the validity of\ntransformer-based OCR and automated transcription alignment for workflows\napplied to scholastic Latin corpora. If successful, this study will provide an\neasily reusable template for the exploratory analysis of collaborative literary\nproduction stemming from medieval universities.", "AI": {"tldr": "Stylometric analysis of medieval scholastic reportationes to identify editorial layers and validate hypotheses about collection formation using computational methods.", "motivation": "There is limited direct evidence about the practice of creating reportationes (records of oral teaching) in early scholastic period, and few sources comment on this practice. The study aims to uncover editorial work layers in Stephen Langton's Quaestiones Theologiae collection.", "method": "Applying stylometric techniques for authorship attribution using HTR pipeline and analysis based on most frequent words, POS tags, and pseudo-affixes. Comparing performance on manually composed vs automatically extracted data, and testing transformer-based OCR with automated transcription alignment.", "result": "The paper describes a proposed study design - results are not yet available as this appears to be a methodology paper outlining planned research.", "conclusion": "If successful, this study will provide a reusable template for exploratory analysis of collaborative literary production from medieval universities, advancing computational research on scholastic tradition."}}
{"id": "2508.12576", "pdf": "https://arxiv.org/pdf/2508.12576", "abs": "https://arxiv.org/abs/2508.12576", "authors": ["Like Jian", "Dong Liu"], "title": "Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Federated learning (FL) enables decentralized clients to train a model\ncollaboratively without sharing local data. A key distinction between FL and\ncentralized learning is that clients' data are non-independent and identically\ndistributed, which poses significant challenges in training a global model that\ngeneralizes well across heterogeneous local data distributions. In this paper,\nwe analyze the convergence of overparameterized FedAvg with gradient descent\n(GD). We prove that the impact of data heterogeneity diminishes as the width of\nneural networks increases, ultimately vanishing when the width approaches\ninfinity. In the infinite-width regime, we further prove that both the global\nand local models in FedAvg behave as linear models, and that FedAvg achieves\nthe same generalization performance as centralized learning with the same\nnumber of GD iterations. Extensive experiments validate our theoretical\nfindings across various network architectures, loss functions, and optimization\nmethods.", "AI": {"tldr": "Overparameterized FedAvg with gradient descent converges better as neural network width increases, with data heterogeneity impact vanishing at infinite width where FedAvg matches centralized learning performance.", "motivation": "Federated learning faces challenges with non-IID client data distributions, making it difficult to train global models that generalize well across heterogeneous local data.", "method": "Theoretical analysis of FedAvg convergence with gradient descent on overparameterized neural networks, proving convergence properties as network width increases to infinity.", "result": "Data heterogeneity impact diminishes with increasing network width, vanishing completely at infinite width where FedAvg behaves like linear models and achieves same generalization as centralized learning.", "conclusion": "Overparameterization in neural networks effectively mitigates data heterogeneity challenges in federated learning, with infinite-width networks enabling FedAvg to match centralized learning performance."}}
{"id": "2508.12356", "pdf": "https://arxiv.org/pdf/2508.12356", "abs": "https://arxiv.org/abs/2508.12356", "authors": ["Ahmet H. G\u00fczel", "Ilija Bogunovic", "Jack Parker-Holder"], "title": "Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) offers a promising framework for training\nagents using pre-collected datasets without the need for further environment\ninteraction. However, policies trained on offline data often struggle to\ngeneralise due to limited exposure to diverse states. The complexity of visual\ndata introduces additional challenges such as noise, distractions, and spurious\ncorrelations, which can misguide the policy and increase the risk of\noverfitting if the training data is not sufficiently diverse. Indeed, this\nmakes it challenging to leverage vision-based offline data in training robust\nagents that can generalize to unseen environments. To solve this problem, we\npropose a simple approach generating additional synthetic training data. We\npropose a two-step process, first augmenting the originally collected offline\ndata to improve zero-shot generalization by introducing diversity, then using a\ndiffusion model to generate additional data in latent space. We test our method\nacross both continuous action spaces (Visual D4RL) and discrete action spaces\n(Procgen), demonstrating that it significantly improves generalization without\nrequiring any algorithmic changes to existing model-free offline RL methods. We\nshow that our method not only increases the diversity of the training data but\nalso significantly reduces the generalization gap at test time while\nmaintaining computational efficiency. We believe this approach could fuel\nadditional progress in generating synthetic data to train more general agents\nin the future.", "AI": {"tldr": "A simple two-step data augmentation method using diffusion models to generate synthetic training data in latent space, improving offline RL generalization without algorithmic changes.", "motivation": "Offline RL policies struggle to generalize due to limited diverse states in visual data, with noise and spurious correlations causing overfitting and poor generalization to unseen environments.", "method": "Two-step process: 1) augment original offline data to introduce diversity for better zero-shot generalization, 2) use diffusion model to generate additional synthetic data in latent space.", "result": "Significantly improves generalization across continuous (Visual D4RL) and discrete (Procgen) action spaces, increases data diversity, reduces generalization gap, and maintains computational efficiency.", "conclusion": "This approach enables leveraging vision-based offline data for training robust agents and could fuel progress in synthetic data generation for more general agents."}}
{"id": "2508.12863", "pdf": "https://arxiv.org/pdf/2508.12863", "abs": "https://arxiv.org/abs/2508.12863", "authors": ["Jumbly Grindrod", "Peter Grindrod"], "title": "Word Meanings in Transformer Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We investigate how word meanings are represented in the transformer language\nmodels. Specifically, we focus on whether transformer models employ something\nanalogous to a lexical store - where each word has an entry that contains\nsemantic information. To do this, we extracted the token embedding space of\nRoBERTa-base and k-means clustered it into 200 clusters. In our first study, we\nthen manually inspected the resultant clusters to consider whether they are\nsensitive to semantic information. In our second study, we tested whether the\nclusters are sensitive to five psycholinguistic measures: valence,\nconcreteness, iconicity, taboo, and age of acquisition. Overall, our findings\nwere very positive - there is a wide variety of semantic information encoded\nwithin the token embedding space. This serves to rule out certain \"meaning\neliminativist\" hypotheses about how transformer LLMs process semantic\ninformation.", "AI": {"tldr": "Transformer language models encode rich semantic information in their token embeddings, challenging meaning eliminativist views of how LLMs process meaning.", "motivation": "To investigate whether transformer models use something analogous to a lexical store containing semantic information for words, and to test specific meaning eliminativist hypotheses about how LLMs process semantic content.", "method": "Extracted token embedding space from RoBERTa-base, performed k-means clustering into 200 clusters, then conducted manual inspection and tested sensitivity to five psycholinguistic measures: valence, concreteness, iconicity, taboo, and age of acquisition.", "result": "Positive findings showing wide variety of semantic information encoded within the token embedding space, with clusters sensitive to semantic information and psycholinguistic measures.", "conclusion": "Transformer LLMs do encode meaningful semantic information in their representations, ruling out certain meaning eliminativist hypotheses about how these models process semantic content."}}
{"id": "2508.12590", "pdf": "https://arxiv.org/pdf/2508.12590", "abs": "https://arxiv.org/abs/2508.12590", "authors": ["Jihoon Park", "Seungeun Oh", "Seong-Lyun Kim"], "title": "Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 5 figures", "summary": "To address the growing demand for on-device LLM inference in\nresource-constrained environments, hybrid language models (HLM) have emerged,\ncombining lightweight local models with powerful cloud-based LLMs. Recent\nstudies on HLM have primarily focused on improving accuracy and latency, while\noften overlooking communication and energy efficiency. We propose a token-level\nfiltering mechanism for an energy-efficient importance- and uncertainty-aware\nHLM inference that leverages both epistemic uncertainty and attention-based\nimportance. Our method opportunistically uploads only informative tokens,\nreducing LLM usage and communication costs. Experiments with TinyLlama-1.1B and\nLLaMA-2-7B demonstrate that our method achieves up to 87.5% BERT Score and\ntoken throughput of 0.37 tokens/sec while saving the energy consumption by\n40.7% compared to standard HLM. Furthermore, compared to our previous U-HLM\nbaseline, our method improves BERTScore from 85.8% to 87.0%, energy savings\nfrom 31.6% to 43.6%, and throughput from 0.36 to 0.40. This approach enables an\nenergy-efficient and accurate deployment of LLMs in bandwidth-constrained edge\nenvironments.", "AI": {"tldr": "Token-level filtering mechanism for hybrid LLMs that reduces energy consumption by 40.7% while maintaining high accuracy through selective upload of informative tokens based on uncertainty and importance.", "motivation": "Address the need for energy-efficient on-device LLM inference in resource-constrained environments by reducing communication costs and energy consumption in hybrid language models, which current approaches overlook.", "method": "Proposes a token-level filtering mechanism that leverages both epistemic uncertainty and attention-based importance to opportunistically upload only informative tokens to cloud-based LLMs, reducing LLM usage and communication overhead.", "result": "Achieves up to 87.5% BERT Score, 0.37 tokens/sec throughput, and 40.7% energy savings compared to standard HLM. Outperforms previous U-HLM baseline with improved BERTScore (85.8% to 87.0%), energy savings (31.6% to 43.6%), and throughput (0.36 to 0.40).", "conclusion": "Enables energy-efficient and accurate deployment of LLMs in bandwidth-constrained edge environments through selective token uploading based on uncertainty and importance metrics."}}
{"id": "2508.11670", "pdf": "https://arxiv.org/pdf/2508.11670", "abs": "https://arxiv.org/abs/2508.11670", "authors": ["Bongsu Kim"], "title": "RRRA: Resampling and Reranking through a Retriever Adapter", "categories": ["cs.IR", "cs.AI"], "comment": "8 pages, 4 figures, submitted to AAAI 2026", "summary": "In dense retrieval, effective training hinges on selecting high quality hard\nnegatives while avoiding false negatives. Recent methods apply heuristics based\non positive document scores to identify hard negatives, improving both\nperformance and interpretability. However, these global, example agnostic\nstrategies often miss instance specific false negatives. To address this, we\npropose a learnable adapter module that monitors Bi-Encoder representations to\nestimate the likelihood that a hard negative is actually a false negative. This\nprobability is modeled dynamically and contextually, enabling fine-grained,\nquery specific judgments. The predicted scores are used in two downstream\ncomponents: (1) resampling, where negatives are reweighted during training, and\n(2) reranking, where top-k retrieved documents are reordered at inference.\nEmpirical results on standard benchmarks show that our adapter-enhanced\nframework consistently outperforms strong Bi-Encoder baselines, underscoring\nthe benefit of explicit false negative modeling in dense retrieval.", "AI": {"tldr": "A learnable adapter module that dynamically identifies false negatives in dense retrieval training, improving performance through resampling and reranking.", "motivation": "Current hard negative selection methods use global heuristics that often miss instance-specific false negatives, limiting training effectiveness.", "method": "Proposes a learnable adapter that monitors Bi-Encoder representations to estimate query-specific false negative probabilities, used for resampling during training and reranking at inference.", "result": "Empirical results show the adapter-enhanced framework consistently outperforms strong Bi-Encoder baselines on standard benchmarks.", "conclusion": "Explicit false negative modeling through contextual probability estimation significantly benefits dense retrieval performance."}}
{"id": "2508.12381", "pdf": "https://arxiv.org/pdf/2508.12381", "abs": "https://arxiv.org/abs/2508.12381", "authors": ["Guo Tang", "Songhan Jiang", "Jinpeng Lu", "Linghan Cai", "Yongbing Zhang"], "title": "IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "13 pages, 5 figures", "summary": "Pathological images play an essential role in cancer prognosis, while\nsurvival analysis, which integrates computational techniques, can predict\ncritical clinical events such as patient mortality or disease recurrence from\nwhole-slide images (WSIs). Recent advancements in multiple instance learning\nhave significantly improved the efficiency of survival analysis. However,\nexisting methods often struggle to balance the modeling of long-range spatial\nrelationships with local contextual dependencies and typically lack inherent\ninterpretability, limiting their clinical utility. To address these challenges,\nwe propose the Interpretable Pathology Graph-Transformer (IPGPhormer), a novel\nframework that captures the characteristics of the tumor microenvironment and\nmodels their spatial dependencies across the tissue. IPGPhormer uniquely\nprovides interpretability at both tissue and cellular levels without requiring\npost-hoc manual annotations, enabling detailed analyses of individual WSIs and\ncross-cohort assessments. Comprehensive evaluations on four public benchmark\ndatasets demonstrate that IPGPhormer outperforms state-of-the-art methods in\nboth predictive accuracy and interpretability. In summary, our method,\nIPGPhormer, offers a promising tool for cancer prognosis assessment, paving the\nway for more reliable and interpretable decision-support systems in pathology.\nThe code is publicly available at\nhttps://anonymous.4open.science/r/IPGPhormer-6EEB.", "AI": {"tldr": "IPGPhormer is an interpretable graph-transformer framework for cancer survival analysis from whole-slide images that balances spatial relationships with local context and provides multi-level interpretability without manual annotations.", "motivation": "Existing survival analysis methods struggle to balance long-range spatial relationships with local contextual dependencies and lack inherent interpretability, limiting clinical utility.", "method": "Proposes Interpretable Pathology Graph-Transformer (IPGPhormer) that captures tumor microenvironment characteristics and models spatial dependencies across tissue, providing interpretability at both tissue and cellular levels without post-hoc annotations.", "result": "Outperforms state-of-the-art methods on four public benchmark datasets in both predictive accuracy and interpretability.", "conclusion": "IPGPhormer offers a promising tool for cancer prognosis assessment, enabling more reliable and interpretable decision-support systems in pathology."}}
{"id": "2508.12868", "pdf": "https://arxiv.org/pdf/2508.12868", "abs": "https://arxiv.org/abs/2508.12868", "authors": ["Yilin Geng", "Shujing Wang", "Chuan Wang", "Keqing He", "Yanfei Lv", "Ying Wang", "Zaiwen Feng", "Xiaoying Bai"], "title": "An LLM Agent-Based Complex Semantic Table Annotation Approach", "categories": ["cs.CL", "cs.DB"], "comment": null, "summary": "The Semantic Table Annotation (STA) task, which includes Column Type\nAnnotation (CTA) and Cell Entity Annotation (CEA), maps table contents to\nontology entities and plays important roles in various semantic applications.\nHowever, complex tables often pose challenges such as semantic loss of column\nnames or cell values, strict ontological hierarchy requirements, homonyms,\nspelling errors, and abbreviations, which hinder annotation accuracy. To\naddress these issues, this paper proposes an LLM-based agent approach for CTA\nand CEA. We design and implement five external tools with tailored prompts\nbased on the ReAct framework, enabling the STA agent to dynamically select\nsuitable annotation strategies depending on table characteristics. Experiments\nare conducted on the Tough Tables and BiodivTab datasets from the SemTab\nchallenge, which contain the aforementioned challenges. Our method outperforms\nexisting approaches across various metrics. Furthermore, by leveraging\nLevenshtein distance to reduce redundant annotations, we achieve a 70%\nreduction in time costs and a 60% reduction in LLM token usage, providing an\nefficient and cost-effective solution for STA.", "AI": {"tldr": "LLM-based agent approach with external tools for semantic table annotation, achieving better performance and significant cost reductions.", "motivation": "Complex tables pose challenges like semantic loss, strict ontological hierarchy, homonyms, spelling errors, and abbreviations that hinder annotation accuracy in Column Type Annotation (CTA) and Cell Entity Annotation (CEA).", "method": "Proposes an LLM-based agent approach with five external tools using ReAct framework, enabling dynamic selection of annotation strategies based on table characteristics. Uses Levenshtein distance to reduce redundant annotations.", "result": "Outperforms existing approaches on Tough Tables and BiodivTab datasets. Achieves 70% reduction in time costs and 60% reduction in LLM token usage.", "conclusion": "Provides an efficient and cost-effective solution for Semantic Table Annotation by leveraging LLM agents with optimized annotation strategies."}}
{"id": "2508.12593", "pdf": "https://arxiv.org/pdf/2508.12593", "abs": "https://arxiv.org/abs/2508.12593", "authors": ["Zhihao Li", "Ting Wang", "Guojian Zou", "Ruofei Wang", "Ye Li"], "title": "Physics-informed deep operator network for traffic state estimation", "categories": ["cs.LG"], "comment": "under review in Transportmetrica B: Transport Dynamics", "summary": "Traffic state estimation (TSE) fundamentally involves solving\nhigh-dimensional spatiotemporal partial differential equations (PDEs) governing\ntraffic flow dynamics from limited, noisy measurements. While Physics-Informed\nNeural Networks (PINNs) enforce PDE constraints point-wise, this paper adopts a\nphysics-informed deep operator network (PI-DeepONet) framework that\nreformulates TSE as an operator learning problem. Our approach trains a\nparameterized neural operator that maps sparse input data to the full\nspatiotemporal traffic state field, governed by the traffic flow conservation\nlaw. Crucially, unlike PINNs that enforce PDE constraints point-wise,\nPI-DeepONet integrates traffic flow conservation model and the fundamental\ndiagram directly into the operator learning process, ensuring physical\nconsistency while capturing congestion propagation, spatial correlations, and\ntemporal evolution. Experiments on the NGSIM dataset demonstrate superior\nperformance over state-of-the-art baselines. Further analysis reveals insights\ninto optimal function generation strategies and branch network complexity.\nAdditionally, the impact of input function generation methods and the number of\nfunctions on model performance is explored, highlighting the robustness and\nefficacy of proposed framework.", "AI": {"tldr": "PI-DeepONet framework for traffic state estimation that learns neural operators mapping sparse data to full traffic fields while enforcing physical conservation laws, outperforming traditional PINNs and other baselines on NGSIM data.", "motivation": "Traditional Physics-Informed Neural Networks (PINNs) enforce PDE constraints point-wise but struggle with high-dimensional spatiotemporal traffic flow problems. There's a need for a more effective approach that integrates physical laws directly into operator learning for traffic state estimation from limited noisy measurements.", "method": "Proposes physics-informed deep operator network (PI-DeepONet) that reformulates TSE as operator learning problem. Trains parameterized neural operator mapping sparse input data to full spatiotemporal traffic state field while integrating traffic flow conservation model and fundamental diagram directly into learning process.", "result": "Superior performance over state-of-the-art baselines on NGSIM dataset. Framework effectively captures congestion propagation, spatial correlations, and temporal evolution while ensuring physical consistency. Analysis reveals optimal function generation strategies and branch network complexity requirements.", "conclusion": "PI-DeepONet provides a robust and effective framework for traffic state estimation that successfully integrates physical constraints into operator learning, demonstrating significant advantages over point-wise PDE enforcement methods like PINNs."}}
{"id": "2508.11671", "pdf": "https://arxiv.org/pdf/2508.11671", "abs": "https://arxiv.org/abs/2508.11671", "authors": ["Ronald Carvalho Boadana", "Ademir Guimar\u00e3es da Costa Junior", "Ricardo Rios", "F\u00e1bio Santos da Silva"], "title": "LLM-Based Intelligent Agents for Music Recommendation: A Comparison with Classical Content-Based Filtering", "categories": ["cs.IR", "cs.AI", "cs.LG", "cs.MA"], "comment": "12 pages, in Portuguese language, 2 figures, 5 tables, 3 formulas. To\n  be published in the Proceedings of the Encontro Nacional de Intelig\\^encia\n  Artificial e Computacional (ENIAC 2025)", "summary": "The growing availability of music on streaming platforms has led to\ninformation overload for users. To address this issue and enhance the user\nexperience, increasingly sophisticated recommendation systems have been\nproposed. This work investigates the use of Large Language Models (LLMs) from\nthe Gemini and LLaMA families, combined with intelligent agents, in a\nmulti-agent personalized music recommendation system. The results are compared\nwith a traditional content-based recommendation model, considering user\nsatisfaction, novelty, and computational efficiency. LLMs achieved satisfaction\nrates of up to \\textit{89{,}32\\%}, indicating their promising potential in\nmusic recommendation systems.", "AI": {"tldr": "LLMs from Gemini and LLaMA families combined with intelligent agents outperform traditional content-based models in music recommendation, achieving 89.32% user satisfaction.", "motivation": "Address information overload on music streaming platforms and enhance user experience through sophisticated recommendation systems.", "method": "Multi-agent personalized music recommendation system using Large Language Models (Gemini and LLaMA families) combined with intelligent agents, compared against traditional content-based recommendation model.", "result": "LLMs achieved satisfaction rates of up to 89.32%, demonstrating superior performance in user satisfaction, novelty, and computational efficiency compared to traditional content-based models.", "conclusion": "LLMs show promising potential for music recommendation systems, offering significant improvements over traditional approaches."}}
{"id": "2508.12384", "pdf": "https://arxiv.org/pdf/2508.12384", "abs": "https://arxiv.org/abs/2508.12384", "authors": ["Hanwen Cao", "Haobo Lu", "Xiaosen Wang", "Kun He"], "title": "ViT-EnsembleAttack: Augmenting Ensemble Models for Stronger Adversarial Transferability in Vision Transformers", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "Ensemble-based attacks have been proven to be effective in enhancing\nadversarial transferability by aggregating the outputs of models with various\narchitectures. However, existing research primarily focuses on refining\nensemble weights or optimizing the ensemble path, overlooking the exploration\nof ensemble models to enhance the transferability of adversarial attacks. To\naddress this gap, we propose applying adversarial augmentation to the surrogate\nmodels, aiming to boost overall generalization of ensemble models and reduce\nthe risk of adversarial overfitting. Meanwhile, observing that ensemble Vision\nTransformers (ViTs) gain less attention, we propose ViT-EnsembleAttack based on\nthe idea of model adversarial augmentation, the first ensemble-based attack\nmethod tailored for ViTs to the best of our knowledge. Our approach generates\naugmented models for each surrogate ViT using three strategies: Multi-head\ndropping, Attention score scaling, and MLP feature mixing, with the associated\nparameters optimized by Bayesian optimization. These adversarially augmented\nmodels are ensembled to generate adversarial examples. Furthermore, we\nintroduce Automatic Reweighting and Step Size Enlargement modules to boost\ntransferability. Extensive experiments demonstrate that ViT-EnsembleAttack\nsignificantly enhances the adversarial transferability of ensemble-based\nattacks on ViTs, outperforming existing methods by a substantial margin. Code\nis available at https://github.com/Trustworthy-AI-Group/TransferAttack.", "AI": {"tldr": "ViT-EnsembleAttack enhances adversarial transferability for Vision Transformers through adversarial augmentation of surrogate models using multi-head dropping, attention scaling, and MLP feature mixing, optimized with Bayesian optimization.", "motivation": "Existing ensemble attacks focus on refining weights or paths but overlook exploring ensemble models themselves to enhance transferability, especially for Vision Transformers which receive less attention in ensemble-based attacks.", "method": "Proposes adversarial augmentation of surrogate ViT models using three strategies: Multi-head dropping, Attention score scaling, and MLP feature mixing with Bayesian optimization. Includes Automatic Reweighting and Step Size Enlargement modules to boost transferability.", "result": "Extensive experiments show ViT-EnsembleAttack significantly enhances adversarial transferability of ensemble-based attacks on ViTs, substantially outperforming existing methods.", "conclusion": "The proposed method effectively addresses the gap in ensemble-based attacks for Vision Transformers and demonstrates superior performance through adversarial augmentation techniques and optimization modules."}}
{"id": "2508.12903", "pdf": "https://arxiv.org/pdf/2508.12903", "abs": "https://arxiv.org/abs/2508.12903", "authors": ["Jinyi Han", "Xinyi Wang", "Haiquan Zhao", "Tingyun li", "Zishang Jiang", "Sihang Jiang", "Jiaqing Liang", "Xin Lin", "Weikang Zhou", "Zeye Sun", "Fei Yu", "Yanghua Xiao"], "title": "A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in self-refinement have demonstrated significant potential\nfor improving the outputs of large language models (LLMs) through iterative\nrefinement. However, most existing self-refinement methods rely on a reactive\nprocess with a fixed number of iterations, making it difficult to determine the\noptimal timing and content of refinement based on the evolving generation\ncontext. Inspired by the way humans dynamically refine their thoughts during\nexecution, we propose ProActive Self-Refinement (PASR), a novel method that\nenables LLMs to refine their outputs during the generation process. Unlike\nmethods that regenerate entire responses, PASR proactively decides whether,\nwhen, and how to refine based on the model's internal state and evolving\ncontext. We conduct extensive experiments on a diverse set of 10 tasks to\nevaluate the effectiveness of PASR. Experimental results show that PASR\nsignificantly enhances problem-solving performance. In particular, on Qwen3-8B,\nPASR reduces average token consumption by 41.6 percent compared to standard\ngeneration, while also achieving an 8.2 percent improvement in accuracy. Our\ncode and all baselines used in the paper are available in the GitHub.", "AI": {"tldr": "PASR enables LLMs to dynamically refine outputs during generation by proactively deciding when and how to refine based on internal state, reducing tokens by 41.6% while improving accuracy by 8.2%.", "motivation": "Existing self-refinement methods use fixed iterative processes that cannot adapt to evolving generation context, unlike human dynamic refinement during execution.", "method": "ProActive Self-Refinement (PASR) allows LLMs to refine outputs during generation by monitoring internal state and context to decide whether, when, and how to refine rather than regenerating entire responses.", "result": "On Qwen3-8B across 10 diverse tasks, PASR reduced average token consumption by 41.6% compared to standard generation while achieving 8.2% accuracy improvement.", "conclusion": "PASR demonstrates that proactive, context-aware refinement during generation significantly enhances LLM performance with reduced computational cost compared to reactive fixed-iteration approaches."}}
{"id": "2508.12594", "pdf": "https://arxiv.org/pdf/2508.12594", "abs": "https://arxiv.org/abs/2508.12594", "authors": ["Vedant Puri", "Aditya Joglekar", "Kevin Ferguson", "Yu-hsuan Chen", "Yongjie Jessica Zhang", "Levent Burak Kara"], "title": "FLARE: Fast Low-rank Attention Routing Engine", "categories": ["cs.LG"], "comment": null, "summary": "The quadratic complexity of self-attention limits its applicability and\nscalability on large unstructured meshes. We introduce Fast Low-rank Attention\nRouting Engine (FLARE), a linear complexity self-attention mechanism that\nroutes attention through fixed-length latent sequences. Each attention head\nperforms global communication among $N$ tokens by projecting the input sequence\nonto a fixed length latent sequence of $M \\ll N$ tokens using learnable query\ntokens. By routing attention through a bottleneck sequence, FLARE learns a\nlow-rank form of attention that can be applied at $O(NM)$ cost. FLARE not only\nscales to unprecedented problem sizes, but also delivers superior accuracy\ncompared to state-of-the-art neural PDE surrogates across diverse benchmarks.\nWe also release a new additive manufacturing dataset to spur further research.\nOur code is available at https://github.com/vpuri3/FLARE.py.", "AI": {"tldr": "FLARE is a linear complexity self-attention mechanism that routes attention through fixed-length latent sequences to enable efficient processing of large unstructured meshes.", "motivation": "The quadratic complexity of standard self-attention limits its scalability on large unstructured meshes, creating a need for more efficient attention mechanisms.", "method": "FLARE projects input sequences onto fixed-length latent sequences using learnable query tokens, routing attention through a bottleneck sequence to achieve O(NM) complexity where M << N.", "result": "FLARE scales to unprecedented problem sizes while delivering superior accuracy compared to state-of-the-art neural PDE surrogates across diverse benchmarks.", "conclusion": "FLARE provides an efficient low-rank attention mechanism that enables scalable processing of large unstructured meshes with improved performance, and the authors release a new additive manufacturing dataset to support further research."}}
{"id": "2508.11672", "pdf": "https://arxiv.org/pdf/2508.11672", "abs": "https://arxiv.org/abs/2508.11672", "authors": ["Zixia Zhou", "Junyan Liu", "Wei Emma Wu", "Ruogu Fang", "Sheng Liu", "Qingyue Wei", "Rui Yan", "Yi Guo", "Qian Tao", "Yuanyuan Wang", "Md Tauhidul Islam", "Lei Xing"], "title": "Revealing Neurocognitive and Behavioral Patterns by Unsupervised Manifold Learning from Dynamic Brain Data", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "comment": null, "summary": "Dynamic brain data, teeming with biological and functional insights, are\nbecoming increasingly accessible through advanced measurements, providing a\ngateway to understanding the inner workings of the brain in living subjects.\nHowever, the vast size and intricate complexity of the data also pose a\ndaunting challenge in reliably extracting meaningful information across various\ndata sources. This paper introduces a generalizable unsupervised deep manifold\nlearning for exploration of neurocognitive and behavioral patterns. Unlike\nexisting methods that extract patterns directly from the input data as in the\nexisting methods, the proposed Brain-dynamic Convolutional-Network-based\nEmbedding (BCNE) seeks to capture the brain-state trajectories by deciphering\nthe temporospatial correlations within the data and subsequently applying\nmanifold learning to this correlative representation. The performance of BCNE\nis showcased through the analysis of several important dynamic brain datasets.\nThe results, both visual and quantitative, reveal a diverse array of intriguing\nand interpretable patterns. BCNE effectively delineates scene transitions,\nunderscores the involvement of different brain regions in memory and narrative\nprocessing, distinguishes various stages of dynamic learning processes, and\nidentifies differences between active and passive behaviors. BCNE provides an\neffective tool for exploring general neuroscience inquiries or\nindividual-specific patterns.", "AI": {"tldr": "BCNE is an unsupervised deep manifold learning method that captures brain-state trajectories by analyzing temporospatial correlations in dynamic brain data, revealing interpretable neurocognitive and behavioral patterns.", "motivation": "Dynamic brain data contains valuable biological and functional insights but is challenging to analyze due to its vast size and complexity. Existing methods extract patterns directly from input data, which may not effectively capture the underlying brain-state trajectories.", "method": "Brain-dynamic Convolutional-Network-based Embedding (BCNE) deciphers temporospatial correlations within brain data and applies manifold learning to this correlative representation to capture brain-state trajectories.", "result": "BCNE successfully identifies scene transitions, reveals brain region involvement in memory and narrative processing, distinguishes dynamic learning stages, and differentiates active vs. passive behaviors through both visual and quantitative analysis.", "conclusion": "BCNE provides an effective unsupervised tool for exploring general neuroscience questions and individual-specific patterns in dynamic brain data by capturing meaningful brain-state trajectories through correlation-based manifold learning."}}
{"id": "2508.12396", "pdf": "https://arxiv.org/pdf/2508.12396", "abs": "https://arxiv.org/abs/2508.12396", "authors": ["Xiaochuan Lin", "Xiangyong Chen", "Xuan Li", "Yichen Su"], "title": "DeCoT: Decomposing Complex Instructions for Enhanced Text-to-Image Generation with Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Despite remarkable advancements, current Text-to-Image (T2I) models struggle\nwith complex, long-form textual instructions, frequently failing to accurately\nrender intricate details, spatial relationships, or specific constraints. This\nlimitation is highlighted by benchmarks such as LongBench-T2I, which reveal\ndeficiencies in handling composition, specific text, and fine textures. To\naddress this, we propose DeCoT (Decomposition-CoT), a novel framework that\nleverages Large Language Models (LLMs) to significantly enhance T2I models'\nunderstanding and execution of complex instructions. DeCoT operates in two core\nstages: first, Complex Instruction Decomposition and Semantic Enhancement,\nwhere an LLM breaks down raw instructions into structured, actionable semantic\nunits and clarifies ambiguities; second, Multi-Stage Prompt Integration and\nAdaptive Generation, which transforms these units into a hierarchical or\noptimized single prompt tailored for existing T2I models. Extensive experiments\non the LongBench-T2I dataset demonstrate that DeCoT consistently and\nsubstantially improves the performance of leading T2I models across all\nevaluated dimensions, particularly in challenging aspects like \"Text\" and\n\"Composition\". Quantitative results, validated by multiple MLLM evaluators\n(Gemini-2.0-Flash and InternVL3-78B), show that DeCoT, when integrated with\nInfinity-8B, achieves an average score of 3.52, outperforming the baseline\nInfinity-8B (3.44). Ablation studies confirm the critical contribution of each\nDeCoT component and the importance of sophisticated LLM prompting. Furthermore,\nhuman evaluations corroborate these findings, indicating superior perceptual\nquality and instruction fidelity. DeCoT effectively bridges the gap between\nhigh-level user intent and T2I model requirements, leading to more faithful and\naccurate image generation.", "AI": {"tldr": "DeCoT is a framework that uses LLMs to decompose complex text instructions into structured semantic units, significantly improving T2I models' ability to handle detailed and complex image generation tasks.", "motivation": "Current T2I models struggle with complex, long-form textual instructions, failing to accurately render intricate details, spatial relationships, and specific constraints as revealed by benchmarks like LongBench-T2I.", "method": "Two-stage framework: 1) Complex Instruction Decomposition and Semantic Enhancement using LLMs to break down instructions into structured semantic units, 2) Multi-Stage Prompt Integration and Adaptive Generation to create hierarchical or optimized prompts for T2I models.", "result": "DeCoT consistently improves T2I model performance across all dimensions, achieving an average score of 3.52 with Infinity-8B (vs baseline 3.44), with significant gains in challenging aspects like \"Text\" and \"Composition\". Human evaluations confirm superior perceptual quality and instruction fidelity.", "conclusion": "DeCoT effectively bridges the gap between user intent and T2I model requirements, enabling more faithful and accurate image generation from complex textual instructions through structured decomposition and LLM-enhanced prompting."}}
{"id": "2508.12981", "pdf": "https://arxiv.org/pdf/2508.12981", "abs": "https://arxiv.org/abs/2508.12981", "authors": ["Tianyue Ou", "Saujas Vaduguru", "Daniel Fried"], "title": "Analyzing Information Sharing and Coordination in Multi-Agent Planning", "categories": ["cs.CL"], "comment": null, "summary": "Multi-agent systems (MASs) have pushed the boundaries of large language model\n(LLM) agents in domains such as web research and software engineering. However,\nlong-horizon, multi-constraint planning tasks involve conditioning on detailed\ninformation and satisfying complex interdependent constraints, which can pose a\nchallenge for these systems. In this study, we construct an LLM-based MAS for a\ntravel planning task which is representative of these challenges. We evaluate\nthe impact of a notebook to facilitate information sharing, and evaluate an\norchestrator agent to improve coordination in free form conversation between\nagents. We find that the notebook reduces errors due to hallucinated details by\n18%, while an orchestrator directs the MAS to focus on and further reduce\nerrors by up to 13.5% within focused sub-areas. Combining both mechanisms\nachieves a 25% final pass rate on the TravelPlanner benchmark, a 17.5% absolute\nimprovement over the single-agent baseline's 7.5% pass rate. These results\nhighlight the potential of structured information sharing and reflective\norchestration as key components in MASs for long horizon planning with LLMs.", "AI": {"tldr": "LLM-based multi-agent system with notebook for information sharing and orchestrator for coordination improves travel planning performance by 17.5% over single-agent baseline.", "motivation": "Multi-agent systems struggle with long-horizon, multi-constraint planning tasks that require detailed information and complex interdependent constraints.", "method": "Constructed an LLM-based multi-agent system for travel planning with two key mechanisms: a notebook for information sharing and an orchestrator agent for coordination in free-form conversations.", "result": "Notebook reduced hallucination errors by 18%, orchestrator reduced errors by up to 13.5% in focused areas. Combined system achieved 25% pass rate on TravelPlanner benchmark vs 7.5% for single-agent baseline.", "conclusion": "Structured information sharing and reflective orchestration are key components for effective multi-agent systems in long-horizon planning with LLMs."}}
{"id": "2508.12596", "pdf": "https://arxiv.org/pdf/2508.12596", "abs": "https://arxiv.org/abs/2508.12596", "authors": ["Meng Zhang", "Chao Wang", "Hao Zhang", "Shaojun Dong", "Lixin He"], "title": "Constructing Invariant and Equivariant Operations by Symmetric Tensor Network", "categories": ["cs.LG"], "comment": null, "summary": "Design of neural networks that incorporate symmetry is crucial for geometric\ndeep learning. Central to this effort is the development of invariant and\nequivariant operations. This works presents a systematic method for\nconstructing valid invariant and equivariant operations. It can handle inputs\nand outputs in the form of Cartesian tensors with different rank, as well as\nspherical tensors with different types. In addition, our method features a\ngraphical representation utilizing the symmetric tensor network, which\nsimplifies both the proofs and constructions related to invariant and\nequivariant functions. We also apply this approach to design the equivariant\ninteraction message for the geometry graph neural network, and equivariant\nmachine learning model to learn the constitutive law of materials.", "AI": {"tldr": "A systematic method for constructing invariant and equivariant operations in neural networks using symmetric tensor networks, with applications to geometric graph neural networks and material constitutive law learning.", "motivation": "To develop neural networks that incorporate symmetry for geometric deep learning, requiring systematic construction of invariant and equivariant operations that can handle various tensor types.", "method": "Presents a systematic construction method using symmetric tensor networks with graphical representation, handling Cartesian tensors of different ranks and spherical tensors of different types.", "result": "Developed a method that simplifies proofs and constructions of invariant and equivariant functions, and successfully applied it to design equivariant interaction messages for geometry graph neural networks.", "conclusion": "The approach provides an effective framework for building symmetry-incorporated neural networks with practical applications in geometric deep learning and material science."}}
{"id": "2508.12399", "pdf": "https://arxiv.org/pdf/2508.12399", "abs": "https://arxiv.org/abs/2508.12399", "authors": ["Suraj Prasad", "Navyansh Mahla", "Sunny Gupta", "Amit Sethi"], "title": "Federated Cross-Modal Style-Aware Prompt Generation", "categories": ["cs.CV"], "comment": null, "summary": "Prompt learning has propelled vision-language models like CLIP to excel in\ndiverse tasks, making them ideal for federated learning due to computational\nefficiency. However, conventional approaches that rely solely on final-layer\nfeatures miss out on rich multi-scale visual cues and domain-specific style\nvariations in decentralized client data. To bridge this gap, we introduce\nFedCSAP (Federated Cross-Modal Style-Aware Prompt Generation). Our framework\nharnesses low, mid, and high-level features from CLIP's vision encoder\nalongside client-specific style indicators derived from batch-level statistics.\nBy merging intricate visual details with textual context, FedCSAP produces\nrobust, context-aware prompt tokens that are both distinct and non-redundant,\nthereby boosting generalization across seen and unseen classes. Operating\nwithin a federated learning paradigm, our approach ensures data privacy through\nlocal training and global aggregation, adeptly handling non-IID class\ndistributions and diverse domain-specific styles. Comprehensive experiments on\nmultiple image classification datasets confirm that FedCSAP outperforms\nexisting federated prompt learning methods in both accuracy and overall\ngeneralization.", "AI": {"tldr": "FedCSAP is a federated learning framework that enhances CLIP's performance by leveraging multi-scale visual features and client-specific style indicators to generate robust, context-aware prompts while maintaining data privacy.", "motivation": "Conventional prompt learning approaches using only final-layer features miss rich multi-scale visual cues and domain-specific style variations in decentralized client data, limiting generalization across diverse datasets.", "method": "Leverages low, mid, and high-level features from CLIP's vision encoder combined with client-specific style indicators from batch-level statistics to generate distinct, non-redundant prompt tokens through local training and global aggregation.", "result": "Outperforms existing federated prompt learning methods in accuracy and generalization across multiple image classification datasets, effectively handling non-IID class distributions and diverse domain styles.", "conclusion": "FedCSAP successfully bridges the gap in federated prompt learning by incorporating multi-scale visual features and style awareness, demonstrating superior performance while preserving data privacy in decentralized settings."}}
{"id": "2508.13024", "pdf": "https://arxiv.org/pdf/2508.13024", "abs": "https://arxiv.org/abs/2508.13024", "authors": ["Ralph Peeters", "Aaron Steiner", "Luca Schwarz", "Julian Yuya Caspary", "Christian Bizer"], "title": "WebMall -- A Multi-Shop Benchmark for Evaluating Web Agents", "categories": ["cs.CL"], "comment": null, "summary": "LLM-based web agents have the potential to automate long-running web tasks,\nsuch as finding offers for specific products in multiple online shops and\nsubsequently ordering the cheapest products that meet the users needs. This\npaper introduces WebMall, a multi-shop online shopping benchmark for evaluating\nthe effectiveness and efficiency of web agents for comparison-shopping. WebMall\nconsists of four simulated online shops populated with authentic product offers\nsourced from the Common Crawl, alongside a suite of 91 cross-shop tasks. These\ntasks include basic tasks such as finding specific products in multiple shops,\nperforming price comparisons, adding items to the shopping cart, and completing\ncheckout. Advanced tasks involve searching for products based on vague\nrequirements, identifying suitable substitutes, and finding compatible\nproducts. Compared to existing e-commerce benchmarks, such as WebShop or\nShoppingBench, WebMall introduces comparison-shopping tasks across multiple\nshops. Furthermore, the product offers are more heterogeneous, as they\noriginate from hundreds of distinct real-world shops. The tasks in WebMall\nrequire longer interaction trajectories than those in WebShop, while remaining\nrepresentative of real-world shopping behaviors. We evaluate eight baseline\nagents on WebMall, varying in observation modality, memory utilization, and\nunderlying large language model (GPT 4.1 and Claude Sonnet 4). The\nbest-performing configurations achieve completion rates of 75% and 53%, and F1\nscores of 87% and 63%, on the basic and advanced task sets, respectively.\nWebMall is publicly released to facilitate research on web agents and to\npromote advancements in navigation, reasoning, and efficiency within e-commerce\nscenarios.", "AI": {"tldr": "WebMall is a new multi-shop online shopping benchmark for evaluating web agents, featuring 4 simulated shops with real products and 91 cross-shop comparison tasks that require longer interaction sequences than existing benchmarks.", "motivation": "Existing e-commerce benchmarks like WebShop and ShoppingBench lack comparison-shopping tasks across multiple shops and don't adequately represent the heterogeneity of real-world shopping scenarios with products from hundreds of distinct shops.", "method": "Created a benchmark with four simulated online shops populated with authentic product offers from Common Crawl, featuring 91 cross-shop tasks including basic tasks (finding products, price comparisons, checkout) and advanced tasks (vague requirements, substitutes, compatibility).", "result": "Evaluated 8 baseline agents with different configurations - best performers achieved 75% completion rate and 87% F1 score on basic tasks, and 53% completion rate with 63% F1 score on advanced tasks.", "conclusion": "WebMall provides a more realistic and challenging benchmark for web agents that better represents real-world shopping behaviors and enables research on navigation, reasoning, and efficiency in e-commerce scenarios."}}
{"id": "2508.12602", "pdf": "https://arxiv.org/pdf/2508.12602", "abs": "https://arxiv.org/abs/2508.12602", "authors": ["Hansol Lim", "Jongseong Brad Choi", "Jee Won Lee", "Haeseong Jeoung", "Minkyu Han"], "title": "A Hybrid Surrogate for Electric Vehicle Parameter Estimation and Power Consumption via Physics-Informed Neural Operators", "categories": ["cs.LG"], "comment": "This preprint corresponding to a manuscript has been submitted to a\n  journal for potential publication", "summary": "We present a hybrid surrogate model for electric vehicle parameter estimation\nand power consumption. We combine our novel architecture Spectral Parameter\nOperator built on a Fourier Neural Operator backbone for global context and a\ndifferentiable physics module in the forward pass. From speed and acceleration\nalone, it outputs time-varying motor and regenerative braking efficiencies, as\nwell as aerodynamic drag, rolling resistance, effective mass, and auxiliary\npower. These parameters drive a physics-embedded estimate of battery power,\neliminating any separate physics-residual loss. The modular design lets\nrepresentations converge to physically meaningful parameters that reflect the\ncurrent state and condition of the vehicle. We evaluate on real-world logs from\na Tesla Model 3, Tesla Model S, and the Kia EV9. The surrogate achieves a mean\nabsolute error of 0.2kW (about 1% of average traction power at highway speeds)\nfor Tesla vehicles and about 0.8kW on the Kia EV9. The framework is\ninterpretable, and it generalizes well to unseen conditions, and sampling\nrates, making it practical for path optimization, eco-routing, on-board\ndiagnostics, and prognostics health management.", "AI": {"tldr": "Hybrid surrogate model combining Fourier Neural Operator with differentiable physics for EV parameter estimation from speed/acceleration data, achieving 0.2-0.8kW error on real-world Tesla and Kia vehicles.", "motivation": "To develop an interpretable and accurate electric vehicle parameter estimation model that can extract physically meaningful parameters from minimal sensor data (speed and acceleration alone) for practical applications like eco-routing and diagnostics.", "method": "Novel Spectral Parameter Operator architecture built on Fourier Neural Operator backbone for global context, combined with differentiable physics module in forward pass. Outputs time-varying motor/braking efficiencies, drag, rolling resistance, mass, and auxiliary power without separate physics-residual loss.", "result": "Achieved mean absolute error of 0.2kW (~1% of average traction power) for Tesla vehicles and 0.8kW for Kia EV9 on real-world logs. Model generalizes well to unseen conditions and sampling rates.", "conclusion": "The hybrid surrogate model provides interpretable, physically meaningful parameter estimation with high accuracy, making it practical for EV applications including path optimization, eco-routing, diagnostics, and health management."}}
{"id": "2508.11674", "pdf": "https://arxiv.org/pdf/2508.11674", "abs": "https://arxiv.org/abs/2508.11674", "authors": ["Zofia Rudnicka", "Janusz Szczepanski", "Agnieszka Pregowska"], "title": "Learning Internal Biological Neuron Parameters and Complexity-Based Encoding for Improved Spiking Neural Networks Performance", "categories": ["cs.NE", "cs.AI", "q-bio.NC"], "comment": null, "summary": "This study introduces a novel approach by replacing the traditional\nperceptron neuron model with a biologically inspired probabilistic meta neuron,\nwhere the internal neuron parameters are jointly learned, leading to improved\nclassification accuracy of spiking neural networks (SNNs). To validate this\ninnovation, we implement and compare two SNN architectures: one based on\nstandard leaky integrate-and-fire (LIF) neurons and another utilizing the\nproposed probabilistic meta neuron model. As a second key contribution, we\npresent a new biologically inspired classification framework that uniquely\nintegrates SNNs with Lempel-Ziv complexity (LZC) a measure closely related to\nentropy rate. By combining the temporal precision and biological plausibility\nof SNNs with the capacity of LZC to capture structural regularity, the proposed\napproach enables efficient and interpretable classification of spatiotemporal\nneural data, an aspect not addressed in existing works. We consider learning\nalgorithms such as backpropagation, spike-timing-dependent plasticity (STDP),\nand the Tempotron learning rule. To explore neural dynamics, we use Poisson\nprocesses to model neuronal spike trains, a well-established method for\nsimulating the stochastic firing behavior of biological neurons. Our results\nreveal that depending on the training method, the classifier's efficiency can\nimprove by up to 11.00%, highlighting the advantage of learning additional\nneuron parameters beyond the traditional focus on weighted inputs alone.", "AI": {"tldr": "Novel probabilistic meta neuron model improves SNN classification accuracy by up to 11% when combined with Lempel-Ziv complexity for spatiotemporal neural data analysis.", "motivation": "To overcome limitations of traditional perceptron neuron models and improve classification accuracy of spiking neural networks by incorporating biologically inspired probabilistic neurons and entropy-based complexity measures.", "method": "Developed probabilistic meta neuron model with jointly learned internal parameters, implemented two SNN architectures (LIF neurons vs probabilistic meta neurons), integrated Lempel-Ziv complexity with SNNs, used backpropagation/STDP/Tempotron learning rules, and modeled spike trains with Poisson processes.", "result": "Classification efficiency improved by up to 11.00% depending on training method, demonstrating advantage of learning additional neuron parameters beyond traditional weighted inputs.", "conclusion": "The probabilistic meta neuron approach combined with Lempel-Ziv complexity enables more efficient and interpretable classification of spatiotemporal neural data, addressing a gap in existing literature."}}
{"id": "2508.12400", "pdf": "https://arxiv.org/pdf/2508.12400", "abs": "https://arxiv.org/abs/2508.12400", "authors": ["Amirul Rahman", "Qiang Xu", "Xueying Huang"], "title": "MPCAR: Multi-Perspective Contextual Augmentation for Enhanced Visual Reasoning in Large Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Despite significant advancements, Large Vision-Language Models (LVLMs)\ncontinue to face challenges in complex visual reasoning tasks that demand deep\ncontextual understanding, multi-angle analysis, or meticulous detail\nrecognition. Existing approaches often rely on single-shot image encoding and\nprompts, limiting their ability to fully capture nuanced visual information.\nInspired by the notion that strategically generated \"additional\" information\ncan serve as beneficial contextual augmentation, we propose Multi-Perspective\nContextual Augmentation for Reasoning (MPCAR), a novel inference-time strategy\ndesigned to enhance LVLM performance. MPCAR operates in three stages: first, an\nLVLM generates N diverse and complementary descriptions or preliminary\nreasoning paths from various angles; second, these descriptions are\nintelligently integrated with the original question to construct a\ncomprehensive context-augmented prompt; and finally, this enriched prompt\nguides the ultimate LVLM for deep reasoning and final answer generation.\nCrucially, MPCAR achieves these enhancements without requiring any fine-tuning\nof the underlying LVLM's parameters. Extensive experiments on challenging\nVisual Question Answering (VQA) datasets, including GQA, VQA-CP v2, and\nScienceQA (Image-VQA), demonstrate that MPCAR consistently outperforms\nestablished baseline methods. Our quantitative results show significant\naccuracy gains, particularly on tasks requiring robust contextual\nunderstanding, while human evaluations confirm improved coherence and\ncompleteness of the generated answers. Ablation studies further highlight the\nimportance of diverse prompt templates and the number of generated\nperspectives. This work underscores the efficacy of leveraging LVLMs' inherent\ngenerative capabilities to enrich input contexts, thereby unlocking their\nlatent reasoning potential for complex multimodal tasks.", "AI": {"tldr": "MPCAR is an inference-time strategy that enhances Large Vision-Language Models' performance by generating diverse perspectives and integrating them into comprehensive prompts for better visual reasoning, without requiring model fine-tuning.", "motivation": "Existing LVLMs struggle with complex visual reasoning tasks that require deep contextual understanding and multi-angle analysis due to limitations in single-shot image encoding and prompts.", "method": "A three-stage approach: 1) Generate N diverse descriptions/reasoning paths from various angles, 2) Intelligently integrate these with original questions to create comprehensive context-augmented prompts, 3) Use enriched prompts to guide final reasoning and answer generation.", "result": "Significant accuracy gains on challenging VQA datasets (GQA, VQA-CP v2, ScienceQA), particularly for tasks requiring robust contextual understanding. Human evaluations confirm improved coherence and completeness of answers.", "conclusion": "MPCAR effectively leverages LVLMs' generative capabilities to enrich input contexts, unlocking latent reasoning potential for complex multimodal tasks without parameter fine-tuning."}}
{"id": "2508.13028", "pdf": "https://arxiv.org/pdf/2508.13028", "abs": "https://arxiv.org/abs/2508.13028", "authors": ["Zhu Li", "Yuqing Zhang", "Xiyuan Gao", "Devraj Raghuvanshi", "Nagendra Kumar", "Shekhar Nayak", "Matt Coler"], "title": "Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis", "categories": ["cs.CL"], "comment": "Speech Synthesis Workshop 2025", "summary": "Sarcastic speech synthesis, which involves generating speech that effectively\nconveys sarcasm, is essential for enhancing natural interactions in\napplications such as entertainment and human-computer interaction. However,\nsynthesizing sarcastic speech remains a challenge due to the nuanced prosody\nthat characterizes sarcasm, as well as the limited availability of annotated\nsarcastic speech data. To address these challenges, this study introduces a\nnovel approach that integrates feedback loss from a bi-modal sarcasm detection\nmodel into the TTS training process, enhancing the model's ability to capture\nand convey sarcasm. In addition, by leveraging transfer learning, a speech\nsynthesis model pre-trained on read speech undergoes a two-stage fine-tuning\nprocess. First, it is fine-tuned on a diverse dataset encompassing various\nspeech styles, including sarcastic speech. In the second stage, the model is\nfurther refined using a dataset focused specifically on sarcastic speech,\nenhancing its ability to generate sarcasm-aware speech. Objective and\nsubjective evaluations demonstrate that our proposed methods improve the\nquality, naturalness, and sarcasm-awareness of synthesized speech.", "AI": {"tldr": "Novel sarcastic speech synthesis method using bi-modal feedback loss and two-stage transfer learning to improve sarcasm conveyance in TTS systems.", "motivation": "Sarcastic speech synthesis is challenging due to nuanced prosody and limited annotated data, but essential for natural human-computer interaction and entertainment applications.", "method": "Integrates feedback loss from bi-modal sarcasm detection model into TTS training, plus two-stage fine-tuning: first on diverse speech styles, then specifically on sarcastic speech data.", "result": "Objective and subjective evaluations show improved quality, naturalness, and sarcasm-awareness of synthesized speech.", "conclusion": "The proposed approach effectively addresses sarcastic speech synthesis challenges and enhances the model's ability to capture and convey sarcasm."}}
{"id": "2508.12604", "pdf": "https://arxiv.org/pdf/2508.12604", "abs": "https://arxiv.org/abs/2508.12604", "authors": ["Yuyang Xu", "Yi Cheng", "Haochao Ying", "Zhuoyun Du", "Renjun Hu", "Xing Shi", "Wei Lin", "Jian Wu"], "title": "SSPO: Self-traced Step-wise Preference Optimization for Process Supervision and Reasoning Compression", "categories": ["cs.LG", "cs.AI"], "comment": "Work in progress", "summary": "Test-time scaling has proven effective in further enhancing the performance\nof pretrained Large Language Models (LLMs). However, mainstream post-training\nmethods (i.e., reinforcement learning (RL) with chain-of-thought (CoT)\nreasoning) often incur substantial computational overhead due to auxiliary\nmodels and overthinking. In this paper, we empirically reveal that the\nincorrect answers partially stem from verbose reasoning processes lacking\ncorrect self-fix, where errors accumulate across multiple reasoning steps. To\nthis end, we propose Self-traced Step-wise Preference Optimization (SSPO), a\npluggable RL process supervision framework that enables fine-grained\noptimization of each reasoning step. Specifically, SSPO requires neither\nauxiliary models nor stepwise manual annotations. Instead, it leverages\nstep-wise preference signals generated by the model itself to guide the\noptimization process for reasoning compression. Experiments demonstrate that\nthe generated reasoning sequences from SSPO are both accurate and succinct,\neffectively mitigating overthinking behaviors without compromising model\nperformance across diverse domains and languages.", "AI": {"tldr": "SSPO is a pluggable RL framework that uses self-generated step-wise preference signals to optimize reasoning steps in LLMs, reducing overthinking and improving efficiency without auxiliary models or manual annotations.", "motivation": "Mainstream post-training methods for LLMs incur substantial computational overhead due to auxiliary models and overthinking, with incorrect answers often stemming from verbose reasoning processes lacking correct self-fix where errors accumulate.", "method": "Self-traced Step-wise Preference Optimization (SSPO) - a pluggable RL process supervision framework that leverages step-wise preference signals generated by the model itself to guide optimization for reasoning compression, requiring no auxiliary models or stepwise manual annotations.", "result": "Experiments show SSPO generates accurate and succinct reasoning sequences, effectively mitigating overthinking behaviors without compromising model performance across diverse domains and languages.", "conclusion": "SSPO provides an efficient solution for optimizing LLM reasoning processes through self-generated step-wise preferences, eliminating the need for external resources while maintaining performance across various applications."}}
{"id": "2508.12404", "pdf": "https://arxiv.org/pdf/2508.12404", "abs": "https://arxiv.org/abs/2508.12404", "authors": ["Nan Song", "Bozhou Zhang", "Xiatian Zhu", "Jiankang Deng", "Li Zhang"], "title": "LMAD: Integrated End-to-End Vision-Language Model for Explainable Autonomous Driving", "categories": ["cs.CV"], "comment": "7 pages, 4 figures,", "summary": "Large vision-language models (VLMs) have shown promising capabilities in\nscene understanding, enhancing the explainability of driving behaviors and\ninteractivity with users. Existing methods primarily fine-tune VLMs on on-board\nmulti-view images and scene reasoning text, but this approach often lacks the\nholistic and nuanced scene recognition and powerful spatial awareness required\nfor autonomous driving, especially in complex situations. To address this gap,\nwe propose a novel vision-language framework tailored for autonomous driving,\ncalled LMAD. Our framework emulates modern end-to-end driving paradigms by\nincorporating comprehensive scene understanding and a task-specialized\nstructure with VLMs. In particular, we introduce preliminary scene interaction\nand specialized expert adapters within the same driving task structure, which\nbetter align VLMs with autonomous driving scenarios. Furthermore, our approach\nis designed to be fully compatible with existing VLMs while seamlessly\nintegrating with planning-oriented driving systems. Extensive experiments on\nthe DriveLM and nuScenes-QA datasets demonstrate that LMAD significantly boosts\nthe performance of existing VLMs on driving reasoning tasks,setting a new\nstandard in explainable autonomous driving.", "AI": {"tldr": "LMAD is a novel vision-language framework that enhances autonomous driving by integrating comprehensive scene understanding and specialized expert adapters with existing VLMs, significantly improving driving reasoning performance.", "motivation": "Existing VLM fine-tuning methods for autonomous driving lack holistic scene recognition and spatial awareness needed for complex driving situations, creating a gap in explainable driving systems.", "method": "Proposes LMAD framework that incorporates preliminary scene interaction and specialized expert adapters within a driving task structure, emulating end-to-end driving paradigms while maintaining compatibility with existing VLMs.", "result": "Extensive experiments on DriveLM and nuScenes-QA datasets show LMAD significantly boosts VLM performance on driving reasoning tasks, setting new standards for explainable autonomous driving.", "conclusion": "LMAD successfully addresses the limitations of current VLM approaches by providing better scene understanding and spatial awareness, making it fully compatible with existing systems while enhancing driving reasoning capabilities."}}
{"id": "2508.13037", "pdf": "https://arxiv.org/pdf/2508.13037", "abs": "https://arxiv.org/abs/2508.13037", "authors": ["Xinhe Li", "Jiajun Liu", "Peng Wang"], "title": "Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by IJCAI2025", "summary": "Recent studies have demonstrated that Large Language Models (LLMs) have\nstrong mathematical reasoning abilities but rely on hundreds of billions of\nparameters. To tackle the challenge of poor reasoning in Small Language Models\n(SLMs), existing methods typically leverage LLMs to generate massive amounts of\ndata for cramming training. In psychology, they are akin to System 1 thinking,\nwhich resolves reasoning problems rapidly based on experience and intuition.\nHowever, human learning also requires System 2 thinking, where knowledge is\nfirst acquired and then reinforced through practice. Inspired by such two\ndistinct modes of thinking, we propose a novel method based on the multi-LoRA\nInteraction for mathematical reasoning Distillation (LoRID). First, we input\nthe question and reasoning of each sample into an LLM to create\nknowledge-enhanced datasets. Subsequently, we train a LoRA block on the student\nmodel as an Intuitive Reasoner (IR), which directly generates Chain-of-Thoughts\nfor problem-solving. Then, to imitate System 2 thinking, we train the Knowledge\nGenerator (KG) and Deep Reasoner (DR), respectively. The former outputs only\nknowledge after receiving problems, while the latter uses that knowledge to\nperform reasoning. Finally, to address the randomness in the generation of IR\nand DR, we evaluate whether their outputs are consistent, and the inference\nprocess needs to be iterated if not. This step can enhance the mathematical\nreasoning ability of SLMs through mutual feedback. Experimental results show\nthat LoRID achieves state-of-the-art performance, especially on the GSM8K\ndataset, where it outperforms the second-best method by 2.3%, 16.1%, 2.4%,\n12.3%, and 1.8% accuracy across the five base models, respectively.", "AI": {"tldr": "LoRID is a novel method that uses multi-LoRA interaction to distill mathematical reasoning capabilities from LLMs to SLMs, inspired by System 1 and System 2 thinking, achieving state-of-the-art performance on GSM8K.", "motivation": "To address the poor mathematical reasoning in Small Language Models (SLMs) by drawing inspiration from human dual-thinking systems (System 1 intuitive thinking and System 2 analytical thinking) rather than just cramming massive data.", "method": "Uses multi-LoRA interaction with three components: Intuitive Reasoner (IR) for direct Chain-of-Thought generation, Knowledge Generator (KG) for knowledge extraction, and Deep Reasoner (DR) for knowledge-based reasoning. Includes iterative consistency checking between IR and DR outputs for mutual feedback enhancement.", "result": "Achieves state-of-the-art performance, particularly on GSM8K dataset, outperforming second-best method by 2.3%, 16.1%, 2.4%, 12.3%, and 1.8% accuracy across five different base models.", "conclusion": "The LoRID method successfully enhances mathematical reasoning in SLMs by mimicking human dual-thinking systems through multi-LoRA interaction and iterative consistency checking, demonstrating significant performance improvements over existing approaches."}}
{"id": "2508.12623", "pdf": "https://arxiv.org/pdf/2508.12623", "abs": "https://arxiv.org/abs/2508.12623", "authors": ["Florian J. Boge", "Annika Schuster"], "title": "How can we trust opaque systems? Criteria for robust explanations in XAI", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 1 figure", "summary": "Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in\nscientific research. However, the price we pay for their impressively accurate\npredictions is significant: their inner workings are notoriously opaque - it is\nunknown to laypeople and researchers alike what features of the data a DL\nsystem focuses on and how it ultimately succeeds in predicting correct outputs.\nA necessary criterion for trustworthy explanations is that they should reflect\nthe relevant processes the algorithms' predictions are based on. The field of\neXplainable Artificial Intelligence (XAI) presents promising methods to create\nsuch explanations. But recent reviews about their performance offer reasons for\nskepticism. As we will argue, a good criterion for trustworthiness is\nexplanatory robustness: different XAI methods produce the same explanations in\ncomparable contexts. However, in some instances, all methods may give the same,\nbut still wrong, explanation. We therefore argue that in addition to\nexplanatory robustness (ER), a prior requirement of explanation method\nrobustness (EMR) has to be fulfilled by every XAI method. Conversely, the\nrobustness of an individual method is in itself insufficient for\ntrustworthiness. In what follows, we develop and formalize criteria for ER as\nwell as EMR, providing a framework for explaining and establishing trust in DL\nalgorithms. We also highlight interesting application cases and outline\ndirections for future work.", "AI": {"tldr": "The paper argues that current XAI methods lack trustworthiness and proposes two robustness criteria - explanatory robustness (ER) and explanation method robustness (EMR) - as necessary conditions for trustworthy explanations of deep learning algorithms.", "motivation": "Deep learning algorithms are opaque and their inner workings are unknown, making it difficult to trust their predictions. While XAI methods promise to provide explanations, recent reviews show they may not be reliable.", "method": "The authors develop and formalize criteria for explanatory robustness (different XAI methods producing the same explanations) and explanation method robustness (individual methods producing consistent explanations across similar contexts).", "result": "The paper provides a framework for establishing trust in DL algorithms by requiring both ER and EMR as necessary conditions for trustworthy explanations.", "conclusion": "Robustness of individual XAI methods is insufficient for trustworthiness - both explanatory robustness and explanation method robustness are required to ensure explanations truly reflect the underlying processes of DL algorithms."}}
{"id": "2508.12409", "pdf": "https://arxiv.org/pdf/2508.12409", "abs": "https://arxiv.org/abs/2508.12409", "authors": ["Liang Lv", "Di Wang", "Jing Zhang", "Lefei Zhang"], "title": "S5: Scalable Semi-Supervised Semantic Segmentation in Remote Sensing", "categories": ["cs.CV"], "comment": null, "summary": "Semi-supervised semantic segmentation (S4) has advanced remote sensing (RS)\nanalysis by leveraging unlabeled data through pseudo-labeling and consistency\nlearning. However, existing S4 studies often rely on small-scale datasets and\nmodels, limiting their practical applicability. To address this, we propose S5,\nthe first scalable framework for semi-supervised semantic segmentation in RS,\nwhich unlocks the potential of vast unlabeled Earth observation data typically\nunderutilized due to costly pixel-level annotations. Built upon existing\nlarge-scale RS datasets, S5 introduces a data selection strategy that\nintegrates entropy-based filtering and diversity expansion, resulting in the\nRS4P-1M dataset. Using this dataset, we systematically scales S4 methods by\npre-training RS foundation models (RSFMs) of varying sizes on this extensive\ncorpus, significantly boosting their performance on land cover segmentation and\nobject detection tasks. Furthermore, during fine-tuning, we incorporate a\nMixture-of-Experts (MoE)-based multi-dataset fine-tuning approach, which\nenables efficient adaptation to multiple RS benchmarks with fewer parameters.\nThis approach improves the generalization and versatility of RSFMs across\ndiverse RS benchmarks. The resulting RSFMs achieve state-of-the-art performance\nacross all benchmarks, underscoring the viability of scaling semi-supervised\nlearning for RS applications. All datasets, code, and models will be released\nat https://github.com/MiliLab/S5", "AI": {"tldr": "S5 is a scalable semi-supervised semantic segmentation framework for remote sensing that uses large-scale datasets and foundation models to achieve state-of-the-art performance across multiple benchmarks.", "motivation": "Existing semi-supervised semantic segmentation methods in remote sensing rely on small datasets and models, limiting practical applicability. There's vast unlabeled Earth observation data that remains underutilized due to costly pixel-level annotations.", "method": "Proposes S5 framework with data selection strategy (entropy-based filtering + diversity expansion) creating RS4P-1M dataset. Pre-trains RS foundation models of varying sizes, then uses Mixture-of-Experts-based multi-dataset fine-tuning for efficient adaptation to multiple benchmarks.", "result": "Achieves state-of-the-art performance across all remote sensing benchmarks. Significantly boosts performance on land cover segmentation and object detection tasks. Improves generalization and versatility of RS foundation models.", "conclusion": "Scaling semi-supervised learning is viable for remote sensing applications. The framework successfully leverages vast unlabeled data and enables efficient adaptation to multiple tasks with fewer parameters."}}
{"id": "2508.13044", "pdf": "https://arxiv.org/pdf/2508.13044", "abs": "https://arxiv.org/abs/2508.13044", "authors": ["M. Ali Bayram", "Ali Arda Fincan", "Ahmet Semih G\u00fcm\u00fc\u015f", "Banu Diri", "Sava\u015f Y\u0131ld\u0131r\u0131m", "\u00d6ner Ayta\u015f"], "title": "B\u00fcy\u00fck Dil Modelleri i\u00e7in TR-MMLU Benchmark\u0131: Performans De\u011ferlendirmesi, Zorluklar ve \u0130yile\u015ftirme F\u0131rsatlar\u0131", "categories": ["cs.CL", "68T50", "I.2.7; I.2.6"], "comment": "10 pages, in Turkish language, 5 figures. Presented at the 2025 33rd\n  Signal Processing and Communications Applications Conference (SIU), 25--28\n  June 2025, Sile, Istanbul, T\\\"urkiye", "summary": "Language models have made significant advancements in understanding and\ngenerating human language, achieving remarkable success in various\napplications. However, evaluating these models remains a challenge,\nparticularly for resource-limited languages like Turkish. To address this\nissue, we introduce the Turkish MMLU (TR-MMLU) benchmark, a comprehensive\nevaluation framework designed to assess the linguistic and conceptual\ncapabilities of large language models (LLMs) in Turkish. TR-MMLU is based on a\nmeticulously curated dataset comprising 6,200 multiple-choice questions across\n62 sections within the Turkish education system. This benchmark provides a\nstandard framework for Turkish NLP research, enabling detailed analyses of\nLLMs' capabilities in processing Turkish text. In this study, we evaluated\nstate-of-the-art LLMs on TR-MMLU, highlighting areas for improvement in model\ndesign. TR-MMLU sets a new standard for advancing Turkish NLP research and\ninspiring future innovations.", "AI": {"tldr": "Introduces TR-MMLU benchmark for evaluating Turkish language models with 6,200 multiple-choice questions across 62 educational sections.", "motivation": "Address the challenge of evaluating language models for resource-limited languages like Turkish, where comprehensive evaluation frameworks are lacking.", "method": "Created a meticulously curated dataset of 6,200 multiple-choice questions organized into 62 sections based on the Turkish education system to assess linguistic and conceptual capabilities.", "result": "Evaluated state-of-the-art LLMs on TR-MMLU, identifying specific areas for improvement in model design for Turkish language processing.", "conclusion": "TR-MMLU establishes a new standard for Turkish NLP research, providing a comprehensive evaluation framework that enables detailed analysis and inspires future innovations in Turkish language model development."}}
{"id": "2508.12629", "pdf": "https://arxiv.org/pdf/2508.12629", "abs": "https://arxiv.org/abs/2508.12629", "authors": ["Ian Dunn", "David R. Koes"], "title": "FlowMol3: Flow Matching for 3D De Novo Small-Molecule Generation", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "A generative model capable of sampling realistic molecules with desired\nproperties could accelerate chemical discovery across a wide range of\napplications. Toward this goal, significant effort has focused on developing\nmodels that jointly sample molecular topology and 3D structure. We present\nFlowMol3, an open-source, multi-modal flow matching model that advances the\nstate of the art for all-atom, small-molecule generation. Its substantial\nperformance gains over previous FlowMol versions are achieved without changes\nto the graph neural network architecture or the underlying flow matching\nformulation. Instead, FlowMol3's improvements arise from three\narchitecture-agnostic techniques that incur negligible computational cost:\nself-conditioning, fake atoms, and train-time geometry distortion. FlowMol3\nachieves nearly 100% molecular validity for drug-like molecules with explicit\nhydrogens, more accurately reproduces the functional group composition and\ngeometry of its training data, and does so with an order of magnitude fewer\nlearnable parameters than comparable methods. We hypothesize that these\ntechniques mitigate a general pathology affecting transport-based generative\nmodels, enabling detection and correction of distribution drift during\ninference. Our results highlight simple, transferable strategies for improving\nthe stability and quality of diffusion- and flow-based molecular generative\nmodels.", "AI": {"tldr": "FlowMol3 is an improved flow matching model for generating valid 3D drug-like molecules with 100% validity using three simple, low-cost techniques: self-conditioning, fake atoms, and train-time geometry distortion.", "motivation": "To accelerate chemical discovery by developing a generative model that can sample realistic molecules with desired properties, particularly focusing on jointly sampling molecular topology and 3D structure.", "method": "Uses flow matching with three architecture-agnostic techniques: self-conditioning, fake atoms, and train-time geometry distortion. These are applied without changing the graph neural network architecture or flow matching formulation.", "result": "Achieves nearly 100% molecular validity for drug-like molecules, more accurately reproduces functional group composition and geometry of training data, and uses an order of magnitude fewer parameters than comparable methods.", "conclusion": "The three simple techniques mitigate distribution drift during inference and provide transferable strategies for improving stability and quality of diffusion- and flow-based molecular generative models."}}
{"id": "2508.12410", "pdf": "https://arxiv.org/pdf/2508.12410", "abs": "https://arxiv.org/abs/2508.12410", "authors": ["Jun Zeng", "Yannan Huang", "Elif Keles", "Halil Ertugrul Aktas", "Gorkem Durak", "Nikhil Kumar Tomar", "Quoc-Huy Trinh", "Deepak Ranjan Nayak", "Ulas Bagci", "Debesh Jha"], "title": "SRMA-Mamba: Spatial Reverse Mamba Attention Network for Pathological Liver Segmentation in MRI Volumes", "categories": ["cs.CV", "cs.AI"], "comment": "9 pages, 4 figures", "summary": "Liver Cirrhosis plays a critical role in the prognosis of chronic liver\ndisease. Early detection and timely intervention are critical in significantly\nreducing mortality rates. However, the intricate anatomical architecture and\ndiverse pathological changes of liver tissue complicate the accurate detection\nand characterization of lesions in clinical settings. Existing methods\nunderutilize the spatial anatomical details in volumetric MRI data, thereby\nhindering their clinical effectiveness and explainability. To address this\nchallenge, we introduce a novel Mamba-based network, SRMA-Mamba, designed to\nmodel the spatial relationships within the complex anatomical structures of MRI\nvolumes. By integrating the Spatial Anatomy-Based Mamba module (SABMamba),\nSRMA-Mamba performs selective Mamba scans within liver cirrhotic tissues and\ncombines anatomical information from the sagittal, coronal, and axial planes to\nconstruct a global spatial context representation, enabling efficient\nvolumetric segmentation of pathological liver structures. Furthermore, we\nintroduce the Spatial Reverse Attention module (SRMA), designed to\nprogressively refine cirrhotic details in the segmentation map, utilizing both\nthe coarse segmentation map and hierarchical encoding features. Extensive\nexperiments demonstrate that SRMA-Mamba surpasses state-of-the-art methods,\ndelivering exceptional performance in 3D pathological liver segmentation. Our\ncode is available for public:\n{\\color{blue}{https://github.com/JunZengz/SRMA-Mamba}}.", "AI": {"tldr": "SRMA-Mamba is a novel Mamba-based network for 3D liver cirrhosis segmentation in MRI volumes that integrates spatial anatomical relationships and uses selective scanning with reverse attention to achieve state-of-the-art performance.", "motivation": "Early detection of liver cirrhosis is critical for reducing mortality, but existing methods underutilize spatial anatomical details in volumetric MRI data, limiting clinical effectiveness and explainability.", "method": "Proposes SRMA-Mamba with Spatial Anatomy-Based Mamba module (SABMamba) that performs selective Mamba scans within cirrhotic tissues and combines anatomical information from sagittal, coronal, and axial planes. Also introduces Spatial Reverse Attention module (SRMA) to progressively refine segmentation details using coarse maps and hierarchical encoding features.", "result": "Extensive experiments demonstrate that SRMA-Mamba surpasses state-of-the-art methods, delivering exceptional performance in 3D pathological liver segmentation.", "conclusion": "The proposed SRMA-Mamba network effectively addresses the challenge of modeling spatial relationships in complex liver anatomical structures and achieves superior volumetric segmentation of pathological liver tissues compared to existing approaches."}}
{"id": "2508.13058", "pdf": "https://arxiv.org/pdf/2508.13058", "abs": "https://arxiv.org/abs/2508.13058", "authors": ["M. Ali Bayram", "Ali Arda Fincan", "Ahmet Semih G\u00fcm\u00fc\u015f", "Sercan Karaka\u015f", "Banu Diri", "Sava\u015f Y\u0131ld\u0131r\u0131m"], "title": "Do\u011fal Dil \u0130\u015flemede Tokenizasyon Standartlar\u0131 ve \u00d6l\u00e7\u00fcm\u00fc: T\u00fcrk\u00e7e \u00dczerinden B\u00fcy\u00fck Dil Modellerinin Kar\u015f\u0131la\u015ft\u0131rmal\u0131 Analizi", "categories": ["cs.CL", "68T50", "I.2.7; I.2.6"], "comment": "in Turkish language, Presented at the 2025 33rd Signal Processing and\n  Communications Applications Conference (SIU), 25--28 June 2025, \\c{S}ile,\n  Istanbul, T\\\"urkiye", "summary": "Tokenization is a fundamental preprocessing step in Natural Language\nProcessing (NLP), significantly impacting the capability of large language\nmodels (LLMs) to capture linguistic and semantic nuances. This study introduces\na novel evaluation framework addressing tokenization challenges specific to\nmorphologically-rich and low-resource languages such as Turkish. Utilizing the\nTurkish MMLU (TR-MMLU) dataset, comprising 6,200 multiple-choice questions from\nthe Turkish education system, we assessed tokenizers based on vocabulary size,\ntoken count, processing time, language-specific token percentages (\\%TR), and\ntoken purity (\\%Pure). These newly proposed metrics measure how effectively\ntokenizers preserve linguistic structures. Our analysis reveals that\nlanguage-specific token percentages exhibit a stronger correlation with\ndownstream performance (e.g., MMLU scores) than token purity. Furthermore,\nincreasing model parameters alone does not necessarily enhance linguistic\nperformance, underscoring the importance of tailored, language-specific\ntokenization methods. The proposed framework establishes robust and practical\ntokenization standards for morphologically complex languages.", "AI": {"tldr": "Novel evaluation framework for tokenization in morphologically-rich languages like Turkish, showing language-specific token percentage correlates better with downstream performance than token purity.", "motivation": "Tokenization significantly impacts LLM performance, especially for morphologically-rich and low-resource languages that face unique challenges in preserving linguistic structures.", "method": "Used Turkish MMLU dataset (6,200 questions) to evaluate tokenizers based on vocabulary size, token count, processing time, language-specific token percentages (%TR), and token purity (%Pure).", "result": "Language-specific token percentages showed stronger correlation with downstream performance than token purity. Increasing model parameters alone doesn't improve linguistic performance.", "conclusion": "Tailored language-specific tokenization methods are crucial for morphologically complex languages, and the proposed framework establishes practical tokenization standards."}}
{"id": "2508.12650", "pdf": "https://arxiv.org/pdf/2508.12650", "abs": "https://arxiv.org/abs/2508.12650", "authors": ["Jiyeon Kang", "Songseong Kim", "Chanhui Lee", "Doyeong Hwang", "Joanie Hayoun Chung", "Yunkyung Ko", "Sumin Lee", "Sungwoong Kim", "Sungbin Lim"], "title": "Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery", "categories": ["cs.LG", "cs.AI", "I.2.6; I.2.8"], "comment": "32 pages, 17 figures, 5 tables", "summary": "Ordering-based approaches to causal discovery identify topological orders of\ncausal graphs, providing scalable alternatives to combinatorial search methods.\nUnder the Additive Noise Model (ANM) assumption, recent causal ordering methods\nbased on score matching require an accurate estimation of the Hessian diagonal\nof the log-densities. However, previous approaches mainly use Stein gradient\nestimators, which are computationally expensive and memory-intensive. Although\nDiffAN addresses these limitations by substituting kernel-based estimates with\ndiffusion models, it remains numerically unstable due to the second-order\nderivatives of score models. To alleviate these problems, we propose\nScore-informed Neural Operator (SciNO), a probabilistic generative model in\nsmooth function spaces designed to stably approximate the Hessian diagonal and\nto preserve structural information during the score modeling. Empirical results\nshow that SciNO reduces order divergence by 42.7% on synthetic graphs and by\n31.5% on real-world datasets on average compared to DiffAN, while maintaining\nmemory efficiency and scalability. Furthermore, we propose a probabilistic\ncontrol algorithm for causal reasoning with autoregressive models that\nintegrates SciNO's probability estimates with autoregressive model priors,\nenabling reliable data-driven causal ordering informed by semantic information.\nConsequently, the proposed method enhances causal reasoning abilities of LLMs\nwithout additional fine-tuning or prompt engineering.", "AI": {"tldr": "SciNO is a neural operator model that improves causal discovery by providing stable Hessian diagonal approximations for score matching, reducing order divergence by 42.7% on synthetic and 31.5% on real data compared to previous methods, while enabling better causal reasoning in LLMs.", "motivation": "Existing causal ordering methods using Stein gradient estimators are computationally expensive and memory-intensive, while DiffAN suffers from numerical instability due to second-order derivatives of score models.", "method": "Proposes Score-informed Neural Operator (SciNO), a probabilistic generative model in smooth function spaces that stably approximates Hessian diagonal and preserves structural information during score modeling. Also introduces a probabilistic control algorithm integrating SciNO's probability estimates with autoregressive model priors.", "result": "SciNO reduces order divergence by 42.7% on synthetic graphs and 31.5% on real-world datasets compared to DiffAN, while maintaining memory efficiency and scalability. Enhances causal reasoning abilities of LLMs without additional fine-tuning.", "conclusion": "SciNO provides a stable and efficient approach for causal discovery that significantly outperforms existing methods and enables improved causal reasoning capabilities in large language models through probabilistic integration with autoregressive priors."}}
{"id": "2508.11681", "pdf": "https://arxiv.org/pdf/2508.11681", "abs": "https://arxiv.org/abs/2508.11681", "authors": ["Vincent C. M\u00fcller", "Nick Bostrom"], "title": "Future progress in artificial intelligence: A survey of expert opinion", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "There is, in some quarters, concern about high-level machine intelligence and\nsuperintelligent AI coming up in a few decades, bringing with it significant\nrisks for humanity. In other quarters, these issues are ignored or considered\nscience fiction. We wanted to clarify what the distribution of opinions\nactually is, what probability the best experts currently assign to high-level\nmachine intelligence coming up within a particular time-frame, which risks they\nsee with that development, and how fast they see these developing. We thus\ndesigned a brief questionnaire and distributed it to four groups of experts in\n2012/2013. The median estimate of respondents was for a one in two chance that\nhigh-level machine intelligence will be developed around 2040-2050, rising to a\nnine in ten chance by 2075. Experts expect that systems will move on to\nsuperintelligence in less than 30 years thereafter. They estimate the chance is\nabout one in three that this development turns out to be 'bad' or 'extremely\nbad' for humanity.", "AI": {"tldr": "Expert survey shows 50% chance of high-level machine intelligence by 2040-2050, 90% by 2075, with superintelligence following within 30 years and 1/3 chance of negative outcomes for humanity.", "motivation": "To clarify expert opinions on the timeline and risks of high-level machine intelligence and superintelligent AI development, addressing concerns about potential risks to humanity.", "method": "Designed and distributed a brief questionnaire to four groups of AI experts in 2012/2013 to gather their estimates on development timelines and risk assessments.", "result": "Median expert estimates: 50% chance of high-level machine intelligence by 2040-2050, 90% chance by 2075; superintelligence expected within 30 years after; 33% chance of bad/extremely bad outcomes for humanity.", "conclusion": "AI experts predict rapid development of advanced AI systems with significant probability of negative consequences, highlighting the need for careful consideration of AI safety and governance."}}
{"id": "2508.12415", "pdf": "https://arxiv.org/pdf/2508.12415", "abs": "https://arxiv.org/abs/2508.12415", "authors": ["Ke Xing", "Hanwen Liang", "Dejia Xu", "Yuyang Yin", "Konstantinos N. Plataniotis", "Yao Zhao", "Yunchao Wei"], "title": "TiP4GEN: Text to Immersive Panorama 4D Scene Generation", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid advancement and widespread adoption of VR/AR technologies,\nthere is a growing demand for the creation of high-quality, immersive dynamic\nscenes. However, existing generation works predominantly concentrate on the\ncreation of static scenes or narrow perspective-view dynamic scenes, falling\nshort of delivering a truly 360-degree immersive experience from any viewpoint.\nIn this paper, we introduce \\textbf{TiP4GEN}, an advanced text-to-dynamic\npanorama scene generation framework that enables fine-grained content control\nand synthesizes motion-rich, geometry-consistent panoramic 4D scenes. TiP4GEN\nintegrates panorama video generation and dynamic scene reconstruction to create\n360-degree immersive virtual environments. For video generation, we introduce a\n\\textbf{Dual-branch Generation Model} consisting of a panorama branch and a\nperspective branch, responsible for global and local view generation,\nrespectively. A bidirectional cross-attention mechanism facilitates\ncomprehensive information exchange between the branches. For scene\nreconstruction, we propose a \\textbf{Geometry-aligned Reconstruction Model}\nbased on 3D Gaussian Splatting. By aligning spatial-temporal point clouds using\nmetric depth maps and initializing scene cameras with estimated poses, our\nmethod ensures geometric consistency and temporal coherence for the\nreconstructed scenes. Extensive experiments demonstrate the effectiveness of\nour proposed designs and the superiority of TiP4GEN in generating visually\ncompelling and motion-coherent dynamic panoramic scenes. Our project page is at\nhttps://ke-xing.github.io/TiP4GEN/.", "AI": {"tldr": "TiP4GEN is a text-to-dynamic panorama scene generation framework that creates 360-degree immersive 4D scenes with fine-grained content control and motion-rich, geometry-consistent panoramic environments.", "motivation": "Existing VR/AR generation works focus on static scenes or narrow perspective-view dynamic scenes, lacking true 360-degree immersive experiences from any viewpoint.", "method": "Combines panorama video generation (using Dual-branch Generation Model with panorama and perspective branches + bidirectional cross-attention) and dynamic scene reconstruction (Geometry-aligned Reconstruction Model based on 3D Gaussian Splatting with metric depth maps and estimated camera poses).", "result": "Extensive experiments demonstrate effectiveness and superiority in generating visually compelling and motion-coherent dynamic panoramic scenes.", "conclusion": "TiP4GEN successfully addresses the gap in 360-degree immersive dynamic scene generation with fine-grained control and geometric consistency."}}
{"id": "2508.13060", "pdf": "https://arxiv.org/pdf/2508.13060", "abs": "https://arxiv.org/abs/2508.13060", "authors": ["John Alderete", "Macarious Kin Fung Hui", "Aanchan Mohan"], "title": "Evaluating ASR robustness to spontaneous speech errors: A study of WhisperX using a Speech Error Database", "categories": ["cs.CL"], "comment": "5 pages, 6 figures, 1 table, Interspeech 2025 (Rotterdam)", "summary": "The Simon Fraser University Speech Error Database (SFUSED) is a public data\ncollection developed for linguistic and psycholinguistic research. Here we\ndemonstrate how its design and annotations can be used to test and evaluate\nspeech recognition models. The database comprises systematically annotated\nspeech errors from spontaneous English speech, with each error tagged for\nintended and actual error productions. The annotation schema incorporates\nmultiple classificatory dimensions that are of some value to model assessment,\nincluding linguistic hierarchical level, contextual sensitivity, degraded\nwords, word corrections, and both word-level and syllable-level error\npositioning. To assess the value of these classificatory variables, we\nevaluated the transcription accuracy of WhisperX across 5,300 documented word\nand phonological errors. This analysis demonstrates the atabase's effectiveness\nas a diagnostic tool for ASR system performance.", "AI": {"tldr": "SFUSED database provides annotated speech errors for evaluating speech recognition models like WhisperX, demonstrating its value as a diagnostic tool for ASR system performance assessment.", "motivation": "To create a systematic framework for testing and evaluating speech recognition models using annotated speech error data from spontaneous English speech, addressing the need for comprehensive diagnostic tools in ASR assessment.", "method": "Developed the Simon Fraser University Speech Error Database (SFUSED) with systematic annotations of speech errors, including multiple classificatory dimensions like linguistic hierarchical level, contextual sensitivity, degraded words, word corrections, and error positioning at both word and syllable levels. Evaluated WhisperX transcription accuracy across 5,300 documented word and phonological errors.", "result": "The database effectively serves as a diagnostic tool for assessing ASR system performance, demonstrating its utility through evaluation of WhisperX's transcription accuracy across thousands of documented speech errors.", "conclusion": "SFUSED provides a valuable resource for linguistic and psycholinguistic research and offers an effective framework for testing and evaluating speech recognition models, with comprehensive annotations that enable detailed performance assessment across multiple classificatory dimensions."}}
{"id": "2508.12672", "pdf": "https://arxiv.org/pdf/2508.12672", "abs": "https://arxiv.org/abs/2508.12672", "authors": ["Emmanouil Kritharakis", "Dusan Jakovetic", "Antonios Makris", "Konstantinos Tserpes"], "title": "Robust Federated Learning under Adversarial Attacks via Loss-Based Client Clustering", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 5 figures", "summary": "Federated Learning (FL) enables collaborative model training across multiple\nclients without sharing private data. We consider FL scenarios wherein FL\nclients are subject to adversarial (Byzantine) attacks, while the FL server is\ntrusted (honest) and has a trustworthy side dataset. This may correspond to,\ne.g., cases where the server possesses trusted data prior to federation, or to\nthe presence of a trusted client that temporarily assumes the server role. Our\napproach requires only two honest participants, i.e., the server and one\nclient, to function effectively, without prior knowledge of the number of\nmalicious clients. Theoretical analysis demonstrates bounded optimality gaps\neven under strong Byzantine attacks. Experimental results show that our\nalgorithm significantly outperforms standard and robust FL baselines such as\nMean, Trimmed Mean, Median, Krum, and Multi-Krum under various attack\nstrategies including label flipping, sign flipping, and Gaussian noise addition\nacross MNIST, FMNIST, and CIFAR-10 benchmarks using the Flower framework.", "AI": {"tldr": "Robust federated learning algorithm that requires only one honest client and a trusted server with side data to defend against Byzantine attacks, outperforming existing baselines.", "motivation": "Federated learning is vulnerable to adversarial (Byzantine) attacks from malicious clients, and existing robust aggregation methods often require knowing the number of malicious clients or have limited effectiveness.", "method": "Proposes a FL approach that uses a trusted server with trustworthy side dataset and requires only one honest client to function effectively, without prior knowledge of malicious client count. Uses theoretical analysis to bound optimality gaps under strong attacks.", "result": "Significantly outperforms standard and robust FL baselines (Mean, Trimmed Mean, Median, Krum, Multi-Krum) under various attack strategies including label flipping, sign flipping, and Gaussian noise across MNIST, FMNIST, and CIFAR-10 benchmarks using Flower framework.", "conclusion": "The approach provides effective Byzantine robustness in FL with minimal trust assumptions (only server and one honest client needed) and no prior knowledge of attack scale, demonstrating strong theoretical guarantees and empirical performance."}}
{"id": "2508.11682", "pdf": "https://arxiv.org/pdf/2508.11682", "abs": "https://arxiv.org/abs/2508.11682", "authors": ["Md Basit Azam", "Sarangthem Ibotombi Singh"], "title": "Age-Normalized HRV Features for Non-Invasive Glucose Prediction: A Pilot Sleep-Aware Machine Learning Study", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Non-invasive glucose monitoring remains a critical challenge in the\nmanagement of diabetes. HRV during sleep shows promise for glucose prediction\nhowever, age-related autonomic changes significantly confound traditional HRV\nanalyses. We analyzed 43 subjects with multi-modal data including sleep-stage\nspecific ECG, HRV features, and clinical measurements. A novel\nage-normalization technique was applied to the HRV features by, dividing the\nraw values by age-scaled factors. BayesianRidge regression with 5-fold\ncross-validation was employed for log-glucose prediction. Age-normalized HRV\nfeatures achieved R2 = 0.161 (MAE = 0.182) for log-glucose prediction,\nrepresenting a 25.6% improvement over non-normalized features (R2 = 0.132). The\ntop predictive features were hrv rem mean rr age normalized (r = 0.443, p =\n0.004), hrv ds mean rr age normalized (r = 0.438, p = 0.005), and diastolic\nblood pressure (r = 0.437, p = 0.005). Systematic ablation studies confirmed\nage-normalization as the critical component, with sleep-stage specific features\nproviding additional predictive value. Age-normalized HRV features\nsignificantly enhance glucose prediction accuracy compared with traditional\napproaches. This sleep-aware methodology addresses fundamental limitations in\nautonomic function assessment and suggests a preliminary feasibility for\nnon-invasive glucose monitoring applications. However, these results require\nvalidation in larger cohorts before clinical consideration.", "AI": {"tldr": "Age-normalized HRV features during sleep improve glucose prediction by 25.6% compared to traditional methods, addressing age-related confounding factors in autonomic function assessment.", "motivation": "Non-invasive glucose monitoring is critical for diabetes management, but traditional HRV analyses are confounded by age-related autonomic changes, limiting their predictive accuracy.", "method": "Analyzed 43 subjects with multi-modal data including sleep-stage specific ECG, HRV features, and clinical measurements. Applied novel age-normalization to HRV features by dividing raw values by age-scaled factors. Used BayesianRidge regression with 5-fold cross-validation for log-glucose prediction.", "result": "Age-normalized HRV features achieved R2 = 0.161 (MAE = 0.182), representing 25.6% improvement over non-normalized features (R2 = 0.132). Top predictive features were REM sleep HRV mean RR, deep sleep HRV mean RR, and diastolic blood pressure.", "conclusion": "Age-normalized HRV features significantly enhance glucose prediction accuracy and suggest preliminary feasibility for non-invasive glucose monitoring, though validation in larger cohorts is needed before clinical application."}}
{"id": "2508.12422", "pdf": "https://arxiv.org/pdf/2508.12422", "abs": "https://arxiv.org/abs/2508.12422", "authors": ["Jianyi Yang", "Junyi Ye", "Ankan Dash", "Guiling Wang"], "title": "Illusions in Humans and AI: How Visual Perception Aligns and Diverges", "categories": ["cs.CV"], "comment": null, "summary": "By comparing biological and artificial perception through the lens of\nillusions, we highlight critical differences in how each system constructs\nvisual reality. Understanding these divergences can inform the development of\nmore robust, interpretable, and human-aligned artificial intelligence (AI)\nvision systems. In particular, visual illusions expose how human perception is\nbased on contextual assumptions rather than raw sensory data. As artificial\nvision systems increasingly perform human-like tasks, it is important to ask:\ndoes AI experience illusions, too? Does it have unique illusions? This article\nexplores how AI responds to classic visual illusions that involve color, size,\nshape, and motion. We find that some illusion-like effects can emerge in these\nmodels, either through targeted training or as by-products of pattern\nrecognition. In contrast, we also identify illusions unique to AI, such as\npixel-level sensitivity and hallucinations, that lack human counterparts. By\nsystematically comparing human and AI responses to visual illusions, we uncover\nalignment gaps and AI-specific perceptual vulnerabilities invisible to human\nperception. These findings provide insights for future research on vision\nsystems that preserve human-beneficial perceptual biases while avoiding\ndistortions that undermine trust and safety.", "AI": {"tldr": "Comparison of human and AI visual perception through illusion responses reveals critical differences, with AI showing both human-like illusion effects and unique vulnerabilities like pixel sensitivity and hallucinations.", "motivation": "To understand how artificial vision systems differ from biological perception and identify AI-specific perceptual vulnerabilities that could impact trust and safety in AI systems performing human-like visual tasks.", "method": "Systematic comparison of human and AI responses to classic visual illusions involving color, size, shape, and motion, examining both targeted training effects and emergent pattern recognition behaviors.", "result": "AI shows some human-like illusion effects but also exhibits unique vulnerabilities including pixel-level sensitivity and hallucinations that lack human counterparts, revealing alignment gaps and AI-specific perceptual weaknesses.", "conclusion": "Understanding these perceptual differences provides insights for developing more robust, interpretable, and human-aligned AI vision systems that preserve beneficial human perceptual biases while avoiding distortions that undermine trust and safety."}}
{"id": "2508.13070", "pdf": "https://arxiv.org/pdf/2508.13070", "abs": "https://arxiv.org/abs/2508.13070", "authors": ["Long Ma", "Fangwei Zhong", "Yizhou Wang"], "title": "Reinforced Context Order Recovery for Adaptive Reasoning and Planning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Modern causal language models, followed by rapid developments in discrete\ndiffusion models, can now produce a wide variety of interesting and useful\ncontent. However, these families of models are predominantly trained to output\ntokens with a fixed (left-to-right) or random order, which may deviate from the\nlogical order in which tokens are generated originally. In this paper, we\nobserve that current causal and diffusion models encounter difficulties in\nproblems that require adaptive token generation orders to solve tractably,\nwhich we characterize with the $\\mathcal{V}$-information framework. Motivated\nby this, we propose Reinforced Context Order Recovery (ReCOR), a\nreinforcement-learning-based framework to extract adaptive, data-dependent\ntoken generation orders from text data without annotations. Self-supervised by\ntoken prediction statistics, ReCOR estimates the hardness of predicting every\nunfilled token and adaptively selects the next token during both training and\ninference. Experiments on challenging reasoning and planning datasets\ndemonstrate the superior performance of ReCOR compared with baselines,\nsometimes outperforming oracle models supervised with the ground-truth order.", "AI": {"tldr": "ReCOR is a reinforcement learning framework that learns adaptive token generation orders from unannotated text data, improving performance on reasoning and planning tasks by selecting tokens based on prediction difficulty rather than fixed orders.", "motivation": "Current causal and diffusion models use fixed or random token generation orders that may not align with logical reasoning sequences, causing difficulties in tasks requiring adaptive generation strategies.", "method": "Reinforcement-learning-based framework that self-supervises by estimating token prediction difficulty and adaptively selects the next token during training and inference without requiring order annotations.", "result": "Superior performance on challenging reasoning and planning datasets, sometimes outperforming oracle models that use ground-truth generation orders.", "conclusion": "Adaptive token generation orders learned through reinforcement learning can significantly improve model performance on complex reasoning tasks compared to fixed-order generation approaches."}}
{"id": "2508.12673", "pdf": "https://arxiv.org/pdf/2508.12673", "abs": "https://arxiv.org/abs/2508.12673", "authors": ["Yuhao Zhou", "Jindi Lv", "Yuxin Tian", "Dan Si", "Qing Ye", "Jiancheng Lv"], "title": "Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages", "summary": "Federated Learning (FL) has emerged as a promising paradigm for\nprivacy-preserving collaborative learning, yet data heterogeneity remains a\ncritical challenge. While existing methods achieve progress in addressing data\nheterogeneity for participating clients, they fail to generalize to\nnon-participating clients with in-domain distribution shifts and resource\nconstraints. To mitigate this issue, we present HyperFedZero, a novel method\nthat dynamically generates specialized models via a hypernetwork conditioned on\ndistribution-aware embeddings. Our approach explicitly incorporates\ndistribution-aware inductive biases into the model's forward pass, extracting\nrobust distribution embeddings using a NoisyEmbed-enhanced extractor with a\nBalancing Penalty, effectively preventing feature collapse. The hypernetwork\nthen leverages these embeddings to generate specialized models chunk-by-chunk\nfor non-participating clients, ensuring adaptability to their unique data\ndistributions. Extensive experiments on multiple datasets and models\ndemonstrate HyperFedZero's remarkable performance, surpassing competing methods\nconsistently with minimal computational, storage, and communication overhead.\nMoreover, ablation studies and visualizations further validate the necessity of\neach component, confirming meaningful adaptations and validating the\neffectiveness of HyperFedZero.", "AI": {"tldr": "HyperFedZero is a federated learning method that uses hypernetworks to generate specialized models for non-participating clients with data distribution shifts, addressing generalization challenges through distribution-aware embeddings.", "motivation": "Existing federated learning methods fail to generalize to non-participating clients with in-domain distribution shifts and resource constraints, creating a need for more adaptable solutions.", "method": "Dynamically generates specialized models via hypernetwork conditioned on distribution-aware embeddings, using NoisyEmbed-enhanced extractor with Balancing Penalty to prevent feature collapse and generate models chunk-by-chunk.", "result": "Extensive experiments show remarkable performance surpassing competing methods with minimal computational, storage, and communication overhead. Ablation studies confirm component effectiveness.", "conclusion": "HyperFedZero effectively addresses generalization to non-participating clients in federated learning through distribution-aware model specialization, validated by comprehensive experiments."}}
{"id": "2508.11689", "pdf": "https://arxiv.org/pdf/2508.11689", "abs": "https://arxiv.org/abs/2508.11689", "authors": ["Eduardo Calle-Ortiz", "Hui Guan", "Deepak Ganesan", "Phuc Nguyen"], "title": "Adaptive Spiking with Plasticity for Energy Aware Neuromorphic Systems", "categories": ["cs.NE", "cs.AI", "q-bio.NC"], "comment": "14 pages", "summary": "This paper presents ASPEN, a novel energy-aware technique for neuromorphic\nsystems that could unleash the future of intelligent, always-on,\nultra-low-power, and low-burden wearables. Our main research objectives are to\nexplore the feasibility of neuromorphic computing for wearables, identify open\nresearch directions, and demonstrate the feasibility of developing an adaptive\nspiking technique for energy-aware computation, which can be game-changing for\nresource-constrained devices in always-on applications. As neuromorphic\ncomputing systems operate based on spike events, their energy consumption is\nclosely related to spiking activity, i.e., each spike incurs computational and\npower costs; consequently, minimizing the number of spikes is a critical\nstrategy for operating under constrained energy budgets. To support this goal,\nASPEN utilizes stochastic perturbations to the neuronal threshold during\ntraining to not only enhance the network's robustness across varying\nthresholds, which can be controlled at inference time, but also act as a\nregularizer that improves generalization, reduces spiking activity, and enables\nenergy control without the need for complex retraining or pruning. More\nspecifically, ASPEN adaptively adjusts intrinsic neuronal parameters as a\nlightweight and scalable technique for dynamic energy control without\nreconfiguring the entire model. Our evaluation on neuromorphic emulator and\nhardware shows that ASPEN significantly reduces spike counts and energy\nconsumption while maintaining accuracy comparable to state-of-the-art methods.", "AI": {"tldr": "ASPEN is an energy-aware neuromorphic technique that uses stochastic threshold perturbations during training to reduce spike counts and energy consumption in wearables while maintaining accuracy.", "motivation": "Neuromorphic systems for wearables need ultra-low-power operation. Since energy consumption is tied to spiking activity, minimizing spikes is crucial for energy-constrained always-on applications.", "method": "ASPEN applies stochastic perturbations to neuronal thresholds during training to enhance robustness, improve generalization, and reduce spiking activity. It adaptively adjusts intrinsic neuronal parameters for dynamic energy control without model reconfiguration.", "result": "Evaluation on neuromorphic emulator and hardware shows ASPEN significantly reduces spike counts and energy consumption while maintaining accuracy comparable to state-of-the-art methods.", "conclusion": "ASPEN provides a lightweight, scalable technique for energy control in neuromorphic wearables without complex retraining or pruning, enabling efficient always-on operation."}}
{"id": "2508.12430", "pdf": "https://arxiv.org/pdf/2508.12430", "abs": "https://arxiv.org/abs/2508.12430", "authors": ["Yahsin Yeh", "Yilun Wu", "Bokai Ruan", "Honghan Shuai"], "title": "Adversarial Attacks on VQA-NLE: Exposing and Alleviating Inconsistencies in Visual Question Answering Explanations", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Natural language explanations in visual question answering (VQA-NLE) aim to\nmake black-box models more transparent by elucidating their decision-making\nprocesses. However, we find that existing VQA-NLE systems can produce\ninconsistent explanations and reach conclusions without genuinely understanding\nthe underlying context, exposing weaknesses in either their inference pipeline\nor explanation-generation mechanism. To highlight these vulnerabilities, we not\nonly leverage an existing adversarial strategy to perturb questions but also\npropose a novel strategy that minimally alters images to induce contradictory\nor spurious outputs. We further introduce a mitigation method that leverages\nexternal knowledge to alleviate these inconsistencies, thereby bolstering model\nrobustness. Extensive evaluations on two standard benchmarks and two widely\nused VQA-NLE models underscore the effectiveness of our attacks and the\npotential of knowledge-based defenses, ultimately revealing pressing security\nand reliability concerns in current VQA-NLE systems.", "AI": {"tldr": "This paper exposes vulnerabilities in VQA-NLE systems that produce inconsistent explanations and proposes adversarial attacks on both questions and images, along with a knowledge-based defense method to improve robustness.", "motivation": "Existing VQA-NLE systems produce inconsistent explanations and reach conclusions without genuine understanding, exposing weaknesses in their inference pipelines and explanation mechanisms.", "method": "Leverage existing adversarial question perturbation and propose novel image perturbation strategy to induce contradictory outputs. Introduce mitigation method using external knowledge to alleviate inconsistencies.", "result": "Extensive evaluations on two standard benchmarks and two VQA-NLE models demonstrate effectiveness of attacks and potential of knowledge-based defenses.", "conclusion": "The research reveals pressing security and reliability concerns in current VQA-NLE systems and shows the potential of knowledge-based approaches to bolster model robustness."}}
{"id": "2508.13079", "pdf": "https://arxiv.org/pdf/2508.13079", "abs": "https://arxiv.org/abs/2508.13079", "authors": ["Dayy\u00e1n O'Brien", "Bhavitvya Malik", "Ona de Gibert", "Pinzhen Chen", "Barry Haddow", "J\u00f6rg Tiedemann"], "title": "DocHPLT: A Massively Multilingual Document-Level Translation Dataset", "categories": ["cs.CL"], "comment": null, "summary": "Existing document-level machine translation resources are only available for\na handful of languages, mostly high-resourced ones. To facilitate the training\nand evaluation of document-level translation and, more broadly, long-context\nmodeling for global communities, we create DocHPLT, the largest publicly\navailable document-level translation dataset to date. It contains 124 million\naligned document pairs across 50 languages paired with English, comprising 4.26\nbillion sentences, with further possibility to provide 2500 bonus pairs not\ninvolving English. Unlike previous reconstruction-based approaches that piece\ntogether documents from sentence-level data, we modify an existing web\nextraction pipeline to preserve complete document integrity from the source,\nretaining all content including unaligned portions. After our preliminary\nexperiments identify the optimal training context strategy for document-level\ntranslation, we demonstrate that LLMs fine-tuned on DocHPLT substantially\noutperform off-the-shelf instruction-tuned baselines, with particularly\ndramatic improvements for under-resourced languages. We open-source the dataset\nunder a permissive license, providing essential infrastructure for advancing\nmultilingual document-level translation.", "AI": {"tldr": "DocHPLT is the largest publicly available document-level translation dataset with 124M document pairs across 50 languages, created by preserving complete document integrity from web sources rather than reconstructing from sentence-level data.", "motivation": "Existing document-level machine translation resources are limited to high-resourced languages, creating a need for comprehensive datasets to facilitate document-level translation and long-context modeling for global communities.", "method": "Modified an existing web extraction pipeline to preserve complete document integrity from source, retaining all content including unaligned portions, rather than using reconstruction-based approaches that piece together documents from sentence-level data.", "result": "LLMs fine-tuned on DocHPLT substantially outperform off-the-shelf instruction-tuned baselines, with particularly dramatic improvements for under-resourced languages.", "conclusion": "DocHPLT provides essential infrastructure for advancing multilingual document-level translation and is open-sourced under a permissive license to benefit the research community."}}
{"id": "2508.12703", "pdf": "https://arxiv.org/pdf/2508.12703", "abs": "https://arxiv.org/abs/2508.12703", "authors": ["Thomas Krug", "Fabian Raisch", "Dominik Aimer", "Markus Wirnsberger", "Ferdinand Sigg", "Benjamin Sch\u00e4fer", "Benjamin Tischler"], "title": "BUILDA: A Thermal Building Data Generation Framework for Transfer Learning", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "Proceedings can be accessed at:\n  https://annsim.org/2025-annsim-proceedings/", "summary": "Transfer learning (TL) can improve data-driven modeling of building thermal\ndynamics. Therefore, many new TL research areas emerge in the field, such as\nselecting the right source model for TL. However, these research directions\nrequire massive amounts of thermal building data which is lacking presently.\nNeither public datasets nor existing data generators meet the needs of TL\nresearch in terms of data quality and quantity. Moreover, existing data\ngeneration approaches typically require expert knowledge in building\nsimulation. We present BuilDa, a thermal building data generation framework for\nproducing synthetic data of adequate quality and quantity for TL research. The\nframework does not require profound building simulation knowledge to generate\nlarge volumes of data. BuilDa uses a single-zone Modelica model that is\nexported as a Functional Mock-up Unit (FMU) and simulated in Python. We\ndemonstrate BuilDa by generating data and utilizing it for pretraining and\nfine-tuning TL models.", "AI": {"tldr": "BuilDa is a framework that generates synthetic thermal building data for transfer learning research without requiring expert building simulation knowledge, addressing the current lack of adequate public datasets.", "motivation": "Transfer learning research for building thermal dynamics requires large amounts of high-quality data, but existing datasets and generators are insufficient and typically require expert simulation knowledge.", "method": "BuilDa uses a single-zone Modelica model exported as a Functional Mock-up Unit (FMU) and simulated in Python to generate synthetic thermal building data.", "result": "The framework successfully generates adequate quality and quantity of data for transfer learning research, demonstrated through pretraining and fine-tuning applications.", "conclusion": "BuilDa provides a practical solution for generating the large volumes of thermal building data needed for transfer learning research without requiring deep building simulation expertise."}}
{"id": "2508.11690", "pdf": "https://arxiv.org/pdf/2508.11690", "abs": "https://arxiv.org/abs/2508.11690", "authors": ["Tadisetty Sai Yashwanth", "Yangalasetty Sruthi Royal", "Vankayala Rajeshwari Shreya", "Mayank Kashyap", "Divyaprabha K N"], "title": "Real Time Child Abduction And Detection System", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Child safety continues to be a paramount concern worldwide, with child\nabduction posing significant threats to communities. This paper presents the\ndevelopment of an edge-based child abduction detection and alert system\nutilizing a multi-agent framework where each agent incorporates Vision-Language\nModels (VLMs) deployed on a Raspberry Pi. Leveraging the advanced capabilities\nof VLMs within individual agents of a multi-agent team, our system is trained\nto accurately detect and interpret complex interactions involving children in\nvarious environments in real-time. The multi-agent system is deployed on a\nRaspberry Pi connected to a webcam, forming an edge device capable of\nprocessing video feeds, thereby reducing latency and enhancing privacy. An\nintegrated alert system utilizes the Twilio API to send immediate SMS and\nWhatsApp notifications, including calls and messages, when a potential child\nabduction event is detected. Experimental results demonstrate that the system\nachieves high accuracy in detecting potential abduction scenarios, with near\nreal-time performance suitable for practical deployment. The multi-agent\narchitecture enhances the system's ability to process complex situational data,\nimproving detection capabilities over traditional single-model approaches. The\nedge deployment ensures scalability and cost-effectiveness, making it\naccessible for widespread use. The proposed system offers a proactive solution\nto enhance child safety through continuous monitoring and rapid alerting,\ncontributing a valuable tool in efforts to prevent child abductions.", "AI": {"tldr": "Edge-based child abduction detection system using multi-agent VLMs on Raspberry Pi with real-time SMS/WhatsApp alerts", "motivation": "Child safety is a global concern, with abduction posing significant threats requiring proactive monitoring solutions", "method": "Multi-agent framework with Vision-Language Models deployed on Raspberry Pi edge devices, processing video feeds and using Twilio API for immediate SMS/WhatsApp notifications", "result": "High accuracy in detecting potential abduction scenarios with near real-time performance, outperforming traditional single-model approaches", "conclusion": "The system provides scalable, cost-effective edge deployment for widespread child safety monitoring with rapid alerting capabilities"}}
{"id": "2508.12455", "pdf": "https://arxiv.org/pdf/2508.12455", "abs": "https://arxiv.org/abs/2508.12455", "authors": ["Chee Ng", "Liliang Sun", "Shaoqing Tang"], "title": "X-Ray-CoT: Interpretable Chest X-ray Diagnosis with Vision-Language Models via Chain-of-Thought Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Chest X-ray imaging is crucial for diagnosing pulmonary and cardiac diseases,\nyet its interpretation demands extensive clinical experience and suffers from\ninter-observer variability. While deep learning models offer high diagnostic\naccuracy, their black-box nature hinders clinical adoption in high-stakes\nmedical settings. To address this, we propose X-Ray-CoT (Chest X-Ray\nChain-of-Thought), a novel framework leveraging Vision-Language Large Models\n(LVLMs) for intelligent chest X-ray diagnosis and interpretable report\ngeneration. X-Ray-CoT simulates human radiologists' \"chain-of-thought\" by first\nextracting multi-modal features and visual concepts, then employing an\nLLM-based component with a structured Chain-of-Thought prompting strategy to\nreason and produce detailed natural language diagnostic reports. Evaluated on\nthe CORDA dataset, X-Ray-CoT achieves competitive quantitative performance,\nwith a Balanced Accuracy of 80.52% and F1 score of 78.65% for disease\ndiagnosis, slightly surpassing existing black-box models. Crucially, it\nuniquely generates high-quality, explainable reports, as validated by\npreliminary human evaluations. Our ablation studies confirm the integral role\nof each proposed component, highlighting the necessity of multi-modal fusion\nand CoT reasoning for robust and transparent medical AI. This work represents a\nsignificant step towards trustworthy and clinically actionable AI systems in\nmedical imaging.", "AI": {"tldr": "X-Ray-CoT is a novel framework that uses Vision-Language Large Models to provide interpretable chest X-ray diagnosis by simulating radiologists' chain-of-thought reasoning, achieving competitive accuracy while generating explainable reports.", "motivation": "Chest X-ray interpretation requires extensive clinical experience and suffers from variability, while existing deep learning models are black-box systems that hinder clinical adoption in high-stakes medical settings.", "method": "Proposes X-Ray-CoT framework that extracts multi-modal features and visual concepts, then uses LLM-based component with structured Chain-of-Thought prompting to reason and generate detailed natural language diagnostic reports.", "result": "Achieves Balanced Accuracy of 80.52% and F1 score of 78.65% on CORDA dataset, slightly surpassing black-box models, while uniquely generating high-quality explainable reports validated by human evaluations.", "conclusion": "Represents a significant step towards trustworthy and clinically actionable AI systems in medical imaging, with ablation studies confirming the necessity of multi-modal fusion and CoT reasoning for robust and transparent medical AI."}}
{"id": "2508.13107", "pdf": "https://arxiv.org/pdf/2508.13107", "abs": "https://arxiv.org/abs/2508.13107", "authors": ["Figarri Keisha", "Prince Singh", "Pallavi", "Dion Fernandes", "Aravindh Manivannan", "Ilham Wicaksono", "Faisal Ahmad"], "title": "All for law and law for all: Adaptive RAG Pipeline for Legal Research", "categories": ["cs.CL", "cs.IR", "F.2.2, H.3.3, I.2.7"], "comment": "submitted to NLLP 2025 Workshop", "summary": "Retrieval-Augmented Generation (RAG) mitigates hallucinations by grounding\nlarge language model outputs in cited sources, a capability that is especially\ncritical in the legal domain. We present an end-to-end RAG pipeline that\nrevisits and extends the LegalBenchRAG baseline with three targeted\nenhancements: (i) a context-aware query translator that disentangles document\nreferences from natural-language questions and adapts retrieval depth and\nresponse style based on expertise and specificity, (ii) open-source retrieval\nstrategies using SBERT and GTE embeddings that achieve substantial performance\ngains (improving Recall@K by 30-95\\% and Precision@K by $\\sim$2.5$\\times$ for\n$K>4$) while remaining cost-efficient, and (iii) a comprehensive evaluation and\ngeneration framework that combines RAGAS, BERTScore-F1, and ROUGE-Recall to\nassess semantic alignment and faithfulness across models and prompt designs.\nOur results show that carefully designed open-source pipelines can rival or\noutperform proprietary approaches in retrieval quality, while a custom\nlegal-grounded prompt consistently produces more faithful and contextually\nrelevant answers than baseline prompting. Taken together, these contributions\ndemonstrate the potential of task-aware, component-level tuning to deliver\nlegally grounded, reproducible, and cost-effective RAG systems for legal\nresearch assistance.", "AI": {"tldr": "Enhanced open-source RAG pipeline for legal domain with context-aware query translation, improved retrieval strategies, and comprehensive evaluation framework that outperforms proprietary approaches while being cost-effective.", "motivation": "To mitigate hallucinations in legal domain by grounding LLM outputs in cited sources, addressing the critical need for accurate and verifiable legal research assistance.", "method": "End-to-end RAG pipeline with three enhancements: (1) context-aware query translator that handles document references and adapts retrieval parameters, (2) open-source retrieval using SBERT and GTE embeddings, (3) comprehensive evaluation framework combining RAGAS, BERTScore-F1, and ROUGE-Recall.", "result": "Substantial performance gains (30-95% improvement in Recall@K and ~2.5x Precision@K for K>4), open-source pipelines rival or outperform proprietary approaches, custom legal-grounded prompts produce more faithful and contextually relevant answers.", "conclusion": "Task-aware, component-level tuning enables legally grounded, reproducible, and cost-effective RAG systems for legal research, demonstrating the potential of carefully designed open-source solutions."}}
{"id": "2508.12712", "pdf": "https://arxiv.org/pdf/2508.12712", "abs": "https://arxiv.org/abs/2508.12712", "authors": ["Seyed Mahdi Haji Seyed Hossein", "Alireza Hosseini", "Soheil Hajian Manesh", "Amirali Shahriary"], "title": "Argos: A Decentralized Federated System for Detection of Traffic Signs in CAVs", "categories": ["cs.LG", "cs.CV", "I.2.6; I.4.8"], "comment": "7 pages, 10 figures", "summary": "Connected and automated vehicles generate vast amounts of sensor data daily,\nraising significant privacy and communication challenges for centralized\nmachine learning approaches in perception tasks. This study presents a\ndecentralized, federated learning framework tailored for traffic sign detection\nin vehicular networks to enable collaborative model training without sharing\nraw data. The framework partitioned traffic sign classes across vehicles for\nspecialized local training using lightweight object detectors, aggregated model\nparameters via algorithms like FedProx, FedAdam and FedAVG in a simulated\nenvironment with the Flower framework, and evaluated multiple configurations\nincluding varying server rounds, local epochs, client participation fractions,\nand data distributions. Experiments demonstrated that increasing server rounds\nfrom 2 to 20 boosted accuracy from below 0.1 to over 0.8, moderate local epochs\n(8-10) provided optimal efficiency with accuracies around 0.67, higher client\nparticipation fractions enhanced generalization up to 0.83, FedProx\noutperformed other aggregators in handling heterogeneity, non-IID data\ndistributions reduced performance compared to IID, and training duration\nprimarily scaled with the number of rounds rather than aggregation strategy. We\nconclude that this federated approach may offer a scalable, privacy-preserving\nsolution for real-world vehicular deployments, potentially guiding future\nintegrations of robust aggregation and communication optimizations to advance\nintelligent transportation systems.", "AI": {"tldr": "Federated learning framework for traffic sign detection in vehicular networks that enables collaborative training without sharing raw data, achieving up to 0.83 accuracy while preserving privacy.", "motivation": "Address privacy and communication challenges from vast sensor data generated by connected/automated vehicles, avoiding centralized machine learning approaches that require raw data sharing.", "method": "Decentralized federated learning with specialized local training using lightweight object detectors, parameter aggregation via FedProx/FedAdam/FedAVG algorithms, and evaluation of multiple configurations (server rounds, local epochs, client participation, data distributions) in simulated Flower framework environment.", "result": "Increasing server rounds (2\u219220) boosted accuracy from <0.1 to >0.8, moderate local epochs (8-10) achieved ~0.67 accuracy, higher client participation enhanced generalization to 0.83, FedProx outperformed other aggregators in heterogeneous settings, non-IID data reduced performance vs IID, training duration scaled with rounds not aggregation strategy.", "conclusion": "Federated learning offers scalable, privacy-preserving solution for real-world vehicular deployments, with potential for future integrations of robust aggregation and communication optimizations to advance intelligent transportation systems."}}
{"id": "2508.11691", "pdf": "https://arxiv.org/pdf/2508.11691", "abs": "https://arxiv.org/abs/2508.11691", "authors": ["Mathis Rezzouk", "Fabrice Gagnon", "Alyson Champagne", "Mathieu Roy", "Philippe Albouy", "Michel-Pierre Coll", "Cem Subakan"], "title": "Towards Generalizable Learning Models for EEG-Based Identification of Pain Perception", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "6 pages, 2 figures, 2 tables, MLSP IEEE conference", "summary": "EEG-based analysis of pain perception, enhanced by machine learning, reveals\nhow the brain encodes pain by identifying neural patterns evoked by noxious\nstimulation. However, a major challenge that remains is the generalization of\nmachine learning models across individuals, given the high cross-participant\nvariability inherent to EEG signals and the limited focus on direct pain\nperception identification in current research. In this study, we systematically\nevaluate the performance of cross-participant generalization of a wide range of\nmodels, including traditional classifiers and deep neural classifiers for\nidentifying the sensory modality of thermal pain and aversive auditory\nstimulation from EEG recordings. Using a novel dataset of EEG recordings from\n108 participants, we benchmark model performance under both within- and\ncross-participant evaluation settings. Our findings show that traditional\nmodels suffered the largest drop from within- to cross-participant performance,\nwhile deep learning models proved more resilient, underscoring their potential\nfor subject-invariant EEG decoding. Even though performance variability\nremained high, the strong results of the graph-based model highlight its\npotential to capture subject-invariant structure in EEG signals. On the other\nhand, we also share the preprocessed dataset used in this study, providing a\nstandardized benchmark for evaluating future algorithms under the same\ngeneralization constraints.", "AI": {"tldr": "EEG-based pain perception analysis using machine learning faces cross-participant generalization challenges due to high variability in EEG signals. This study evaluates various models on a novel 108-participant dataset, finding deep learning models more resilient than traditional classifiers for subject-invariant EEG decoding.", "motivation": "The high cross-participant variability in EEG signals and limited research focus on direct pain perception identification create challenges for generalizing machine learning models across individuals in pain perception analysis.", "method": "Systematic evaluation of traditional classifiers and deep neural classifiers for identifying thermal pain and aversive auditory stimulation from EEG recordings, using a novel dataset of 108 participants under both within- and cross-participant evaluation settings.", "result": "Traditional models suffered the largest performance drop from within- to cross-participant evaluation, while deep learning models proved more resilient. Graph-based models showed strong potential for capturing subject-invariant structure in EEG signals, though performance variability remained high.", "conclusion": "Deep learning models demonstrate better generalization capabilities for subject-invariant EEG decoding of pain perception. The study also provides a standardized preprocessed dataset for future algorithm evaluation under the same generalization constraints."}}
{"id": "2508.12466", "pdf": "https://arxiv.org/pdf/2508.12466", "abs": "https://arxiv.org/abs/2508.12466", "authors": ["Xuhui Zhan", "Tyler Derr"], "title": "Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "15pages, 3 figures", "summary": "Traditional multimodal learning approaches require expensive alignment\npre-training to bridge vision and language modalities, typically projecting\nvisual features into discrete text token spaces. We challenge both fundamental\nassumptions underlying this paradigm by proposing Inverse-LLaVA, a novel\napproach that eliminates alignment pre-training entirely while inverting the\nconventional mapping direction. Rather than projecting visual features to text\nspace, our method maps text embeddings into continuous visual representation\nspace and performs fusion within transformer intermediate layers. Through\nselective additive components in attention mechanisms, we enable dynamic\nintegration of visual and textual representations without requiring massive\nimage-text alignment datasets. Comprehensive experiments across nine multimodal\nbenchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves\nnotable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%,\nVizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing\nexpected decreases in perception tasks requiring memorized visual-text\nassociations (celebrity recognition: -49.5%, OCR: -21.3%). These results\nprovide the first empirical evidence that alignment pre-training is not\nnecessary for effective multimodal learning, particularly for complex reasoning\ntasks. Our work establishes the feasibility of a new paradigm that reduces\ncomputational requirements by 45%, challenges conventional wisdom about\nmodality fusion, and opens new research directions for efficient multimodal\narchitectures that preserve modality-specific characteristics. Our project\nwebsite with code and additional resources is available at\nhttps://inverse-llava.github.io.", "AI": {"tldr": "Inverse-LLaVA eliminates alignment pre-training by mapping text to visual space instead of visual to text, achieving better reasoning performance while reducing computation by 45%.", "motivation": "Challenge traditional multimodal learning that requires expensive alignment pre-training and projects visual features to text space, seeking more efficient fusion without massive alignment datasets.", "method": "Maps text embeddings into continuous visual representation space, performs fusion within transformer intermediate layers using selective additive components in attention mechanisms.", "result": "Improves reasoning-intensive tasks (MM-VET: +0.2%, VizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%) but decreases in perception tasks (celebrity recognition: -49.5%, OCR: -21.3%). Reduces computational requirements by 45%.", "conclusion": "Alignment pre-training is not necessary for effective multimodal learning, particularly for complex reasoning. Establishes a new paradigm that preserves modality-specific characteristics and enables efficient multimodal architectures."}}
{"id": "2508.13118", "pdf": "https://arxiv.org/pdf/2508.13118", "abs": "https://arxiv.org/abs/2508.13118", "authors": ["Zefang Liu", "Arman Anwar"], "title": "AutoBnB-RAG: Enhancing Multi-Agent Incident Response with Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.CR"], "comment": null, "summary": "Incident response (IR) requires fast, coordinated, and well-informed\ndecision-making to contain and mitigate cyber threats. While large language\nmodels (LLMs) have shown promise as autonomous agents in simulated IR settings,\ntheir reasoning is often limited by a lack of access to external knowledge. In\nthis work, we present AutoBnB-RAG, an extension of the AutoBnB framework that\nincorporates retrieval-augmented generation (RAG) into multi-agent incident\nresponse simulations. Built on the Backdoors & Breaches (B&B) tabletop game\nenvironment, AutoBnB-RAG enables agents to issue retrieval queries and\nincorporate external evidence during collaborative investigations. We introduce\ntwo retrieval settings: one grounded in curated technical documentation\n(RAG-Wiki), and another using narrative-style incident reports (RAG-News). We\nevaluate performance across eight team structures, including newly introduced\nargumentative configurations designed to promote critical reasoning. To\nvalidate practical utility, we also simulate real-world cyber incidents based\non public breach reports, demonstrating AutoBnB-RAG's ability to reconstruct\ncomplex multi-stage attacks. Our results show that retrieval augmentation\nimproves decision quality and success rates across diverse organizational\nmodels. This work demonstrates the value of integrating retrieval mechanisms\ninto LLM-based multi-agent systems for cybersecurity decision-making.", "AI": {"tldr": "AutoBnB-RAG enhances incident response simulations by integrating retrieval-augmented generation (RAG) into multi-agent systems, improving decision quality and success rates through access to external knowledge sources.", "motivation": "Incident response requires fast, coordinated decision-making, but current LLM-based agents lack access to external knowledge, limiting their reasoning capabilities in cybersecurity simulations.", "method": "Extends AutoBnB framework with RAG capabilities, using two retrieval settings: technical documentation (RAG-Wiki) and narrative incident reports (RAG-News). Evaluates eight team structures including argumentative configurations to promote critical reasoning, and simulates real-world cyber incidents based on public breach reports.", "result": "Retrieval augmentation improves decision quality and success rates across diverse organizational models. The system demonstrates ability to reconstruct complex multi-stage attacks from real-world breach scenarios.", "conclusion": "Integration of retrieval mechanisms into LLM-based multi-agent systems provides significant value for cybersecurity decision-making, enhancing autonomous incident response capabilities."}}
{"id": "2508.12727", "pdf": "https://arxiv.org/pdf/2508.12727", "abs": "https://arxiv.org/abs/2508.12727", "authors": ["Manning Zhu", "Songtao Guo", "Pengzhan Zhou", "Yansong Ning", "Chang Han", "Dewen Qiao"], "title": "FedSODA: Federated Fine-tuning of LLMs via Similarity Group Pruning and Orchestrated Distillation Alignment", "categories": ["cs.LG"], "comment": null, "summary": "Federated fine-tuning (FFT) of large language models (LLMs) has recently\nemerged as a promising solution to enable domain-specific adaptation while\npreserving data privacy. Despite its benefits, FFT on resource-constrained\nclients relies on the high computational and memory demands of full-model\nfine-tuning, which limits the potential advancement. This paper presents\nFedSODA, a resource-efficient FFT framework that enables clients to adapt LLMs\nwithout accessing or storing the full model. Specifically, we first propose a\nsimilarity group pruning (SGP) module, which prunes redundant layers from the\nfull LLM while retaining the most critical layers to preserve the model\nperformance. Moreover, we introduce an orchestrated distillation alignment\n(ODA) module to reduce gradient divergence between the sub-LLM and the full LLM\nduring FFT. Through the use of the QLoRA, clients only need to deploy quantized\nsub-LLMs and fine-tune lightweight adapters, significantly reducing local\nresource requirements. We conduct extensive experiments on three open-source\nLLMs across a variety of downstream tasks. The experimental results demonstrate\nthat FedSODA reduces communication overhead by an average of 70.6%, decreases\nstorage usage by 75.6%, and improves task accuracy by 3.1%, making it highly\nsuitable for practical FFT applications under resource constraints.", "AI": {"tldr": "FedSODA is a resource-efficient federated fine-tuning framework that reduces computational and memory demands by pruning redundant LLM layers and using orchestrated distillation alignment with QLoRA.", "motivation": "Federated fine-tuning of LLMs faces challenges with high computational and memory requirements on resource-constrained clients, limiting practical deployment.", "method": "Uses similarity group pruning to remove redundant layers while preserving critical ones, orchestrated distillation alignment to reduce gradient divergence, and QLoRA for quantized sub-LLMs with lightweight adapter fine-tuning.", "result": "Reduces communication overhead by 70.6%, decreases storage usage by 75.6%, and improves task accuracy by 3.1% across various downstream tasks.", "conclusion": "FedSODA enables practical federated fine-tuning under resource constraints while maintaining performance and privacy."}}
{"id": "2508.11692", "pdf": "https://arxiv.org/pdf/2508.11692", "abs": "https://arxiv.org/abs/2508.11692", "authors": ["Eduardo Di Santi", "Ruixiang Ci", "Cl\u00e9ment Lefebvre", "Nenad Mijatovic", "Michele Pugnaloni", "Jonathan Brown", "Victor Mart\u00edn", "Kenza Saiah"], "title": "Scalable, Technology-Agnostic Diagnosis and Predictive Maintenance for Point Machine using Deep Learning", "categories": ["eess.SP", "cs.AI", "68T07, 68T05", "I.2.6; I.5.1; I.5.4"], "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025, Dresden,\n  Germany. Conference: https://tu-dresden.de/raildresden2025. Book of\n  abstracts: https://tu-dresden.de/raildresden2025/BoA.pdf. 8 pages, 6 figures,\n  1 table", "summary": "The Point Machine (PM) is a critical piece of railway equipment that switches\ntrain routes by diverting tracks through a switchblade. As with any critical\nsafety equipment, a failure will halt operations leading to service\ndisruptions; therefore, pre-emptive maintenance may avoid unnecessary\ninterruptions by detecting anomalies before they become failures. Previous work\nrelies on several inputs and crafting custom features by segmenting the signal.\nThis not only adds additional requirements for data collection and processing,\nbut it is also specific to the PM technology, the installed locations and\noperational conditions limiting scalability. Based on the available maintenance\nrecords, the main failure causes for PM are obstacles, friction, power source\nissues and misalignment. Those failures affect the energy consumption pattern\nof PMs, altering the usual (or healthy) shape of the power signal during the PM\nmovement. In contrast to the current state-of-the-art, our method requires only\none input. We apply a deep learning model to the power signal pattern to\nclassify if the PM is nominal or associated with any failure type, achieving\n>99.99\\% precision, <0.01\\% false positives and negligible false negatives. Our\nmethodology is generic and technology-agnostic, proven to be scalable on\nseveral electromechanical PM types deployed in both real-world and test bench\nenvironments. Finally, by using conformal prediction the maintainer gets a\nclear indication of the certainty of the system outputs, adding a confidence\nlayer to operations and making the method compliant with the ISO-17359\nstandard.", "AI": {"tldr": "Deep learning method for railway point machine failure detection using only power signal patterns, achieving >99.99% precision and ISO-17359 compliance through conformal prediction.", "motivation": "Point machine failures cause railway service disruptions. Current methods require multiple inputs and custom feature engineering, making them technology-specific and not scalable. Pre-emptive maintenance through anomaly detection can prevent operational interruptions.", "method": "Uses deep learning model applied to power signal patterns to classify point machines as nominal or associated with failure types (obstacles, friction, power issues, misalignment). Requires only one input (power signal) and uses conformal prediction for confidence estimation.", "result": "Achieves >99.99% precision, <0.01% false positives, and negligible false negatives. Proven scalable on multiple electromechanical point machine types in both real-world and test bench environments.", "conclusion": "Methodology is generic, technology-agnostic, and provides maintainers with clear certainty indications through conformal prediction, making it compliant with ISO-17359 standard for condition monitoring and diagnostics."}}
{"id": "2508.12473", "pdf": "https://arxiv.org/pdf/2508.12473", "abs": "https://arxiv.org/abs/2508.12473", "authors": ["Eranga Bandara", "Ross Gore", "Sachin Shetty", "Ravi Mukkamala", "Christopher Rhea", "Atmaram Yarlagadda", "Shaifali Kaushik", "L. H. M. P. De Silva", "Andriy Maznychenko", "Inna Sokolowska", "Amin Hass", "Kasun De Zoysa"], "title": "Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a\ncritical role in sports science, rehabilitation, and clinical neurology.\nTraditional analysis of H-reflex EMG waveforms is subject to variability and\ninterpretation bias among clinicians and researchers, limiting reliability and\nstandardization. To address these challenges, we propose a Fine-Tuned\nVision-Language Model (VLM) Consortium and a reasoning Large-Language Model\n(LLM)-enabled Decision Support System for automated H-reflex waveform\ninterpretation and diagnosis. Our approach leverages multiple VLMs, each\nfine-tuned on curated datasets of H-reflex EMG waveform images annotated with\nclinical observations, recovery timelines, and athlete metadata. These models\nare capable of extracting key electrophysiological features and predicting\nneuromuscular states, including fatigue, injury, and recovery, directly from\nEMG images and contextual metadata. Diagnostic outputs from the VLM consortium\nare aggregated using a consensus-based method and refined by a specialized\nreasoning LLM, which ensures robust, transparent, and explainable decision\nsupport for clinicians and sports scientists. The end-to-end platform\norchestrates seamless communication between the VLM ensemble and the reasoning\nLLM, integrating prompt engineering strategies and automated reasoning\nworkflows using LLM Agents. Experimental results demonstrate that this hybrid\nsystem delivers highly accurate, consistent, and interpretable H-reflex\nassessments, significantly advancing the automation and standardization of\nneuromuscular diagnostics. To our knowledge, this work represents the first\nintegration of a fine-tuned VLM consortium with a reasoning LLM for image-based\nH-reflex analysis, laying the foundation for next-generation AI-assisted\nneuromuscular assessment and athlete monitoring platforms.", "AI": {"tldr": "A hybrid AI system combining fine-tuned vision-language models and reasoning LLMs for automated H-reflex EMG waveform interpretation, improving standardization and accuracy in neuromuscular diagnostics.", "motivation": "Traditional H-reflex EMG analysis suffers from variability and interpretation bias among clinicians, limiting reliability and standardization in sports science and clinical neurology.", "method": "Fine-tuned multiple VLMs on curated H-reflex EMG waveform images with clinical annotations, then aggregated outputs using consensus method and refined with specialized reasoning LLM for transparent decision support.", "result": "The hybrid system delivers highly accurate, consistent, and interpretable H-reflex assessments, significantly advancing automation and standardization of neuromuscular diagnostics.", "conclusion": "First integration of fine-tuned VLM consortium with reasoning LLM for image-based H-reflex analysis, laying foundation for next-generation AI-assisted neuromuscular assessment platforms."}}
{"id": "2508.13124", "pdf": "https://arxiv.org/pdf/2508.13124", "abs": "https://arxiv.org/abs/2508.13124", "authors": ["Kawin Mayilvaghanan", "Siddhant Gupta", "Ayush Kumar"], "title": "Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Abstractive summarization is a core application in contact centers, where\nLarge Language Models (LLMs) generate millions of summaries of call transcripts\ndaily. Despite their apparent quality, it remains unclear whether LLMs\nsystematically under- or over-attend to specific aspects of the transcript,\npotentially introducing biases in the generated summary. While prior work has\nexamined social and positional biases, the specific forms of bias pertinent to\ncontact center operations - which we term Operational Bias - have remained\nunexplored. To address this gap, we introduce BlindSpot, a framework built upon\na taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic)\nfor the identification and quantification of these biases. BlindSpot leverages\nan LLM as a zero-shot classifier to derive categorical distributions for each\nbias dimension in a pair of transcript and its summary. The bias is then\nquantified using two metrics: Fidelity Gap (the JS Divergence between\ndistributions) and Coverage (the percentage of source labels omitted). Using\nBlindSpot, we conducted an empirical study with 2500 real call transcripts and\ntheir summaries generated by 20 LLMs of varying scales and families (e.g., GPT,\nLlama, Claude). Our analysis reveals that biases are systemic and present\nacross all evaluated models, regardless of size or family.", "AI": {"tldr": "BlindSpot framework identifies and quantifies operational biases in LLM-generated call center summaries, revealing systemic biases across all tested models.", "motivation": "LLMs generate millions of call transcript summaries daily in contact centers, but it's unclear if they systematically under- or over-attend to specific aspects, potentially introducing operational biases that haven't been explored.", "method": "Introduced BlindSpot framework with 15 operational bias dimensions, using LLM as zero-shot classifier to derive categorical distributions for transcript-summary pairs, quantified via Fidelity Gap (JS Divergence) and Coverage metrics.", "result": "Analysis of 2500 real call transcripts and summaries from 20 LLMs (various scales and families) revealed that biases are systemic and present across all evaluated models, regardless of size or family.", "conclusion": "Operational biases in LLM-generated call summaries are pervasive and systematic, affecting all model types and sizes, highlighting the need for bias detection frameworks like BlindSpot in contact center applications."}}
{"id": "2508.12740", "pdf": "https://arxiv.org/pdf/2508.12740", "abs": "https://arxiv.org/abs/2508.12740", "authors": ["Beomseok Seo", "Kichang Lee", "JaeYeon Park"], "title": "FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models", "categories": ["cs.LG", "cs.AI", "68T01 (Primary), 68T07 (Secondary)", "I.2"], "comment": "6 pages, 4 figures", "summary": "Federated learning (FL) enables decentralized model training without sharing\nlocal data. However, most existing methods assume identical model architectures\nacross clients, limiting their applicability in heterogeneous real-world\nenvironments. To address this, we propose FedUNet, a lightweight and\narchitecture-agnostic FL framework that attaches a U-Net-inspired additive\nmodule to each client's backbone. By sharing only the compact bottleneck of the\nU-Net, FedUNet enables efficient knowledge transfer without structural\nalignment. The encoder-decoder design and skip connections in the U-Net help\ncapture both low-level and high-level features, facilitating the extraction of\nclientinvariant representations. This enables cooperative learning between the\nbackbone and the additive module with minimal communication cost. Experiment\nwith VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in\ncompact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low\ncommunication overhead.", "AI": {"tldr": "FedUNet is a lightweight federated learning framework that uses U-Net-inspired additive modules to enable heterogeneous model training across clients with minimal communication overhead.", "motivation": "Existing federated learning methods assume identical model architectures across clients, which limits applicability in real-world heterogeneous environments where clients may have different hardware capabilities and model architectures.", "method": "Attaches a U-Net-inspired additive module to each client's backbone, sharing only the compact bottleneck of the U-Net for efficient knowledge transfer without requiring structural alignment between different client models.", "result": "Achieves 93.11% accuracy with standard version and 92.68% with lightweight version, while maintaining only 0.89 MB communication overhead, as demonstrated with VGG variants.", "conclusion": "FedUNet enables effective federated learning across heterogeneous model architectures with minimal communication cost, making it suitable for real-world deployment where clients have varying computational resources and model structures."}}
{"id": "2508.11693", "pdf": "https://arxiv.org/pdf/2508.11693", "abs": "https://arxiv.org/abs/2508.11693", "authors": ["Francisco L\u00f3pez", "Eduardo Di Santi", "Cl\u00e9ment Lefebvre", "Nenad Mijatovic", "Michele Pugnaloni", "Victor Mart\u00edn", "Kenza Saiah"], "title": "Track Component Failure Detection Using Data Analytics over existing STDS Track Circuit data", "categories": ["eess.SP", "cs.AI", "cs.LG", "68T05, 68T10", "I.2.6; I.5.1; I.5.4"], "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025\n  (International Conference on Railway Operations Modelling and Analysis),\n  Dresden, Germany", "summary": "Track Circuits (TC) are the main signalling devices used to detect the\npresence of a train on a rail track. It has been used since the 19th century\nand nowadays there are many types depending on the technology. As a general\nclassification, Track Circuits can be divided into 2 main groups, DC (Direct\nCurrent) and AC (Alternating Current) circuits. This work is focused on a\nparticular AC track circuit, called \"Smart Train Detection System\" (STDS),\ndesigned with both high and low-frequency bands. This approach uses STDS\ncurrent data applied to an SVM (support vector machine) classifier as a type of\nfailure identifier. The main purpose of this work consists on determine\nautomatically which is the component of the track that is failing to improve\nthe maintenance action. Model was trained to classify 15 different failures\nthat belong to 3 more general categories. The method was tested with field data\nfrom 10 different track circuits and validated by the STDS track circuit expert\nand maintainers. All use cases were correctly classified by the method.", "AI": {"tldr": "Using SVM classifier on STDS track circuit current data to automatically identify 15 specific failures across 3 categories, achieving 100% accuracy on field data from 10 track circuits.", "motivation": "Track circuits are critical signaling devices for train detection, but current maintenance relies on manual troubleshooting. The research aims to automate failure identification to improve maintenance efficiency and reduce downtime.", "method": "Applied SVM (support vector machine) classifier to current data from Smart Train Detection System (STDS) track circuits, which use both high and low-frequency bands. Model trained to classify 15 different failures across 3 general categories.", "result": "The method was tested with field data from 10 different track circuits and validated by STDS experts and maintainers. All use cases were correctly classified, achieving 100% accuracy in failure identification.", "conclusion": "The SVM-based approach successfully automates track circuit failure identification, providing an effective solution for maintenance optimization in railway signaling systems."}}
{"id": "2508.12484", "pdf": "https://arxiv.org/pdf/2508.12484", "abs": "https://arxiv.org/abs/2508.12484", "authors": ["Shubhi Agarwal", "Amulya Kumar Mahto"], "title": "Skin Cancer Classification: Hybrid CNN-Transformer Models with KAN-Based Fusion", "categories": ["cs.CV"], "comment": null, "summary": "Skin cancer classification is a crucial task in medical image analysis, where\nprecise differentiation between malignant and non-malignant lesions is\nessential for early diagnosis and treatment. In this study, we explore\nSequential and Parallel Hybrid CNN-Transformer models with Convolutional\nKolmogorov-Arnold Network (CKAN). Our approach integrates transfer learning and\nextensive data augmentation, where CNNs extract local spatial features,\nTransformers model global dependencies, and CKAN facilitates nonlinear feature\nfusion for improved representation learning. To assess generalization, we\nevaluate our models on multiple benchmark datasets (HAM10000,BCN20000 and\nPAD-UFES) under varying data distributions and class imbalances. Experimental\nresults demonstrate that hybrid CNN-Transformer architectures effectively\ncapture both spatial and contextual features, leading to improved\nclassification performance. Additionally, the integration of CKAN enhances\nfeature fusion through learnable activation functions, yielding more\ndiscriminative representations. Our proposed approach achieves competitive\nperformance in skin cancer classification, demonstrating 92.81% accuracy and\n92.47% F1-score on the HAM10000 dataset, 97.83% accuracy and 97.83% F1-score on\nthe PAD-UFES dataset, and 91.17% accuracy with 91.79% F1- score on the BCN20000\ndataset highlighting the effectiveness and generalizability of our model across\ndiverse datasets. This study highlights the significance of feature\nrepresentation and model design in advancing robust and accurate medical image\nclassification.", "AI": {"tldr": "Hybrid CNN-Transformer models with Convolutional Kolmogorov-Arnold Network (CKAN) achieve state-of-the-art performance in skin cancer classification across multiple datasets, demonstrating effective integration of local spatial features and global contextual information.", "motivation": "Skin cancer classification requires precise differentiation between malignant and non-malignant lesions for early diagnosis. Existing methods need improved feature representation and generalization across diverse datasets with varying distributions and class imbalances.", "method": "Sequential and Parallel Hybrid CNN-Transformer models integrated with Convolutional Kolmogorov-Arnold Network (CKAN), using transfer learning and extensive data augmentation. CNNs extract local spatial features, Transformers model global dependencies, and CKAN facilitates nonlinear feature fusion.", "result": "Achieved 92.81% accuracy and 92.47% F1-score on HAM10000, 97.83% accuracy and 97.83% F1-score on PAD-UFES, and 91.17% accuracy with 91.79% F1-score on BCN20000 dataset, demonstrating competitive performance and strong generalization.", "conclusion": "Hybrid CNN-Transformer architectures with CKAN effectively capture both spatial and contextual features, enhancing classification performance. The approach highlights the importance of feature representation and model design for robust medical image classification."}}
{"id": "2508.13130", "pdf": "https://arxiv.org/pdf/2508.13130", "abs": "https://arxiv.org/abs/2508.13130", "authors": ["Kareem Elozeiri", "Mervat Abassy", "Preslav Nakov", "Yuxia Wang"], "title": "MuDRiC: Multi-Dialect Reasoning for Arabic Commonsense Validation", "categories": ["cs.CL"], "comment": null, "summary": "Commonsense validation evaluates whether a sentence aligns with everyday\nhuman understanding, a critical capability for developing robust natural\nlanguage understanding systems. While substantial progress has been made in\nEnglish, the task remains underexplored in Arabic, particularly given its rich\nlinguistic diversity. Existing Arabic resources have primarily focused on\nModern Standard Arabic (MSA), leaving regional dialects underrepresented\ndespite their prevalence in spoken contexts. To bridge this gap, we present two\nkey contributions: (i) we introduce MuDRiC, an extended Arabic commonsense\ndataset incorporating multiple dialects, and (ii) a novel method adapting Graph\nConvolutional Networks (GCNs) to Arabic commonsense reasoning, which enhances\nsemantic relationship modeling for improved commonsense validation. Our\nexperimental results demonstrate that this approach achieves superior\nperformance in Arabic commonsense validation. Our work enhances Arabic natural\nlanguage understanding by providing both a foundational dataset and a novel\nmethod for handling its complex variations. To the best of our knowledge, we\nrelease the first Arabic multi-dialect commonsense reasoning dataset.", "AI": {"tldr": "Introduces MuDRiC - first Arabic multi-dialect commonsense dataset and novel GCN-based method for Arabic commonsense validation, achieving superior performance.", "motivation": "Address the gap in Arabic commonsense validation resources, which have focused primarily on Modern Standard Arabic while neglecting regional dialects despite their prevalence in spoken contexts.", "method": "Proposes a novel method adapting Graph Convolutional Networks (GCNs) to Arabic commonsense reasoning, enhancing semantic relationship modeling for improved commonsense validation.", "result": "Experimental results demonstrate superior performance in Arabic commonsense validation compared to existing approaches.", "conclusion": "The work enhances Arabic natural language understanding by providing both a foundational multi-dialect dataset and a novel method for handling Arabic's complex linguistic variations."}}
{"id": "2508.12741", "pdf": "https://arxiv.org/pdf/2508.12741", "abs": "https://arxiv.org/abs/2508.12741", "authors": ["Manuela Imbriani", "Gina Belmonte", "Mieke Massink", "Alessandro Tofani", "Vincenzo Ciancia"], "title": "A Multi-Resolution Benchmark Framework for Spatial Reasoning Assessment in Neural Networks", "categories": ["cs.LG", "physics.app-ph", "physics.med-ph"], "comment": null, "summary": "This paper presents preliminary results in the definition of a comprehensive\nbenchmark framework designed to systematically evaluate spatial reasoning\ncapabilities in neural networks, with a particular focus on morphological\nproperties such as connectivity and distance relationships. The framework is\ncurrently being used to study the capabilities of nnU-Net, exploiting the\nspatial model checker VoxLogicA to generate two distinct categories of\nsynthetic datasets: maze connectivity problems for topological analysis and\nspatial distance computation tasks for geometric understanding. Each category\nis evaluated across multiple resolutions to assess scalability and\ngeneralization properties. The automated pipeline encompasses a complete\nmachine learning workflow including: synthetic dataset generation, standardized\ntraining with cross-validation, inference execution, and comprehensive\nevaluation using Dice coefficient and IoU (Intersection over Union) metrics.\nPreliminary experimental results demonstrate significant challenges in neural\nnetwork spatial reasoning capabilities, revealing systematic failures in basic\ngeometric and topological understanding tasks. The framework provides a\nreproducible experimental protocol, enabling researchers to identify specific\nlimitations. Such limitations could be addressed through hybrid approaches\ncombining neural networks with symbolic reasoning methods for improved spatial\nunderstanding in clinical applications, establishing a foundation for ongoing\nresearch into neural network spatial reasoning limitations and potential\nsolutions.", "AI": {"tldr": "A benchmark framework for evaluating neural network spatial reasoning capabilities using synthetic datasets and automated ML workflow, revealing systematic failures in geometric and topological understanding.", "motivation": "To systematically evaluate spatial reasoning capabilities in neural networks, particularly focusing on morphological properties like connectivity and distance relationships, to identify limitations that could be addressed through hybrid approaches.", "method": "Uses spatial model checker VoxLogicA to generate synthetic datasets (maze connectivity problems and spatial distance tasks) across multiple resolutions. Implements automated pipeline with dataset generation, standardized training with cross-validation, inference execution, and evaluation using Dice coefficient and IoU metrics.", "result": "Preliminary results demonstrate significant challenges and systematic failures in neural network spatial reasoning capabilities for basic geometric and topological understanding tasks.", "conclusion": "The framework provides reproducible experimental protocol to identify specific limitations, suggesting hybrid approaches combining neural networks with symbolic reasoning could improve spatial understanding for clinical applications."}}
{"id": "2508.11695", "pdf": "https://arxiv.org/pdf/2508.11695", "abs": "https://arxiv.org/abs/2508.11695", "authors": ["Yiyun Chen", "Weikai Yang"], "title": "RefAdGen: High-Fidelity Advertising Image Generation", "categories": ["cs.GR", "cs.AI"], "comment": null, "summary": "The rapid advancement of Artificial Intelligence Generated Content (AIGC)\ntechniques has unlocked opportunities in generating diverse and compelling\nadvertising images based on referenced product images and textual scene\ndescriptions. This capability substantially reduces human labor and production\ncosts in traditional marketing workflows. However, existing AIGC techniques\neither demand extensive fine-tuning for each referenced image to achieve high\nfidelity, or they struggle to maintain fidelity across diverse products, making\nthem impractical for e-commerce and marketing industries. To tackle this\nlimitation, we first construct AdProd-100K, a large-scale advertising image\ngeneration dataset. A key innovation in its construction is our dual data\naugmentation strategy, which fosters robust, 3D-aware representations crucial\nfor realistic and high-fidelity image synthesis. Leveraging this dataset, we\npropose RefAdGen, a generation framework that achieves high fidelity through a\ndecoupled design. The framework enforces precise spatial control by injecting a\nproduct mask at the U-Net input, and employs an efficient Attention Fusion\nModule (AFM) to integrate product features. This design effectively resolves\nthe fidelity-efficiency dilemma present in existing methods. Extensive\nexperiments demonstrate that RefAdGen achieves state-of-the-art performance,\nshowcasing robust generalization by maintaining high fidelity and remarkable\nvisual results for both unseen products and challenging real-world, in-the-wild\nimages. This offers a scalable and cost-effective alternative to traditional\nworkflows. Code and datasets are publicly available at\nhttps://github.com/Anonymous-Name-139/RefAdgen.", "AI": {"tldr": "RefAdGen is a novel framework for high-fidelity advertising image generation that addresses fidelity-efficiency tradeoffs in existing AIGC methods through a decoupled design with product mask injection and attention fusion.", "motivation": "Existing AIGC techniques for advertising image generation either require extensive fine-tuning per product or struggle to maintain fidelity across diverse products, making them impractical for e-commerce and marketing applications.", "method": "Constructed AdProd-100K dataset with dual data augmentation strategy, then proposed RefAdGen framework with decoupled design: product mask injection for spatial control and Attention Fusion Module (AFM) for product feature integration.", "result": "State-of-the-art performance with robust generalization, maintaining high fidelity for both unseen products and challenging real-world images, offering scalable and cost-effective alternative to traditional workflows.", "conclusion": "RefAdGen effectively resolves the fidelity-efficiency dilemma in AIGC-based advertising generation, providing a practical solution for e-commerce and marketing industries with publicly available code and datasets."}}
{"id": "2508.12506", "pdf": "https://arxiv.org/pdf/2508.12506", "abs": "https://arxiv.org/abs/2508.12506", "authors": ["E. Ulises Moya-S\u00e1nchez", "Abraham S\u00e1nchez-Perez", "Ra\u00fal Nanclares Da Veiga", "Alejandro Zarate-Mac\u00edas", "Edgar Villareal", "Alejandro S\u00e1nchez-Montes", "Edtna Jauregui-Ulloa", "H\u00e9ctor Moreno", "Ulises Cort\u00e9s"], "title": "Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages,3 figures, under review", "summary": "Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age\nindividuals. Early detection of DR can reduce the risk of vision loss by up to\n95%, but a shortage of retinologists and challenges in timely examination\ncomplicate detection. Artificial Intelligence (AI) models using retinal fundus\nphotographs (RFPs) offer a promising solution. However, adoption in clinical\nsettings is hindered by low-quality data and biases that may lead AI systems to\nlearn unintended features. To address these challenges, we developed RAIS-DR, a\nResponsible AI System for DR screening that incorporates ethical principles\nacross the AI lifecycle. RAIS-DR integrates efficient convolutional models for\npreprocessing, quality assessment, and three specialized DR classification\nmodels. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local\ndataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated\nsignificant improvements, with F1 scores increasing by 5-12%, accuracy by\n6-19%, and specificity by 10-20%. Additionally, fairness metrics such as\nDisparate Impact and Equal Opportunity Difference indicated equitable\nperformance across demographic subgroups, underscoring RAIS-DR's potential to\nreduce healthcare disparities. These results highlight RAIS-DR as a robust and\nethically aligned solution for DR screening in clinical settings. The code,\nweights of RAIS-DR are available at\nhttps://gitlab.com/inteligencia-gubernamental-jalisco/jalisco-retinopathy with\nRAIL.", "AI": {"tldr": "RAIS-DR is a responsible AI system for diabetic retinopathy screening that outperforms FDA-approved EyeArt system with 5-12% higher F1 scores, 6-19% better accuracy, and demonstrates equitable performance across demographic groups.", "motivation": "Diabetic Retinopathy is a leading cause of vision loss, but early detection is hindered by shortage of specialists and low-quality data with biases in AI systems. There's a need for ethical AI solutions that address healthcare disparities.", "method": "Developed RAIS-DR system incorporating ethical principles across AI lifecycle, using efficient convolutional models for preprocessing, quality assessment, and three specialized DR classification models. Evaluated against FDA-approved EyeArt on local dataset of 1,046 unseen patients.", "result": "RAIS-DR showed significant improvements: F1 scores increased by 5-12%, accuracy by 6-19%, specificity by 10-20%. Fairness metrics (Disparate Impact, Equal Opportunity Difference) indicated equitable performance across demographic subgroups.", "conclusion": "RAIS-DR is a robust and ethically aligned solution for DR screening that can reduce healthcare disparities, with code and weights publicly available under RAIL license."}}
{"id": "2508.13131", "pdf": "https://arxiv.org/pdf/2508.13131", "abs": "https://arxiv.org/abs/2508.13131", "authors": ["Dara Bahri", "John Wieting"], "title": "Improving Detection of Watermarked Language Models", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "Watermarking has recently emerged as an effective strategy for detecting the\ngenerations of large language models (LLMs). The strength of a watermark\ntypically depends strongly on the entropy afforded by the language model and\nthe set of input prompts. However, entropy can be quite limited in practice,\nespecially for models that are post-trained, for example via instruction tuning\nor reinforcement learning from human feedback (RLHF), which makes detection\nbased on watermarking alone challenging. In this work, we investigate whether\ndetection can be improved by combining watermark detectors with non-watermark\nones. We explore a number of hybrid schemes that combine the two, observing\nperformance gains over either class of detector under a wide range of\nexperimental conditions.", "AI": {"tldr": "Hybrid detection combining watermark and non-watermark methods improves LLM generation detection, especially in low-entropy scenarios where watermarking alone struggles.", "motivation": "Watermark detection effectiveness depends heavily on language model entropy, which is often limited in post-trained models (instruction tuning, RLHF), making standalone watermark detection challenging.", "method": "Explored various hybrid schemes that combine watermark detectors with non-watermark detectors to improve detection performance.", "result": "Observed performance gains over either class of detector (watermark-only or non-watermark-only) under a wide range of experimental conditions.", "conclusion": "Combining watermark and non-watermark detection methods provides improved detection capabilities for LLM-generated content, particularly in low-entropy scenarios."}}
{"id": "2508.12758", "pdf": "https://arxiv.org/pdf/2508.12758", "abs": "https://arxiv.org/abs/2508.12758", "authors": ["Sowmini Devi Veeramachaneni", "Ramamurthy Garimella"], "title": "Constrained Centroid Clustering: A Novel Approach for Compact and Structured Partitioning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper presents Constrained Centroid Clustering (CCC), a method that\nextends classical centroid-based clustering by enforcing a constraint on the\nmaximum distance between the cluster center and the farthest point in the\ncluster. Using a Lagrangian formulation, we derive a closed-form solution that\nmaintains interpretability while controlling cluster spread. To evaluate CCC,\nwe conduct experiments on synthetic circular data with radial symmetry and\nuniform angular distribution. Using ring-wise, sector-wise, and joint entropy\nas evaluation metrics, we show that CCC achieves more compact clusters by\nreducing radial spread while preserving angular structure, outperforming\nstandard methods such as K-means and GMM. The proposed approach is suitable for\napplications requiring structured clustering with spread control, including\nsensor networks, collaborative robotics, and interpretable pattern analysis.", "AI": {"tldr": "CCC extends centroid clustering with maximum distance constraints, using Lagrangian formulation for closed-form solutions that control cluster spread while maintaining interpretability.", "motivation": "Standard centroid-based clustering methods lack explicit control over cluster spread, which is needed for applications requiring structured clustering with bounded cluster sizes.", "method": "Constrained Centroid Clustering (CCC) enforces maximum distance constraints between cluster centers and farthest points using Lagrangian formulation to derive closed-form solutions.", "result": "Experiments on synthetic circular data show CCC achieves more compact clusters by reducing radial spread while preserving angular structure, outperforming K-means and GMM.", "conclusion": "CCC provides effective spread-controlled clustering suitable for sensor networks, collaborative robotics, and interpretable pattern analysis applications."}}
{"id": "2508.12512", "pdf": "https://arxiv.org/pdf/2508.12512", "abs": "https://arxiv.org/abs/2508.12512", "authors": ["Krishna Teja Chitty-Venkata", "Murali Emani", "Venkatram Vishwanath"], "title": "LangVision-LoRA-NAS: Neural Architecture Search for Variable LoRA Rank in Vision Language Models", "categories": ["cs.CV"], "comment": "Accepted by ICIP 2025 Conference", "summary": "Vision Language Models (VLMs) integrate visual and text modalities to enable\nmultimodal understanding and generation. These models typically combine a\nVision Transformer (ViT) as an image encoder and a Large Language Model (LLM)\nfor text generation. LoRA (Low-Rank Adaptation) is an efficient fine-tuning\nmethod to adapt pre-trained models to new tasks by introducing low-rank updates\nto their weights. While LoRA has emerged as a powerful technique for\nfine-tuning large models by introducing low-rank updates, current\nimplementations assume a fixed rank, potentially limiting flexibility and\nefficiency across diverse tasks. This paper introduces\n\\textit{LangVision-LoRA-NAS}, a novel framework that integrates Neural\nArchitecture Search (NAS) with LoRA to optimize VLMs for variable-rank\nadaptation. Our approach leverages NAS to dynamically search for the optimal\nLoRA rank configuration tailored to specific multimodal tasks, balancing\nperformance and computational efficiency. Through extensive experiments using\nthe LLaMA-3.2-11B model on several datasets, LangVision-LoRA-NAS demonstrates\nnotable improvement in model performance while reducing fine-tuning costs. Our\nBase and searched fine-tuned models on LLaMA-3.2-11B-Vision-Instruct can be\nfound\n\\href{https://huggingface.co/collections/krishnateja95/llama-32-11b-vision-instruct-langvision-lora-nas-6786cac480357a6a6fcc59ee}{\\textcolor{blue}{here}}\nand the code for LangVision-LoRA-NAS can be found\n\\href{https://github.com/krishnateja95/LangVision-NAS}{\\textcolor{blue}{here}}.", "AI": {"tldr": "LangVision-LoRA-NAS integrates Neural Architecture Search with LoRA to dynamically optimize Vision Language Models for variable-rank adaptation, improving performance while reducing computational costs.", "motivation": "Current LoRA implementations use fixed ranks, limiting flexibility and efficiency across diverse multimodal tasks. This paper addresses the need for adaptive rank configurations tailored to specific Vision Language Model tasks.", "method": "The framework combines Neural Architecture Search with Low-Rank Adaptation to dynamically search for optimal LoRA rank configurations for VLMs. It uses LLaMA-3.2-11B model and experiments on multiple datasets to find the best balance between performance and efficiency.", "result": "Extensive experiments show notable improvement in model performance while reducing fine-tuning costs. The approach demonstrates effectiveness across various multimodal tasks with optimized computational efficiency.", "conclusion": "LangVision-LoRA-NAS provides an effective framework for optimizing Vision Language Models through dynamic rank adaptation, offering both performance gains and computational savings compared to fixed-rank LoRA approaches."}}
{"id": "2508.13141", "pdf": "https://arxiv.org/pdf/2508.13141", "abs": "https://arxiv.org/abs/2508.13141", "authors": ["Pranjal Aggarwal", "Seungone Kim", "Jack Lanchantin", "Sean Welleck", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "OptimalThinkingBench: Evaluating Over and Underthinking in LLMs", "categories": ["cs.CL", "cs.LG"], "comment": "26 pages, 6 tables, 10 figures", "summary": "Thinking LLMs solve complex tasks at the expense of increased compute and\noverthinking on simpler problems, while non-thinking LLMs are faster and\ncheaper but underthink on harder reasoning problems. This has led to the\ndevelopment of separate thinking and non-thinking LLM variants, leaving the\nonus of selecting the optimal model for each query on the end user. In this\nwork, we introduce OptimalThinkingBench, a unified benchmark that jointly\nevaluates overthinking and underthinking in LLMs and also encourages the\ndevelopment of optimally-thinking models that balance performance and\nefficiency. Our benchmark comprises two sub-benchmarks: OverthinkingBench,\nfeaturing simple queries in 72 domains, and UnderthinkingBench, containing 11\nchallenging reasoning tasks. Using novel thinking-adjusted accuracy metrics, we\nperform extensive evaluation of 33 different thinking and non-thinking models\nand show that no model is able to optimally think on our benchmark. Thinking\nmodels often overthink for hundreds of tokens on the simplest user queries\nwithout improving performance. In contrast, large non-thinking models\nunderthink, often falling short of much smaller thinking models. We further\nexplore several methods to encourage optimal thinking, but find that these\napproaches often improve on one sub-benchmark at the expense of the other,\nhighlighting the need for better unified and optimal models in the future.", "AI": {"tldr": "OptimalThinkingBench is a unified benchmark that evaluates both overthinking and underthinking in LLMs, showing current models fail to balance performance and efficiency optimally.", "motivation": "Current LLMs either overthink simple problems (wasting compute) or underthink complex reasoning tasks, requiring users to manually select appropriate models for different queries.", "method": "Developed two sub-benchmarks: OverthinkingBench with 72 simple domains and UnderthinkingBench with 11 challenging reasoning tasks, using novel thinking-adjusted accuracy metrics to evaluate 33 different thinking and non-thinking models.", "result": "No model achieved optimal thinking - thinking models overthink simple queries without performance gains, while large non-thinking models underthink and perform worse than smaller thinking models on complex tasks.", "conclusion": "Current approaches improve one sub-benchmark at the expense of the other, highlighting the need for better unified models that can balance performance and efficiency across different query complexities."}}
{"id": "2508.12764", "pdf": "https://arxiv.org/pdf/2508.12764", "abs": "https://arxiv.org/abs/2508.12764", "authors": ["Cyril Voyant", "Milan Despotovic", "Luis Garcia-Gutierrez", "Mohammed Asloune", "Yves-Marie Saint-Drenan", "Jean-Laurent Duchaud", "hjuvan Antone Faggianelli", "Elena Magliaro"], "title": "Short-Term Forecasting of Energy Production and Consumption Using Extreme Learning Machine: A Comprehensive MIMO based ELM Approach", "categories": ["cs.LG", "physics.data-an"], "comment": null, "summary": "A novel methodology for short-term energy forecasting using an Extreme\nLearning Machine ($\\mathtt{ELM}$) is proposed. Using six years of hourly data\ncollected in Corsica (France) from multiple energy sources (solar, wind, hydro,\nthermal, bioenergy, and imported electricity), our approach predicts both\nindividual energy outputs and total production (\\cyr{including imports, which\nclosely follow energy demand, modulo losses)} through a Multi-Input\nMulti-Output ($\\mathtt{MIMO}$) architecture. To address non-stationarity and\nseasonal variability, sliding window techniques and cyclic time encoding are\nincorporated, enabling dynamic adaptation to fluctuations. The $\\mathtt{ELM}$\nmodel significantly outperforms persistence-based forecasting, particularly for\nsolar and thermal energy, achieving an $\\mathtt{nRMSE}$ of $17.9\\%$ and\n$5.1\\%$, respectively, with $\\mathtt{R^2} > 0.98$ (1-hour horizon). The model\nmaintains high accuracy up to five hours ahead, beyond which renewable energy\nsources become increasingly volatile. While $\\mathtt{MIMO}$ provides marginal\ngains over Single-Input Single-Output ($\\mathtt{SISO}$) architectures and\noffers key advantages over deep learning methods such as $\\mathtt{LSTM}$, it\nprovides a closed-form solution with lower computational demands, making it\nwell-suited for real-time applications, including online learning. Beyond\npredictive accuracy, the proposed methodology is adaptable to various contexts\nand datasets, as it can be tuned to local constraints such as resource\navailability, grid characteristics, and market structures.", "AI": {"tldr": "ELM-based MIMO architecture for short-term energy forecasting outperforms persistence models, achieves high accuracy up to 5 hours ahead with nRMSE as low as 5.1%, and offers computational efficiency for real-time applications.", "motivation": "To develop an efficient short-term energy forecasting method that can handle multiple energy sources, address non-stationarity and seasonal variability, and provide real-time predictions adaptable to local grid constraints.", "method": "Extreme Learning Machine (ELM) with Multi-Input Multi-Output (MIMO) architecture, using sliding window techniques and cyclic time encoding to handle non-stationarity and seasonal patterns from 6 years of hourly multi-source energy data.", "result": "Significantly outperforms persistence forecasting with nRMSE of 17.9% for solar and 5.1% for thermal energy, R\u00b2 > 0.98 at 1-hour horizon. Maintains high accuracy up to 5 hours ahead. MIMO provides marginal gains over SISO with lower computational demands than LSTM.", "conclusion": "ELM-based MIMO approach provides accurate, computationally efficient short-term energy forecasting suitable for real-time applications and adaptable to various local constraints and energy market structures."}}
{"id": "2508.11704", "pdf": "https://arxiv.org/pdf/2508.11704", "abs": "https://arxiv.org/abs/2508.11704", "authors": ["Suman Saha", "Fatemeh Rahbari", "Farhan Sadique", "Sri Krishna Chaitanya Velamakanni", "Mahfuza Farooque", "William J. Rothwell"], "title": "Next-Gen Education: Enhancing AI for Microlearning", "categories": ["cs.CY", "cs.AI", "cs.ET", "cs.HC", "cs.MM"], "comment": "Published and presented in 2025 ASEE Annual Conference and\n  Exposition, 22 pages, 6 figures", "summary": "This paper explores integrating microlearning strategies into university\ncurricula, particularly in computer science education, to counteract the\ndecline in class attendance and engagement in US universities after COVID. As\nstudents increasingly opt for remote learning and recorded lectures,\ntraditional educational approaches struggle to maintain engagement and\neffectiveness. Microlearning, which breaks complex subjects into manageable\nunits, is proposed to address shorter attention spans and enhance educational\noutcomes. It uses interactive formats such as videos, quizzes, flashcards, and\nscenario-based exercises, which are especially beneficial for topics like\nalgorithms and programming logic requiring deep understanding and ongoing\npractice. Adoption of microlearning is often limited by the effort needed to\ncreate such materials. This paper proposes leveraging AI tools, specifically\nChatGPT, to reduce the workload for educators by automating the creation of\nsupplementary materials. While AI can automate certain tasks, educators remain\nessential in guiding and shaping the learning process. This AI-enhanced\napproach ensures course content is kept current with the latest research and\ntechnology, with educators providing context and insights. By examining AI\ncapabilities in microlearning, this study shows the potential to transform\neducational practices and outcomes in computer science, offering a practical\nmodel for combining advanced technology with established teaching methods.", "AI": {"tldr": "AI-enhanced microlearning using ChatGPT automates creation of interactive educational materials to improve engagement and outcomes in computer science education.", "motivation": "Address declining class attendance and engagement in US universities post-COVID by adapting to students' preference for remote learning and shorter attention spans.", "method": "Integrate microlearning strategies with AI tools (ChatGPT) to automate creation of interactive materials (videos, quizzes, flashcards, scenario-based exercises) for complex computer science topics.", "result": "Potential to transform educational practices by reducing educator workload while keeping course content current with latest research and technology.", "conclusion": "AI-enhanced microlearning offers a practical model combining advanced technology with established teaching methods to improve computer science education outcomes."}}
{"id": "2508.12520", "pdf": "https://arxiv.org/pdf/2508.12520", "abs": "https://arxiv.org/abs/2508.12520", "authors": ["Felipe Carlos dos Santos", "Eric Aislan Antonelo", "Gustavo Claudio Karl Couto"], "title": "An Initial Study of Bird's-Eye View Generation for Autonomous Vehicles using Cross-View Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages,submitted in ENIAC 2025", "summary": "Bird's-Eye View (BEV) maps provide a structured, top-down abstraction that is\ncrucial for autonomous-driving perception. In this work, we employ Cross-View\nTransformers (CVT) for learning to map camera images to three BEV's channels -\nroad, lane markings, and planned trajectory - using a realistic simulator for\nurban driving. Our study examines generalization to unseen towns, the effect of\ndifferent camera layouts, and two loss formulations (focal and L1). Using\ntraining data from only a town, a four-camera CVT trained with the L1 loss\ndelivers the most robust test performance, evaluated in a new town. Overall,\nour results underscore CVT's promise for mapping camera inputs to reasonably\naccurate BEV maps.", "AI": {"tldr": "Cross-View Transformers effectively map camera images to Bird's-Eye View maps for autonomous driving, showing strong generalization to unseen environments with optimal performance using 4 cameras and L1 loss.", "motivation": "Bird's-Eye View maps provide crucial top-down perception for autonomous driving, but learning to generate accurate BEV maps from camera inputs remains challenging, especially for generalization to new environments.", "method": "Used Cross-View Transformers (CVT) to map camera images to three BEV channels (road, lane markings, planned trajectory) using a realistic urban driving simulator. Tested different camera layouts and compared focal vs L1 loss formulations.", "result": "A four-camera CVT trained with L1 loss achieved the most robust performance when tested in unseen towns, demonstrating strong generalization capabilities from training data collected in only one town.", "conclusion": "Cross-View Transformers show significant promise for generating reasonably accurate BEV maps from camera inputs, with particular effectiveness in generalization to novel driving environments using optimal camera configuration and loss function."}}
{"id": "2508.13144", "pdf": "https://arxiv.org/pdf/2508.13144", "abs": "https://arxiv.org/abs/2508.13144", "authors": ["David Heineman", "Valentin Hofmann", "Ian Magnusson", "Yuling Gu", "Noah A. Smith", "Hannaneh Hajishirzi", "Kyle Lo", "Jesse Dodge"], "title": "Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Developing large language models is expensive and involves making decisions\nwith small experiments, typically by evaluating on large, multi-task evaluation\nsuites. In this work, we analyze specific properties which make a benchmark\nmore reliable for such decisions, and interventions to design higher-quality\nevaluation benchmarks. We introduce two key metrics that show differences in\ncurrent benchmarks: signal, a benchmark's ability to separate better models\nfrom worse models, and noise, a benchmark's sensitivity to random variability\nbetween training steps. We demonstrate that benchmarks with a better\nsignal-to-noise ratio are more reliable when making decisions at small scale,\nand those with less noise have lower scaling law prediction error. These\nresults suggest that improving signal or noise will lead to more useful\nbenchmarks, so we introduce three interventions designed to directly affect\nsignal or noise. For example, we propose that switching to a metric that has\nbetter signal and noise (e.g., perplexity rather than accuracy) leads to better\nreliability and improved scaling law error. We also find that filtering noisy\nsubtasks, to improve an aggregate signal-to-noise ratio, leads to more reliable\nmulti-task evaluations. We also find that averaging the output of a model's\nintermediate checkpoints to reduce noise leads to consistent improvements. We\nconclude by recommending that those creating new benchmarks, or selecting which\nexisting benchmarks to use, aim for high signal and low noise. We use 30\nbenchmarks for these experiments, and 375 open-weight language models from 60M\nto 32B parameters, resulting in a new, publicly available dataset of 900K\nevaluation benchmark results, totaling 200M instances.", "AI": {"tldr": "Analysis of benchmark reliability metrics (signal and noise) showing that better signal-to-noise ratios improve decision-making in LLM development and scaling law predictions, with practical interventions to enhance benchmark quality.", "motivation": "Large language model development is expensive and relies on small-scale experiments with evaluation benchmarks. Current benchmarks vary in reliability, making it difficult to make confident decisions about model improvements.", "method": "Introduced two key metrics: signal (ability to separate better from worse models) and noise (sensitivity to random variability). Tested 30 benchmarks with 375 language models (60M-32B parameters), analyzing 900K evaluation results. Proposed three interventions: switching to better metrics (e.g., perplexity over accuracy), filtering noisy subtasks, and averaging intermediate checkpoints.", "result": "Benchmarks with better signal-to-noise ratio were more reliable for small-scale decisions and had lower scaling law prediction error. All three interventions consistently improved reliability - better metrics improved both signal and noise, filtering noisy subtasks improved aggregate signal-to-noise, and checkpoint averaging reduced noise.", "conclusion": "Benchmark creators and users should prioritize high signal and low noise. Practical recommendations include using perplexity over accuracy metrics, filtering unreliable subtasks, and averaging model checkpoints to improve evaluation reliability."}}
{"id": "2508.12773", "pdf": "https://arxiv.org/pdf/2508.12773", "abs": "https://arxiv.org/abs/2508.12773", "authors": ["Jiadong Chen", "Xiao He", "Hengyu Ye", "Fuxin Jiang", "Tieying Zhang", "Jianjun Chen", "Xiaofeng Gao"], "title": "Online Ensemble Transformer for Accurate Cloud Workload Forecasting in Predictive Auto-Scaling", "categories": ["cs.LG"], "comment": "12 pages, 11 figures", "summary": "In the swiftly evolving domain of cloud computing, the advent of serverless\nsystems underscores the crucial need for predictive auto-scaling systems. This\nnecessity arises to ensure optimal resource allocation and maintain operational\nefficiency in inherently volatile environments. At the core of a predictive\nauto-scaling system is the workload forecasting model. Existing forecasting\nmodels struggle to quickly adapt to the dynamics in online workload streams and\nhave difficulty capturing the complex periodicity brought by fine-grained,\nhigh-frequency forecasting tasks. Addressing this, we propose a novel online\nensemble model, E3Former, for online workload forecasting in large-scale\npredictive auto-scaling. Our model synergizes the predictive capabilities of\nmultiple subnetworks to surmount the limitations of single-model approaches,\nthus ensuring superior accuracy and robustness. Remarkably, it accomplishes\nthis with a minimal increase in computational overhead, adhering to the lean\noperational ethos of serverless systems. Through extensive experimentation on\nreal-world workload datasets, we establish the efficacy of our ensemble model.\nIn online forecasting tasks, the proposed method reduces forecast error by an\naverage of 10%, and its effectiveness is further demonstrated through a\npredictive auto-scaling test in the real-life online system. Currently, our\nmethod has been deployed within ByteDance's Intelligent Horizontal Pod\nAuto-scaling (IHPA) platform, which supports the stable operation of over 30\napplications, such as Douyin E-Comerce, TouTiao, and Volcano Engine. The\npredictive auto-scaling capacity reaching over 600,000 CPU cores. On the basis\nof essentially ensuring service quality, the predictive auto-scaling system can\nreduce resource utilization by over 40%.", "AI": {"tldr": "E3Former is an online ensemble model for workload forecasting in serverless systems that reduces forecast error by 10% and enables 40% resource utilization reduction while supporting over 600,000 CPU cores.", "motivation": "Serverless systems require predictive auto-scaling for optimal resource allocation in volatile environments, but existing forecasting models struggle with rapid adaptation to online workload dynamics and capturing complex periodicity in high-frequency tasks.", "method": "Proposes E3Former, a novel online ensemble model that synergizes multiple subnetworks to overcome single-model limitations, achieving superior accuracy and robustness with minimal computational overhead increase.", "result": "Reduces forecast error by average 10% in online forecasting tasks, deployed in ByteDance's IHPA platform supporting 30+ applications and 600,000+ CPU cores, achieving over 40% resource utilization reduction while maintaining service quality.", "conclusion": "E3Former demonstrates effective online workload forecasting for large-scale predictive auto-scaling, providing both accuracy improvements and significant resource savings in real-world serverless deployments."}}
{"id": "2508.11706", "pdf": "https://arxiv.org/pdf/2508.11706", "abs": "https://arxiv.org/abs/2508.11706", "authors": ["Zhuofan Xu", "Benedikt Bollig", "Matthias F\u00fcgger", "Thomas Nowak", "Vincent Le Dr\u00e9au"], "title": "Centralized Permutation Equivariant Policy for Cooperative Multi-Agent Reinforcement Learning", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "The Centralized Training with Decentralized Execution (CTDE) paradigm has\ngained significant attention in multi-agent reinforcement learning (MARL) and\nis the foundation of many recent algorithms. However, decentralized policies\noperate under partial observability and often yield suboptimal performance\ncompared to centralized policies, while fully centralized approaches typically\nface scalability challenges as the number of agents increases.\n  We propose Centralized Permutation Equivariant (CPE) learning, a centralized\ntraining and execution framework that employs a fully centralized policy to\novercome these limitations. Our approach leverages a novel permutation\nequivariant architecture, Global-Local Permutation Equivariant (GLPE) networks,\nthat is lightweight, scalable, and easy to implement. Experiments show that CPE\nintegrates seamlessly with both value decomposition and actor-critic methods,\nsubstantially improving the performance of standard CTDE algorithms across\ncooperative benchmarks including MPE, SMAC, and RWARE, and matching the\nperformance of state-of-the-art RWARE implementations.", "AI": {"tldr": "CPE learning is a centralized training and execution framework that uses permutation equivariant networks to overcome limitations of decentralized policies while maintaining scalability.", "motivation": "Decentralized policies under CTDE suffer from partial observability and suboptimal performance, while fully centralized approaches face scalability issues as agent numbers increase.", "method": "Proposes Centralized Permutation Equivariant (CPE) learning with Global-Local Permutation Equivariant (GLPE) networks - a lightweight, scalable permutation equivariant architecture for fully centralized policy execution.", "result": "CPE integrates seamlessly with value decomposition and actor-critic methods, substantially improves performance of standard CTDE algorithms across MPE, SMAC, and RWARE benchmarks, and matches state-of-the-art RWARE performance.", "conclusion": "The CPE framework with GLPE networks provides an effective solution for centralized execution that overcomes scalability challenges while maintaining or improving performance over decentralized approaches."}}
{"id": "2508.12522", "pdf": "https://arxiv.org/pdf/2508.12522", "abs": "https://arxiv.org/abs/2508.12522", "authors": ["Muhammad Osama Zeeshan", "Natacha Gillet", "Alessandro Lameiras Koerich", "Marco Pedersoli", "Francois Bremond", "Eric Granger"], "title": "MuSACo: Multimodal Subject-Specific Selection and Adaptation for Expression Recognition with Co-Training", "categories": ["cs.CV"], "comment": null, "summary": "Personalized expression recognition (ER) involves adapting a machine learning\nmodel to subject-specific data for improved recognition of expressions with\nconsiderable interpersonal variability. Subject-specific ER can benefit\nsignificantly from multi-source domain adaptation (MSDA) methods, where each\ndomain corresponds to a specific subject, to improve model accuracy and\nrobustness. Despite promising results, state-of-the-art MSDA approaches often\noverlook multimodal information or blend sources into a single domain, limiting\nsubject diversity and failing to explicitly capture unique subject-specific\ncharacteristics. To address these limitations, we introduce MuSACo, a\nmulti-modal subject-specific selection and adaptation method for ER based on\nco-training. It leverages complementary information across multiple modalities\nand multiple source domains for subject-specific adaptation. This makes MuSACo\nparticularly relevant for affective computing applications in digital health,\nsuch as patient-specific assessment for stress or pain, where subject-level\nnuances are crucial. MuSACo selects source subjects relevant to the target and\ngenerates pseudo-labels using the dominant modality for class-aware learning,\nin conjunction with a class-agnostic loss to learn from less confident target\nsamples. Finally, source features from each modality are aligned, while only\nconfident target features are combined. Our experimental results on challenging\nmultimodal ER datasets: BioVid and StressID, show that MuSACo can outperform\nUDA (blending) and state-of-the-art MSDA methods.", "AI": {"tldr": "MuSACo is a multi-modal subject-specific adaptation method for expression recognition that uses co-training to leverage complementary information across modalities and source domains, outperforming existing methods on challenging datasets.", "motivation": "Current MSDA methods for personalized expression recognition often overlook multimodal information or blend sources into a single domain, failing to capture unique subject-specific characteristics crucial for applications like digital health assessment.", "method": "MuSACo uses co-training to select relevant source subjects, generates pseudo-labels using dominant modality for class-aware learning, employs class-agnostic loss for less confident samples, and aligns source features while combining only confident target features across modalities.", "result": "Experimental results on BioVid and StressID datasets show MuSACo outperforms UDA (blending) and state-of-the-art MSDA methods.", "conclusion": "MuSACo effectively addresses limitations of existing MSDA approaches by preserving subject diversity and explicitly capturing subject-specific characteristics through multimodal co-training, making it particularly suitable for affective computing applications in digital health."}}
{"id": "2508.13152", "pdf": "https://arxiv.org/pdf/2508.13152", "abs": "https://arxiv.org/abs/2508.13152", "authors": ["Xin Chen", "Junchao Wu", "Shu Yang", "Runzhe Zhan", "Zeyu Wu", "Ziyang Luo", "Di Wang", "Min Yang", "Lidia S. Chao", "Derek F. Wong"], "title": "RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to TACL 2025. This version is a pre-MIT Press publication\n  version", "summary": "Detecting content generated by large language models (LLMs) is crucial for\npreventing misuse and building trustworthy AI systems. Although existing\ndetection methods perform well, their robustness in out-of-distribution (OOD)\nscenarios is still lacking. In this paper, we hypothesize that, compared to\nfeatures used by existing detection methods, the internal representations of\nLLMs contain more comprehensive and raw features that can more effectively\ncapture and distinguish the statistical pattern differences between\nLLM-generated texts (LGT) and human-written texts (HWT). We validated this\nhypothesis across different LLMs and observed significant differences in neural\nactivation patterns when processing these two types of texts. Based on this, we\npropose RepreGuard, an efficient statistics-based detection method.\nSpecifically, we first employ a surrogate model to collect representation of\nLGT and HWT, and extract the distinct activation feature that can better\nidentify LGT. We can classify the text by calculating the projection score of\nthe text representations along this feature direction and comparing with a\nprecomputed threshold. Experimental results show that RepreGuard outperforms\nall baselines with average 94.92% AUROC on both in-distribution (ID) and OOD\nscenarios, while also demonstrating robust resilience to various text sizes and\nmainstream attacks. Data and code are publicly available at:\nhttps://github.com/NLP2CT/RepreGuard", "AI": {"tldr": "RepreGuard is a new LLM-generated text detection method that uses internal model representations to better distinguish AI-generated from human-written text, achieving 94.92% AUROC across both in-distribution and out-of-distribution scenarios.", "motivation": "Existing detection methods lack robustness in out-of-distribution scenarios. The authors hypothesize that LLMs' internal representations contain more comprehensive features that can better capture statistical pattern differences between AI-generated and human-written texts.", "method": "RepreGuard uses a surrogate model to collect representations of both text types, extracts distinct activation features that identify AI-generated content, and classifies texts by calculating projection scores along these feature directions compared to a precomputed threshold.", "result": "The method achieves average 94.92% AUROC, outperforming all baselines in both in-distribution and out-of-distribution scenarios, while showing robustness to various text sizes and mainstream attacks.", "conclusion": "Internal LLM representations provide superior features for detecting AI-generated content, enabling more robust detection across diverse scenarios compared to existing methods."}}
{"id": "2508.12776", "pdf": "https://arxiv.org/pdf/2508.12776", "abs": "https://arxiv.org/abs/2508.12776", "authors": ["Muhammad Rajabinasab", "Farhad Pakdaman", "Moncef Gabbouj", "Peter Schneider-Kamp", "Arthur Zimek"], "title": "Randomized PCA Forest for Outlier Detection", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We propose a novel unsupervised outlier detection method based on Randomized\nPrincipal Component Analysis (PCA). Inspired by the performance of Randomized\nPCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a\nnovel unsupervised outlier detection method that utilizes RPCA Forest for\noutlier detection. Experimental results showcase the superiority of the\nproposed approach compared to the classical and state-of-the-art methods in\nperforming the outlier detection task on several datasets while performing\ncompetitively on the rest. The extensive analysis of the proposed method\nreflects it high generalization power and its computational efficiency,\nhighlighting it as a good choice for unsupervised outlier detection.", "AI": {"tldr": "A novel unsupervised outlier detection method using Randomized PCA Forest that outperforms classical and state-of-the-art methods on multiple datasets while maintaining computational efficiency.", "motivation": "Inspired by the success of Randomized PCA Forest in approximate K-Nearest Neighbor search, the authors aim to develop an efficient and effective unsupervised outlier detection method that can generalize well across different datasets.", "method": "The method utilizes Randomized Principal Component Analysis (PCA) Forest for outlier detection, building on the RPCA Forest approach that was previously successful in approximate KNN search tasks.", "result": "Experimental results demonstrate superiority over classical and state-of-the-art methods on several datasets, with competitive performance on others. The method shows high generalization power and computational efficiency.", "conclusion": "The proposed Randomized PCA Forest-based approach is presented as an excellent choice for unsupervised outlier detection due to its strong performance, generalization capabilities, and computational efficiency."}}
{"id": "2508.11707", "pdf": "https://arxiv.org/pdf/2508.11707", "abs": "https://arxiv.org/abs/2508.11707", "authors": ["Sai Siddartha Maram", "Ulia Zaman", "Magy Seif El-Nasr"], "title": "Listening with Language Models: Using LLMs to Collect and Interpret Classroom Feedback", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Traditional end-of-quarter surveys often fail to provide instructors with\ntimely, detailed, and actionable feedback about their teaching. In this paper,\nwe explore how Large Language Model (LLM)-powered chatbots can reimagine the\nclassroom feedback process by engaging students in reflective, conversational\ndialogues. Through the design and deployment of a three-part\nsystem-PromptDesigner, FeedbackCollector, and FeedbackAnalyzer-we conducted a\npilot study across two graduate courses at UC Santa Cruz. Our findings suggest\nthat LLM-based feedback systems offer richer insights, greater contextual\nrelevance, and higher engagement compared to standard survey tools. Instructors\nvalued the system's adaptability, specificity, and ability to support\nmid-course adjustments, while students appreciated the conversational format\nand opportunity for elaboration. We conclude by discussing the design\nimplications of using AI to facilitate more meaningful and responsive feedback\nin higher education.", "AI": {"tldr": "LLM-powered chatbots provide more timely, detailed, and actionable classroom feedback compared to traditional end-of-quarter surveys through conversational dialogues with students.", "motivation": "Traditional end-of-quarter surveys fail to provide instructors with timely, detailed, and actionable feedback about their teaching, limiting opportunities for mid-course improvements.", "method": "Designed and deployed a three-part system (PromptDesigner, FeedbackCollector, FeedbackAnalyzer) using LLM-powered chatbots to engage students in reflective dialogues. Conducted a pilot study across two graduate courses at UC Santa Cruz.", "result": "LLM-based feedback systems offered richer insights, greater contextual relevance, and higher engagement compared to standard surveys. Instructors valued adaptability and specificity, while students appreciated conversational format and elaboration opportunities.", "conclusion": "AI-powered conversational feedback systems can facilitate more meaningful and responsive feedback in higher education, supporting mid-course adjustments and improving teaching effectiveness."}}
{"id": "2508.12543", "pdf": "https://arxiv.org/pdf/2508.12543", "abs": "https://arxiv.org/abs/2508.12543", "authors": ["Ipsita Praharaj", "Yukta Butala", "Yash Butala"], "title": "REVEAL -- Reasoning and Evaluation of Visual Evidence through Aligned Language", "categories": ["cs.CV"], "comment": "4 pages, 6 figures, International Conference on Computer Vision, ICCV\n  2025", "summary": "The rapid advancement of generative models has intensified the challenge of\ndetecting and interpreting visual forgeries, necessitating robust frameworks\nfor image forgery detection while providing reasoning as well as localization.\nWhile existing works approach this problem using supervised training for\nspecific manipulation or anomaly detection in the embedding space,\ngeneralization across domains remains a challenge. We frame this problem of\nforgery detection as a prompt-driven visual reasoning task, leveraging the\nsemantic alignment capabilities of large vision-language models. We propose a\nframework, `REVEAL` (Reasoning and Evaluation of Visual Evidence through\nAligned Language), that incorporates generalized guidelines. We propose two\ntangential approaches - (1) Holistic Scene-level Evaluation that relies on the\nphysics, semantics, perspective, and realism of the image as a whole and (2)\nRegion-wise anomaly detection that splits the image into multiple regions and\nanalyzes each of them. We conduct experiments over datasets from different\ndomains (Photoshop, DeepFake and AIGC editing). We compare the Vision Language\nModels against competitive baselines and analyze the reasoning provided by\nthem.", "AI": {"tldr": "REVEAL is a prompt-driven framework using vision-language models for image forgery detection that combines holistic scene evaluation and region-wise anomaly detection, showing strong generalization across different manipulation domains.", "motivation": "The rapid advancement of generative models has intensified challenges in detecting visual forgeries, requiring robust frameworks that can generalize across domains while providing both detection and reasoning capabilities.", "method": "Proposes REVEAL framework that uses large vision-language models for semantic alignment. Two approaches: (1) Holistic scene-level evaluation analyzing physics, semantics, perspective, and realism, and (2) Region-wise anomaly detection by splitting images into regions for individual analysis.", "result": "Experiments conducted across multiple domains (Photoshop, DeepFake, AIGC editing) show competitive performance against baselines, with analysis of the reasoning capabilities provided by the models.", "conclusion": "The prompt-driven visual reasoning approach using vision-language models provides an effective framework for generalized image forgery detection with interpretable reasoning across diverse manipulation types."}}
{"id": "2508.12787", "pdf": "https://arxiv.org/pdf/2508.12787", "abs": "https://arxiv.org/abs/2508.12787", "authors": ["Satoshi Noguchi", "Yoshinobu Kawahara"], "title": "Wavy Transformer", "categories": ["cs.LG"], "comment": "25 pages, 5 figures", "summary": "Transformers have achieved remarkable success across natural language\nprocessing (NLP) and computer vision (CV). However, deep transformer models\noften suffer from an over-smoothing issue, in which token representations\nconverge to similar values as they pass through successive transformer blocks.\nIn this paper, we establish an equivalence between the hidden-state dynamics\ninduced by stacked attention layers and graph neural diffusion on a complete\ngraph. From this perspective, over-smoothing can be interpreted as a\nconsequence of the dissipative nature of the underlying diffusion dynamics.\nMotivated by this physical interpretation, we propose Wavy Transformer, which\nconsists of a novel attention layer based on second-order wavy dynamics. We\nalso introduce a feed-forward network and a normalization layer designed to\npreserve the physical state-velocity relationship under the chain rule, thereby\nextending the transformer architecture. We further validate our proposed\ntechniques on various transformer models for NLP and CV tasks. The results\nconsistently demonstrate that Wavy Transformer improves performance with\nminimal additional parameters and no extra hyperparameter tuning.", "AI": {"tldr": "Wavy Transformer addresses over-smoothing in deep transformers by modeling attention layers as graph neural diffusion and introducing second-order wavy dynamics to prevent token representation convergence.", "motivation": "Deep transformer models suffer from over-smoothing where token representations become similar across layers, limiting model performance. The paper establishes an equivalence between attention layers and graph neural diffusion, revealing over-smoothing as a consequence of dissipative diffusion dynamics.", "method": "Proposes Wavy Transformer with novel attention layer based on second-order wavy dynamics. Also introduces specialized feed-forward network and normalization layer to preserve physical state-velocity relationship under chain rule, extending transformer architecture.", "result": "Validated on various transformer models for NLP and CV tasks. Consistently improves performance with minimal additional parameters and no extra hyperparameter tuning required.", "conclusion": "The physical interpretation of transformers as diffusion processes enables effective solutions to over-smoothing. Wavy Transformer provides a principled approach to enhance transformer performance without significant computational overhead."}}
{"id": "2508.11708", "pdf": "https://arxiv.org/pdf/2508.11708", "abs": "https://arxiv.org/abs/2508.11708", "authors": ["Rashid Mushkani", "Shin Koseki"], "title": "Street Review: A Participatory AI-Based Framework for Assessing Streetscape Inclusivity", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Urban centers undergo social, demographic, and cultural changes that shape\npublic street use and require systematic evaluation of public spaces. This\nstudy presents Street Review, a mixed-methods approach that combines\nparticipatory research with AI-based analysis to assess streetscape\ninclusivity. In Montr\\'eal, Canada, 28 residents participated in semi-directed\ninterviews and image evaluations, supported by the analysis of approximately\n45,000 street-view images from Mapillary. The approach produced visual\nanalytics, such as heatmaps, to correlate subjective user ratings with physical\nattributes like sidewalk, maintenance, greenery, and seating. Findings reveal\nvariations in perceptions of inclusivity and accessibility across demographic\ngroups, demonstrating that incorporating diverse user feedback can enhance\nmachine learning models through careful data-labeling and co-production\nstrategies. The Street Review framework offers a systematic method for urban\nplanners and policy analysts to inform planning, policy development, and\nmanagement of public streets.", "AI": {"tldr": "Street Review is a mixed-methods framework combining participatory research with AI analysis to assess streetscape inclusivity using resident feedback and 45,000 street-view images in Montreal.", "motivation": "Urban centers experience social and demographic changes that require systematic evaluation of public spaces to understand how streetscapes serve diverse communities.", "method": "Combines participatory research (28 resident interviews and image evaluations) with AI-based analysis of 45,000 Mapillary street-view images, producing visual analytics like heatmaps to correlate subjective ratings with physical attributes.", "result": "Revealed variations in perceptions of inclusivity and accessibility across demographic groups, showing that diverse user feedback enhances machine learning models through careful data-labeling and co-production strategies.", "conclusion": "The Street Review framework provides urban planners and policy analysts with a systematic method to inform planning, policy development, and management of public streets based on inclusive assessment."}}
{"id": "2508.12570", "pdf": "https://arxiv.org/pdf/2508.12570", "abs": "https://arxiv.org/abs/2508.12570", "authors": ["Yingxue Pang", "Xin Jin", "Jun Fu", "Zhibo Chen"], "title": "Structure-preserving Feature Alignment for Old Photo Colorization", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning techniques have made significant advancements in\nreference-based colorization by training on large-scale datasets. However,\ndirectly applying these methods to the task of colorizing old photos is\nchallenging due to the lack of ground truth and the notorious domain gap\nbetween natural gray images and old photos. To address this issue, we propose a\nnovel CNN-based algorithm called SFAC, i.e., Structure-preserving Feature\nAlignment Colorizer. SFAC is trained on only two images for old photo\ncolorization, eliminating the reliance on big data and allowing direct\nprocessing of the old photo itself to overcome the domain gap problem. Our\nprimary objective is to establish semantic correspondence between the two\nimages, ensuring that semantically related objects have similar colors. We\nachieve this through a feature distribution alignment loss that remains robust\nto different metric choices. However, utilizing robust semantic correspondence\nto transfer color from the reference to the old photo can result in inevitable\nstructure distortions. To mitigate this, we introduce a structure-preserving\nmechanism that incorporates a perceptual constraint at the feature level and a\nfrozen-updated pyramid at the pixel level. Extensive experiments demonstrate\nthe effectiveness of our method for old photo colorization, as confirmed by\nqualitative and quantitative metrics.", "AI": {"tldr": "SFAC is a novel CNN-based algorithm for old photo colorization that requires only two images (reference and target), uses feature alignment for semantic color transfer, and incorporates structure-preserving mechanisms to prevent distortions.", "motivation": "Existing deep learning colorization methods struggle with old photos due to lack of ground truth and domain gap between natural gray images and historical photos. Big data approaches are impractical for this specific domain.", "method": "SFAC uses structure-preserving feature alignment with semantic correspondence between reference and target images. It employs feature distribution alignment loss and structure-preserving mechanisms including perceptual constraints at feature level and frozen-updated pyramid at pixel level.", "result": "Extensive experiments show SFAC effectively colorizes old photos with both qualitative and quantitative improvements, overcoming the domain gap problem without requiring large datasets.", "conclusion": "The proposed SFAC method successfully addresses old photo colorization by eliminating big data dependency, establishing robust semantic correspondence, and preserving structure while transferring colors from reference images."}}
{"id": "2508.12792", "pdf": "https://arxiv.org/pdf/2508.12792", "abs": "https://arxiv.org/abs/2508.12792", "authors": ["Felipe Maia Polo", "Xinhe Wang", "Mikhail Yurochkin", "Gongjun Xu", "Moulinath Banerjee", "Yuekai Sun"], "title": "Bridging Human and LLM Judgments: Understanding and Narrowing the Gap", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Large language models are increasingly used as judges (LLM-as-a-judge) to\nevaluate model outputs at scale, but their assessments often diverge\nsystematically from human judgments. We present Bridge, a unified statistical\nframework that explicitly bridges human and LLM evaluations under both absolute\nscoring and pairwise comparison paradigms. Bridge posits a latent human\npreference score for each prompt-response pair and models LLM deviations as\nlinear transformations of covariates that capture sources of discrepancies.\nThis offers a simple and principled framework for refining LLM ratings and\ncharacterizing systematic discrepancies between humans and LLMs. We provide an\nefficient fitting algorithm with asymptotic guarantees for statistical\ninference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot\nArena), Bridge achieves higher agreement with human ratings (accuracy,\ncalibration, and KL divergence) and exposes systematic human-LLM gaps.", "AI": {"tldr": "Bridge is a statistical framework that bridges human and LLM evaluations by modeling systematic discrepancies through linear transformations of covariates, improving LLM-as-a-judge accuracy.", "motivation": "Large language models are increasingly used as judges to evaluate model outputs, but their assessments often diverge systematically from human judgments, creating a need for better alignment.", "method": "Bridge posits latent human preference scores and models LLM deviations as linear transformations of covariates that capture sources of discrepancies, with an efficient fitting algorithm for statistical inference.", "result": "Using six LLM judges and two benchmarks (BigGen Bench and Chatbot Arena), Bridge achieves higher agreement with human ratings in accuracy, calibration, and KL divergence, while exposing systematic human-LLM gaps.", "conclusion": "Bridge provides a simple and principled framework for refining LLM ratings and characterizing systematic discrepancies between human and LLM evaluations, improving the reliability of LLM-as-a-judge systems."}}
{"id": "2508.11709", "pdf": "https://arxiv.org/pdf/2508.11709", "abs": "https://arxiv.org/abs/2508.11709", "authors": ["Rajan Kadel", "Samar Shailendra", "Urvashi Rahul Saxena"], "title": "Navigating the New Landscape: A Conceptual Model for Project-Based Assessment (PBA) in the Age of GenAI", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The rapid integration of Generative Artificial Intelligence (GenAI) into\nhigher education presents both opportunities and challenges for assessment\ndesign, particularly within Project-Based Assessment (PBA) contexts.\nTraditional assessment methods often emphasise the final product in the PBA,\nwhich can now be significantly influenced or created by GenAI tools, raising\nconcerns regarding product authenticity, academic integrity, and learning\nvalidation. This paper advocates for a reimagined assessment model for\nProject-Based Learning (PBL) or a capstone project that prioritises\nprocess-oriented evaluation, multi-modal and multifaceted assessment design,\nand ethical engagement with GenAI to enable higher-order thinking. The model\nalso emphasises the use of (GenAI-assisted) personalised feedback by a\nsupervisor as an observance of the learning process during the project\nlifecycle. A use case scenario is provided to illustrate the application of the\nmodel in a capstone project setting. The paper concludes with recommendations\nfor educators and curriculum designers to ensure that assessment practices\nremain robust, learner-centric, and integrity-driven in the evolving landscape\nof GenAI.", "AI": {"tldr": "Proposes a process-oriented assessment model for Project-Based Learning that addresses GenAI challenges by focusing on learning process evaluation, multimodal assessment, and ethical AI engagement rather than final products.", "motivation": "The integration of Generative AI in higher education threatens traditional Project-Based Assessment methods by enabling AI-generated final products, raising concerns about authenticity, academic integrity, and learning validation.", "method": "Develops a reimagined assessment model emphasizing process-oriented evaluation, multimodal multifaceted assessment design, ethical GenAI engagement, and GenAI-assisted personalized feedback throughout the project lifecycle.", "result": "Presents a use case scenario demonstrating the model's application in capstone projects, showing how it maintains assessment robustness while accommodating GenAI tools.", "conclusion": "Provides recommendations for educators to ensure assessments remain learner-centric and integrity-driven in the GenAI era, shifting focus from product to process evaluation."}}
{"id": "2508.12586", "pdf": "https://arxiv.org/pdf/2508.12586", "abs": "https://arxiv.org/abs/2508.12586", "authors": ["Hongsong Wang", "Wanjiang Weng", "Junbo Wang", "Fang Zhao", "Guo-Sen Xie", "Xin Geng", "Liang Wang"], "title": "Foundation Model for Skeleton-Based Human Action Understanding", "categories": ["cs.CV"], "comment": "Accepted by TPAMI, Code is available at:\n  https://github.com/wengwanjiang/FoundSkelModel", "summary": "Human action understanding serves as a foundational pillar in the field of\nintelligent motion perception. Skeletons serve as a modality- and\ndevice-agnostic representation for human modeling, and skeleton-based action\nunderstanding has potential applications in humanoid robot control and\ninteraction. \\RED{However, existing works often lack the scalability and\ngeneralization required to handle diverse action understanding tasks. There is\nno skeleton foundation model that can be adapted to a wide range of action\nunderstanding tasks}. This paper presents a Unified Skeleton-based Dense\nRepresentation Learning (USDRL) framework, which serves as a foundational model\nfor skeleton-based human action understanding. USDRL consists of a\nTransformer-based Dense Spatio-Temporal Encoder (DSTE), Multi-Grained Feature\nDecorrelation (MG-FD), and Multi-Perspective Consistency Training (MPCT). The\nDSTE module adopts two parallel streams to learn temporal dynamic and spatial\nstructure features. The MG-FD module collaboratively performs feature\ndecorrelation across temporal, spatial, and instance domains to reduce\ndimensional redundancy and enhance information extraction. The MPCT module\nemploys both multi-view and multi-modal self-supervised consistency training.\nThe former enhances the learning of high-level semantics and mitigates the\nimpact of low-level discrepancies, while the latter effectively facilitates the\nlearning of informative multimodal features. We perform extensive experiments\non 25 benchmarks across across 9 skeleton-based action understanding tasks,\ncovering coarse prediction, dense prediction, and transferred prediction. Our\napproach significantly outperforms the current state-of-the-art methods. We\nhope that this work would broaden the scope of research in skeleton-based\naction understanding and encourage more attention to dense prediction tasks.", "AI": {"tldr": "USDRL is a unified skeleton foundation model that achieves state-of-the-art performance across 25 benchmarks and 9 action understanding tasks through dense spatio-temporal encoding, multi-grained feature decorrelation, and multi-perspective consistency training.", "motivation": "Existing skeleton-based action understanding methods lack scalability and generalization for diverse tasks, with no existing foundation model that can be adapted to a wide range of action understanding applications.", "method": "Transformer-based Dense Spatio-Temporal Encoder (DSTE) with parallel streams for temporal and spatial features, Multi-Grained Feature Decorrelation (MG-FD) across temporal/spatial/instance domains, and Multi-Perspective Consistency Training (MPCT) with multi-view and multi-modal self-supervision.", "result": "Significantly outperforms current state-of-the-art methods on 25 benchmarks across 9 skeleton-based action understanding tasks covering coarse, dense, and transferred prediction.", "conclusion": "USDRL serves as a foundational model that broadens research scope in skeleton-based action understanding and encourages more attention to dense prediction tasks."}}
{"id": "2508.11710", "pdf": "https://arxiv.org/pdf/2508.11710", "abs": "https://arxiv.org/abs/2508.11710", "authors": ["Hael Abdulhakim Ali Humran", "Ferdi Sonmez"], "title": "Code Vulnerability Detection Across Different Programming Languages with AI Models", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Security vulnerabilities present in a code that has been written in diverse\nprogramming languages are among the most critical yet complicated aspects of\nsource code to detect. Static analysis tools based on rule-based patterns\nusually do not work well at detecting the context-dependent bugs and lead to\nhigh false positive rates. Recent developments in artificial intelligence,\nspecifically the use of transformer-based models like CodeBERT and CodeLlama,\nprovide light to this problem, as they show potential in finding such flaws\nbetter. This paper presents the implementations of these models on various\ndatasets of code vulnerability, showing how off-the-shelf models can\nsuccessfully produce predictive capacity in models through dynamic fine-tuning\nof the models on vulnerable and safe code fragments. The methodology comprises\nthe gathering of the dataset, normalization of the language, fine-tuning of the\nmodel, and incorporation of ensemble learning and explainable AI. Experiments\nshow that a well-trained CodeBERT can be as good as or even better than some\nexisting static analyzers in terms of accuracy greater than 97%. Further study\nhas indicated that although language models can achieve close-to-perfect\nrecall, the precision can decrease. A solution to this is given by hybrid\nmodels and validation procedures, which will reduce false positives. According\nto the results, the AI-based solutions generalize to different programming\nlanguages and classes of vulnerability. Nevertheless, robustness,\ninterpretability, and deployment readiness are still being developed. The\nresults illustrate the probabilities that AI will enhance the trustworthiness\nin the usability and scalability of machine-learning-based detectors of\nvulnerabilities.", "AI": {"tldr": "Transformer-based AI models like CodeBERT and CodeLlama show strong potential for detecting security vulnerabilities in code, achieving over 97% accuracy and outperforming traditional rule-based static analysis tools.", "motivation": "Traditional static analysis tools based on rule-based patterns struggle with context-dependent bugs and produce high false positive rates, creating a need for more effective vulnerability detection methods.", "method": "The approach involves dataset collection, code normalization, fine-tuning transformer models (CodeBERT/CodeLlama) on vulnerable/safe code fragments, and incorporating ensemble learning with explainable AI techniques.", "result": "Experiments show well-trained CodeBERT achieves >97% accuracy, outperforming existing static analyzers. Models demonstrate good generalization across programming languages and vulnerability types, though precision can decrease while recall remains high.", "conclusion": "AI-based solutions show promise for enhancing vulnerability detection trustworthiness, usability, and scalability, but require further development in robustness, interpretability, and deployment readiness through hybrid models and validation procedures."}}
{"id": "2508.12798", "pdf": "https://arxiv.org/pdf/2508.12798", "abs": "https://arxiv.org/abs/2508.12798", "authors": ["Damian Machlanski", "Stephanie Riley", "Edward Moroshko", "Kurt Butler", "Panagiotis Dimitrakopoulos", "Thomas Melistas", "Akchunya Chanchal", "Steven McDonagh", "Ricardo Silva", "Sotirios A. Tsaftaris"], "title": "A Shift in Perspective on Causality in Domain Generalization", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "2 pages, 1 figure, to be presented at the UK AI Research Symposium\n  (UKAIRS) 2025", "summary": "The promise that causal modelling can lead to robust AI generalization has\nbeen challenged in recent work on domain generalization (DG) benchmarks. We\nrevisit the claims of the causality and DG literature, reconciling apparent\ncontradictions and advocating for a more nuanced theory of the role of\ncausality in generalization. We also provide an interactive demo at\nhttps://chai-uk.github.io/ukairs25-causal-predictors/.", "AI": {"tldr": "The paper reconciles contradictions between causal modeling claims and domain generalization benchmarks, advocating for a more nuanced theory of causality's role in AI generalization.", "motivation": "Recent domain generalization benchmarks have challenged the promise that causal modeling leads to robust AI generalization, creating apparent contradictions that need reconciliation.", "method": "The authors revisit claims from both causality and domain generalization literature, analyzing and reconciling apparent contradictions through theoretical examination.", "result": "The paper provides a more nuanced understanding of causality's role in generalization and offers an interactive demo to demonstrate their findings.", "conclusion": "A more sophisticated theory is needed for understanding how causal modeling contributes to robust AI generalization, moving beyond oversimplified claims."}}
{"id": "2508.12587", "pdf": "https://arxiv.org/pdf/2508.12587", "abs": "https://arxiv.org/abs/2508.12587", "authors": ["Tan-Hanh Pham", "Chris Ngo"], "title": "Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Many reasoning techniques for large multimodal models adapt language model\napproaches, such as Chain-of-Thought (CoT) prompting, which express reasoning\nas word sequences. While effective for text, these methods are suboptimal for\nmultimodal contexts, struggling to align audio, visual, and textual information\ndynamically. To explore an alternative paradigm, we propose the Multimodal\nChain of Continuous Thought (MCOUT), which enables reasoning directly in a\njoint latent space rather than in natural language. In MCOUT, the reasoning\nstate is represented as a continuous hidden vector, iteratively refined and\naligned with visual and textual embeddings, inspired by human reflective\ncognition. We develop two variants: MCOUT-Base, which reuses the language\nmodel`s last hidden state as the continuous thought for iterative reasoning,\nand MCOUT-Multi, which integrates multimodal latent attention to strengthen\ncross-modal alignment between visual and textual features. Experiments on\nbenchmarks including MMMU, ScienceQA, and MMStar show that MCOUT consistently\nimproves multimodal reasoning, yielding up to 8.23% accuracy gains over strong\nbaselines and improving BLEU scores up to 8.27% across multiple-choice and\nopen-ended tasks. These findings highlight latent continuous reasoning as a\npromising direction for advancing LMMs beyond language-bound CoT, offering a\nscalable framework for human-like reflective multimodal inference. Code is\navailable at https://github.com/Hanhpt23/OmniMod.", "AI": {"tldr": "MCOUT introduces continuous latent space reasoning for multimodal models instead of language-based CoT, achieving up to 8.23% accuracy gains on benchmarks.", "motivation": "Existing language-based reasoning methods like Chain-of-Thought are suboptimal for multimodal contexts as they struggle to dynamically align audio, visual, and textual information.", "method": "Proposes Multimodal Chain of Continuous Thought (MCOUT) with reasoning in joint latent space using continuous hidden vectors. Two variants: MCOUT-Base reuses language model's last hidden state, MCOUT-Multi uses multimodal latent attention for cross-modal alignment.", "result": "Experiments on MMMU, ScienceQA, and MMStar benchmarks show consistent improvements with up to 8.23% accuracy gains over baselines and up to 8.27% BLEU score improvements across multiple-choice and open-ended tasks.", "conclusion": "Latent continuous reasoning is a promising direction for advancing multimodal models beyond language-bound approaches, offering scalable framework for human-like reflective multimodal inference."}}
{"id": "2508.12801", "pdf": "https://arxiv.org/pdf/2508.12801", "abs": "https://arxiv.org/abs/2508.12801", "authors": ["Bowen Dong", "Yilong Fan", "Yutao Sun", "Zhenyu Li", "Tengyu Pan", "Xun Zhou", "Jianyong Wang"], "title": "Maximum Score Routing For Mixture-of-Experts", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Routing networks in sparsely activated mixture-of-experts (MoE) dynamically\nallocate input tokens to top-k experts through differentiable sparse\ntransformations, enabling scalable model capacity while preserving\ncomputational efficiency. Traditional MoE networks impose an expert capacity\nconstraint to ensure GPU-friendly computation. However, this leads to token\ndropping when capacity is saturated and results in low hardware efficiency due\nto padding in underutilized experts. Removing the capacity constraint, in turn,\ncompromises load balancing and computational efficiency. To address these\nissues, we propose Maximum Score Routing ($\\mathbf{MaxScore}$), a novel MoE\nrouting paradigm that models routing as a minimum-cost maximum-flow problem and\nintegrates a SoftTopk operator. MaxScore resolves the fundamental limitations\nof iterative rerouting and optimal transport formulations, achieving lower\ntraining losses and higher evaluation scores at equivalent FLOPs compared to\nboth constrained and unconstrained baselines. Implementation details and\nexperimental configurations can be obtained from\n$\\href{https://github.com/dongbw18/MaxScore.git}{MaxScore}$.", "AI": {"tldr": "MaxScore is a novel MoE routing method that uses minimum-cost maximum-flow optimization with SoftTopk operator to eliminate token dropping and improve hardware efficiency while maintaining load balancing.", "motivation": "Traditional MoE networks suffer from token dropping when expert capacity is saturated and low hardware efficiency due to padding in underutilized experts, while removing capacity constraints compromises load balancing and computational efficiency.", "method": "Proposes Maximum Score Routing (MaxScore) that models routing as a minimum-cost maximum-flow problem and integrates a SoftTopk operator to resolve limitations of iterative rerouting and optimal transport formulations.", "result": "Achieves lower training losses and higher evaluation scores at equivalent FLOPs compared to both constrained and unconstrained baselines.", "conclusion": "MaxScore provides an effective solution to the fundamental limitations of MoE routing, offering improved performance and efficiency without the drawbacks of traditional capacity-constrained approaches."}}
{"id": "2508.11711", "pdf": "https://arxiv.org/pdf/2508.11711", "abs": "https://arxiv.org/abs/2508.11711", "authors": ["Irash Perera", "Hiranya Abeyrathne", "Sanjeewa Malalgoda", "Arshardh Ifthikar"], "title": "Enhancing GraphQL Security by Detecting Malicious Queries Using Large Language Models, Sentence Transformers, and Convolutional Neural Networks", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "GraphQL's flexibility, while beneficial for efficient data fetching,\nintroduces unique security vulnerabilities that traditional API security\nmechanisms often fail to address. Malicious GraphQL queries can exploit the\nlanguage's dynamic nature, leading to denial-of-service attacks, data\nexfiltration through injection, and other exploits. Existing solutions, such as\nstatic analysis, rate limiting, and general-purpose Web Application Firewalls,\noffer limited protection against sophisticated, context-aware attacks. This\npaper presents a novel, AI-driven approach for real-time detection of malicious\nGraphQL queries. Our method combines static analysis with machine learning\ntechniques, including Large Language Models (LLMs) for dynamic schema-based\nconfiguration, Sentence Transformers (SBERT and Doc2Vec) for contextual\nembedding of query payloads, and Convolutional Neural Networks (CNNs), Random\nForests, and Multilayer Perceptrons for classification. We detail the system\narchitecture, implementation strategies optimized for production environments\n(including ONNX Runtime optimization and parallel processing), and evaluate the\nperformance of our detection models and the overall system under load. Results\ndemonstrate high accuracy in detecting various threats, including SQL\ninjection, OS command injection, and XSS exploits, alongside effective\nmitigation of DoS and SSRF attempts. This research contributes a robust and\nadaptable solution for enhancing GraphQL API security.", "AI": {"tldr": "AI-driven real-time detection system for malicious GraphQL queries using machine learning and static analysis to address unique security vulnerabilities in GraphQL APIs.", "motivation": "GraphQL's flexibility introduces security vulnerabilities that traditional API security mechanisms fail to address, including DoS attacks, data exfiltration, and injection exploits that existing solutions like static analysis and WAFs cannot effectively handle.", "method": "Combines static analysis with machine learning techniques including LLMs for dynamic schema configuration, Sentence Transformers (SBERT and Doc2Vec) for contextual embedding, and CNNs, Random Forests, and MLPs for classification. Features production-optimized implementation with ONNX Runtime and parallel processing.", "result": "High accuracy in detecting various threats including SQL injection, OS command injection, XSS exploits, and effective mitigation of DoS and SSRF attacks. System performs well under load with optimized production deployment.", "conclusion": "Presents a robust and adaptable AI-driven solution that significantly enhances GraphQL API security by effectively detecting and mitigating sophisticated, context-aware attacks that traditional methods cannot address."}}
{"id": "2508.12603", "pdf": "https://arxiv.org/pdf/2508.12603", "abs": "https://arxiv.org/abs/2508.12603", "authors": ["Can Cui", "Yupeng Zhou", "Juntong Peng", "Sung-Yeon Park", "Zichong Yang", "Prashanth Sankaranarayanan", "Jiaru Zhang", "Ruqi Zhang", "Ziran Wang"], "title": "ViLaD: A Large Vision Language Diffusion Framework for End-to-End Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "End-to-end autonomous driving systems built on Vision Language Models (VLMs)\nhave shown significant promise, yet their reliance on autoregressive\narchitectures introduces some limitations for real-world applications. The\nsequential, token-by-token generation process of these models results in high\ninference latency and cannot perform bidirectional reasoning, making them\nunsuitable for dynamic, safety-critical environments. To overcome these\nchallenges, we introduce ViLaD, a novel Large Vision Language Diffusion (LVLD)\nframework for end-to-end autonomous driving that represents a paradigm shift.\nViLaD leverages a masked diffusion model that enables parallel generation of\nentire driving decision sequences, significantly reducing computational\nlatency. Moreover, its architecture supports bidirectional reasoning, allowing\nthe model to consider both past and future simultaneously, and supports\nprogressive easy-first generation to iteratively improve decision quality. We\nconduct comprehensive experiments on the nuScenes dataset, where ViLaD\noutperforms state-of-the-art autoregressive VLM baselines in both planning\naccuracy and inference speed, while achieving a near-zero failure rate.\nFurthermore, we demonstrate the framework's practical viability through a\nreal-world deployment on an autonomous vehicle for an interactive parking task,\nconfirming its effectiveness and soundness for practical applications.", "AI": {"tldr": "ViLaD is a novel Large Vision Language Diffusion framework that replaces autoregressive VLMs for autonomous driving, enabling parallel generation of driving decisions with reduced latency and bidirectional reasoning capabilities.", "motivation": "Autoregressive Vision Language Models have high inference latency and cannot perform bidirectional reasoning, making them unsuitable for safety-critical autonomous driving applications that require real-time decision making.", "method": "Uses a masked diffusion model that enables parallel generation of entire driving decision sequences, supports bidirectional reasoning (considering both past and future simultaneously), and progressive easy-first generation for iterative decision improvement.", "result": "Outperforms state-of-the-art autoregressive VLM baselines on nuScenes dataset in both planning accuracy and inference speed, achieving near-zero failure rate. Successfully deployed on real autonomous vehicle for interactive parking task.", "conclusion": "ViLaD represents a paradigm shift for end-to-end autonomous driving, offering practical viability with reduced computational latency and improved decision quality through parallel generation and bidirectional reasoning capabilities."}}
{"id": "2508.11759", "pdf": "https://arxiv.org/pdf/2508.11759", "abs": "https://arxiv.org/abs/2508.11759", "authors": ["Peter Lindes", "Kaoutar Skiker"], "title": "Using Natural Language for Human-Robot Collaboration in the Real World", "categories": ["cs.RO", "cs.AI", "cs.CL"], "comment": "34 pages, 11 figures, 5 tables. Submitted for publication (2026) in\n  W.F. Lawless, Ranjeev Mittu, Shannon P. McGrarry, & Marco Brambilla (Eds.),\n  Generative AI Risks and Benefits within Human-Machine Teams, Elsevier,\n  Chapter 6", "summary": "We have a vision of a day when autonomous robots can collaborate with humans\nas assistants in performing complex tasks in the physical world. This vision\nincludes that the robots will have the ability to communicate with their human\ncollaborators using language that is natural to the humans. Traditional\nInteractive Task Learning (ITL) systems have some of this ability, but the\nlanguage they can understand is very limited. The advent of large language\nmodels (LLMs) provides an opportunity to greatly improve the language\nunderstanding of robots, yet integrating the language abilities of LLMs with\nrobots that operate in the real physical world is a challenging problem.\n  In this chapter we first review briefly a few commercial robot products that\nwork closely with humans, and discuss how they could be much better\ncollaborators with robust language abilities. We then explore how an AI system\nwith a cognitive agent that controls a physical robot at its core, interacts\nwith both a human and an LLM, and accumulates situational knowledge through its\nexperiences, can be a possible approach to reach that vision. We focus on three\nspecific challenges of having the robot understand natural language, and\npresent a simple proof-of-concept experiment using ChatGPT for each. Finally,\nwe discuss what it will take to turn these simple experiments into an\noperational system where LLM-assisted language understanding is a part of an\nintegrated robotic assistant that uses language to collaborate with humans.", "AI": {"tldr": "Exploring integration of large language models (LLMs) with physical robots to enable natural language collaboration between humans and robotic assistants, addressing challenges in real-world language understanding.", "motivation": "To enable autonomous robots to collaborate with humans using natural language, overcoming limitations of traditional Interactive Task Learning systems by leveraging LLMs' advanced language capabilities.", "method": "Proposes a cognitive agent architecture that controls physical robots, interacts with humans and LLMs, and accumulates situational knowledge. Presents proof-of-concept experiments using ChatGPT to address three specific natural language understanding challenges.", "result": "Demonstrates feasibility through simple experiments showing that LLMs can help robots understand natural language commands, though operational integration requires further development.", "conclusion": "LLM-assisted language understanding shows promise for creating integrated robotic assistants that can collaborate with humans using natural language, but requires turning proof-of-concept experiments into fully operational systems."}}
{"id": "2508.12815", "pdf": "https://arxiv.org/pdf/2508.12815", "abs": "https://arxiv.org/abs/2508.12815", "authors": ["Jayneel Parekh", "Pegah Khayatan", "Mustafa Shukor", "Arnaud Dapogny", "Alasdair Newson", "Matthieu Cord"], "title": "Learning to Steer: Input-dependent Steering for Multimodal LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Steering has emerged as a practical approach to enable post-hoc guidance of\nLLMs towards enforcing a specific behavior. However, it remains largely\nunderexplored for multimodal LLMs (MLLMs); furthermore, existing steering\ntechniques, such as mean steering, rely on a single steering vector, applied\nindependently of the input query. This paradigm faces limitations when the\ndesired behavior is dependent on the example at hand. For example, a safe\nanswer may consist in abstaining from answering when asked for an illegal\nactivity, or may point to external resources or consultation with an expert\nwhen asked about medical advice. In this paper, we investigate a fine-grained\nsteering that uses an input-specific linear shift. This shift is computed using\ncontrastive input-specific prompting. However, the input-specific prompts\nrequired for this approach are not known at test time. Therefore, we propose to\ntrain a small auxiliary module to predict the input-specific steering vector.\nOur approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces\nhallucinations and enforces safety in MLLMs, outperforming other static\nbaselines.", "AI": {"tldr": "L2S (Learn-to-Steer) introduces input-specific steering for multimodal LLMs using contrastive prompting and an auxiliary module to predict steering vectors, reducing hallucinations and improving safety.", "motivation": "Existing steering techniques like mean steering use a single static vector that doesn't account for input-dependent behaviors, limiting effectiveness for context-sensitive tasks like safety enforcement.", "method": "Proposes fine-grained steering with input-specific linear shifts computed via contrastive prompting, and trains a small auxiliary module to predict these steering vectors at test time.", "result": "L2S outperforms static baselines by reducing hallucinations and enforcing safety in multimodal LLMs through context-aware steering.", "conclusion": "Input-specific steering via learned auxiliary modules provides more effective and context-aware control over MLLM behavior compared to static steering approaches."}}
{"id": "2508.11715", "pdf": "https://arxiv.org/pdf/2508.11715", "abs": "https://arxiv.org/abs/2508.11715", "authors": ["Ananya Singha", "Harshita Sahijwani", "Walt Williams", "Emmanuel Aboah Boateng", "Nick Hausman", "Miguel Di Luca", "Keegan Choudhury", "Chaya Binet", "Vu Le", "Tianwei Chen", "Oryan Rokeah Chen", "Sulaiman Vesal", "Sadid Hasan"], "title": "Benchmark Dataset Generation and Evaluation for Excel Formula Repair with LLMs", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted at the KDD workshop on Evaluation and Trustworthiness of\n  Agentic and Generative AI Models", "summary": "Excel is a pervasive yet often complex tool, particularly for novice users,\nwhere runtime errors arising from logical mistakes or misinterpretations of\nfunctions pose a significant challenge. While large language models (LLMs)\noffer promising assistance by explaining formula errors, the automated\ncorrection of these semantic runtime errors remains an open problem. A primary\nchallenge to advancing models for such scenarios is the severe lack of\nhigh-quality, comprehensive datasets for training and rigorous evaluation. This\npaper addresses this gap by introducing a novel approach for constructing a\nbenchmark dataset specifically designed for Excel formula repair. We propose a\ndata generation pipeline, which leverages a small set of curated seed samples\nfrom online forums to synthetically expand the dataset. Our pipeline integrates\nfew-shot prompting with LLMs and employs a robust \\textit{LLM-as-a-Judge}\nvalidation framework, combined with execution-based checks to ensure the\ncorrectness and semantic fidelity of the generated data. This process produced\na benchmark dataset of 618 high-quality samples, covering common runtime\nerrors. Furthermore, we propose a context-aware baseline technique for Excel\nformula repair that utilizes LLMs to leverage both the faulty formula, and\nrelevant spreadsheet context. We evaluate the performance of various LLMs\n(GPT-4o, GPT-4.1, Phi-3, Mistral) on our newly generated benchmark using\nexecution-based metrics. Our analysis demonstrates the dataset's quality\nthrough manual annotation and provides insights into error and function\ndistributions. The proposed generation methodology is highly scalable and can\nbe readily adapted to create evaluation benchmarks for similar code repair\ntasks in other low-resource programming languages.", "AI": {"tldr": "This paper introduces a novel benchmark dataset and generation pipeline for Excel formula repair, addressing the lack of high-quality datasets for training and evaluating models that fix semantic runtime errors in Excel formulas.", "motivation": "Excel is complex for novice users who often make logical errors in formulas, but there's a severe lack of comprehensive datasets to train and evaluate models for automated Excel formula repair.", "method": "Proposed a data generation pipeline using few-shot prompting with LLMs and LLM-as-a-Judge validation framework with execution-based checks. Also developed a context-aware baseline technique that uses LLMs to repair formulas using both faulty formulas and spreadsheet context.", "result": "Created a benchmark dataset of 618 high-quality samples covering common runtime errors. Evaluated various LLMs (GPT-4o, GPT-4.1, Phi-3, Mistral) using execution-based metrics, with manual annotation confirming dataset quality.", "conclusion": "The generation methodology is scalable and adaptable for creating evaluation benchmarks for similar code repair tasks in other low-resource programming languages."}}
{"id": "2508.12605", "pdf": "https://arxiv.org/pdf/2508.12605", "abs": "https://arxiv.org/abs/2508.12605", "authors": ["Wenjie Liao", "Jieyu Yuan", "Yifang Xu", "Chunle Guo", "Zilong Zhang", "Jihong Li", "Jiachen Fu", "Haotian Fan", "Tao Li", "Junhui Cui", "Chongyi Li"], "title": "ViDA-UGC: Detailed Image Quality Analysis via Visual Distortion Assessment for UGC Images", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have introduced a\nparadigm shift for Image Quality Assessment (IQA) from unexplainable image\nquality scoring to explainable IQA, demonstrating practical applications like\nquality control and optimization guidance. However, current explainable IQA\nmethods not only inadequately use the same distortion criteria to evaluate both\nUser-Generated Content (UGC) and AI-Generated Content (AIGC) images, but also\nlack detailed quality analysis for monitoring image quality and guiding image\nrestoration. In this study, we establish the first large-scale Visual\nDistortion Assessment Instruction Tuning Dataset for UGC images, termed\nViDA-UGC, which comprises 11K images with fine-grained quality grounding,\ndetailed quality perception, and reasoning quality description data. This\ndataset is constructed through a distortion-oriented pipeline, which involves\nhuman subject annotation and a Chain-of-Thought (CoT) assessment framework.\nThis framework guides GPT-4o to generate quality descriptions by identifying\nand analyzing UGC distortions, which helps capturing rich low-level visual\nfeatures that inherently correlate with distortion patterns. Moreover, we\ncarefully select 476 images with corresponding 6,149 question answer pairs from\nViDA-UGC and invite a professional team to ensure the accuracy and quality of\nGPT-generated information. The selected and revised data further contribute to\nthe first UGC distortion assessment benchmark, termed ViDA-UGC-Bench.\nExperimental results demonstrate the effectiveness of the ViDA-UGC and CoT\nframework for consistently enhancing various image quality analysis abilities\nacross multiple base MLLMs on ViDA-UGC-Bench and Q-Bench, even surpassing\nGPT-4o.", "AI": {"tldr": "This paper introduces ViDA-UGC, the first large-scale visual distortion assessment dataset for user-generated content images, featuring fine-grained quality annotations and a Chain-of-Thought framework that enables explainable image quality assessment surpassing GPT-4o performance.", "motivation": "Current explainable IQA methods inadequately evaluate both UGC and AIGC images using the same distortion criteria, and lack detailed quality analysis for monitoring image quality and guiding image restoration.", "method": "Created ViDA-UGC dataset with 11K images using human annotation and CoT assessment framework to guide GPT-4o in generating quality descriptions. Also developed ViDA-UGC-Bench benchmark with 476 images and 6,149 QA pairs professionally validated.", "result": "Experimental results show the ViDA-UGC dataset and CoT framework consistently enhance various image quality analysis abilities across multiple base MLLMs, even surpassing GPT-4o performance.", "conclusion": "The proposed ViDA-UGC dataset and CoT framework provide an effective solution for explainable image quality assessment of user-generated content, enabling better quality monitoring and restoration guidance."}}
{"id": "2508.12833", "pdf": "https://arxiv.org/pdf/2508.12833", "abs": "https://arxiv.org/abs/2508.12833", "authors": ["Kichang Lee", "Songkuk Kim", "JaeYeon Park", "JeongGil Ko"], "title": "Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG", "categories": ["cs.LG", "cs.AI", "68Txx", "I.2; I.4.2; E.4"], "comment": "6pages, 6figures", "summary": "On-device machine learning is often constrained by limited storage,\nparticularly in continuous data collection scenarios. This paper presents an\nempirical study on storage-aware learning, focusing on the trade-off between\ndata quantity and quality via compression. We demonstrate that naive\nstrategies, such as uniform data dropping or one-size-fits-all compression, are\nsuboptimal. Our findings further reveal that data samples exhibit varying\nsensitivities to compression, supporting the feasibility of a sample-wise\nadaptive compression strategy. These insights provide a foundation for\ndeveloping a new class of storage-aware learning systems. The primary\ncontribution of this work is the systematic characterization of this\nunder-explored challenge, offering valuable insights that advance the\nunderstanding of storage-aware learning.", "AI": {"tldr": "Empirical study shows naive compression strategies are suboptimal for on-device ML storage constraints, revealing sample-dependent compression sensitivity enables adaptive strategies.", "motivation": "On-device machine learning faces storage limitations, especially in continuous data collection scenarios, requiring efficient compression strategies.", "method": "Empirical study analyzing trade-offs between data quantity and quality through compression, comparing naive strategies vs. sample-wise adaptive approaches.", "result": "Demonstrated that uniform data dropping and one-size-fits-all compression are suboptimal, and revealed varying compression sensitivity across data samples.", "conclusion": "Findings provide foundation for developing storage-aware learning systems with sample-adaptive compression strategies, advancing understanding of this under-explored challenge."}}
{"id": "2508.11716", "pdf": "https://arxiv.org/pdf/2508.11716", "abs": "https://arxiv.org/abs/2508.11716", "authors": ["Javier Mu\u00f1oz-Haro", "Ruben Tolosana", "Ruben Vera-Rodriguez", "Aythami Morales", "Julian Fierrez"], "title": "Privacy-Aware Detection of Fake Identity Documents: Methodology, Benchmark, and Improved Detection Methods (FakeIDet2)", "categories": ["cs.CR", "cs.AI", "cs.CV", "eess.IV"], "comment": null, "summary": "Remote user verification in Internet-based applications is becoming\nincreasingly important nowadays. A popular scenario for it consists of\nsubmitting a picture of the user's Identity Document (ID) to a service\nplatform, authenticating its veracity, and then granting access to the\nrequested digital service. An ID is well-suited to verify the identity of an\nindividual, since it is government issued, unique, and nontransferable.\nHowever, with recent advances in Artificial Intelligence (AI), attackers can\nsurpass security measures in IDs and create very realistic physical and\nsynthetic fake IDs. Researchers are now trying to develop methods to detect an\never-growing number of these AI-based fakes that are almost indistinguishable\nfrom authentic (bona fide) IDs. In this counterattack effort, researchers are\nfaced with an important challenge: the difficulty in using real data to train\nfake ID detectors. This real data scarcity for research and development is\noriginated by the sensitive nature of these documents, which are usually kept\nprivate by the ID owners (the users) and the ID Holders (e.g., government,\npolice, bank, etc.). The main contributions of our study are: 1) We propose and\ndiscuss a patch-based methodology to preserve privacy in fake ID detection\nresearch. 2) We provide a new public database, FakeIDet2-db, comprising over\n900K real/fake ID patches extracted from 2,000 ID images, acquired using\ndifferent smartphone sensors, illumination and height conditions, etc. In\naddition, three physical attacks are considered: print, screen, and composite.\n3) We present a new privacy-aware fake ID detection method, FakeIDet2. 4) We\nrelease a standard reproducible benchmark that considers physical and synthetic\nattacks from popular databases in the literature.", "AI": {"tldr": "Proposes privacy-preserving fake ID detection using patch-based methodology, releases FakeIDet2-db dataset with 900K+ patches, and introduces FakeIDet2 method with benchmark for physical and synthetic ID attacks.", "motivation": "Remote user verification via ID documents is crucial but vulnerable to AI-generated fake IDs. Research is hindered by lack of real ID data due to privacy concerns.", "method": "Patch-based methodology to preserve privacy, creation of FakeIDet2-db dataset with 900K+ real/fake ID patches, development of FakeIDet2 detection method, and reproducible benchmark.", "result": "Provides comprehensive solution addressing data scarcity through privacy-preserving patches and establishes benchmark for evaluating fake ID detection against various physical attacks.", "conclusion": "The proposed approach enables effective fake ID detection research while maintaining privacy, with publicly available dataset and benchmark to advance the field."}}
{"id": "2508.12610", "pdf": "https://arxiv.org/pdf/2508.12610", "abs": "https://arxiv.org/abs/2508.12610", "authors": ["Chen Qian", "Danyang Li", "Xinran Yu", "Zheng Yang", "Qiang Ma"], "title": "OpenMoCap: Rethinking Optical Motion Capture under Real-world Occlusion", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Optical motion capture is a foundational technology driving advancements in\ncutting-edge fields such as virtual reality and film production. However,\nsystem performance suffers severely under large-scale marker occlusions common\nin real-world applications. An in-depth analysis identifies two primary\nlimitations of current models: (i) the lack of training datasets accurately\nreflecting realistic marker occlusion patterns, and (ii) the absence of\ntraining strategies designed to capture long-range dependencies among markers.\nTo tackle these challenges, we introduce the CMU-Occlu dataset, which\nincorporates ray tracing techniques to realistically simulate practical marker\nocclusion patterns. Furthermore, we propose OpenMoCap, a novel motion-solving\nmodel designed specifically for robust motion capture in environments with\nsignificant occlusions. Leveraging a marker-joint chain inference mechanism,\nOpenMoCap enables simultaneous optimization and construction of deep\nconstraints between markers and joints. Extensive comparative experiments\ndemonstrate that OpenMoCap consistently outperforms competing methods across\ndiverse scenarios, while the CMU-Occlu dataset opens the door for future\nstudies in robust motion solving. The proposed OpenMoCap is integrated into the\nMoSen MoCap system for practical deployment. The code is released at:\nhttps://github.com/qianchen214/OpenMoCap.", "AI": {"tldr": "OpenMoCap introduces a novel motion-solving model and CMU-Occlu dataset to address severe performance degradation in optical motion capture systems under large-scale marker occlusions, outperforming existing methods.", "motivation": "Current optical motion capture systems suffer severely from performance degradation under large-scale marker occlusions common in real-world applications, due to lack of realistic training datasets and training strategies for long-range marker dependencies.", "method": "Created CMU-Occlu dataset using ray tracing to simulate realistic occlusion patterns, and developed OpenMoCap model with marker-joint chain inference mechanism for simultaneous optimization and deep constraint construction between markers and joints.", "result": "OpenMoCap consistently outperforms competing methods across diverse scenarios, and the CMU-Occlu dataset enables future robust motion solving studies.", "conclusion": "The proposed solution effectively addresses marker occlusion challenges in motion capture, with OpenMoCap integrated into practical MoSen MoCap system and code publicly released for community use."}}
{"id": "2508.12837", "pdf": "https://arxiv.org/pdf/2508.12837", "abs": "https://arxiv.org/abs/2508.12837", "authors": ["Aditya Varre", "Gizem Y\u00fcce", "Nicolas Flammarion"], "title": "Learning In-context $\\pmb{n}$-grams with Transformers: Sub-$\\pmb{n}$-grams Are Near-stationary Points", "categories": ["cs.LG"], "comment": "ICML2025", "summary": "Motivated by empirical observations of prolonged plateaus and stage-wise\nprogression during training, we investigate the loss landscape of transformer\nmodels trained on in-context next-token prediction tasks. In particular, we\nfocus on learning in-context $n$-gram language models under cross-entropy loss,\nand establish a sufficient condition for parameter configurations to be\nstationary points. We then construct a set of parameter configurations for a\nsimplified transformer model that represent $k$-gram estimators (for $k \\leq\nn$), and show that the gradient of the population loss at these solutions\nvanishes in the limit of infinite sequence length and parameter norm. This\nreveals a key property of the loss landscape: {sub-$n$-grams are\nnear-stationary points of the population cross-entropy loss}, offering\ntheoretical insight into widely observed phenomena such as stage-wise learning\ndynamics and emergent phase transitions. These insights are further supported\nby numerical experiments that illustrate the learning dynamics of $n$-grams,\ncharacterized by discrete transitions between near-stationary solutions.", "AI": {"tldr": "Transformers learning n-gram language models exhibit stage-wise progression with sub-n-grams as near-stationary points in the loss landscape, explaining observed plateaus and discrete transitions during training.", "motivation": "Empirical observations show prolonged plateaus and stage-wise progression during transformer training, motivating investigation of the loss landscape for in-context next-token prediction tasks.", "method": "Analyze learning of in-context n-gram language models under cross-entropy loss, establish sufficient conditions for stationary points, and construct parameter configurations representing k-gram estimators for simplified transformer models.", "result": "Sub-n-grams are near-stationary points of population cross-entropy loss in the limit of infinite sequence length and parameter norm, revealing discrete transitions between near-stationary solutions.", "conclusion": "Theoretical analysis provides insight into stage-wise learning dynamics and emergent phase transitions, supported by numerical experiments showing characteristic learning dynamics of n-grams."}}
{"id": "2508.11719", "pdf": "https://arxiv.org/pdf/2508.11719", "abs": "https://arxiv.org/abs/2508.11719", "authors": ["Matthias Scheutz"], "title": "Are AI Machines Making Humans Obsolete?", "categories": ["cs.CY", "cs.AI"], "comment": "Forthcoming in Ramana Kumar Vinjamuri (ed.) \"Bridging the Gap between\n  Mind and Machine\", Springer", "summary": "This chapter starts with a sketch of how we got to \"generative AI\" (GenAI)\nand a brief summary of the various impacts it had so far. It then discusses\nsome of the opportunities of GenAI, followed by the challenges and dangers,\nincluding dystopian outcomes resulting from using uncontrolled machine learning\nand our failures to understand the results. It concludes with some suggestions\nfor how to control GenAI and address its dangers.", "AI": {"tldr": "Overview of generative AI's evolution, impacts, opportunities, challenges, and control measures", "motivation": "To provide a comprehensive understanding of generative AI's development, current impacts, and future implications including both opportunities and risks", "method": "Analytical review and discussion of generative AI's trajectory, examining its technological evolution, societal impacts, and potential control mechanisms", "result": "Identifies both promising opportunities and significant dangers of generative AI, including dystopian risks from uncontrolled machine learning systems", "conclusion": "Proposes specific suggestions for controlling generative AI and addressing its potential dangers to prevent negative outcomes"}}
{"id": "2508.12615", "pdf": "https://arxiv.org/pdf/2508.12615", "abs": "https://arxiv.org/abs/2508.12615", "authors": ["Wenhao Zhang", "Hao Zhu", "Delong Wu", "Di Kang", "Linchao Bao", "Zhan Ma", "Xun Cao"], "title": "WIPES: Wavelet-based Visual Primitives", "categories": ["cs.CV"], "comment": "IEEE/CVF International Conference on Computer Vision", "summary": "Pursuing a continuous visual representation that offers flexible frequency\nmodulation and fast rendering speed has recently garnered increasing attention\nin the fields of 3D vision and graphics. However, existing representations\noften rely on frequency guidance or complex neural network decoding, leading to\nspectrum loss or slow rendering. To address these limitations, we propose\nWIPES, a universal Wavelet-based vIsual PrimitivES for representing\nmulti-dimensional visual signals. Building on the spatial-frequency\nlocalization advantages of wavelets, WIPES effectively captures both the\nlow-frequency \"forest\" and the high-frequency \"trees.\" Additionally, we develop\na wavelet-based differentiable rasterizer to achieve fast visual rendering.\nExperimental results on various visual tasks, including 2D image\nrepresentation, 5D static and 6D dynamic novel view synthesis, demonstrate that\nWIPES, as a visual primitive, offers higher rendering quality and faster\ninference than INR-based methods, and outperforms Gaussian-based\nrepresentations in rendering quality.", "AI": {"tldr": "WIPES is a wavelet-based visual primitive that achieves high-quality rendering with fast inference by leveraging wavelet spatial-frequency localization, outperforming both INR-based methods in speed and Gaussian-based representations in quality.", "motivation": "Existing visual representations suffer from spectrum loss or slow rendering due to reliance on frequency guidance or complex neural decoding. There's a need for a continuous visual representation that offers flexible frequency modulation and fast rendering speed.", "method": "Proposes WIPES, a universal wavelet-based visual primitive that builds on wavelet spatial-frequency localization advantages to capture both low and high frequency details. Also develops a wavelet-based differentiable rasterizer for fast visual rendering.", "result": "Experimental results across various visual tasks (2D image representation, 5D static and 6D dynamic novel view synthesis) show WIPES offers higher rendering quality and faster inference than INR-based methods, and outperforms Gaussian-based representations in rendering quality.", "conclusion": "WIPES serves as an effective visual primitive that addresses spectrum loss and slow rendering issues in existing representations, providing superior rendering performance across multiple visual tasks."}}
{"id": "2508.12839", "pdf": "https://arxiv.org/pdf/2508.12839", "abs": "https://arxiv.org/abs/2508.12839", "authors": ["Tiancheng Zhang", "Cheng Zhang", "Shuren Liu", "Xiaofei Wang", "Shaoyuan Huang", "Wenyu Wang"], "title": "HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 14 figures, ECAI2025", "summary": "With the rapid proliferation of streaming services, network load exhibits\nhighly time-varying and bursty behavior, posing serious challenges for\nmaintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms\n(CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS\nand profitability, accurate load forecasting remains challenging under traffic\nsurges. Existing methods either minimize mean absolute error, resulting in\nunderprovisioning and potential Service Level Agreement (SLA) violations during\npeak periods, or adopt conservative overprovisioning strategies, which mitigate\nSLA risks at the expense of increased resource expenditure. To address this\ndilemma, we propose HRS, a hybrid representation framework with scheduling\nawareness that integrates numerical and image-based representations to better\ncapture extreme load dynamics. We further introduce a Scheduling-Aware Loss\n(SAL) that captures the asymmetric impact of prediction errors, guiding\npredictions that better support scheduling decisions. Extensive experiments on\nfour real-world datasets demonstrate that HRS consistently outperforms ten\nbaselines and achieves state-of-the-art performance, reducing SLA violation\nrates by 63.1% and total profit loss by 32.3%.", "AI": {"tldr": "HRS framework combines numerical and image representations with scheduling-aware loss to improve load forecasting accuracy during traffic surges, reducing SLA violations by 63.1% and profit loss by 32.3%.", "motivation": "Existing load forecasting methods for streaming services either cause underprovisioning (SLA violations) or conservative overprovisioning (increased costs), creating a dilemma for maintaining QoS in Crowdsourced Cloud-Edge Platforms.", "method": "Proposed HRS - a hybrid representation framework that integrates numerical and image-based representations to capture extreme load dynamics, plus a Scheduling-Aware Loss (SAL) that accounts for asymmetric impact of prediction errors.", "result": "Extensive experiments on four real-world datasets show HRS outperforms ten baselines, achieving state-of-the-art performance with 63.1% reduction in SLA violation rates and 32.3% reduction in total profit loss.", "conclusion": "HRS effectively addresses the forecasting dilemma in CCPs by providing more accurate predictions that better support scheduling decisions, significantly improving both QoS and profitability."}}
{"id": "2508.12628", "pdf": "https://arxiv.org/pdf/2508.12628", "abs": "https://arxiv.org/abs/2508.12628", "authors": ["Yukang Lin", "Xiang Zhang", "Shichang Jia", "Bowen Wan", "Chenghan Fu", "Xudong Ren", "Yueran Liu", "Wanxian Guan", "Pengji Wang", "Jian Xu", "Bo Zheng", "Baolin Liu"], "title": "Creative4U: MLLMs-based Advertising Creative Image Selector with Comparative Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Creative image in advertising is the heart and soul of e-commerce platform.\nAn eye-catching creative image can enhance the shopping experience for users,\nboosting income for advertisers and advertising revenue for platforms. With the\nadvent of AIGC technology, advertisers can produce large quantities of creative\nimages at minimal cost. However, they struggle to assess the creative quality\nto select. Existing methods primarily focus on creative ranking, which fails to\naddress the need for explainable creative selection.\n  In this work, we propose the first paradigm for explainable creative\nassessment and selection. Powered by multimodal large language models (MLLMs),\nour approach integrates the assessment and selection of creative images into a\nnatural language generation task. To facilitate this research, we construct\nCreativePair, the first comparative reasoning-induced creative dataset\nfeaturing 8k annotated image pairs, with each sample including a label\nindicating which image is superior. Additionally, we introduce Creative4U\n(pronounced Creative for You), a MLLMs-based creative selector that takes into\naccount users' interests. Through Reason-to-Select RFT, which includes\nsupervised fine-tuning with Chain-of-Thought (CoT-SFT) and Group Relative\nPolicy Optimization (GRPO) based reinforcement learning, Creative4U is able to\nevaluate and select creative images accurately. Both offline and online\nexperiments demonstrate the effectiveness of our approach. Our code and dataset\nwill be made public to advance research and industrial applications.", "AI": {"tldr": "Proposes Creative4U, an MLLM-based explainable creative image assessment system using comparative reasoning and reinforcement learning for e-commerce advertising.", "motivation": "Advertisers can generate large quantities of creative images with AIGC but lack methods to assess quality and make explainable selections for optimal advertising performance.", "method": "Uses multimodal LLMs to integrate assessment and selection into natural language generation. Creates CreativePair dataset with 8k annotated image pairs. Develops Creative4U with Chain-of-Thought supervised fine-tuning and Group Relative Policy Optimization reinforcement learning.", "result": "Both offline and online experiments demonstrate effective creative image evaluation and selection capabilities.", "conclusion": "The approach provides the first paradigm for explainable creative assessment and selection, advancing both research and industrial applications in e-commerce advertising."}}
{"id": "2508.12885", "pdf": "https://arxiv.org/pdf/2508.12885", "abs": "https://arxiv.org/abs/2508.12885", "authors": ["Aleksei Liuliakov", "Alexander Schulz", "Luca Hermes", "Barbara Hammer"], "title": "One-Class Intrusion Detection with Dynamic Graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "With the growing digitalization all over the globe, the relevance of network\nsecurity becomes increasingly important. Machine learning-based intrusion\ndetection constitutes a promising approach for improving security, but it bears\nseveral challenges. These include the requirement to detect novel and unseen\nnetwork events, as well as specific data properties, such as events over time\ntogether with the inherent graph structure of network communication. In this\nwork, we propose a novel intrusion detection method, TGN-SVDD, which builds\nupon modern dynamic graph modelling and deep anomaly detection. We demonstrate\nits superiority over several baselines for realistic intrusion detection data\nand suggest a more challenging variant of the latter.", "AI": {"tldr": "TGN-SVDD: A novel intrusion detection method combining dynamic graph modeling and deep anomaly detection that outperforms baselines on realistic network data.", "motivation": "Growing digitalization increases network security importance. Machine learning-based intrusion detection faces challenges including detecting novel/unseen network events, handling temporal events, and capturing inherent graph structure of network communications.", "method": "Proposes TGN-SVDD method that builds upon modern dynamic graph modelling and deep anomaly detection techniques to address the specific challenges of network intrusion detection.", "result": "Demonstrates superiority over several baselines for realistic intrusion detection data.", "conclusion": "Suggests a more challenging variant of intrusion detection data and presents TGN-SVDD as an effective solution that outperforms existing approaches."}}
{"id": "2508.12638", "pdf": "https://arxiv.org/pdf/2508.12638", "abs": "https://arxiv.org/abs/2508.12638", "authors": ["Chen Qian", "Xinran Yu", "Zewen Huang", "Danyang Li", "Qiang Ma", "Fan Dang", "Xuan Ding", "Guangyong Shang", "Zheng Yang"], "title": "SpotVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) are increasingly deployed in real-time\napplications such as autonomous driving and human-computer interaction, which\ndemand fast and reliable responses based on accurate perception. To meet these\nrequirements, existing systems commonly employ cloud-edge collaborative\narchitectures, such as partitioned Large Vision-Language Models (LVLMs) or task\noffloading strategies between Large and Small Vision-Language Models (SVLMs).\nHowever, these methods fail to accommodate cloud latency fluctuations and\noverlook the full potential of delayed but accurate LVLM responses. In this\nwork, we propose a novel cloud-edge collaborative paradigm for VLMs, termed\nContext Transfer, which treats the delayed outputs of LVLMs as historical\ncontext to provide real-time guidance for SVLMs inference. Based on this\nparadigm, we design SpotVLM, which incorporates both context replacement and\nvisual focus modules to refine historical textual input and enhance visual\ngrounding consistency. Extensive experiments on three real-time vision tasks\nacross four datasets demonstrate the effectiveness of the proposed framework.\nThe new paradigm lays the groundwork for more effective and latency-aware\ncollaboration strategies in future VLM systems.", "AI": {"tldr": "Proposes Context Transfer paradigm using delayed LVLM outputs as historical context to guide real-time SVLM inference, with SpotVLM implementation showing effectiveness across vision tasks.", "motivation": "Existing cloud-edge collaborative architectures for VLMs fail to handle cloud latency fluctuations and don't leverage delayed but accurate LVLM responses for real-time applications like autonomous driving.", "method": "Context Transfer paradigm treats delayed LVLM outputs as historical context to guide SVLM inference. SpotVLM implementation includes context replacement and visual focus modules to refine textual input and enhance visual grounding consistency.", "result": "Extensive experiments on three real-time vision tasks across four datasets demonstrate the effectiveness of the proposed framework.", "conclusion": "The new paradigm establishes groundwork for more effective and latency-aware collaboration strategies in future VLM systems."}}
{"id": "2508.11925", "pdf": "https://arxiv.org/pdf/2508.11925", "abs": "https://arxiv.org/abs/2508.11925", "authors": ["Zhimeng Guo", "Huaisheng Zhu", "Siyuan Xu", "Hangfan Zhang", "Teng Xiao", "Minhao Cheng"], "title": "Optimizing Token Choice for Code Watermarking: A RL Approach", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": "18 pages, 3 figures", "summary": "The need for detecting LLM-generated code necessitates watermarking systems\ncapable of operating within its highly structured and syntactically constrained\nenvironment. To address this, we introduce CodeTracer, an innovative adaptive\ncode watermarking framework underpinned by a novel reinforcement learning\ntraining paradigm. At its core, CodeTracer features a policy-driven approach\nthat utilizes a parameterized model to intelligently bias token choices during\nnext-token prediction. This strategy ensures that embedded watermarks maintain\ncode functionality while exhibiting subtle yet statistically detectable\ndeviations from typical token distributions. To facilitate policy learning, we\ndevise a comprehensive reward system that seamlessly integrates execution\nfeedback with watermark embedding signals, balancing process-level and\noutcome-level rewards. Additionally, we employ Gumbel Top-k reparameterization\nto enable gradient-based optimization of discrete watermarking decisions.\nExtensive comparative evaluations demonstrate CodeTracer's significant\nsuperiority over state-of-the-art baselines in both watermark detectability and\nthe preservation of generated code's functionality.", "AI": {"tldr": "CodeTracer is a reinforcement learning-based framework for watermarking LLM-generated code that intelligently biases token choices to embed detectable watermarks while preserving code functionality.", "motivation": "There's a growing need to detect LLM-generated code, requiring watermarking systems that can operate within the highly structured and syntactically constrained environment of programming languages.", "method": "Uses a policy-driven reinforcement learning approach with parameterized model to bias token choices during next-token prediction, Gumbel Top-k reparameterization for gradient optimization, and comprehensive reward system integrating execution feedback with watermark signals.", "result": "Extensive evaluations show CodeTracer significantly outperforms state-of-the-art baselines in both watermark detectability and preservation of generated code's functionality.", "conclusion": "The framework successfully addresses the challenge of watermarking LLM-generated code by maintaining functionality while embedding statistically detectable deviations through adaptive reinforcement learning."}}
{"id": "2508.12905", "pdf": "https://arxiv.org/pdf/2508.12905", "abs": "https://arxiv.org/abs/2508.12905", "authors": ["Ismail Lamaakal", "Chaymae Yahyati", "Khalid El Makkaoui", "Ibrahim Ouahbi", "Yassine Maleh"], "title": "TCUQ: Single-Pass Uncertainty Quantification from Temporal Consistency with Streaming Conformal Calibration for TinyML", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We introduce TCUQ, a single pass, label free uncertainty monitor for\nstreaming TinyML that converts short horizon temporal consistency captured via\nlightweight signals on posteriors and features into a calibrated risk score\nwith an O(W ) ring buffer and O(1) per step updates. A streaming conformal\nlayer turns this score into a budgeted accept/abstain rule, yielding calibrated\nbehavior without online labels or extra forward passes. On microcontrollers,\nTCUQ fits comfortably on kilobyte scale devices and reduces footprint and\nlatency versus early exit and deep ensembles (typically about 50 to 60% smaller\nand about 30 to 45% faster), while methods of similar accuracy often run out of\nmemory. Under corrupted in distribution streams, TCUQ improves accuracy drop\ndetection by 3 to 7 AUPRC points and reaches up to 0.86 AUPRC at high\nseverities; for failure detection it attains up to 0.92 AUROC. These results\nshow that temporal consistency, coupled with streaming conformal calibration,\nprovides a practical and resource efficient foundation for on device monitoring\nin TinyML.", "AI": {"tldr": "TCUQ is a lightweight uncertainty monitor for TinyML that uses temporal consistency and streaming conformal calibration to provide risk scores with minimal resource usage, achieving significant footprint and latency reductions compared to alternatives.", "motivation": "To enable reliable uncertainty monitoring on resource-constrained TinyML devices without requiring online labels or extra computational overhead, addressing the limitations of existing methods like early exit and deep ensembles.", "method": "Single-pass, label-free approach that converts short-horizon temporal consistency from lightweight signals on posteriors and features into calibrated risk scores using O(W) ring buffer and O(1) per-step updates, with streaming conformal calibration for budgeted accept/abstain decisions.", "result": "50-60% smaller footprint and 30-45% faster than early exit/ensembles; 3-7 AUPRC improvement in accuracy drop detection (up to 0.86 AUPRC); up to 0.92 AUROC for failure detection; fits on kilobyte-scale microcontrollers.", "conclusion": "Temporal consistency coupled with streaming conformal calibration provides a practical, resource-efficient foundation for on-device uncertainty monitoring in TinyML applications."}}
{"id": "2508.11729", "pdf": "https://arxiv.org/pdf/2508.11729", "abs": "https://arxiv.org/abs/2508.11729", "authors": ["Ninell Oldenburg", "Gleb Papyshev"], "title": "The Stories We Govern By: AI, Risk, and the Power of Imaginaries", "categories": ["cs.CY", "cs.AI", "K.4.2"], "comment": "10 pages, accepted at the 8th AAAI/ACM Conference on AI, Ethics, and\n  Society", "summary": "This paper examines how competing sociotechnical imaginaries of artificial\nintelligence (AI) risk shape governance decisions and regulatory constraints.\nDrawing on concepts from science and technology studies, we analyse three\ndominant narrative groups: existential risk proponents, who emphasise\ncatastrophic AGI scenarios; accelerationists, who portray AI as a\ntransformative force to be unleashed; and critical AI scholars, who foreground\npresent-day harms rooted in systemic inequality. Through an analysis of\nrepresentative manifesto-style texts, we explore how these imaginaries differ\nacross four dimensions: normative visions of the future, diagnoses of the\npresent social order, views on science and technology, and perceived human\nagency in managing AI risks. Our findings reveal how these narratives embed\ndistinct assumptions about risk and have the potential to progress into\npolicy-making processes by narrowing the space for alternative governance\napproaches. We argue against speculative dogmatism and for moving beyond\ndeterministic imaginaries toward regulatory strategies that are grounded in\npragmatism.", "AI": {"tldr": "Analysis of three competing AI risk narratives and their influence on governance, advocating for pragmatic regulatory approaches over speculative determinism.", "motivation": "To understand how different sociotechnical imaginaries of AI risk shape governance decisions and regulatory constraints, examining how these narratives influence policy-making processes.", "method": "Analysis of representative manifesto-style texts from three dominant narrative groups: existential risk proponents, accelerationists, and critical AI scholars, comparing them across four dimensions: normative visions, present diagnoses, views on technology, and perceived human agency.", "result": "Reveals how these narratives embed distinct assumptions about risk and narrow the space for alternative governance approaches, potentially progressing into policy-making processes.", "conclusion": "Argues against speculative dogmatism and for moving beyond deterministic imaginaries toward regulatory strategies grounded in pragmatism rather than speculative future scenarios."}}
{"id": "2508.12640", "pdf": "https://arxiv.org/pdf/2508.12640", "abs": "https://arxiv.org/abs/2508.12640", "authors": ["Bastian Brandst\u00f6tter", "Erich Kobler"], "title": "Synthesizing Accurate and Realistic T1-weighted Contrast-Enhanced MR Images using Posterior-Mean Rectified Flow", "categories": ["cs.CV", "cs.LG"], "comment": "12 pages, 3 figures, MICCAI workshops (SASHIMI) 2025", "summary": "Contrast-enhanced (CE) T1-weighted MRI is central to neuro-oncologic\ndiagnosis but requires gadolinium-based agents, which add cost and scan time,\nraise environmental concerns, and may pose risks to patients. In this work, we\npropose a two-stage Posterior-Mean Rectified Flow (PMRF) pipeline for\nsynthesizing volumetric CE brain MRI from non-contrast inputs. First, a\npatch-based 3D U-Net predicts the voxel-wise posterior mean (minimizing MSE).\nThen, this initial estimate is refined by a time-conditioned 3D rectified flow\nto incorporate realistic textures without compromising structural fidelity. We\ntrain this model on a multi-institutional collection of paired pre- and\npost-contrast T1w volumes (BraTS 2023-2025). On a held-out test set of 360\ndiverse volumes, our best refined outputs achieve an axial FID of $12.46$ and\nKID of $0.007$ ($\\sim 68.7\\%$ lower FID than the posterior mean) while\nmaintaining low volumetric MSE of $0.057$ ($\\sim 27\\%$ higher than the\nposterior mean). Qualitative comparisons confirm that our method restores\nlesion margins and vascular details realistically, effectively navigating the\nperception-distortion trade-off for clinical deployment.", "AI": {"tldr": "Two-stage PMRF pipeline synthesizes contrast-enhanced brain MRI from non-contrast inputs using patch-based 3D U-Net and rectified flow refinement, achieving significant FID/KID improvements while maintaining structural fidelity.", "motivation": "Eliminate need for gadolinium-based contrast agents in MRI to reduce cost, scan time, environmental impact, and patient risks while maintaining diagnostic quality.", "method": "Two-stage approach: 1) Patch-based 3D U-Net predicts voxel-wise posterior mean (MSE minimization), 2) Time-conditioned 3D rectified flow refines initial estimate to add realistic textures without compromising structure.", "result": "Achieved axial FID of 12.46 and KID of 0.007 (68.7% lower FID than posterior mean) with volumetric MSE of 0.057 (27% higher than posterior mean) on 360 test volumes. Restores lesion margins and vascular details realistically.", "conclusion": "Method effectively navigates perception-distortion trade-off for clinical deployment, providing realistic contrast-enhanced MRI synthesis without gadolinium agents."}}
{"id": "2508.12906", "pdf": "https://arxiv.org/pdf/2508.12906", "abs": "https://arxiv.org/abs/2508.12906", "authors": ["Boran Zhao", "Haiming Zhai", "Zihang Yuan", "Hetian Liu", "Tian Xia", "Wenzhe Zhao", "Pengju Ren"], "title": "SparseMap: A Sparse Tensor Accelerator Framework Based on Evolution Strategy", "categories": ["cs.LG"], "comment": null, "summary": "The growing demand for sparse tensor algebra (SpTA) in machine learning and\nbig data has driven the development of various sparse tensor accelerators.\nHowever, most existing manually designed accelerators are limited to specific\nscenarios, and it's time-consuming and challenging to adjust a large number of\ndesign factors when scenarios change. Therefore, automating the design of SpTA\naccelerators is crucial. Nevertheless, previous works focus solely on either\nmapping (i.e., tiling communication and computation in space and time) or\nsparse strategy (i.e., bypassing zero elements for efficiency), leading to\nsuboptimal designs due to the lack of comprehensive consideration of both. A\nunified framework that jointly optimizes both is urgently needed. However,\nintegrating mapping and sparse strategies leads to a combinatorial explosion in\nthe design space(e.g., as large as $O(10^{41})$ for the workload $P_{32 \\times\n64} \\times Q_{64 \\times 48} = Z_{32 \\times 48}$). This vast search space\nrenders most conventional optimization methods (e.g., particle swarm\noptimization, reinforcement learning and Monte Carlo tree search) inefficient.\nTo address this challenge, we propose an evolution strategy-based sparse tensor\naccelerator optimization framework, called SparseMap. SparseMap constructing a\nmore comprehensive design space with the consideration of both mapping and\nsparse strategy. We introduce a series of enhancements to genetic encoding and\nevolutionary operators, enabling SparseMap to efficiently explore the vast and\ndiverse design space. We quantitatively compare SparseMap with prior works and\nclassical optimization methods, demonstrating that SparseMap consistently finds\nsuperior solutions.", "AI": {"tldr": "SparseMap is an evolution strategy-based framework that jointly optimizes mapping and sparse strategies for tensor accelerators, overcoming combinatorial explosion in design space to find superior solutions.", "motivation": "Existing sparse tensor accelerator designs are limited to specific scenarios and lack comprehensive optimization of both mapping and sparse strategies, leading to suboptimal performance when scenarios change.", "method": "Proposes SparseMap framework using enhanced genetic encoding and evolutionary operators to efficiently explore the vast design space (up to O(10^41) that combines both mapping (tiling communication/computation) and sparse strategies (zero-element bypassing).", "result": "SparseMap consistently finds superior solutions compared to prior works and classical optimization methods like particle swarm optimization, reinforcement learning, and Monte Carlo tree search.", "conclusion": "The unified framework successfully addresses the combinatorial explosion challenge in sparse tensor accelerator design space, providing an efficient automated optimization approach that outperforms conventional methods."}}
{"id": "2508.12643", "pdf": "https://arxiv.org/pdf/2508.12643", "abs": "https://arxiv.org/abs/2508.12643", "authors": ["Pinci Yang", "Peisong Wen", "Ke Ma", "Qianqian Xu"], "title": "Learn Faster and Remember More: Balancing Exploration and Exploitation for Continual Test-time Adaptation", "categories": ["cs.CV"], "comment": null, "summary": "Continual Test-Time Adaptation (CTTA) aims to adapt a source pre-trained\nmodel to continually changing target domains during inference. As a fundamental\nprinciple, an ideal CTTA method should rapidly adapt to new domains\n(exploration) while retaining and exploiting knowledge from previously\nencountered domains to handle similar domains in the future. Despite\nsignificant advances, balancing exploration and exploitation in CTTA is still\nchallenging: 1) Existing methods focus on adjusting predictions based on\ndeep-layer outputs of neural networks. However, domain shifts typically affect\nshallow features, which are inefficient to be adjusted from deep predictions,\nleading to dilatory exploration; 2) A single model inevitably forgets knowledge\nof previous domains during the exploration, making it incapable of exploiting\nhistorical knowledge to handle similar future domains. To address these\nchallenges, this paper proposes a mean teacher framework that strikes an\nappropriate Balance between Exploration and Exploitation (BEE) during the CTTA\nprocess. For the former challenge, we introduce a Multi-level Consistency\nRegularization (MCR) loss that aligns the intermediate features of the student\nand teacher models, accelerating adaptation to the current domain. For the\nlatter challenge, we employ a Complementary Anchor Replay (CAR) mechanism to\nreuse historical checkpoints (anchors), recovering complementary knowledge for\ndiverse domains. Experiments show that our method significantly outperforms\nstate-of-the-art methods on several benchmarks, demonstrating its effectiveness\nfor CTTA tasks.", "AI": {"tldr": "A mean teacher framework called BEE that balances exploration (quick adaptation to new domains) and exploitation (retaining historical knowledge) in Continual Test-Time Adaptation using multi-level consistency regularization and complementary anchor replay.", "motivation": "Existing CTTA methods struggle to balance rapid adaptation to new domains while retaining knowledge from previous domains. They focus on deep-layer adjustments which are inefficient for shallow feature domain shifts, and single models forget historical knowledge during adaptation.", "method": "Proposes a mean teacher framework with Multi-level Consistency Regularization (MCR) to align intermediate features between student and teacher models for faster adaptation, and Complementary Anchor Replay (CAR) to reuse historical checkpoints for knowledge retention.", "result": "Significantly outperforms state-of-the-art methods on several benchmarks, demonstrating effective balance between exploration and exploitation in CTTA tasks.", "conclusion": "The proposed BEE framework successfully addresses the exploration-exploitation trade-off in CTTA through feature-level consistency regularization and historical knowledge reuse, achieving superior performance compared to existing methods."}}
{"id": "2508.12072", "pdf": "https://arxiv.org/pdf/2508.12072", "abs": "https://arxiv.org/abs/2508.12072", "authors": ["Wei Jie Yeo", "Ranjan Satapathy", "Erik Cambria"], "title": "Mitigating Jailbreaks with Intent-Aware LLMs", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Despite extensive safety-tuning, large language models (LLMs) remain\nvulnerable to jailbreak attacks via adversarially crafted instructions,\nreflecting a persistent trade-off between safety and task performance. In this\nwork, we propose Intent-FT, a simple and lightweight fine-tuning approach that\nexplicitly trains LLMs to infer the underlying intent of an instruction before\nresponding. By fine-tuning on a targeted set of adversarial instructions,\nIntent-FT enables LLMs to generalize intent deduction to unseen attacks,\nthereby substantially improving their robustness. We comprehensively evaluate\nboth parametric and non-parametric attacks across open-source and proprietary\nmodels, considering harmfulness from attacks, utility, over-refusal, and impact\nagainst white-box threats. Empirically, Intent-FT consistently mitigates all\nevaluated attack categories, with no single attack exceeding a 50\\% success\nrate -- whereas existing defenses remain only partially effective. Importantly,\nour method preserves the model's general capabilities and reduces excessive\nrefusals on benign instructions containing superficially harmful keywords.\nFurthermore, models trained with Intent-FT accurately identify hidden harmful\nintent in adversarial attacks, and these learned intentions can be effectively\ntransferred to enhance vanilla model defenses.", "AI": {"tldr": "Intent-FT is a lightweight fine-tuning method that trains LLMs to infer instruction intent before responding, significantly improving jailbreak resistance while preserving general capabilities.", "motivation": "Large language models remain vulnerable to jailbreak attacks despite safety-tuning, reflecting a persistent trade-off between safety and task performance.", "method": "Fine-tuning LLMs on adversarial instructions to explicitly infer underlying intent before generating responses, enabling generalization to unseen attacks.", "result": "Consistently mitigates all evaluated attack categories with no single attack exceeding 50% success rate, preserves general capabilities, reduces excessive refusals, and enables intent transfer to enhance vanilla models.", "conclusion": "Intent-FT provides a simple yet effective approach to significantly improve LLM robustness against jailbreak attacks while maintaining utility and reducing over-refusal issues."}}
{"id": "2508.12907", "pdf": "https://arxiv.org/pdf/2508.12907", "abs": "https://arxiv.org/abs/2508.12907", "authors": ["Ismail Lamaakal", "Chaymae Yahyati", "Khalid El Makkaoui", "Ibrahim Ouahbi", "Yassine Maleh"], "title": "SNAP-UQ: Self-supervised Next-Activation Prediction for Single-Pass Uncertainty in TinyML", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We introduce \\textbf{SNAP-UQ}, a single-pass, label-free uncertainty method\nfor TinyML that estimates risk from \\emph{depth-wise next-activation\nprediction}: tiny int8 heads forecast the statistics of the next layer from a\ncompressed view of the previous one, and a lightweight monotone mapper turns\nthe resulting surprisal into an actionable score. The design requires no\ntemporal buffers, auxiliary exits, or repeated forward passes, and adds only a\nfew tens of kilobytes to MCU deployments. Across vision and audio backbones,\nSNAP-UQ consistently reduces flash and latency relative to early-exit and deep\nensembles (typically $\\sim$40--60\\% smaller and $\\sim$25--35\\% faster), with\ncompeting methods of similar accuracy often exceeding memory limits. In\ncorrupted streams it improves accuracy-drop detection by several AUPRC points\nand maintains strong failure detection (AUROC $\\approx$0.9) in a single pass.\nGrounding uncertainty in layer-to-layer dynamics yields a practical,\nresource-efficient basis for on-device monitoring in TinyML.", "AI": {"tldr": "SNAP-UQ is a single-pass, label-free uncertainty estimation method for TinyML that predicts next layer activations to estimate risk, requiring minimal resources while maintaining strong performance.", "motivation": "Existing uncertainty quantification methods for TinyML are resource-intensive, requiring temporal buffers, auxiliary exits, or repeated forward passes, which are impractical for memory-constrained microcontrollers.", "method": "Uses tiny int8 heads to forecast statistics of the next layer from compressed previous layer views, with a lightweight monotone mapper converting surprisal into actionable uncertainty scores without buffers or multiple passes.", "result": "Reduces flash and latency by 40-60% and 25-35% respectively compared to early-exit and deep ensembles, improves accuracy-drop detection by several AUPRC points, and maintains AUROC \u22480.9 for failure detection in single pass.", "conclusion": "Grounding uncertainty in layer-to-layer dynamics provides a practical, resource-efficient solution for on-device monitoring in TinyML applications with minimal memory footprint."}}
{"id": "2508.11733", "pdf": "https://arxiv.org/pdf/2508.11733", "abs": "https://arxiv.org/abs/2508.11733", "authors": ["Ruijia Zhang", "Xinyan Zhao", "Ruixiang Wang", "Sigen Chen", "Guibin Zhang", "An Zhang", "Kun Wang", "Qingsong Wen"], "title": "SafeSieve: From Heuristics to Experience in Progressive Pruning for LLM-based Multi-Agent Communication", "categories": ["cs.MA", "cs.AI"], "comment": "7 pages for main content, 5 figures, 4 tables", "summary": "LLM-based multi-agent systems exhibit strong collaborative capabilities but\noften suffer from redundant communication and excessive token overhead.\nExisting methods typically enhance efficiency through pretrained GNNs or greedy\nalgorithms, but often isolate pre- and post-task optimization, lacking a\nunified strategy. To this end, we present SafeSieve, a progressive and adaptive\nmulti-agent pruning algorithm that dynamically refines the inter-agent\ncommunication through a novel dual-mechanism. SafeSieve integrates initial\nLLM-based semantic evaluation with accumulated performance feedback, enabling a\nsmooth transition from heuristic initialization to experience-driven\nrefinement. Unlike existing greedy Top-k pruning methods, SafeSieve employs\n0-extension clustering to preserve structurally coherent agent groups while\neliminating ineffective links. Experiments across benchmarks (SVAMP, HumanEval,\netc.) showcase that SafeSieve achieves 94.01% average accuracy while reducing\ntoken usage by 12.4%-27.8%. Results further demonstrate robustness under prompt\ninjection attacks (1.23% average accuracy drop). In heterogeneous settings,\nSafeSieve reduces deployment costs by 13.3% while maintaining performance.\nThese results establish SafeSieve as a robust, efficient, and scalable\nframework for practical multi-agent systems. Our code can be found in\nhttps://anonymous.4open.science/r/SafeSieve-D8F2FFUN.", "AI": {"tldr": "SafeSieve is a progressive multi-agent pruning algorithm that reduces token usage by 12.4%-27.8% while maintaining 94.01% accuracy, using dual-mechanism communication refinement and 0-extension clustering.", "motivation": "LLM-based multi-agent systems suffer from redundant communication and excessive token overhead, with existing methods isolating pre- and post-task optimization without unified strategy.", "method": "Progressive adaptive pruning algorithm with dual-mechanism: initial LLM-based semantic evaluation + accumulated performance feedback, using 0-extension clustering to preserve coherent agent groups while eliminating ineffective links.", "result": "Achieves 94.01% average accuracy, reduces token usage by 12.4%-27.8%, shows robustness under prompt injection attacks (only 1.23% accuracy drop), and reduces deployment costs by 13.3% in heterogeneous settings.", "conclusion": "SafeSieve establishes a robust, efficient, and scalable framework for practical multi-agent systems, outperforming existing greedy Top-k pruning methods with better structural coherence preservation."}}
{"id": "2508.12644", "pdf": "https://arxiv.org/pdf/2508.12644", "abs": "https://arxiv.org/abs/2508.12644", "authors": ["Hao Wen", "Hongbo Kang", "Jian Ma", "Jing Huang", "Yuanwang Yang", "Haozhe Lin", "Yu-Kun Lai", "Kun Li"], "title": "DyCrowd: Towards Dynamic Crowd Reconstruction from a Large-scene Video", "categories": ["cs.CV"], "comment": null, "summary": "3D reconstruction of dynamic crowds in large scenes has become increasingly\nimportant for applications such as city surveillance and crowd analysis.\nHowever, current works attempt to reconstruct 3D crowds from a static image,\ncausing a lack of temporal consistency and inability to alleviate the typical\nimpact caused by occlusions. In this paper, we propose DyCrowd, the first\nframework for spatio-temporally consistent 3D reconstruction of hundreds of\nindividuals' poses, positions and shapes from a large-scene video. We design a\ncoarse-to-fine group-guided motion optimization strategy for occlusion-robust\ncrowd reconstruction in large scenes. To address temporal instability and\nsevere occlusions, we further incorporate a VAE (Variational Autoencoder)-based\nhuman motion prior along with a segment-level group-guided optimization. The\ncore of our strategy leverages collective crowd behavior to address long-term\ndynamic occlusions. By jointly optimizing the motion sequences of individuals\nwith similar motion segments and combining this with the proposed Asynchronous\nMotion Consistency (AMC) loss, we enable high-quality unoccluded motion\nsegments to guide the motion recovery of occluded ones, ensuring robust and\nplausible motion recovery even in the presence of temporal desynchronization\nand rhythmic inconsistencies. Additionally, in order to fill the gap of no\nexisting well-annotated large-scene video dataset, we contribute a virtual\nbenchmark dataset, VirtualCrowd, for evaluating dynamic crowd reconstruction\nfrom large-scene videos. Experimental results demonstrate that the proposed\nmethod achieves state-of-the-art performance in the large-scene dynamic crowd\nreconstruction task. The code and dataset will be available for research\npurposes.", "AI": {"tldr": "DyCrowd is a framework for spatio-temporally consistent 3D reconstruction of hundreds of individuals' poses, positions and shapes from large-scene videos, addressing occlusion challenges through group-guided motion optimization and VAE-based motion priors.", "motivation": "Current 3D crowd reconstruction methods work from static images, lacking temporal consistency and struggling with occlusions. There's a need for robust reconstruction from video sequences in large scenes for applications like city surveillance and crowd analysis.", "method": "Coarse-to-fine group-guided motion optimization strategy with VAE-based human motion prior and segment-level optimization. Uses collective crowd behavior to handle occlusions, with Asynchronous Motion Consistency (AMC) loss for temporal synchronization. Also created VirtualCrowd benchmark dataset.", "result": "Achieves state-of-the-art performance in large-scene dynamic crowd reconstruction, demonstrating robust motion recovery even with temporal desynchronization and severe occlusions.", "conclusion": "The proposed framework successfully addresses temporal consistency and occlusion challenges in 3D crowd reconstruction from videos, providing a comprehensive solution with both methodology and benchmark dataset for future research."}}
{"id": "2508.12978", "pdf": "https://arxiv.org/pdf/2508.12978", "abs": "https://arxiv.org/abs/2508.12978", "authors": ["Yue Xia", "Tayyebeh Jahani-Nezhad", "Rawad Bitar"], "title": "Fed-DPRoC:Communication-Efficient Differentially Private and Robust Federated Learning", "categories": ["cs.LG", "cs.DC", "cs.IT", "math.IT"], "comment": null, "summary": "We propose Fed-DPRoC, a novel federated learning framework that\nsimultaneously ensures differential privacy (DP), Byzantine robustness, and\ncommunication efficiency. We introduce the concept of robust-compatible\ncompression, which enables users to compress DP-protected updates while\nmaintaining the robustness of the aggregation rule. We instantiate our\nframework as RobAJoL, combining the Johnson-Lindenstrauss (JL) transform for\ncompression with robust averaging for robust aggregation. We theoretically\nprove the compatibility of JL transform with robust averaging and show that\nRobAJoL preserves robustness guarantees, ensures DP, and reduces communication\ncost. Experiments on CIFAR-10 and Fashion MNIST validate our theoretical claims\nand demonstrate that RobAJoL outperforms existing methods in terms of\nrobustness and utility under different Byzantine attacks.", "AI": {"tldr": "Fed-DPRoC is a federated learning framework that combines differential privacy, Byzantine robustness, and communication efficiency through robust-compatible compression.", "motivation": "Existing federated learning approaches struggle to simultaneously address privacy protection (DP), robustness against Byzantine attacks, and communication efficiency, creating a need for an integrated solution.", "method": "Proposes RobAJoL which combines Johnson-Lindenstrauss transform for compression with robust averaging for aggregation, theoretically proving their compatibility for maintaining robustness while compressing DP-protected updates.", "result": "Theoretical proofs show RobAJoL preserves robustness guarantees, ensures differential privacy, and reduces communication costs. Experiments on CIFAR-10 and Fashion MNIST demonstrate superior robustness and utility under various Byzantine attacks compared to existing methods.", "conclusion": "Fed-DPRoC successfully integrates DP, Byzantine robustness, and communication efficiency through the novel concept of robust-compatible compression, with RobAJoL providing a practical instantiation that outperforms current approaches."}}
{"id": "2508.12663", "pdf": "https://arxiv.org/pdf/2508.12663", "abs": "https://arxiv.org/abs/2508.12663", "authors": ["Seung Young Noh", "Ju Yong Chang"], "title": "Stable Diffusion-Based Approach for Human De-Occlusion", "categories": ["cs.CV"], "comment": "MM 2025", "summary": "Humans can infer the missing parts of an occluded object by leveraging prior\nknowledge and visible cues. However, enabling deep learning models to\naccurately predict such occluded regions remains a challenging task.\nDe-occlusion addresses this problem by reconstructing both the mask and RGB\nappearance. In this work, we focus on human de-occlusion, specifically\ntargeting the recovery of occluded body structures and appearances. Our\napproach decomposes the task into two stages: mask completion and RGB\ncompletion. The first stage leverages a diffusion-based human body prior to\nprovide a comprehensive representation of body structure, combined with\noccluded joint heatmaps that offer explicit spatial cues about missing regions.\nThe reconstructed amodal mask then serves as a conditioning input for the\nsecond stage, guiding the model on which areas require RGB reconstruction. To\nfurther enhance RGB generation, we incorporate human-specific textual features\nderived using a visual question answering (VQA) model and encoded via a CLIP\nencoder. RGB completion is performed using Stable Diffusion, with decoder\nfine-tuning applied to mitigate pixel-level degradation in visible regions -- a\nknown limitation of prior diffusion-based de-occlusion methods caused by latent\nspace transformations. Our method effectively reconstructs human appearances\neven under severe occlusions and consistently outperforms existing methods in\nboth mask and RGB completion. Moreover, the de-occluded images generated by our\napproach can improve the performance of downstream human-centric tasks, such as\n2D pose estimation and 3D human reconstruction. The code will be made publicly\navailable.", "AI": {"tldr": "A two-stage human de-occlusion method using diffusion models for mask completion with body priors and joint heatmaps, followed by RGB completion with Stable Diffusion and human-specific textual features, achieving state-of-the-art results.", "motivation": "Deep learning models struggle to accurately predict occluded regions of humans, and existing diffusion-based methods suffer from pixel-level degradation in visible areas due to latent space transformations.", "method": "Two-stage approach: 1) Mask completion using diffusion-based human body prior and occluded joint heatmaps, 2) RGB completion using Stable Diffusion with decoder fine-tuning, conditioned on the reconstructed mask and enhanced with human-specific textual features from VQA and CLIP.", "result": "Effectively reconstructs human appearances under severe occlusions, outperforms existing methods in both mask and RGB completion, and improves downstream tasks like 2D pose estimation and 3D human reconstruction.", "conclusion": "The proposed method successfully addresses human de-occlusion by leveraging body structure priors and human-specific features, with the generated de-occluded images benefiting various human-centric applications."}}
{"id": "2508.12984", "pdf": "https://arxiv.org/pdf/2508.12984", "abs": "https://arxiv.org/abs/2508.12984", "authors": ["Zehang Lin", "Zheng Lin", "Miao Yang", "Jianhao Huang", "Yuxin Zhang", "Zihan Fang", "Xia Du", "Zhe Chen", "Shunzhi Zhu", "Wei Ni"], "title": "SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression", "categories": ["cs.LG", "cs.AI", "cs.NI"], "comment": "6 pages, 7 figures", "summary": "The increasing complexity of neural networks poses a significant barrier to\nthe deployment of distributed machine learning (ML) on resource-constrained\ndevices, such as federated learning (FL). Split learning (SL) offers a\npromising solution by offloading the primary computing load from edge devices\nto a server via model partitioning. However, as the number of participating\ndevices increases, the transmission of excessive smashed data (i.e.,\nactivations and gradients) becomes a major bottleneck for SL, slowing down the\nmodel training. To tackle this challenge, we propose a communication-efficient\nSL framework, named SL-ACC, which comprises two key components: adaptive\nchannel importance identification (ACII) and channel grouping compression\n(CGC). ACII first identifies the contribution of each channel in the smashed\ndata to model training using Shannon entropy. Following this, CGC groups the\nchannels based on their entropy and performs group-wise adaptive compression to\nshrink the transmission volume without compromising training accuracy.\nExtensive experiments across various datasets validate that our proposed SL-ACC\nframework takes considerably less time to achieve a target accuracy than\nstate-of-the-art benchmarks.", "AI": {"tldr": "SL-ACC is a communication-efficient split learning framework that reduces transmission bottlenecks by adaptively compressing smashed data using entropy-based channel importance identification and group-wise compression.", "motivation": "The increasing complexity of neural networks creates deployment challenges for distributed ML on resource-constrained devices. Split learning helps but suffers from transmission bottlenecks as smashed data grows with more participating devices.", "method": "Proposes SL-ACC framework with two components: Adaptive Channel Importance Identification (ACII) using Shannon entropy to identify channel contributions, and Channel Grouping Compression (CGC) that groups channels by entropy and performs group-wise adaptive compression.", "result": "Extensive experiments across various datasets show SL-ACC takes considerably less time to achieve target accuracy compared to state-of-the-art benchmarks.", "conclusion": "SL-ACC effectively addresses communication bottlenecks in split learning through adaptive entropy-based compression, enabling faster training without compromising accuracy."}}
{"id": "2508.11738", "pdf": "https://arxiv.org/pdf/2508.11738", "abs": "https://arxiv.org/abs/2508.11738", "authors": ["Kiruthika Balakrishnan", "Durgadevi Velusamy", "Hana E. Hinkle", "Zhi Li", "Karthikeyan Ramasamy", "Hikmat Khan", "Srini Ramaswamy", "Pir Masoom Shah"], "title": "Artificial Intelligence in Rural Healthcare Delivery: Bridging Gaps and Enhancing Equity through Innovation", "categories": ["cs.CY", "cs.AI", "cs.CV"], "comment": null, "summary": "Rural healthcare faces persistent challenges, including inadequate\ninfrastructure, workforce shortages, and socioeconomic disparities that hinder\naccess to essential services. This study investigates the transformative\npotential of artificial intelligence (AI) in addressing these issues in\nunderserved rural areas. We systematically reviewed 109 studies published\nbetween 2019 and 2024 from PubMed, Embase, Web of Science, IEEE Xplore, and\nScopus. Articles were screened using PRISMA guidelines and Covidence software.\nA thematic analysis was conducted to identify key patterns and insights\nregarding AI implementation in rural healthcare delivery. The findings reveal\nsignificant promise for AI applications, such as predictive analytics,\ntelemedicine platforms, and automated diagnostic tools, in improving healthcare\naccessibility, quality, and efficiency. Among these, advanced AI systems,\nincluding Multimodal Foundation Models (MFMs) and Large Language Models (LLMs),\noffer particularly transformative potential. MFMs integrate diverse data\nsources, such as imaging, clinical records, and bio signals, to support\ncomprehensive decision-making, while LLMs facilitate clinical documentation,\npatient triage, translation, and virtual assistance. Together, these\ntechnologies can revolutionize rural healthcare by augmenting human capacity,\nreducing diagnostic delays, and democratizing access to expertise. However,\nbarriers remain, including infrastructural limitations, data quality concerns,\nand ethical considerations. Addressing these challenges requires\ninterdisciplinary collaboration, investment in digital infrastructure, and the\ndevelopment of regulatory frameworks. This review offers actionable\nrecommendations and highlights areas for future research to ensure equitable\nand sustainable integration of AI in rural healthcare systems.", "AI": {"tldr": "AI shows transformative potential for rural healthcare through predictive analytics, telemedicine, and diagnostic tools, but faces infrastructure, data quality, and ethical barriers that require interdisciplinary solutions.", "motivation": "Rural healthcare faces persistent challenges including inadequate infrastructure, workforce shortages, and socioeconomic disparities that limit access to essential services, creating a need for innovative solutions.", "method": "Systematic review of 109 studies (2019-2024) from multiple databases using PRISMA guidelines and Covidence software, followed by thematic analysis to identify AI implementation patterns in rural healthcare.", "result": "AI applications (predictive analytics, telemedicine, diagnostic tools) significantly improve healthcare accessibility, quality, and efficiency. MFMs and LLMs show particular promise for comprehensive decision-making and clinical support, though infrastructure limitations and ethical concerns remain barriers.", "conclusion": "AI can revolutionize rural healthcare by augmenting human capacity and democratizing expertise, but requires interdisciplinary collaboration, infrastructure investment, and regulatory frameworks for equitable and sustainable integration."}}
{"id": "2508.12668", "pdf": "https://arxiv.org/pdf/2508.12668", "abs": "https://arxiv.org/abs/2508.12668", "authors": ["Abhijay Ghildyal", "Li-Yun Wang", "Feng Liu"], "title": "WP-CLIP: Leveraging CLIP to Predict W\u00f6lfflin's Principles in Visual Art", "categories": ["cs.CV"], "comment": "ICCV 2025 AI4VA workshop (oral), Code:\n  https://github.com/abhijay9/wpclip", "summary": "W\\\"olfflin's five principles offer a structured approach to analyzing\nstylistic variations for formal analysis. However, no existing metric\neffectively predicts all five principles in visual art. Computationally\nevaluating the visual aspects of a painting requires a metric that can\ninterpret key elements such as color, composition, and thematic choices. Recent\nadvancements in vision-language models (VLMs) have demonstrated their ability\nto evaluate abstract image attributes, making them promising candidates for\nthis task. In this work, we investigate whether CLIP, pre-trained on\nlarge-scale data, can understand and predict W\\\"olfflin's principles. Our\nfindings indicate that it does not inherently capture such nuanced stylistic\nelements. To address this, we fine-tune CLIP on annotated datasets of real art\nimages to predict a score for each principle. We evaluate our model, WP-CLIP,\non GAN-generated paintings and the Pandora-18K art dataset, demonstrating its\nability to generalize across diverse artistic styles. Our results highlight the\npotential of VLMs for automated art analysis.", "AI": {"tldr": "Fine-tuned CLIP model (WP-CLIP) can effectively predict W\u00f6lfflin's five stylistic principles in visual art, addressing limitations of pre-trained models.", "motivation": "Existing metrics fail to predict all five W\u00f6lfflin's principles for formal art analysis, and pre-trained vision-language models like CLIP lack inherent understanding of nuanced stylistic elements in paintings.", "method": "Fine-tuned CLIP on annotated datasets of real art images to predict scores for each of W\u00f6lfflin's five principles, creating WP-CLIP model.", "result": "WP-CLIP successfully generalizes across diverse artistic styles, performing well on both GAN-generated paintings and the Pandora-18K art dataset.", "conclusion": "Vision-language models show strong potential for automated art analysis when properly fine-tuned for specific stylistic evaluation tasks."}}
{"id": "2508.12993", "pdf": "https://arxiv.org/pdf/2508.12993", "abs": "https://arxiv.org/abs/2508.12993", "authors": ["Shalima Binta Manir", "Tim Oates"], "title": "Predicting the Performance of Graph Convolutional Networks with Spectral Properties of the Graph Laplacian", "categories": ["cs.LG"], "comment": "9 pages, 3 figures", "summary": "A common observation in the Graph Convolutional Network (GCN) literature is\nthat stacking GCN layers may or may not result in better performance on tasks\nlike node classification and edge prediction. We have found empirically that a\ngraph's algebraic connectivity, which is known as the Fiedler value, is a good\npredictor of GCN performance. Intuitively, graphs with similar Fiedler values\nhave analogous structural properties, suggesting that the same filters and\nhyperparameters may yield similar results when used with GCNs, and that\ntransfer learning may be more effective between graphs with similar algebraic\nconnectivity. We explore this theoretically and empirically with experiments on\nsynthetic and real graph data, including the Cora, CiteSeer and Polblogs\ndatasets. We explore multiple ways of aggregating the Fiedler value for\nconnected components in the graphs to arrive at a value for the entire graph,\nand show that it can be used to predict GCN performance. We also present\ntheoretical arguments as to why the Fiedler value is a good predictor.", "AI": {"tldr": "The Fiedler value (algebraic connectivity) predicts GCN performance - graphs with similar Fiedler values have analogous structural properties enabling better transfer learning and hyperparameter sharing.", "motivation": "Stacking GCN layers inconsistently improves performance on tasks like node classification, suggesting the need for a reliable predictor of GCN effectiveness across different graph structures.", "method": "Theoretical analysis and empirical experiments on synthetic and real graph datasets (Cora, CiteSeer, Polblogs) using the Fiedler value as a predictor, exploring multiple aggregation methods for connected components.", "result": "The Fiedler value serves as a good predictor of GCN performance, with graphs sharing similar algebraic connectivity showing comparable structural properties and performance patterns.", "conclusion": "Algebraic connectivity (Fiedler value) provides a reliable metric for predicting GCN performance and facilitating transfer learning between graphs with similar structural properties."}}
{"id": "2508.12680", "pdf": "https://arxiv.org/pdf/2508.12680", "abs": "https://arxiv.org/abs/2508.12680", "authors": ["Yuheng Zha", "Kun Zhou", "Yujia Wu", "Yushu Wang", "Jie Feng", "Zhi Xu", "Shibo Hao", "Zhengzhong Liu", "Eric P. Xing", "Zhiting Hu"], "title": "Vision-G1: Towards General Vision Language Reasoning with Multi-Domain Data Curation", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Despite their success, current training pipelines for reasoning VLMs focus on\na limited range of tasks, such as mathematical and logical reasoning. As a\nresult, these models face difficulties in generalizing their reasoning\ncapabilities to a wide range of domains, primarily due to the scarcity of\nreadily available and verifiable reward data beyond these narrowly defined\nareas. Moreover, integrating data from multiple domains is challenging, as the\ncompatibility between domain-specific datasets remains uncertain. To address\nthese limitations, we build a comprehensive RL-ready visual reasoning dataset\nfrom 46 data sources across 8 dimensions, covering a wide range of tasks such\nas infographic, mathematical, spatial, cross-image, graphic user interface,\nmedical, common sense and general science. We propose an influence function\nbased data selection and difficulty based filtering strategy to identify\nhigh-quality training samples from this dataset. Subsequently, we train the\nVLM, referred to as Vision-G1, using multi-round RL with a data curriculum to\niteratively improve its visual reasoning capabilities. Our model achieves\nstate-of-the-art performance across various visual reasoning benchmarks,\noutperforming similar-sized VLMs and even proprietary models like GPT-4o and\nGemini-1.5 Flash. The model, code and dataset are publicly available at\nhttps://github.com/yuh-zha/Vision-G1.", "AI": {"tldr": "Vision-G1 is a visual reasoning VLM trained on a comprehensive multi-domain dataset using influence-based data selection and multi-round RL, achieving SOTA performance across benchmarks and outperforming proprietary models.", "motivation": "Current reasoning VLMs focus on narrow tasks like math/logic and struggle with generalization due to limited verifiable reward data and uncertain compatibility between domain-specific datasets.", "method": "Built a comprehensive RL-ready dataset from 46 sources across 8 domains, used influence function-based data selection and difficulty filtering, trained with multi-round RL and data curriculum.", "result": "Achieves state-of-the-art performance across various visual reasoning benchmarks, outperforms similar-sized VLMs and proprietary models like GPT-4o and Gemini-1.5 Flash.", "conclusion": "The comprehensive multi-domain dataset combined with sophisticated data selection and RL training enables superior visual reasoning generalization across diverse domains."}}
{"id": "2508.12398", "pdf": "https://arxiv.org/pdf/2508.12398", "abs": "https://arxiv.org/abs/2508.12398", "authors": ["Zhixin Xie", "Xurui Song", "Jun Luo"], "title": "Where to Start Alignment? Diffusion Large Language Model May Demand a Distinct Position", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Diffusion Large Language Models (dLLMs) have recently emerged as a\ncompetitive non-autoregressive paradigm due to their unique training and\ninference approach. However, there is currently a lack of safety study on this\nnovel architecture. In this paper, we present the first analysis of dLLMs'\nsafety performance and propose a novel safety alignment method tailored to\ntheir unique generation characteristics. Specifically, we identify a critical\nasymmetry between the defender and attacker in terms of security. For the\ndefender, we reveal that the middle tokens of the response, rather than the\ninitial ones, are more critical to the overall safety of dLLM outputs; this\nseems to suggest that aligning middle tokens can be more beneficial to the\ndefender. The attacker, on the contrary, may have limited power to manipulate\nmiddle tokens, as we find dLLMs have a strong tendency towards a sequential\ngeneration order in practice, forcing the attack to meet this distribution and\ndiverting it from influencing the critical middle tokens. Building on this\nasymmetry, we introduce Middle-tOken Safety Alignment (MOSA), a novel method\nthat directly aligns the model's middle generation with safe refusals\nexploiting reinforcement learning. We implement MOSA and compare its security\nperformance against eight attack methods on two benchmarks. We also test the\nutility of MOSA-aligned dLLM on coding, math, and general reasoning. The\nresults strongly prove the superiority of MOSA.", "AI": {"tldr": "First safety analysis of Diffusion Large Language Models (dLLMs) revealing critical asymmetry between defenders and attackers, with middle tokens being most important for safety. Proposes MOSA method for middle-token alignment using reinforcement learning.", "motivation": "dLLMs have emerged as competitive non-autoregressive models but lack safety studies. There's a need to understand their unique security characteristics and develop tailored safety alignment methods.", "method": "Identifies asymmetry in security: defenders benefit from aligning middle tokens, while attackers have limited middle-token manipulation due to dLLMs' sequential generation order. Proposes MOSA (Middle-tOken Safety Alignment) using reinforcement learning to directly align middle generation with safe refusals.", "result": "Tested MOSA against eight attack methods on two benchmarks. MOSA-aligned dLLM showed superior security performance while maintaining utility on coding, math, and general reasoning tasks.", "conclusion": "MOSA proves highly effective for dLLM safety alignment, leveraging the identified asymmetry between defender and attacker capabilities. Middle tokens are critical for safety in dLLMs, and MOSA successfully addresses this through targeted reinforcement learning alignment."}}
{"id": "2508.12996", "pdf": "https://arxiv.org/pdf/2508.12996", "abs": "https://arxiv.org/abs/2508.12996", "authors": ["Stavros C. Kassinos"], "title": "Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair", "categories": ["cs.LG", "cs.AI", "65K10, 68T07", "I.2.6; G.1.6"], "comment": "54 pages, 8 figures, 19 tables", "summary": "Transformer neural networks are increasingly used for physics-based problems.\nIn data-driven PDE surrogates, training samples from varying boundary and\ninitial conditions can cause erratic losses and spiky gradients; in\nphysics-informed neural networks (PINNs), stiff composite losses amplify this\neffect.\n  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed\nsecond-moment discount beta2 is replaced by a layer-wise dynamic value driven\nby a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an\nexponential moving average (EMA) of past norms, squashed to the interval [0,1).\nSpikes lower beta2 toward beta2_min; calm phases keep it near beta2_max.\nOptions include leaky-AMSGrad (decay), trust-region clipping (max_ratio),\nadaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'',\n``exact'). With all features off and bias_correction=``none'', the method is\nexactly Adam.\n  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D\nPINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with\njitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB\nof enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss\nversus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about\n38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller\nvariance. The method remains drop-in, with runtime overhead comparable to Adam\nin testbeds A-C and within single-digit percent in testbed D. It preserves\nAdam-style convergence guarantees while improving robustness under spiky\ngradients.", "AI": {"tldr": "Kourkoutas-Beta is a novel Adam-style optimizer that dynamically adjusts the second-moment discount factor beta2 based on gradient spike detection, improving stability and performance for physics-based problems with erratic gradients.", "motivation": "Transformer neural networks for physics problems suffer from erratic losses and spiky gradients in PDE surrogates and PINNs, where stiff composite losses amplify gradient instability issues.", "method": "Replaces fixed beta2 with layer-wise dynamic values driven by a bounded 'sunspike' ratio (current pooled gradient norm divided by EMA of past norms). Spikes lower beta2 toward beta2_min, calm phases keep it near beta2_max, with options for leaky-AMSGrad, trust-region clipping, and bias-correction modes.", "result": "Improves stability and final loss versus fixed-beta2 Adam across four test settings. On small-enwik8, lowers bits-per-character by 38% vs Adam-0.95 and 58% vs Adam-0.999 with smaller variance. Runtime overhead comparable to Adam.", "conclusion": "Kourkoutas-Beta provides drop-in replacement for Adam with improved robustness under spiky gradients while preserving Adam-style convergence guarantees, making it particularly effective for physics-based neural network applications."}}
{"id": "2508.12684", "pdf": "https://arxiv.org/pdf/2508.12684", "abs": "https://arxiv.org/abs/2508.12684", "authors": ["Zhongyao Li", "Peirui Cheng", "Liangjin Zhao", "Chen Chen", "Yundu Li", "Zhechao Wang", "Xue Yang", "Xian Sun", "Zhirui Wang"], "title": "Refine-and-Contrast: Adaptive Instance-Aware BEV Representations for Multi-UAV Collaborative Object Detection", "categories": ["cs.CV"], "comment": "9 pages", "summary": "Multi-UAV collaborative 3D detection enables accurate and robust perception\nby fusing multi-view observations from aerial platforms, offering significant\nadvantages in coverage and occlusion handling, while posing new challenges for\ncomputation on resource-constrained UAV platforms. In this paper, we present\nAdaBEV, a novel framework that learns adaptive instance-aware BEV\nrepresentations through a refine-and-contrast paradigm. Unlike existing methods\nthat treat all BEV grids equally, AdaBEV introduces a Box-Guided Refinement\nModule (BG-RM) and an Instance-Background Contrastive Learning (IBCL) to\nenhance semantic awareness and feature discriminability. BG-RM refines only BEV\ngrids associated with foreground instances using 2D supervision and spatial\nsubdivision, while IBCL promotes stronger separation between foreground and\nbackground features via contrastive learning in BEV space. Extensive\nexperiments on the Air-Co-Pred dataset demonstrate that AdaBEV achieves\nsuperior accuracy-computation trade-offs across model scales, outperforming\nother state-of-the-art methods at low resolutions and approaching upper bound\nperformance while maintaining low-resolution BEV inputs and negligible\noverhead.", "AI": {"tldr": "AdaBEV is a novel framework for multi-UAV 3D detection that creates adaptive instance-aware BEV representations using refine-and-contrast approach, achieving superior accuracy-computation trade-offs with minimal overhead.", "motivation": "Multi-UAV collaborative 3D detection offers advantages in coverage and occlusion handling but faces computational challenges on resource-constrained UAV platforms, requiring efficient methods that maintain performance while reducing computational burden.", "method": "Introduces Box-Guided Refinement Module (BG-RM) that refines only foreground-associated BEV grids using 2D supervision and spatial subdivision, and Instance-Background Contrastive Learning (IBCL) that enhances feature discriminability through contrastive learning in BEV space.", "result": "Extensive experiments on Air-Co-Pred dataset show AdaBEV achieves superior accuracy-computation trade-offs across model scales, outperforms state-of-the-art methods at low resolutions, and approaches upper bound performance while maintaining low-resolution BEV inputs with negligible overhead.", "conclusion": "AdaBEV successfully addresses computational constraints in multi-UAV 3D detection by focusing computational resources on foreground instances and improving feature discrimination, making it highly suitable for resource-constrained aerial platforms."}}
{"id": "2508.12997", "pdf": "https://arxiv.org/pdf/2508.12997", "abs": "https://arxiv.org/abs/2508.12997", "authors": ["Haishun Chen", "Cai Xu", "Jinlong Yu", "Yilin Zhang", "Ziyu Guan", "Wei Zhao"], "title": "Fairness-Aware Multi-view Evidential Learning with Adaptive Prior", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multi-view evidential learning aims to integrate information from multiple\nviews to improve prediction performance and provide trustworthy uncertainty\nesitimation. Most previous methods assume that view-specific evidence learning\nis naturally reliable. However, in practice, the evidence learning process\ntends to be biased. Through empirical analysis on real-world data, we reveal\nthat samples tend to be assigned more evidence to support data-rich classes,\nthereby leading to unreliable uncertainty estimation in predictions. This\nmotivates us to delve into a new Biased Evidential Multi-view Learning (BEML)\nproblem. To this end, we propose Fairness-Aware Multi-view Evidential Learning\n(FAML). FAML first introduces an adaptive prior based on training trajectory,\nwhich acts as a regularization strategy to flexibly calibrate the biased\nevidence learning process. Furthermore, we explicitly incorporate a fairness\nconstraint based on class-wise evidence variance to promote balanced evidence\nallocation. In the multi-view fusion stage, we propose an opinion alignment\nmechanism to mitigate view-specific bias across views, thereby encouraging the\nintegration of consistent and mutually supportive evidence. Extensive\nexperiments on five real-world multi-view datasets demonstrate that FAML\nachieves more balanced evidence allocation and improves both prediction\nperformance and the reliability of uncertainty estimation compared to\nstate-of-the-art methods.", "AI": {"tldr": "FAML addresses biased evidence learning in multi-view evidential learning by introducing adaptive priors, fairness constraints, and opinion alignment to achieve balanced evidence allocation and improved uncertainty estimation.", "motivation": "Traditional multi-view evidential learning assumes reliable view-specific evidence learning, but empirical analysis reveals samples are assigned more evidence to data-rich classes, leading to unreliable uncertainty estimation.", "method": "Proposes FAML with three components: 1) adaptive prior based on training trajectory for regularization, 2) fairness constraint based on class-wise evidence variance, 3) opinion alignment mechanism for multi-view fusion to mitigate view-specific bias.", "result": "Extensive experiments on five real-world datasets show FAML achieves more balanced evidence allocation and improves both prediction performance and uncertainty estimation reliability compared to state-of-the-art methods.", "conclusion": "FAML effectively addresses the biased evidential multi-view learning problem through adaptive regularization, fairness constraints, and opinion alignment, demonstrating superior performance in balanced evidence allocation and trustworthy uncertainty estimation."}}
{"id": "2508.12690", "pdf": "https://arxiv.org/pdf/2508.12690", "abs": "https://arxiv.org/abs/2508.12690", "authors": ["Dongjae Jeon", "Taeheon Kim", "Seongwon Cho", "Minhyuk Seo", "Jonghyun Choi"], "title": "TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically\nadapt and perform optimally on shifting target domains. This task is\nparticularly emphasized in real-world driving scenes, where weather domain\nshifts occur frequently. To address such dynamic changes, our proposed method,\nTTA-DAME, leverages source domain data augmentation into target domains.\nAdditionally, we introduce a domain discriminator and a specialized domain\ndetector to mitigate drastic domain shifts, especially from daytime to\nnighttime conditions. To further improve adaptability, we train multiple\ndetectors and consolidate their predictions through Non-Maximum Suppression\n(NMS). Our empirical validation demonstrates the effectiveness of our method,\nshowing significant performance enhancements on the SHIFT Benchmark.", "AI": {"tldr": "TTA-DAME improves test-time adaptation for driving scenes by using source domain augmentation, domain discrimination, and multiple detector fusion with NMS.", "motivation": "Address dynamic domain shifts in real-world driving scenes, particularly weather and day/night transitions, where models need to adapt continuously to changing conditions.", "method": "Leverages source domain data augmentation into target domains, introduces domain discriminator and specialized domain detector, trains multiple detectors and consolidates predictions through Non-Maximum Suppression (NMS).", "result": "Demonstrates significant performance enhancements on the SHIFT Benchmark for driving scene adaptation.", "conclusion": "The proposed TTA-DAME method effectively handles dynamic domain shifts in driving scenarios through augmented adaptation and multi-detector fusion."}}
{"id": "2508.13006", "pdf": "https://arxiv.org/pdf/2508.13006", "abs": "https://arxiv.org/abs/2508.13006", "authors": ["Pengcheng Hao", "Menghao Waiyan William Zhu", "Ercan Engin Kuruoglu"], "title": "Monte Carlo Functional Regularisation for Continual Learning", "categories": ["cs.LG"], "comment": null, "summary": "Continual learning (CL) is crucial for the adaptation of neural network\nmodels to new environments. Although outperforming weight-space regularisation\napproaches, the functional regularisation-based CL methods suffer from high\ncomputational costs and large linear approximation errors. In this work, we\npresent a new functional regularisation CL framework, called MCFRCL, which\napproximates model prediction distributions by Monte Carlo (MC) sampling.\nMoreover, three continuous distributions are leveraged to capture the\nstatistical characteristics of the MC samples via moment-based methods.\nAdditionally, both the Wasserstein distance and the Kullback-Leibler (KL)\ndistance are employed to construct the regularisation function. The proposed\nMCFRCL is evaluated against multiple benchmark methods on the MNIST and CIFAR\ndatasets, with simulation results highlighting its effectiveness in both\nprediction accuracy and training efficiency.", "AI": {"tldr": "MCFRCL is a new functional regularization continual learning method that uses Monte Carlo sampling and statistical distributions to improve accuracy and efficiency.", "motivation": "Functional regularization CL methods outperform weight-space approaches but suffer from high computational costs and large linear approximation errors.", "method": "Uses Monte Carlo sampling to approximate model prediction distributions, leverages three continuous distributions to capture statistical characteristics via moment-based methods, and employs both Wasserstein and KL distances for regularization.", "result": "Evaluated on MNIST and CIFAR datasets, MCFRCL shows effectiveness in both prediction accuracy and training efficiency compared to benchmark methods.", "conclusion": "The proposed MCFRCL framework provides an effective solution for continual learning with improved computational efficiency and reduced approximation errors."}}
{"id": "2508.12692", "pdf": "https://arxiv.org/pdf/2508.12692", "abs": "https://arxiv.org/abs/2508.12692", "authors": ["Taeheon Kim", "San Kim", "Minhyuk Seo", "Dongjae Jeon", "Wonje Jeong", "Jonghyun Choi"], "title": "Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Class-incremental with repetition (CIR), where previously trained classes\nrepeatedly introduced in future tasks, is a more realistic scenario than the\ntraditional class incremental setup, which assumes that each task contains\nunseen classes. CIR assumes that we can easily access abundant unlabeled data\nfrom external sources, such as the Internet. Therefore, we propose two\ncomponents that efficiently use the unlabeled data to ensure the high stability\nand the plasticity of models trained in CIR setup. First, we introduce\nmulti-level knowledge distillation (MLKD) that distills knowledge from multiple\nprevious models across multiple perspectives, including features and logits, so\nthe model can maintain much various previous knowledge. Moreover, we implement\ndynamic self-supervised loss (SSL) to utilize the unlabeled data that\naccelerates the learning of new classes, while dynamic weighting of SSL keeps\nthe focus of training to the primary task. Both of our proposed components\nsignificantly improve the performance in CIR setup, achieving 2nd place in the\nCVPR 5th CLVISION Challenge.", "AI": {"tldr": "Proposes multi-level knowledge distillation and dynamic self-supervised learning for class-incremental learning with repetition using unlabeled external data.", "motivation": "Class-incremental learning with repetition (CIR) is more realistic than traditional setups, and abundant unlabeled data from external sources like the Internet can be leveraged to improve model stability and plasticity.", "method": "Two components: 1) Multi-level knowledge distillation (MLKD) that distills knowledge from multiple previous models across features and logits, 2) Dynamic self-supervised loss (SSL) that utilizes unlabeled data to accelerate new class learning while maintaining focus on primary tasks.", "result": "Significantly improved performance in CIR setup, achieving 2nd place in the CVPR 5th CLVISION Challenge.", "conclusion": "The proposed MLKD and dynamic SSL components effectively leverage unlabeled external data to enhance both stability (retaining previous knowledge) and plasticity (learning new classes) in class-incremental learning with repetition scenarios."}}
{"id": "2508.12574", "pdf": "https://arxiv.org/pdf/2508.12574", "abs": "https://arxiv.org/abs/2508.12574", "authors": ["Bin Ma", "Yifei Zhang", "Yongjin Xian", "Qi Li", "Linna Zhou", "Gongxun Miao"], "title": "Insight Rumors: A Novel Textual Rumor Locating and Marking Model Leveraging Att_BiMamba2 Network", "categories": ["cs.SI", "cs.CL"], "comment": null, "summary": "With the development of social media networks, rumor detection models have\nattracted more and more attention. Whereas, these models primarily focus on\nclassifying contexts as rumors or not, lacking the capability to locate and\nmark specific rumor content. To address this limitation, this paper proposes a\nnovel rumor detection model named Insight Rumors to locate and mark rumor\ncontent within textual data. Specifically, we propose the Bidirectional Mamba2\nNetwork with Dot-Product Attention (Att_BiMamba2), a network that constructs a\nbidirectional Mamba2 model and applies dot-product attention to weight and\ncombine the outputs from both directions, thereby enhancing the representation\nof high-dimensional rumor features. Simultaneously, a Rumor Locating and\nMarking module is designed to locate and mark rumors. The module constructs a\nskip-connection network to project high-dimensional rumor features onto\nlow-dimensional label features. Moreover, Conditional Random Fields (CRF) is\nemployed to impose strong constraints on the output label features, ensuring\naccurate rumor content location. Additionally, a labeled dataset for rumor\nlocating and marking is constructed, with the effectiveness of the proposed\nmodel is evaluated through comprehensive experiments. Extensive experiments\nindicate that the proposed scheme not only detects rumors accurately but also\nlocates and marks them in context precisely, outperforming state-of-the-art\nschemes that can only discriminate rumors roughly.", "AI": {"tldr": "A novel rumor detection model called Insight Rumors that not only classifies but also locates and marks specific rumor content within text using bidirectional Mamba2 networks with attention mechanisms and CRF constraints.", "motivation": "Existing rumor detection models only classify contexts as rumors or not, lacking the capability to locate and mark specific rumor content within textual data.", "method": "Proposes Att_BiMamba2 network with bidirectional Mamba2 model and dot-product attention to enhance rumor feature representation, plus a Rumor Locating and Marking module with skip-connection network and Conditional Random Fields for accurate content location.", "result": "The model accurately detects rumors and precisely locates/marks them in context, outperforming state-of-the-art schemes that only discriminate rumors roughly.", "conclusion": "The proposed Insight Rumors model effectively addresses the limitation of traditional rumor detection by providing both classification and precise content location/marking capabilities."}}
{"id": "2508.13018", "pdf": "https://arxiv.org/pdf/2508.13018", "abs": "https://arxiv.org/abs/2508.13018", "authors": ["Iam Kim de S. Hermont", "Andre R. Flores", "Rodrigo C. de Lamare"], "title": "Design and Analysis of Robust Adaptive Filtering with the Hyperbolic Tangent Exponential Kernel M-Estimator Function for Active Noise Control", "categories": ["cs.LG"], "comment": "12 figures, 11 pages", "summary": "In this work, we propose a robust adaptive filtering approach for active\nnoise control applications in the presence of impulsive noise. In particular,\nwe develop the filtered-x hyperbolic tangent exponential generalized Kernel\nM-estimate function (FXHEKM) robust adaptive algorithm. A statistical analysis\nof the proposed FXHEKM algorithm is carried out along with a study of its\ncomputational cost. {In order to evaluate the proposed FXHEKM algorithm, the\nmean-square error (MSE) and the average noise reduction (ANR) performance\nmetrics have been adopted.} Numerical results show the efficiency of the\nproposed FXHEKM algorithm to cancel the presence of the additive spurious\nsignals, such as \\textbf{$\\alpha$}-stable noises against competing algorithms.", "AI": {"tldr": "Proposed FXHEKM robust adaptive algorithm for active noise control with impulsive noise, showing superior performance against alpha-stable noises compared to competing methods.", "motivation": "Need for robust noise cancellation in presence of impulsive noise environments where traditional methods fail, particularly addressing alpha-stable noise distributions.", "method": "Developed filtered-x hyperbolic tangent exponential generalized Kernel M-estimate function (FXHEKM) algorithm with statistical analysis and computational cost study.", "result": "Numerical results demonstrate efficient cancellation of additive spurious signals and alpha-stable noises, outperforming competing algorithms in MSE and ANR metrics.", "conclusion": "FXHEKM algorithm provides effective robust adaptive filtering solution for active noise control applications dealing with impulsive noise scenarios."}}
{"id": "2508.12695", "pdf": "https://arxiv.org/pdf/2508.12695", "abs": "https://arxiv.org/abs/2508.12695", "authors": ["Felix Embacher", "David Holtz", "Jonas Uhrig", "Marius Cordts", "Markus Enzweiler"], "title": "Neural Rendering for Sensor Adaptation in 3D Object Detection", "categories": ["cs.CV"], "comment": "Accepted at IEEE Intelligent Vehicles Symposium (IV) 2025", "summary": "Autonomous vehicles often have varying camera sensor setups, which is\ninevitable due to restricted placement options for different vehicle types.\nTraining a perception model on one particular setup and evaluating it on a new,\ndifferent sensor setup reveals the so-called cross-sensor domain gap, typically\nleading to a degradation in accuracy. In this paper, we investigate the impact\nof the cross-sensor domain gap on state-of-the-art 3D object detectors. To this\nend, we introduce CamShift, a dataset inspired by nuScenes and created in CARLA\nto specifically simulate the domain gap between subcompact vehicles and sport\nutility vehicles (SUVs). Using CamShift, we demonstrate significant\ncross-sensor performance degradation, identify robustness dependencies on model\narchitecture, and propose a data-driven solution to mitigate the effect. On the\none hand, we show that model architectures based on a dense Bird's Eye View\n(BEV) representation with backward projection, such as BEVFormer, are the most\nrobust against varying sensor configurations. On the other hand, we propose a\nnovel data-driven sensor adaptation pipeline based on neural rendering, which\ncan transform entire datasets to match different camera sensor setups. Applying\nthis approach improves performance across all investigated 3D object detectors,\nmitigating the cross-sensor domain gap by a large margin and reducing the need\nfor new data collection by enabling efficient data reusability across vehicles\nwith different sensor setups. The CamShift dataset and the sensor adaptation\nbenchmark are available at https://dmholtz.github.io/camshift/.", "AI": {"tldr": "Cross-sensor domain gap causes performance degradation in 3D object detectors when trained on one vehicle sensor setup and tested on another. BEVFormer shows best robustness, and a neural rendering adaptation pipeline significantly mitigates this gap.", "motivation": "Autonomous vehicles have varying camera sensor setups due to different vehicle types, causing cross-sensor domain gap that degrades perception model accuracy when evaluated on different sensor configurations.", "method": "Created CamShift dataset in CARLA to simulate domain gap between subcompact vehicles and SUVs. Investigated various 3D object detectors, identified BEVFormer as most robust, and proposed neural rendering-based sensor adaptation pipeline to transform datasets between different camera setups.", "result": "Significant cross-sensor performance degradation observed. BEVFormer with dense BEV representation and backward projection showed best robustness. Neural rendering adaptation pipeline improved performance across all detectors, mitigating domain gap by large margin.", "conclusion": "Model architecture matters for cross-sensor robustness, and data-driven neural rendering adaptation effectively bridges sensor domain gaps, enabling data reusability across different vehicle sensor setups without new data collection."}}
{"id": "2508.13030", "pdf": "https://arxiv.org/pdf/2508.13030", "abs": "https://arxiv.org/abs/2508.13030", "authors": ["Bipin Chhetri", "Akbar Siami Namin"], "title": "The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "21 pages, 6 figures,Proceedings of the IEEE International Conference\n  on Computers, Software, & Applications (COMPSAC), EATA Symposium, Toronto,\n  Canada, July 8-11, 2025", "summary": "Cyberattacks are increasing, and securing against such threats is costing\nindustries billions of dollars annually. Threat Modeling, that is,\ncomprehending the consequences of these attacks, can provide critical support\nto cybersecurity professionals, enabling them to take timely action and\nallocate resources that could be used elsewhere. Cybersecurity is heavily\ndependent on threat modeling, as it assists security experts in assessing and\nmitigating risks related to identifying vulnerabilities and threats. Recently,\nthere has been a pressing need for automated methods to assess attack\ndescriptions and forecast the future consequences of the increasing complexity\nof cyberattacks. This study examines how Natural Language Processing (NLP) and\ndeep learning can be applied to analyze the potential impact of cyberattacks by\nleveraging textual descriptions from the MITRE Common Weakness Enumeration\n(CWE) database. We emphasize classifying attack consequences into five\nprincipal categories: Availability, Access Control, Confidentiality, Integrity,\nand Other. This paper investigates the use of Bidirectional Encoder\nRepresentations from Transformers (BERT) in combination with Hierarchical\nAttention Networks (HANs) for Multi-label classification, evaluating their\nperformance in comparison with conventional CNN and LSTM-based models.\nExperimental findings show that BERT achieves an overall accuracy of $0.972$,\nfar higher than conventional deep learning models in multi-label\nclassification. HAN outperforms baseline forms of CNN and LSTM-based models on\nspecific cybersecurity labels. However, BERT consistently achieves better\nprecision and recall, making it more suitable for predicting the consequences\nof a cyberattack.", "AI": {"tldr": "This paper presents an NLP-based approach using BERT and HANs for multi-label classification of cyberattack consequences from MITRE CWE descriptions, achieving superior performance over traditional deep learning models.", "motivation": "The increasing complexity and cost of cyberattacks require automated methods to analyze attack descriptions and predict consequences, helping cybersecurity professionals allocate resources effectively.", "method": "The study uses BERT (Bidirectional Encoder Representations from Transformers) combined with Hierarchical Attention Networks (HANs) for multi-label classification of cyberattack consequences into five categories: Availability, Access Control, Confidentiality, Integrity, and Other.", "result": "BERT achieved an overall accuracy of 0.972, significantly outperforming conventional CNN and LSTM-based models. HANs also outperformed baseline CNN and LSTM models on specific cybersecurity labels, but BERT consistently showed better precision and recall.", "conclusion": "BERT is more suitable for predicting cyberattack consequences due to its superior performance in precision and recall compared to traditional deep learning models, making it effective for automated threat modeling and consequence analysis."}}
{"id": "2508.11824", "pdf": "https://arxiv.org/pdf/2508.11824", "abs": "https://arxiv.org/abs/2508.11824", "authors": ["Satyam Kumar Navneet", "Joydeep Chandra"], "title": "Rethinking Autonomy: Preventing Failures in AI-Driven Software Engineering", "categories": ["cs.SE", "cs.AI", "cs.CR", "cs.PF"], "comment": null, "summary": "The integration of Large Language Models (LLMs) into software engineering has\nrevolutionized code generation, enabling unprecedented productivity through\npromptware and autonomous AI agents. However, this transformation introduces\nsignificant risks, including insecure code generation, hallucinated outputs,\nirreversible actions, and a lack of transparency and accountability. Incidents\nlike the Replit database deletion underscore the urgent need for robust safety\nand governance mechanisms. This paper comprehensively analyzes the inherent\nchallenges of LLM-assisted code generation, such as vulnerability inheritance,\novertrust, misinterpretation, and the absence of standardized validation and\nrollback protocols. To address these, we propose the SAFE-AI Framework, a\nholistic approach emphasizing Safety, Auditability, Feedback, and\nExplainability. The framework integrates guardrails, sandboxing, runtime\nverification, risk-aware logging, human-in-the-loop systems, and explainable AI\ntechniques to mitigate risks while fostering trust and compliance. We introduce\na novel taxonomy of AI behaviors categorizing suggestive, generative,\nautonomous, and destructive actions to guide risk assessment and oversight.\nAdditionally, we identify open problems, including the lack of standardized\nbenchmarks for code specific hallucinations and autonomy levels, and propose\nfuture research directions for hybrid verification, semantic guardrails, and\nproactive governance tools. Through detailed comparisons of autonomy control,\nprompt engineering, explainability, and governance frameworks, this paper\nprovides a roadmap for responsible AI integration in software engineering,\naligning with emerging regulations like the EU AI Act and Canada's AIDA to\nensure safe, transparent, and accountable AI-driven development.", "AI": {"tldr": "The paper proposes the SAFE-AI Framework to address security and safety risks in LLM-assisted code generation, focusing on safety, auditability, feedback, and explainability to enable responsible AI integration in software engineering.", "motivation": "The integration of LLMs into software engineering introduces significant risks including insecure code generation, hallucinations, irreversible actions, and lack of transparency, as demonstrated by incidents like the Replit database deletion.", "method": "The authors propose the SAFE-AI Framework that integrates guardrails, sandboxing, runtime verification, risk-aware logging, human-in-the-loop systems, and explainable AI techniques. They also introduce a novel taxonomy of AI behaviors categorizing suggestive, generative, autonomous, and destructive actions.", "result": "The paper provides a comprehensive analysis of LLM-assisted code generation challenges and proposes a holistic framework with detailed comparisons of autonomy control, prompt engineering, explainability, and governance frameworks.", "conclusion": "The SAFE-AI Framework provides a roadmap for responsible AI integration in software engineering, aligning with emerging regulations to ensure safe, transparent, and accountable AI-driven development, while identifying open problems and future research directions."}}
{"id": "2508.12711", "pdf": "https://arxiv.org/pdf/2508.12711", "abs": "https://arxiv.org/abs/2508.12711", "authors": ["Fanxiao Li", "Jiaying Wu", "Tingchao Fu", "Yunyun Dong", "Bingbing Song", "Wei Zhou"], "title": "Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection", "categories": ["cs.CV"], "comment": null, "summary": "The proliferation of multimodal misinformation poses growing threats to\npublic discourse and societal trust. While Large Vision-Language Models (LVLMs)\nhave enabled recent progress in multimodal misinformation detection (MMD), the\nrise of generative AI (GenAI) tools introduces a new challenge: GenAI-driven\nnews diversity, characterized by highly varied and complex content. We show\nthat this diversity induces multi-level drift, comprising (1) model-level\nmisperception drift, where stylistic variations disrupt a model's internal\nreasoning, and (2) evidence-level drift, where expression diversity degrades\nthe quality or relevance of retrieved external evidence. These drifts\nsignificantly degrade the robustness of current LVLM-based MMD systems. To\nsystematically study this problem, we introduce DriftBench, a large-scale\nbenchmark comprising 16,000 news instances across six categories of\ndiversification. We design three evaluation tasks: (1) robustness of truth\nverification under multi-level drift; (2) susceptibility to adversarial\nevidence contamination generated by GenAI; and (3) analysis of reasoning\nconsistency across diverse inputs. Experiments with six state-of-the-art\nLVLM-based detectors show substantial performance drops (average F1 -14.8%) and\nincreasingly unstable reasoning traces, with even more severe failures under\nadversarial evidence injection. Our findings uncover fundamental\nvulnerabilities in existing MMD systems and suggest an urgent need for more\nresilient approaches in the GenAI era.", "AI": {"tldr": "GenAI-driven news diversity causes multi-level drift that significantly degrades LVLM-based misinformation detection systems, with performance dropping 14.8% on average and reasoning becoming unstable.", "motivation": "The proliferation of multimodal misinformation and rise of GenAI tools create highly varied content that challenges current detection systems, requiring systematic study of these vulnerabilities.", "method": "Introduce DriftBench - a large-scale benchmark with 16,000 news instances across six diversification categories, and design three evaluation tasks to test robustness, adversarial susceptibility, and reasoning consistency.", "result": "Experiments with six state-of-the-art LVLM detectors show substantial performance drops (average F1 -14.8%), increasingly unstable reasoning traces, and severe failures under adversarial evidence injection.", "conclusion": "Findings reveal fundamental vulnerabilities in existing MMD systems, indicating an urgent need for more resilient approaches to handle GenAI-driven content diversity."}}
{"id": "2508.13040", "pdf": "https://arxiv.org/pdf/2508.13040", "abs": "https://arxiv.org/abs/2508.13040", "authors": ["Varsha Ramineni", "Hossein A. Rahmani", "Emine Yilmaz", "David Barber"], "title": "Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data", "categories": ["cs.LG"], "comment": "9 pages, 3 figures", "summary": "Ensuring fairness in AI systems is critical, especially in high-stakes\ndomains such as lending, hiring, and healthcare. This urgency is reflected in\nemerging global regulations that mandate fairness assessments and independent\nbias audits. However, procuring the necessary complete data for fairness\ntesting remains a significant challenge. In industry settings, legal and\nprivacy concerns restrict the collection of demographic data required to assess\ngroup disparities, and auditors face practical and cultural challenges in\ngaining access to data. In practice, data relevant for fairness testing is\noften split across separate sources: internal datasets held by institutions\nwith predictive attributes, and external public datasets such as census data\ncontaining protected attributes, each providing only partial, marginal\ninformation. Our work seeks to leverage such available separate data to\nestimate model fairness when complete data is inaccessible. We propose\nutilising the available separate data to estimate a set of feasible joint\ndistributions and then compute the set plausible fairness metrics. Through\nsimulation and real experiments, we demonstrate that we can derive meaningful\nbounds on fairness metrics and obtain reliable estimates of the true metric.\nOur results demonstrate that this approach can serve as a practical and\neffective solution for fairness testing in real-world settings where access to\ncomplete data is restricted.", "AI": {"tldr": "Proposes method to estimate AI fairness metrics using separate incomplete datasets when complete demographic data is unavailable due to privacy/legal constraints.", "motivation": "Addresses the challenge of fairness testing in AI systems where complete demographic data is inaccessible due to legal, privacy, and practical constraints, particularly in high-stakes domains like lending, hiring, and healthcare.", "method": "Utilizes available separate datasets (internal with predictive attributes and external with protected attributes) to estimate feasible joint distributions and compute plausible fairness metrics through bounds estimation.", "result": "Demonstrates through simulations and real experiments that meaningful bounds on fairness metrics can be derived, providing reliable estimates of true fairness metrics.", "conclusion": "The approach serves as a practical and effective solution for fairness testing in real-world settings where access to complete data is restricted, enabling compliance with emerging fairness regulations."}}
{"id": "2508.12713", "pdf": "https://arxiv.org/pdf/2508.12713", "abs": "https://arxiv.org/abs/2508.12713", "authors": ["Brandone Fonya"], "title": "Real-Time Sign Language Gestures to Speech Transcription using Deep Learning", "categories": ["cs.CV"], "comment": "Course related research project", "summary": "Communication barriers pose significant challenges for individuals with\nhearing and speech impairments, often limiting their ability to effectively\ninteract in everyday environments. This project introduces a real-time\nassistive technology solution that leverages advanced deep learning techniques\nto translate sign language gestures into textual and audible speech. By\nemploying convolution neural networks (CNN) trained on the Sign Language MNIST\ndataset, the system accurately classifies hand gestures captured live via\nwebcam. Detected gestures are instantaneously translated into their\ncorresponding meanings and transcribed into spoken language using\ntext-to-speech synthesis, thus facilitating seamless communication.\nComprehensive experiments demonstrate high model accuracy and robust real-time\nperformance with some latency, highlighting the system's practical\napplicability as an accessible, reliable, and user-friendly tool for enhancing\nthe autonomy and integration of sign language users in diverse social settings.", "AI": {"tldr": "Real-time sign language translation system using CNN on Sign Language MNIST dataset that converts gestures to text and speech via webcam capture with high accuracy but some latency.", "motivation": "Address communication barriers for individuals with hearing and speech impairments by creating an accessible tool that enables seamless interaction in everyday environments.", "method": "Uses convolution neural networks (CNN) trained on Sign Language MNIST dataset to classify hand gestures captured live via webcam, then translates detected gestures into text and audible speech using text-to-speech synthesis.", "result": "Comprehensive experiments demonstrate high model accuracy and robust real-time performance, though with some latency. The system proves to be practical, accessible, reliable, and user-friendly.", "conclusion": "The system effectively enhances autonomy and integration of sign language users in diverse social settings, serving as a valuable assistive technology solution for real-time communication."}}
{"id": "2508.13057", "pdf": "https://arxiv.org/pdf/2508.13057", "abs": "https://arxiv.org/abs/2508.13057", "authors": ["Adolfo Gonz\u00e1lez", "V\u00edctor Parada"], "title": "Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models", "categories": ["cs.LG", "cs.AI", "cs.PF", "62M10, 90C59, 68T05", "I.2.6; I.5.1; I.5.2; I.5.4; G.1.6"], "comment": "31 pages, 15 figures, 110 tables. Submitted as a preprint. The\n  manuscript introduces the Hierarchical Evaluation Function (HEF), a\n  multi-metric framework for optimizing demand forecasting models under high\n  uncertainty. Includes extensive experimental validation using real-world\n  datasets and a comparative analysis against classical and modern methods", "summary": "Demand forecasting is essential for strategic planning in competitive\nenvironments, enabling resource optimization and improved responsiveness to\nmarket dynamics. However, multivariate time series modeling faces challenges\ndue to data complexity, uncertainty, and frequent regime shifts. Traditional\nevaluation metrics can introduce biases and limit generalization. This work\ncompares two custom evaluation functions: FMAE (Focused Mean Absolute Error),\nfocused on minimizing absolute errors, and HEF (Hierarchical Evaluation\nFunction), designed to weight global metrics and penalize large deviations.\nExperiments were conducted under different data splits (91:9, 80:20, 70:30)\nusing three optimizers (Grid Search, PSO, Optuna), assessing fit, relative\naccuracy, robustness, and computational efficiency. Results show that HEF\nconsistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,\nRMSSE), enhancing model robustness and explanatory power. These findings were\nconfirmed via visualizations and statistical tests. Conversely, FMAE offers\nadvantages in local metrics (MAE, MASE) and execution time, making it suitable\nfor short-term scenarios. The study highlights a methodological trade-off: HEF\nis ideal for strategic planning, while FMAE is better suited for operational\nefficiency. A replicable framework is proposed for optimizing predictive models\nin dynamic environments.", "AI": {"tldr": "Comparison of two custom evaluation functions (FMAE and HEF) for demand forecasting shows HEF excels in global metrics and robustness for strategic planning, while FMAE performs better in local metrics and speed for operational efficiency.", "motivation": "Multivariate time series modeling faces challenges from data complexity, uncertainty, and regime shifts, with traditional evaluation metrics introducing biases and limiting generalization in demand forecasting.", "method": "Experiments comparing FMAE (focused on minimizing absolute errors) and HEF (weighting global metrics and penalizing large deviations) under different data splits (91:9, 80:20, 70:30) using three optimizers (Grid Search, PSO, Optuna).", "result": "HEF consistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE, RMSSE) and enhances model robustness, while FMAE offers advantages in local metrics (MAE, MASE) and execution time.", "conclusion": "Methodological trade-off exists: HEF is ideal for strategic planning due to better global performance, while FMAE is better suited for operational efficiency with faster execution and local metric advantages."}}
{"id": "2508.12718", "pdf": "https://arxiv.org/pdf/2508.12718", "abs": "https://arxiv.org/abs/2508.12718", "authors": ["Syed Muhmmad Israr", "Feng Zhao"], "title": "Single-Reference Text-to-Image Manipulation with Dual Contrastive Denoising Score", "categories": ["cs.CV"], "comment": null, "summary": "Large-scale text-to-image generative models have shown remarkable ability to\nsynthesize diverse and high-quality images. However, it is still challenging to\ndirectly apply these models for editing real images for two reasons. First, it\nis difficult for users to come up with a perfect text prompt that accurately\ndescribes every visual detail in the input image. Second, while existing models\ncan introduce desirable changes in certain regions, they often dramatically\nalter the input content and introduce unexpected changes in unwanted regions.\nTo address these challenges, we present Dual Contrastive Denoising Score, a\nsimple yet powerful framework that leverages the rich generative prior of\ntext-to-image diffusion models. Inspired by contrastive learning approaches for\nunpaired image-to-image translation, we introduce a straightforward dual\ncontrastive loss within the proposed framework. Our approach utilizes the\nextensive spatial information from the intermediate representations of the\nself-attention layers in latent diffusion models without depending on auxiliary\nnetworks. Our method achieves both flexible content modification and structure\npreservation between input and output images, as well as zero-shot\nimage-to-image translation. Through extensive experiments, we show that our\napproach outperforms existing methods in real image editing while maintaining\nthe capability to directly utilize pretrained text-to-image diffusion models\nwithout further training.", "AI": {"tldr": "Dual Contrastive Denoising Score framework enables precise real image editing using text-to-image diffusion models by preserving input structure while allowing flexible content modifications through dual contrastive loss.", "motivation": "Existing text-to-image models struggle with real image editing due to difficulty in creating perfect text prompts and unwanted alterations in unchanged regions of input images.", "method": "Leverages self-attention layers of latent diffusion models with dual contrastive loss inspired by contrastive learning, enabling structure preservation and content modification without auxiliary networks or additional training.", "result": "Outperforms existing methods in real image editing while maintaining zero-shot image-to-image translation capabilities and directly utilizing pretrained models.", "conclusion": "The framework successfully addresses key challenges in real image editing by combining diffusion model generative priors with contrastive learning principles for precise, structure-preserving modifications."}}
{"id": "2508.13088", "pdf": "https://arxiv.org/pdf/2508.13088", "abs": "https://arxiv.org/abs/2508.13088", "authors": ["Xiaohan Wang", "Zhimin Li", "Joshua A. Levine", "Matthew Berger"], "title": "Seeing the Many: Exploring Parameter Distributions Conditioned on Features in Surrogates", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "Recently, neural surrogate models have emerged as a compelling alternative to\ntraditional simulation workflows. This is accomplished by modeling the\nunderlying function of scientific simulations, removing the need to run\nexpensive simulations. Beyond just mapping from input parameter to output,\nsurrogates have also been shown useful for inverse problems: output to input\nparameters. Inverse problems can be understood as search, where we aim to find\nparameters whose surrogate outputs contain a specified feature. Yet finding\nthese parameters can be costly, especially for high-dimensional parameter\nspaces. Thus, existing surrogate-based solutions primarily focus on finding a\nsmall set of matching parameters, in the process overlooking the broader\npicture of plausible parameters. Our work aims to model and visualize the\ndistribution of possible input parameters that produce a given output feature.\nTo achieve this goal, we aim to address two challenges: (1) the approximation\nerror inherent in the surrogate model and (2) forming the parameter\ndistribution in an interactive manner. We model error via density estimation,\nreporting high density only if a given parameter configuration is close to\ntraining parameters, measured both over the input and output space. Our density\nestimate is used to form a prior belief on parameters, and when combined with a\nlikelihood on features, gives us an efficient way to sample plausible parameter\nconfigurations that generate a target output feature. We demonstrate the\nusability of our solution through a visualization interface by performing\nfeature-driven parameter analysis over the input parameter space of three\nsimulation datasets. Source code is available at\nhttps://github.com/matthewberger/seeing-the-many", "AI": {"tldr": "This paper presents a method for modeling and visualizing the distribution of input parameters that produce specific output features in neural surrogate models, addressing approximation error and enabling interactive exploration of parameter spaces.", "motivation": "Existing surrogate-based solutions focus on finding individual matching parameters but overlook the broader distribution of plausible parameters. The authors aim to address this gap by modeling the complete parameter distribution that produces given output features.", "method": "The approach uses density estimation to model surrogate approximation error, reporting high density only for parameters close to training data in both input and output spaces. This density estimate forms a prior belief on parameters, which when combined with feature likelihood, enables efficient sampling of plausible parameter configurations for target output features.", "result": "The method demonstrates usability through a visualization interface for feature-driven parameter analysis across three simulation datasets, providing an efficient way to explore high-dimensional parameter spaces.", "conclusion": "The proposed solution successfully addresses the challenges of surrogate approximation error and interactive parameter distribution formation, enabling comprehensive exploration of plausible parameter configurations that generate target output features in scientific simulations."}}
{"id": "2508.12720", "pdf": "https://arxiv.org/pdf/2508.12720", "abs": "https://arxiv.org/abs/2508.12720", "authors": ["Kangjie Chen", "Yingji Zhong", "Zhihao Li", "Jiaqi Lin", "Youyu Chen", "Minghan Qin", "Haoqian Wang"], "title": "Quantifying and Alleviating Co-Adaptation in Sparse-View 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": "Under review. Project page:\n  https://chenkangjie1123.github.io/Co-Adaptation-3DGS/", "summary": "3D Gaussian Splatting (3DGS) has demonstrated impressive performance in novel\nview synthesis under dense-view settings. However, in sparse-view scenarios,\ndespite the realistic renderings in training views, 3DGS occasionally manifests\nappearance artifacts in novel views. This paper investigates the appearance\nartifacts in sparse-view 3DGS and uncovers a core limitation of current\napproaches: the optimized Gaussians are overly-entangled with one another to\naggressively fit the training views, which leads to a neglect of the real\nappearance distribution of the underlying scene and results in appearance\nartifacts in novel views. The analysis is based on a proposed metric, termed\nCo-Adaptation Score (CA), which quantifies the entanglement among Gaussians,\ni.e., co-adaptation, by computing the pixel-wise variance across multiple\nrenderings of the same viewpoint, with different random subsets of Gaussians.\nThe analysis reveals that the degree of co-adaptation is naturally alleviated\nas the number of training views increases. Based on the analysis, we propose\ntwo lightweight strategies to explicitly mitigate the co-adaptation in\nsparse-view 3DGS: (1) random gaussian dropout; (2) multiplicative noise\ninjection to the opacity. Both strategies are designed to be plug-and-play, and\ntheir effectiveness is validated across various methods and benchmarks. We hope\nthat our insights into the co-adaptation effect will inspire the community to\nachieve a more comprehensive understanding of sparse-view 3DGS.", "AI": {"tldr": "3D Gaussian Splatting suffers from appearance artifacts in sparse-view scenarios due to Gaussian co-adaptation, which is mitigated through random dropout and opacity noise injection.", "motivation": "3DGS produces realistic renderings in training views but shows appearance artifacts in novel views under sparse-view conditions, indicating a fundamental limitation in current approaches.", "method": "Proposed Co-Adaptation Score (CA) metric to quantify Gaussian entanglement, and introduced two lightweight strategies: random Gaussian dropout and multiplicative noise injection to opacity.", "result": "Analysis reveals co-adaptation decreases with more training views. Both proposed strategies effectively mitigate co-adaptation across various methods and benchmarks.", "conclusion": "The co-adaptation effect in sparse-view 3DGS is a critical issue that can be addressed through simple plug-and-play techniques, providing insights for better understanding and improvement of sparse-view 3DGS."}}
{"id": "2508.13099", "pdf": "https://arxiv.org/pdf/2508.13099", "abs": "https://arxiv.org/abs/2508.13099", "authors": ["Mingyu Kim", "Daniel Stilwell", "Jorge Jimenez"], "title": "Outlier Detection of Poisson-Distributed Targets Using a Seabed Sensor Network", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "IEEE OCEANS", "summary": "This paper presents a framework for classifying and detecting spatial\ncommission outliers in maritime environments using seabed acoustic sensor\nnetworks and log Gaussian Cox processes (LGCPs). By modeling target arrivals as\na mixture of normal and outlier processes, we estimate the probability that a\nnewly observed event is an outlier. We propose a second-order approximation of\nthis probability that incorporates both the mean and variance of the normal\nintensity function, providing improved classification accuracy compared to\nmean-only approaches. We analytically show that our method yields a tighter\nbound to the true probability using Jensen's inequality. To enhance detection,\nwe integrate a real-time, near-optimal sensor placement strategy that\ndynamically adjusts sensor locations based on the evolving outlier intensity.\nThe proposed framework is validated using real ship traffic data near Norfolk,\nVirginia, where numerical results demonstrate the effectiveness of our approach\nin improving both classification performance and outlier detection through\nsensor deployment.", "AI": {"tldr": "Framework for detecting spatial outliers in maritime environments using sensor networks and LGCPs, with improved classification accuracy through second-order probability approximation and dynamic sensor placement.", "motivation": "Need to accurately classify and detect spatial commission outliers in maritime environments to improve surveillance and security using seabed acoustic sensor networks.", "method": "Model target arrivals as mixture of normal and outlier processes using log Gaussian Cox processes. Propose second-order probability approximation incorporating mean and variance of normal intensity. Use Jensen's inequality for tighter probability bounds. Implement real-time near-optimal sensor placement strategy.", "result": "Validated with real ship traffic data near Norfolk, Virginia. Numerical results show improved classification performance and outlier detection effectiveness through optimized sensor deployment.", "conclusion": "The proposed framework successfully enhances spatial outlier detection in maritime environments through improved probability estimation and dynamic sensor placement, demonstrating practical effectiveness with real-world data."}}
{"id": "2508.11845", "pdf": "https://arxiv.org/pdf/2508.11845", "abs": "https://arxiv.org/abs/2508.11845", "authors": ["Marius Miron", "David Robinson", "Milad Alizadeh", "Ellen Gilsenan-McMahon", "Gagan Narula", "Olivier Pietquin", "Matthieu Geist", "Emmanuel Chemla", "Maddie Cusimano", "Felix Effenberger", "Masato Hagiwara", "Benjamin Hoffman", "Sara Keen", "Diane Kim", "Jane Lawton", "Jen-Yu Liu", "Aza Raskin"], "title": "What Matters for Bioacoustic Encoding", "categories": ["cs.SD", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Bioacoustics, the study of sounds produced by living organisms, plays a vital\nrole in conservation, biodiversity monitoring, and behavioral studies. Many\ntasks in this field, such as species, individual, and behavior classification\nand detection, are well-suited to machine learning. However, they often suffer\nfrom limited annotated data, highlighting the need for a general-purpose\nbioacoustic encoder capable of extracting useful representations for diverse\ndownstream tasks. Such encoders have been proposed before, but are often\nlimited in scope due to a focus on a narrow range of species (typically birds),\nand a reliance on a single model architecture or training paradigm. Moreover,\nthey are usually evaluated on a small set of tasks and datasets. In this work,\nwe present a large-scale empirical study that covers aspects of bioacoustics\nthat are relevant to research but have previously been scarcely considered:\ntraining data diversity and scale, model architectures and training recipes,\nand the breadth of evaluation tasks and datasets. We obtain encoders that are\nstate-of-the-art on the existing and proposed benchmarks. We also identify what\nmatters for training these encoders, such that this work can be extended when\nmore data are available or better architectures are proposed. Specifically,\nacross 26 datasets with tasks including species classification, detection,\nindividual ID, and vocal repertoire discovery, we find self-supervised\npre-training followed by supervised post-training on a mixed bioacoustics +\ngeneral-audio corpus yields the strongest in- and out-of-distribution\nperformance. We show the importance of data diversity in both stages. To\nsupport ongoing research and application, we will release the model\ncheckpoints.", "AI": {"tldr": "Large-scale study on bioacoustic encoders showing that self-supervised pre-training followed by supervised training on diverse audio data yields state-of-the-art performance across 26 bioacoustic tasks.", "motivation": "Bioacoustic tasks suffer from limited annotated data, and existing encoders are limited in scope (focusing mainly on birds), architecture diversity, and evaluation breadth. There's a need for general-purpose bioacoustic encoders that can handle diverse species and tasks.", "method": "Conducted large-scale empirical study covering training data diversity/scale, model architectures, and training recipes. Used self-supervised pre-training followed by supervised post-training on mixed bioacoustics + general-audio corpus across 26 datasets.", "result": "Achieved state-of-the-art performance on existing and proposed benchmarks. Identified that data diversity in both pre-training and post-training stages is crucial for strong in-distribution and out-of-distribution performance.", "conclusion": "The proposed training approach with diverse data yields the best bioacoustic encoders. The study provides a foundation for future extensions with more data or better architectures, and model checkpoints will be released to support ongoing research."}}
{"id": "2508.12736", "pdf": "https://arxiv.org/pdf/2508.12736", "abs": "https://arxiv.org/abs/2508.12736", "authors": ["Ying Zhang", "Xiongxin Tang", "Chongyi Li", "Qiao Chen", "Yuquan Wu"], "title": "Frequency-Driven Inverse Kernel Prediction for Single Image Defocus Deblurring", "categories": ["cs.CV"], "comment": null, "summary": "Single image defocus deblurring aims to recover an all-in-focus image from a\ndefocus counterpart, where accurately modeling spatially varying blur kernels\nremains a key challenge. Most existing methods rely on spatial features for\nkernel estimation, but their performance degrades in severely blurry regions\nwhere local high-frequency details are missing. To address this, we propose a\nFrequency-Driven Inverse Kernel Prediction network (FDIKP) that incorporates\nfrequency-domain representations to enhance structural identifiability in\nkernel modeling. Given the superior discriminative capability of the frequency\ndomain for blur modeling, we design a Dual-Branch Inverse Kernel Prediction\n(DIKP) strategy that improves the accuracy of kernel estimation while\nmaintaining stability. Moreover, considering the limited number of predicted\ninverse kernels, we introduce a Position Adaptive Convolution (PAC) to enhance\nthe adaptability of the deconvolution process. Finally, we propose a\nDual-Domain Scale Recurrent Module (DSRM) to fuse deconvolution results and\nprogressively improve deblurring quality from coarse to fine. Extensive\nexperiments demonstrate that our method outperforms existing approaches. Code\nwill be made publicly available.", "AI": {"tldr": "Frequency-Driven Inverse Kernel Prediction network (FDIKP) uses frequency-domain representations and dual-branch strategy to improve defocus deblurring by enhancing kernel estimation accuracy and deconvolution adaptability.", "motivation": "Existing methods relying on spatial features degrade in severely blurry regions where local high-frequency details are missing, creating a need for better kernel modeling approaches.", "method": "Proposes FDIKP with Dual-Branch Inverse Kernel Prediction strategy, Position Adaptive Convolution for deconvolution adaptability, and Dual-Domain Scale Recurrent Module for progressive quality improvement.", "result": "Extensive experiments demonstrate that the method outperforms existing approaches in single image defocus deblurring.", "conclusion": "The frequency-domain approach with dual-branch kernel prediction and adaptive deconvolution effectively addresses the challenges of spatially varying blur kernels in defocus deblurring."}}
{"id": "2508.13100", "pdf": "https://arxiv.org/pdf/2508.13100", "abs": "https://arxiv.org/abs/2508.13100", "authors": ["Jason Hartline", "Lunjia Hu", "Yifan Wu"], "title": "A Perfectly Truthful Calibration Measure", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": null, "summary": "Calibration requires that predictions are conditionally unbiased and,\ntherefore, reliably interpretable as probabilities. Calibration measures\nquantify how far a predictor is from perfect calibration. As introduced by\nHaghtalab et al. (2024), a calibration measure is truthful if it is minimized\nin expectation when a predictor outputs the ground-truth probabilities.\nAlthough predicting the true probabilities guarantees perfect calibration, in\nreality, when calibration is evaluated on a finite sample, predicting the truth\nis not guaranteed to minimize any known calibration measure. All known\ncalibration measures incentivize predictors to lie in order to appear more\ncalibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et\nal. (2024) and Qiao and Zhao (2025) to construct approximately truthful\ncalibration measures in the sequential prediction setting, but no perfectly\ntruthful calibration measure was known to exist even in the more basic batch\nsetting.\n  We design a perfectly truthful calibration measure in the batch setting:\naveraged two-bin calibration error (ATB). In addition to being truthful, ATB is\nsound, complete, continuous, and quadratically related to two existing\ncalibration measures: the smooth calibration error (smCal) and the (lower)\ndistance to calibration (distCal). The simplicity in our definition of ATB\nmakes it efficient and straightforward to compute. ATB allows faster estimation\nalgorithms with significantly easier implementations than smCal and distCal,\nachieving improved running time and simplicity for the calibration testing\nproblem studied by Hu et al. (2024). We also introduce a general recipe for\nconstructing truthful measures, which proves the truthfulness of ATB as a\nspecial case and allows us to construct other truthful calibration measures\nsuch as quantile-binned l_2-ECE.", "AI": {"tldr": "ATB is a perfectly truthful calibration measure that prevents predictors from lying to appear more calibrated on finite samples, with efficient computation and improved running time.", "motivation": "Existing calibration measures are not truthful - they incentivize predictors to lie about probabilities to appear more calibrated on finite samples rather than outputting true probabilities.", "method": "Designed averaged two-bin calibration error (ATB) as a perfectly truthful measure, and introduced a general recipe for constructing truthful calibration measures including quantile-binned l_2-ECE.", "result": "ATB is truthful, sound, complete, continuous, and quadratically related to existing measures (smCal and distCal), with faster estimation algorithms and easier implementation.", "conclusion": "ATB provides the first perfectly truthful calibration measure that enables reliable probability interpretation while being computationally efficient and simple to implement."}}
{"id": "2508.12745", "pdf": "https://arxiv.org/pdf/2508.12745", "abs": "https://arxiv.org/abs/2508.12745", "authors": ["Xizhan Gao", "Wei Hu"], "title": "DCSCR: A Class-Specific Collaborative Representation based Network for Image Set Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Image set classification (ISC), which can be viewed as a task of comparing\nsimilarities between sets consisting of unordered heterogeneous images with\nvariable quantities and qualities, has attracted growing research attention in\nrecent years. How to learn effective feature representations and how to explore\nthe similarities between different image sets are two key yet challenging\nissues in this field. However, existing traditional ISC methods classify image\nsets based on raw pixel features, ignoring the importance of feature learning.\nExisting deep ISC methods can learn deep features, but they fail to adaptively\nadjust the features when measuring set distances, resulting in limited\nperformance in few-shot ISC. To address the above issues, this paper combines\ntraditional ISC methods with deep models and proposes a novel few-shot ISC\napproach called Deep Class-specific Collaborative Representation (DCSCR)\nnetwork to simultaneously learn the frame- and concept-level feature\nrepresentations of each image set and the distance similarities between\ndifferent sets. Specifically, DCSCR consists of a fully convolutional deep\nfeature extractor module, a global feature learning module, and a\nclass-specific collaborative representation-based metric learning module. The\ndeep feature extractor and global feature learning modules are used to learn\n(local and global) frame-level feature representations, while the\nclass-specific collaborative representation-based metric learning module is\nexploit to adaptively learn the concept-level feature representation of each\nimage set and thus obtain the distance similarities between different sets by\ndeveloping a new CSCR-based contrastive loss function. Extensive experiments on\nseveral well-known few-shot ISC datasets demonstrate the effectiveness of the\nproposed method compared with some state-of-the-art image set classification\nalgorithms.", "AI": {"tldr": "Proposes DCSCR network combining traditional and deep learning approaches for few-shot image set classification, learning both frame-level and concept-level features with adaptive distance measurement.", "motivation": "Existing methods either use raw pixel features (ignoring feature learning) or deep features but fail to adaptively adjust features when measuring set distances, limiting performance in few-shot scenarios.", "method": "Deep Class-specific Collaborative Representation (DCSCR) network with three modules: fully convolutional deep feature extractor, global feature learning, and class-specific collaborative representation-based metric learning with new contrastive loss function.", "result": "Extensive experiments on several well-known few-shot ISC datasets demonstrate effectiveness compared with state-of-the-art image set classification algorithms.", "conclusion": "The proposed DCSCR approach successfully addresses limitations of existing methods by simultaneously learning frame- and concept-level feature representations and adaptive distance similarities for improved few-shot image set classification."}}
{"id": "2508.13111", "pdf": "https://arxiv.org/pdf/2508.13111", "abs": "https://arxiv.org/abs/2508.13111", "authors": ["Michael Mayr", "Georgios C. Chasparis"], "title": "Causally-Guided Pairwise Transformer -- Towards Foundational Digital Twins in Process Industry", "categories": ["cs.LG"], "comment": "12 pages, 2 figures, 4 tables", "summary": "Foundational modelling of multi-dimensional time-series data in industrial\nsystems presents a central trade-off: channel-dependent (CD) models capture\nspecific cross-variable dynamics but lack robustness and adaptability as model\nlayers are commonly bound to the data dimensionality of the tackled use-case,\nwhile channel-independent (CI) models offer generality at the cost of modelling\nthe explicit interactions crucial for system-level predictive regression tasks.\nTo resolve this, we propose the Causally-Guided Pairwise Transformer (CGPT), a\nnovel architecture that integrates a known causal graph as an inductive bias.\nThe core of CGPT is built around a pairwise modeling paradigm, tackling the\nCD/CI conflict by decomposing the multidimensional data into pairs. The model\nuses channel-agnostic learnable layers where all parameter dimensions are\nindependent of the number of variables. CGPT enforces a CD information flow at\nthe pair-level and CI-like generalization across pairs. This approach\ndisentangles complex system dynamics and results in a highly flexible\narchitecture that ensures scalability and any-variate adaptability. We validate\nCGPT on a suite of synthetic and real-world industrial datasets on long-term\nand one-step forecasting tasks designed to simulate common industrial\ncomplexities. Results demonstrate that CGPT significantly outperforms both CI\nand CD baselines in predictive accuracy and shows competitive performance with\nend-to-end trained CD models while remaining agnostic to the problem\ndimensionality.", "AI": {"tldr": "CGPT is a novel transformer architecture that integrates causal graphs to resolve the trade-off between channel-dependent and channel-independent models for industrial time-series forecasting.", "motivation": "To address the fundamental trade-off where channel-dependent models capture specific cross-variable dynamics but lack robustness, while channel-independent models offer generality but miss explicit interactions crucial for system-level predictive tasks.", "method": "Proposes Causally-Guided Pairwise Transformer (CGPT) that uses known causal graphs as inductive bias, decomposes multidimensional data into pairs, employs channel-agnostic learnable layers, and enforces CD information flow at pair-level with CI-like generalization across pairs.", "result": "CGPT significantly outperforms both CI and CD baselines in predictive accuracy on synthetic and real-world industrial datasets, showing competitive performance with end-to-end trained CD models while remaining dimensionality-agnostic.", "conclusion": "The pairwise modeling paradigm with causal guidance successfully resolves the CD/CI conflict, creating a flexible architecture that ensures scalability and any-variate adaptability for industrial time-series forecasting."}}
{"id": "2508.11867", "pdf": "https://arxiv.org/pdf/2508.11867", "abs": "https://arxiv.org/abs/2508.11867", "authors": ["Mohammad Baqar", "Saba Naqvi", "Rajat Khanda"], "title": "AI-Augmented CI/CD Pipelines: From Code Commit to Production with Autonomous Decisions", "categories": ["cs.SE", "cs.AI"], "comment": "13 Pages", "summary": "Modern software delivery has accelerated from quarterly releases to multiple\ndeployments per day. While CI/CD tooling has matured, human decision points\ninterpreting flaky tests, choosing rollback strategies, tuning feature flags,\nand deciding when to promote a canary remain major sources of latency and\noperational toil. We propose AI-Augmented CI/CD Pipelines, where large language\nmodels (LLMs) and autonomous agents act as policy-bounded co-pilots and\nprogressively as decision makers. We contribute: (1) a reference architecture\nfor embedding agentic decision points into CI/CD, (2) a decision taxonomy and\npolicy-as-code guardrail pattern, (3) a trust-tier framework for staged\nautonomy, (4) an evaluation methodology using DevOps Research and Assessment (\nDORA) metrics and AI-specific indicators, and (5) a detailed industrial-style\ncase study migrating a React 19 microservice to an AI-augmented pipeline. We\ndiscuss ethics, verification, auditability, and threats to validity, and chart\na roadmap for verifiable autonomy in production delivery systems.", "AI": {"tldr": "AI-Augmented CI/CD Pipelines use LLMs and autonomous agents as policy-bounded co-pilots to automate human decision points in software delivery, reducing latency and operational toil.", "motivation": "Human decision points in CI/CD pipelines (interpreting flaky tests, rollback strategies, feature flag tuning, canary promotion) remain major sources of latency and operational toil despite mature tooling.", "method": "Proposes a reference architecture for embedding agentic decision points, decision taxonomy with policy-as-code guardrails, trust-tier framework for staged autonomy, and evaluation using DORA metrics and AI-specific indicators.", "result": "Includes a detailed industrial-style case study migrating a React 19 microservice to an AI-augmented pipeline, demonstrating practical implementation.", "conclusion": "The paper charts a roadmap for verifiable autonomy in production delivery systems while addressing ethics, verification, auditability, and validity threats."}}
{"id": "2508.12750", "pdf": "https://arxiv.org/pdf/2508.12750", "abs": "https://arxiv.org/abs/2508.12750", "authors": ["Linhao Li", "Boya Jin", "Zizhe Li", "Lanqing Guo", "Hao Cheng", "Bo Li", "Yongfeng Dong"], "title": "D2-Mamba: Dual-Scale Fusion and Dual-Path Scanning with SSMs for Shadow Removal", "categories": ["cs.CV"], "comment": "Paper Under Review", "summary": "Shadow removal aims to restore images that are partially degraded by shadows,\nwhere the degradation is spatially localized and non-uniform. Unlike general\nrestoration tasks that assume global degradation, shadow removal can leverage\nabundant information from non-shadow regions for guidance. However, the\ntransformation required to correct shadowed areas often differs significantly\nfrom that of well-lit regions, making it challenging to apply uniform\ncorrection strategies. This necessitates the effective integration of non-local\ncontextual cues and adaptive modeling of region-specific transformations. To\nthis end, we propose a novel Mamba-based network featuring dual-scale fusion\nand dual-path scanning to selectively propagate contextual information based on\ntransformation similarity across regions. Specifically, the proposed Dual-Scale\nFusion Mamba Block (DFMB) enhances multi-scale feature representation by fusing\noriginal features with low-resolution features, effectively reducing boundary\nartifacts. The Dual-Path Mamba Group (DPMG) captures global features via\nhorizontal scanning and incorporates a mask-aware adaptive scanning strategy,\nwhich improves structural continuity and fine-grained region modeling.\nExperimental results demonstrate that our method significantly outperforms\nexisting state-of-the-art approaches on shadow removal benchmarks.", "AI": {"tldr": "A novel Mamba-based network with dual-scale fusion and dual-path scanning for shadow removal, outperforming state-of-the-art methods by effectively leveraging non-shadow region information and adaptive region-specific transformations.", "motivation": "Shadow removal requires different transformations for shadowed vs well-lit regions, making uniform correction strategies ineffective. The paper aims to address the challenge of integrating non-local contextual cues and modeling region-specific transformations by leveraging information from non-shadow regions.", "method": "Proposes a Mamba-based network with Dual-Scale Fusion Mamba Block (DFMB) for multi-scale feature representation and boundary artifact reduction, and Dual-Path Mamba Group (DPMG) with horizontal scanning and mask-aware adaptive scanning for global feature capture and fine-grained region modeling.", "result": "Experimental results demonstrate that the proposed method significantly outperforms existing state-of-the-art approaches on shadow removal benchmarks.", "conclusion": "The proposed Mamba-based network with dual-scale fusion and dual-path scanning effectively addresses shadow removal challenges by selectively propagating contextual information based on transformation similarity and improving structural continuity through adaptive scanning strategies."}}
{"id": "2508.13113", "pdf": "https://arxiv.org/pdf/2508.13113", "abs": "https://arxiv.org/abs/2508.13113", "authors": ["Alicja Ziarko", "Michal Bortkiewicz", "Michal Zawalski", "Benjamin Eysenbach", "Piotr Milos"], "title": "Contrastive Representations for Temporal Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": "Project website: https://princeton-rl.github.io/CRTR/", "summary": "In classical AI, perception relies on learning state-based representations,\nwhile planning, which can be thought of as temporal reasoning over action\nsequences, is typically achieved through search. We study whether such\nreasoning can instead emerge from representations that capture both perceptual\nand temporal structure. We show that standard temporal contrastive learning,\ndespite its popularity, often fails to capture temporal structure due to its\nreliance on spurious features. To address this, we introduce Combinatorial\nRepresentations for Temporal Reasoning (CRTR), a method that uses a negative\nsampling scheme to provably remove these spurious features and facilitate\ntemporal reasoning. CRTR achieves strong results on domains with complex\ntemporal structure, such as Sokoban and Rubik's Cube. In particular, for the\nRubik's Cube, CRTR learns representations that generalize across all initial\nstates and allow it to solve the puzzle using fewer search steps than BestFS,\nthough with longer solutions. To our knowledge, this is the first method that\nefficiently solves arbitrary Cube states using only learned representations,\nwithout relying on an external search algorithm.", "AI": {"tldr": "CRTR is a novel temporal representation learning method that overcomes spurious feature reliance in standard contrastive learning, enabling effective temporal reasoning for complex domains like Sokoban and Rubik's Cube without external search algorithms.", "motivation": "Traditional AI separates perception (state-based representations) from planning (search-based temporal reasoning). The paper explores whether temporal reasoning can emerge from representations that capture both perceptual and temporal structure simultaneously.", "method": "Introduces Combinatorial Representations for Temporal Reasoning (CRTR), which uses a negative sampling scheme to provably remove spurious features that plague standard temporal contrastive learning methods.", "result": "CRTR achieves strong performance on complex temporal domains: solves Sokoban and Rubik's Cube using only learned representations, generalizes across all initial Cube states, and requires fewer search steps than BestFS (though with longer solution paths).", "conclusion": "CRTR demonstrates that temporal reasoning can effectively emerge from properly designed representations, enabling efficient solving of complex temporal problems without relying on external search algorithms - a first for arbitrary Rubik's Cube states."}}
{"id": "2508.11868", "pdf": "https://arxiv.org/pdf/2508.11868", "abs": "https://arxiv.org/abs/2508.11868", "authors": ["Lida Xu"], "title": "Data Shift of Object Detection in Autonomous Driving", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "With the widespread adoption of machine learning technologies in autonomous\ndriving systems, their role in addressing complex environmental perception\nchallenges has become increasingly crucial. However, existing machine learning\nmodels exhibit significant vulnerability, as their performance critically\ndepends on the fundamental assumption that training and testing data satisfy\nthe independent and identically distributed condition, which is difficult to\nguarantee in real-world applications. Dynamic variations in data distribution\ncaused by seasonal changes, weather fluctuations lead to data shift problems in\nautonomous driving systems. This study investigates the data shift problem in\nautonomous driving object detection tasks, systematically analyzing its\ncomplexity and diverse manifestations. We conduct a comprehensive review of\ndata shift detection methods and employ shift detection analysis techniques to\nperform dataset categorization and balancing. Building upon this foundation, we\nconstruct an object detection model. To validate our approach, we optimize the\nmodel by integrating CycleGAN-based data augmentation techniques with the\nYOLOv5 framework. Experimental results demonstrate that our method achieves\nsuperior performance compared to baseline models on the BDD100K dataset.", "AI": {"tldr": "This paper addresses data shift problems in autonomous driving object detection by analyzing data shift complexity, using detection methods for dataset categorization, and integrating CycleGAN data augmentation with YOLOv5 to achieve superior performance on BDD100K dataset.", "motivation": "Machine learning models in autonomous driving are vulnerable to data distribution shifts caused by seasonal and weather changes, which violate the independent and identically distributed assumption critical for model performance.", "method": "Systematic analysis of data shift complexity, comprehensive review of detection methods, dataset categorization and balancing, and integration of CycleGAN-based data augmentation with YOLOv5 framework.", "result": "Experimental results show superior performance compared to baseline models on the BDD100K dataset.", "conclusion": "The proposed approach effectively addresses data shift problems in autonomous driving object detection through systematic analysis and optimized data augmentation techniques."}}
{"id": "2508.12755", "pdf": "https://arxiv.org/pdf/2508.12755", "abs": "https://arxiv.org/abs/2508.12755", "authors": ["Cristo J. van den Berg", "Frank G. te Nijenhuis", "Mirre J. Blaauboer", "Daan T. W. van Erp", "Carlijn M. Keppels", "Matthijs van der Sluijs", "Bob Roozenbeek", "Wim van Zwam", "Sandra Cornelissen", "Danny Ruijters", "Ruisheng Su", "Theo van Walsum"], "title": "CLAIRE-DSA: Fluoroscopic Image Classification for Quality Assurance of Computer Vision Pipelines in Acute Ischemic Stroke", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 4 figures, workshop paper accepted at\n  https://switchmiccai.github.io/switch/", "summary": "Computer vision models can be used to assist during mechanical thrombectomy\n(MT) for acute ischemic stroke (AIS), but poor image quality often degrades\nperformance. This work presents CLAIRE-DSA, a deep learning--based framework\ndesigned to categorize key image properties in minimum intensity projections\n(MinIPs) acquired during MT for AIS, supporting downstream quality control and\nworkflow optimization. CLAIRE-DSA uses pre-trained ResNet backbone models,\nfine-tuned to predict nine image properties (e.g., presence of contrast,\nprojection angle, motion artefact severity). Separate classifiers were trained\non an annotated dataset containing $1,758$ fluoroscopic MinIPs. The model\nachieved excellent performance on all labels, with ROC-AUC ranging from $0.91$\nto $0.98$, and precision ranging from $0.70$ to $1.00$. The ability of\nCLAIRE-DSA to identify suitable images was evaluated on a segmentation task by\nfiltering poor quality images and comparing segmentation performance on\nfiltered and unfiltered datasets. Segmentation success rate increased from\n$42%$ to $69%$, $p < 0.001$. CLAIRE-DSA demonstrates strong potential as an\nautomated tool for accurately classifying image properties in DSA series of\nacute ischemic stroke patients, supporting image annotation and quality control\nin clinical and research applications. Source code is available at\nhttps://gitlab.com/icai-stroke-lab/wp3_neurointerventional_ai/claire-dsa.", "AI": {"tldr": "CLAIRE-DSA is a deep learning framework that classifies image quality in fluoroscopic minimum intensity projections during mechanical thrombectomy for stroke, improving downstream segmentation performance by filtering poor quality images.", "motivation": "Computer vision models for assisting mechanical thrombectomy in acute ischemic stroke suffer from degraded performance due to poor image quality, necessitating automated quality assessment tools.", "method": "Uses pre-trained ResNet backbone models fine-tuned to predict nine image properties (contrast presence, projection angle, motion artifacts, etc.) on an annotated dataset of 1,758 fluoroscopic MinIPs with separate classifiers for each property.", "result": "Achieved excellent performance with ROC-AUC 0.91-0.98 and precision 0.70-1.00 across all labels. Filtering poor quality images increased segmentation success rate from 42% to 69% (p < 0.001).", "conclusion": "CLAIRE-DSA shows strong potential as an automated tool for image quality classification in DSA series, supporting clinical and research applications through improved image annotation and quality control."}}
{"id": "2508.13135", "pdf": "https://arxiv.org/pdf/2508.13135", "abs": "https://arxiv.org/abs/2508.13135", "authors": ["Yueyang Liu", "Lance Kennedy", "Ruochen Kong", "Joon-Seok Kim", "Andreas Z\u00fcfle"], "title": "Training Machine Learning Models on Human Spatio-temporal Mobility Data: An Experimental Study [Experiment Paper]", "categories": ["cs.LG"], "comment": null, "summary": "Individual-level human mobility prediction has emerged as a significant topic\nof research with applications in infectious disease monitoring, child, and\nelderly care. Existing studies predominantly focus on the microscopic aspects\nof human trajectories: such as predicting short-term trajectories or the next\nlocation visited, while offering limited attention to macro-level mobility\npatterns and the corresponding life routines. In this paper, we focus on an\nunderexplored problem in human mobility prediction: determining the best\npractices to train a machine learning model using historical data to forecast\nan individuals complete trajectory over the next days and weeks. In this\nexperiment paper, we undertake a comprehensive experimental analysis of diverse\nmodels, parameter configurations, and training strategies, accompanied by an\nin-depth examination of the statistical distribution inherent in human mobility\npatterns. Our empirical evaluations encompass both Long Short-Term Memory and\nTransformer-based architectures, and further investigate how incorporating\nindividual life patterns can enhance the effectiveness of the prediction. We\nshow that explicitly including semantic information such as day-of-the-week and\nuser-specific historical information can help the model better understand\nindividual patterns of life and improve predictions. Moreover, since the\nabsence of explicit user information is often missing due to user privacy, we\nshow that the sampling of users may exacerbate data skewness and result in a\nsubstantial loss in predictive accuracy. To mitigate data imbalance and\npreserve diversity, we apply user semantic clustering with stratified sampling\nto ensure that the sampled dataset remains representative. Our results further\nshow that small-batch stochastic gradient optimization improves model\nperformance, especially when human mobility training data is limited.", "AI": {"tldr": "This paper explores best practices for training ML models to predict complete individual trajectories over days/weeks, focusing on incorporating life patterns and addressing data imbalance issues.", "motivation": "Existing mobility prediction research focuses on short-term trajectories and next-location prediction, neglecting macro-level mobility patterns and life routines. The paper aims to determine optimal training strategies for forecasting complete individual trajectories over extended periods.", "method": "Comprehensive experimental analysis of LSTM and Transformer models with various parameter configurations and training strategies. Incorporates semantic information (day-of-week, user-specific historical data) and addresses data skewness through user semantic clustering with stratified sampling. Tests small-batch stochastic gradient optimization.", "result": "Explicit inclusion of semantic information improves model understanding of individual life patterns. User sampling without proper stratification exacerbates data skewness and reduces predictive accuracy. Small-batch optimization enhances performance, especially with limited training data.", "conclusion": "Incorporating life pattern semantics and addressing data imbalance through stratified sampling are crucial for effective long-term human mobility prediction. Small-batch optimization benefits models when training data is limited."}}
{"id": "2508.12766", "pdf": "https://arxiv.org/pdf/2508.12766", "abs": "https://arxiv.org/abs/2508.12766", "authors": ["Peihao Li", "Yan Fang", "Man Liu", "Huihui Bai", "Anhong Wang", "Yunchao Wei", "Yao Zhao"], "title": "Harnessing Group-Oriented Consistency Constraints for Semi-Supervised Semantic Segmentation in CdZnTe Semiconductors", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Labeling Cadmium Zinc Telluride (CdZnTe) semiconductor images is challenging\ndue to the low-contrast defect boundaries, necessitating annotators to\ncross-reference multiple views. These views share a single ground truth (GT),\nforming a unique ``many-to-one'' relationship. This characteristic renders\nadvanced semi-supervised semantic segmentation (SSS) methods suboptimal, as\nthey are generally limited by a ``one-to-one'' relationship, where each image\nis independently associated with its GT. Such limitation may lead to error\naccumulation in low-contrast regions, further exacerbating confirmation bias.\nTo address this issue, we revisit the SSS pipeline from a group-oriented\nperspective and propose a human-inspired solution: the Intra-group Consistency\nAugmentation Framework (ICAF). First, we experimentally validate the inherent\nconsistency constraints within CdZnTe groups, establishing a group-oriented\nbaseline using the Intra-group View Sampling (IVS). Building on this insight,\nwe introduce the Pseudo-label Correction Network (PCN) to enhance consistency\nrepresentation, which consists of two key modules. The View Augmentation Module\n(VAM) improves boundary details by dynamically synthesizing a boundary-aware\nview through the aggregation of multiple views. In the View Correction Module\n(VCM), this synthesized view is paired with other views for information\ninteraction, effectively emphasizing salient regions while minimizing noise.\nExtensive experiments demonstrate the effectiveness of our solution for CdZnTe\nmaterials. Leveraging DeepLabV3+ with a ResNet-101 backbone as our segmentation\nmodel, we achieve a 70.6\\% mIoU on the CdZnTe dataset using only 2\ngroup-annotated data (5\\textperthousand). The code is available at\n\\href{https://github.com/pipixiapipi/ICAF}{https://github.com/pipixiapipi/ICAF}.", "AI": {"tldr": "Proposes ICAF framework for semi-supervised semantic segmentation of CdZnTe semiconductor images with many-to-one view relationships, achieving 70.6% mIoU with only 0.5% annotated data.", "motivation": "Standard semi-supervised segmentation methods fail for CdZnTe images due to many-to-one view relationships (multiple views share single ground truth) and low-contrast defect boundaries, causing error accumulation and confirmation bias.", "method": "Intra-group Consistency Augmentation Framework (ICAF) with Pseudo-label Correction Network (PCN) containing View Augmentation Module (VAM) for boundary-aware view synthesis and View Correction Module (VCM) for information interaction between views.", "result": "Achieves 70.6% mIoU on CdZnTe dataset using only 2 group-annotated data (0.5%) with DeepLabV3+ and ResNet-101 backbone, significantly outperforming traditional methods.", "conclusion": "The group-oriented approach effectively addresses many-to-one view relationships in CdZnTe segmentation, providing robust performance with minimal annotation through intra-group consistency constraints and boundary-aware view synthesis."}}
{"id": "2508.13148", "pdf": "https://arxiv.org/pdf/2508.13148", "abs": "https://arxiv.org/abs/2508.13148", "authors": ["Haoyu He", "Katrin Renz", "Yong Cao", "Andreas Geiger"], "title": "MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion language models, as a promising alternative to traditional\nautoregressive (AR) models, enable faster generation and richer conditioning on\nbidirectional context. However, they suffer from a key discrepancy between\ntraining and inference: during inference, MDLMs progressively reveal the\nstructure of the generated sequence by producing fewer and fewer masked tokens,\nwhereas this structure is ignored in training as tokens are masked at random.\nAlthough this discrepancy between training and inference can lead to suboptimal\nperformance, it has been largely overlooked by previous works, leaving closing\nthis gap between the two stages an open problem. To address this, we frame the\nproblem of learning effective denoising trajectories as a sequential\ndecision-making problem and use the resulting framework to apply reinforcement\nlearning. We propose a novel Masked Diffusion Policy Optimization (MDPO) to\nexploit the Markov property diffusion possesses and explicitly train the model\nunder the same progressive refining schedule used at inference. MDPO matches\nthe performance of the previous state-of-the-art (SOTA) method with 60x fewer\ngradient updates, while achieving average improvements of 9.6% on MATH500 and\n54.2% on Countdown over SOTA when trained within the same number of weight\nupdates. Additionally, we improve the remasking strategy of MDLMs as a plug-in\ninference replacement to overcome the limitation that the model cannot refine\ntokens flexibly. This simple yet effective training-free strategy, what we\nrefer to as RCR, consistently improves performance and yields additional gains\nwhen combined with MDPO. Our findings establish great potential for\ninvestigating the discrepancy between pre-training and inference of MDLMs.\nCode: https://github.com/autonomousvision/mdpo. Project Page:\nhttps://cli212.github.io/MDPO/.", "AI": {"tldr": "MDPO addresses training-inference discrepancy in masked diffusion language models using reinforcement learning and progressive refining, achieving 60x faster training and significant performance improvements on MATH500 and Countdown tasks.", "motivation": "Diffusion language models suffer from a key discrepancy between training (random masking) and inference (progressive revealing of structure), leading to suboptimal performance that previous works have overlooked.", "method": "Proposed Masked Diffusion Policy Optimization (MDPO) that frames denoising trajectories as sequential decision-making using reinforcement learning, explicitly training under the same progressive refining schedule used at inference. Also improved remasking strategy (RCR) as a plug-in inference replacement.", "result": "MDPO matches previous SOTA performance with 60x fewer gradient updates, achieves 9.6% improvement on MATH500 and 54.2% on Countdown over SOTA with same update budget. RCR strategy provides consistent performance improvements and additional gains when combined with MDPO.", "conclusion": "The work establishes great potential for investigating the discrepancy between pre-training and inference of masked diffusion language models, with MDPO and RCR providing effective solutions for improved training efficiency and performance."}}
{"id": "2508.11872", "pdf": "https://arxiv.org/pdf/2508.11872", "abs": "https://arxiv.org/abs/2508.11872", "authors": ["Xinxing Wu"], "title": "Singing Syllabi with Virtual Avatars: Enhancing Student Engagement Through AI-Generated Music and Digital Embodiment", "categories": ["cs.CY", "cs.AI", "cs.LG", "cs.MM"], "comment": "17 pages, 4 figures, 3 tables", "summary": "In practical teaching, we observe that few students thoroughly read or fully\ncomprehend the information provided in traditional, text-based course syllabi.\nAs a result, essential details, such as course policies and learning outcomes,\nare frequently overlooked. To address this challenge, in this paper, we propose\na novel approach leveraging AI-generated singing and virtual avatars to present\nsyllabi in a format that is more visually appealing, engaging, and memorable.\nEspecially, we leveraged the open-source tool, HeyGem, to transform textual\nsyllabi into audiovisual presentations, in which digital avatars perform the\nsyllabus content as songs. The proposed approach aims to stimulate students'\ncuriosity, foster emotional connection, and enhance retention of critical\ncourse information. Student feedback indicated that AI-sung syllabi\nsignificantly improved awareness and recall of key course information.", "AI": {"tldr": "AI-generated singing avatars transform text-based course syllabi into engaging audiovisual presentations to improve student engagement and information retention.", "motivation": "Traditional text-based syllabi are often overlooked by students, leading to missed critical course information like policies and learning outcomes.", "method": "Leveraged open-source tool HeyGem to convert textual syllabi into audiovisual presentations where digital avatars sing the syllabus content.", "result": "Student feedback showed AI-sung syllabi significantly improved awareness and recall of key course information.", "conclusion": "AI-generated singing avatars present an effective approach to make course syllabi more engaging and memorable for students."}}
{"id": "2508.12777", "pdf": "https://arxiv.org/pdf/2508.12777", "abs": "https://arxiv.org/abs/2508.12777", "authors": ["Wenguang Tao", "Xiaotian Wang", "Tian Yan", "Jie Yan", "Guodong Li", "Kun Bai"], "title": "SocialTrack: Multi-Object Tracking in Complex Urban Traffic Scenes Inspired by Social Behavior", "categories": ["cs.CV"], "comment": null, "summary": "As a key research direction in the field of multi-object tracking (MOT),\nUAV-based multi-object tracking has significant application value in the\nanalysis and understanding of urban intelligent transportation systems.\nHowever, in complex UAV perspectives, challenges such as small target scale\nvariations, occlusions, nonlinear crossing motions, and motion blur severely\nhinder the stability of multi-object tracking. To address these challenges,\nthis paper proposes a novel multi-object tracking framework, SocialTrack, aimed\nat enhancing the tracking accuracy and robustness of small targets in complex\nurban traffic environments. The specialized small-target detector enhances the\ndetection performance by employing a multi-scale feature enhancement mechanism.\nThe Velocity Adaptive Cubature Kalman Filter (VACKF) improves the accuracy of\ntrajectory prediction by incorporating a velocity dynamic modeling mechanism.\nThe Group Motion Compensation Strategy (GMCS) models social group motion priors\nto provide stable state update references for low-quality tracks, significantly\nimproving the target association accuracy in complex dynamic environments.\nFurthermore, the Spatio-Temporal Memory Prediction (STMP) leverages historical\ntrajectory information to predict the future state of low-quality tracks,\neffectively mitigating identity switching issues. Extensive experiments on the\nUAVDT and MOT17 datasets demonstrate that SocialTrack outperforms existing\nstate-of-the-art (SOTA) methods across several key metrics. Significant\nimprovements in MOTA and IDF1, among other core performance indicators,\nhighlight its superior robustness and adaptability. Additionally, SocialTrack\nis highly modular and compatible, allowing for seamless integration with\nexisting trackers to further enhance performance.", "AI": {"tldr": "SocialTrack is a novel UAV-based multi-object tracking framework that addresses challenges like small target variations, occlusions, and motion blur in complex urban environments through specialized detection, adaptive filtering, group motion modeling, and spatio-temporal memory prediction.", "motivation": "UAV-based multi-object tracking has significant value for urban intelligent transportation systems, but faces challenges including small target scale variations, occlusions, nonlinear crossing motions, and motion blur that hinder tracking stability in complex UAV perspectives.", "method": "Proposes SocialTrack framework with: 1) specialized small-target detector with multi-scale feature enhancement, 2) Velocity Adaptive Cubature Kalman Filter for trajectory prediction, 3) Group Motion Compensation Strategy for social group motion modeling, and 4) Spatio-Temporal Memory Prediction using historical trajectory information.", "result": "Extensive experiments on UAVDT and MOT17 datasets show SocialTrack outperforms state-of-the-art methods across key metrics, with significant improvements in MOTA and IDF1 performance indicators, demonstrating superior robustness and adaptability.", "conclusion": "SocialTrack effectively addresses UAV-based tracking challenges in complex urban environments and is highly modular and compatible, allowing seamless integration with existing trackers to further enhance performance."}}
{"id": "2508.13142", "pdf": "https://arxiv.org/pdf/2508.13142", "abs": "https://arxiv.org/abs/2508.13142", "authors": ["Zhongang Cai", "Yubo Wang", "Qingping Sun", "Ruisi Wang", "Chenyang Gu", "Wanqi Yin", "Zhiqian Lin", "Zhitao Yang", "Chen Wei", "Xuanke Shi", "Kewang Deng", "Xiaoyang Han", "Zukai Chen", "Jiaqi Li", "Xiangyu Fan", "Hanming Deng", "Lewei Lu", "Bo Li", "Ziwei Liu", "Quan Wang", "Dahua Lin", "Lei Yang"], "title": "Has GPT-5 Achieved Spatial Intelligence? An Empirical Study", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.MM", "cs.RO"], "comment": null, "summary": "Multi-modal models have achieved remarkable progress in recent years.\nNevertheless, they continue to exhibit notable limitations in spatial\nunderstanding and reasoning, which are fundamental capabilities to achieving\nartificial general intelligence. With the recent release of GPT-5, allegedly\nthe most powerful AI model to date, it is timely to examine where the leading\nmodels stand on the path toward spatial intelligence. First, we propose a\ncomprehensive taxonomy of spatial tasks that unifies existing benchmarks and\ndiscuss the challenges in ensuring fair evaluation. We then evaluate\nstate-of-the-art proprietary and open-source models on eight key benchmarks, at\na cost exceeding one billion total tokens. Our empirical study reveals that (1)\nGPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2)\nstill falls short of human performance across a broad spectrum of tasks.\nMoreover, we (3) identify the more challenging spatial intelligence problems\nfor multi-modal models, and (4) proprietary models do not exhibit a decisive\nadvantage when facing the most difficult problems. In addition, we conduct a\nqualitative evaluation across a diverse set of scenarios that are intuitive for\nhumans yet fail even the most advanced multi-modal models.", "AI": {"tldr": "GPT-5 shows unprecedented spatial intelligence capabilities but still falls short of human performance across various spatial reasoning tasks, with proprietary models not having decisive advantages on the most difficult problems.", "motivation": "Multi-modal models have limitations in spatial understanding and reasoning, which are fundamental for artificial general intelligence. With GPT-5's release, it's timely to evaluate leading models' progress toward spatial intelligence.", "method": "Proposed a comprehensive taxonomy of spatial tasks unifying existing benchmarks, evaluated state-of-the-art proprietary and open-source models on eight key benchmarks using over one billion total tokens, and conducted qualitative evaluation on diverse scenarios.", "result": "GPT-5 demonstrates unprecedented strength in spatial intelligence but still falls short of human performance across broad spectrum of tasks. Proprietary models don't show decisive advantage on most difficult problems. Identified challenging spatial intelligence problems for multi-modal models.", "conclusion": "While GPT-5 represents significant progress in spatial intelligence, current multi-modal models still struggle with spatial reasoning tasks that are intuitive for humans, indicating substantial room for improvement in this critical capability for AGI."}}
{"id": "2508.09395", "pdf": "https://arxiv.org/pdf/2508.09395", "abs": "https://arxiv.org/abs/2508.09395", "authors": ["Quentin Ploussard", "Xiang Li", "Matija Pavi\u010devi\u0107"], "title": "Tightening the mixed integer linear formulation for the piecewise linear approximation in general dimensions", "categories": ["math.OC", "cs.CG", "cs.DM", "cs.LG"], "comment": "Added Acknowledgements and U.S. Government license disclaimer", "summary": "This paper addresses the problem of tightening the mixed-integer linear\nprogramming (MILP) formulation for continuous piecewise linear (CPWL)\napproximations of data sets in arbitrary dimensions. The MILP formulation\nleverages the difference-of-convex (DC) representation of CPWL functions. We\nintroduce the concept of well-behaved CPWL interpolations and demonstrate that\nany CPWL interpolation of a data set has a well-behaved version. This result is\ncritical to tighten the MILP problem. We present six different strategies to\ntighten the problem, which include fixing the values of some variables,\nintroducing additional constraints, identifying small big-M parameter values\nand applying tighter variable bounds. These methods leverage key aspects of the\nDC representation and the inherent structure of well-behaved CPWL\ninterpolations. Experimental results demonstrate that specific combinations of\nthese tightening strategies lead to significant improvement in solution times,\nespecially for tightening strategies that consider well-behaved CPWL solutions.", "AI": {"tldr": "This paper presents methods to tighten MILP formulations for continuous piecewise linear approximations using difference-of-convex representations and well-behaved interpolations, showing significant improvements in solution times.", "motivation": "To improve the efficiency of solving mixed-integer linear programming problems for continuous piecewise linear approximations by tightening the formulation through better mathematical representations and constraints.", "method": "Introduces well-behaved CPWL interpolations concept and six tightening strategies including variable fixing, additional constraints, optimized big-M parameters, and tighter variable bounds leveraging DC representation properties.", "result": "Experimental results show that specific combinations of tightening strategies lead to significant improvements in solution times, particularly those considering well-behaved CPWL solutions.", "conclusion": "The proposed tightening methods based on well-behaved CPWL interpolations and DC representations effectively improve MILP solution efficiency for piecewise linear approximation problems."}}
{"id": "2508.11873", "pdf": "https://arxiv.org/pdf/2508.11873", "abs": "https://arxiv.org/abs/2508.11873", "authors": ["Truong Thanh Hung Nguyen", "Tran Diem Quynh Nguyen", "Hoang Loc Cao", "Thi Cam Thanh Tran", "Thi Cam Mai Truong", "Hung Cao"], "title": "SimInterview: Transforming Business Education through Large Language Model-Based Simulated Multilingual Interview Training System", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.MM"], "comment": "Published as a conference paper at ICEFM 2025", "summary": "Business interview preparation demands both solid theoretical grounding and\nrefined soft skills, yet conventional classroom methods rarely deliver the\nindividualized, culturally aware practice employers currently expect. This\npaper introduces SimInterview, a large language model (LLM)-based simulated\nmultilingual interview training system designed for business professionals\nentering the AI-transformed labor market. Our system leverages an LLM agent and\nsynthetic AI technologies to create realistic virtual recruiters capable of\nconducting personalized, real-time conversational interviews. The framework\ndynamically adapts interview scenarios using retrieval-augmented generation\n(RAG) to match individual resumes with specific job requirements across\nmultiple languages. Built on LLMs (OpenAI o3, Llama 4 Maverick, Gemma 3),\nintegrated with Whisper speech recognition, GPT-SoVITS voice synthesis, Ditto\ndiffusion-based talking head generation model, and ChromaDB vector databases,\nour system significantly improves interview readiness across English and\nJapanese markets. Experiments with university-level candidates show that the\nsystem consistently aligns its assessments with job requirements, faithfully\npreserves resume content, and earns high satisfaction ratings, with the\nlightweight Gemma 3 model producing the most engaging conversations.\nQualitative findings revealed that the standardized Japanese resume format\nimproved document retrieval while diverse English resumes introduced additional\nvariability, and they highlighted how cultural norms shape follow-up\nquestioning strategies. Finally, we also outlined a contestable AI design that\ncan explain, detect bias, and preserve human-in-the-loop to meet emerging\nregulatory expectations.", "AI": {"tldr": "SimInterview is an LLM-based multilingual interview training system that uses AI technologies to create realistic virtual recruiters, adapting interviews to individual resumes and job requirements across languages, showing improved interview readiness and cultural adaptation.", "motivation": "Business interview preparation requires both theoretical knowledge and soft skills, but traditional classroom methods fail to provide individualized, culturally aware practice that modern employers expect in the AI-transformed labor market.", "method": "Leverages LLM agents and synthetic AI technologies with retrieval-augmented generation (RAG) to create virtual recruiters. Built on multiple LLMs (OpenAI o3, Llama 4 Maverick, Gemma 3) integrated with Whisper speech recognition, GPT-SoVITS voice synthesis, Ditto talking head generation, and ChromaDB vector databases for multilingual interview simulations.", "result": "System consistently aligns assessments with job requirements, preserves resume content accurately, and earns high satisfaction ratings. Gemma 3 produced most engaging conversations. Japanese standardized resumes improved document retrieval while diverse English formats introduced variability. Cultural norms influenced follow-up questioning strategies.", "conclusion": "The system significantly improves interview readiness across English and Japanese markets. The paper also outlines a contestable AI design that can explain decisions, detect bias, and preserve human oversight to meet emerging regulatory requirements."}}
{"id": "2508.12784", "pdf": "https://arxiv.org/pdf/2508.12784", "abs": "https://arxiv.org/abs/2508.12784", "authors": ["Dan Ruta", "Abdelaziz Djelouah", "Raphael Ortiz", "Christopher Schroers"], "title": "Leveraging Diffusion Models for Stylization using Multiple Style Images", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in latent diffusion models have enabled exciting progress in\nimage style transfer. However, several key issues remain. For example, existing\nmethods still struggle to accurately match styles. They are often limited in\nthe number of style images that can be used. Furthermore, they tend to entangle\ncontent and style in undesired ways. To address this, we propose leveraging\nmultiple style images which helps better represent style features and prevent\ncontent leaking from the style images. We design a method that leverages both\nimage prompt adapters and statistical alignment of the features during the\ndenoising process. With this, our approach is designed such that it can\nintervene both at the cross-attention and the self-attention layers of the\ndenoising UNet. For the statistical alignment, we employ clustering to distill\na small representative set of attention features from the large number of\nattention values extracted from the style samples. As demonstrated in our\nexperimental section, the resulting method achieves state-of-the-art results\nfor stylization.", "AI": {"tldr": "A novel image style transfer method using multiple style images with image prompt adapters and statistical feature alignment during denoising to prevent content leakage and improve style matching.", "motivation": "Existing latent diffusion models for style transfer struggle with accurate style matching, limited style image usage, and content-style entanglement issues.", "method": "Leverages multiple style images with image prompt adapters and statistical alignment of features during denoising process, intervening at both cross-attention and self-attention layers of the UNet, using clustering to distill representative attention features.", "result": "Achieves state-of-the-art results for stylization as demonstrated in experimental evaluations.", "conclusion": "The proposed approach effectively addresses key limitations in current style transfer methods by using multiple style references and strategic feature alignment during diffusion."}}
{"id": "2508.11874", "pdf": "https://arxiv.org/pdf/2508.11874", "abs": "https://arxiv.org/abs/2508.11874", "authors": ["Hanyu Li", "Dongchen Li", "Xiaotie Deng"], "title": "Discovering Expert-Level Nash Equilibrium Algorithms with Large Language Models", "categories": ["cs.GT", "cs.AI", "cs.DS", "cs.LO", "cs.PL"], "comment": null, "summary": "Algorithm design and analysis is a cornerstone of computer science, but it\nconfronts a major challenge. Proving an algorithm's performance guarantee\nacross all inputs has traditionally required extensive and often error-prone\nhuman effort. While AI has shown great success in finding solutions to specific\nproblem instances, automating the discovery of general algorithms with such\nprovable guarantees has remained a significant barrier. This challenge stems\nfrom the difficulty of integrating the creative process of algorithm design\nwith the rigorous process of formal analysis. To address this gap, we propose\nLegoNE, a framework that tightly fuses these two processes for the fundamental\nand notoriously difficult problem of computing approximate Nash equilibria.\nLegoNE automatically translates any algorithm written by a simple Python-like\nlanguage into a constrained optimization problem. Solving this problem derives\nand proves the algorithm's approximation bound. Using LegoNE, a\nstate-of-the-art large language model rediscovered the state-of-the-art\nalgorithm for two-player games within hours, a feat that had taken human\nresearchers 15 years to achieve. For three-player games, the model discovered a\nnovel algorithm surpassing all existing human-designed ones. This work\ndemonstrates a new human-machine collaborative paradigm for theoretical\nscience: humans reason at a higher-abstract level, using symbols to compress\nthe search space, and AI explores within it, achieving what neither could\nalone.", "AI": {"tldr": "LegoNE is a framework that automates algorithm design and formal analysis by translating algorithms into constrained optimization problems to derive and prove approximation bounds, enabling AI to rediscover state-of-the-art algorithms and discover novel ones.", "motivation": "Traditional algorithm design requires extensive human effort for proving performance guarantees, and while AI excels at solving specific instances, automating the discovery of general algorithms with provable guarantees has remained challenging due to the difficulty of integrating creative design with rigorous analysis.", "method": "LegoNE framework translates algorithms written in a simple Python-like language into constrained optimization problems, which when solved, automatically derive and prove the algorithm's approximation bound for computing approximate Nash equilibria.", "result": "Using LegoNE, a large language model rediscovered the state-of-the-art algorithm for two-player games within hours (which took humans 15 years) and discovered a novel algorithm for three-player games that surpasses all existing human-designed ones.", "conclusion": "This work demonstrates a new human-machine collaborative paradigm where humans reason at abstract levels using symbols to compress search spaces, and AI explores within them, achieving what neither could accomplish alone in theoretical science."}}
{"id": "2508.12794", "pdf": "https://arxiv.org/pdf/2508.12794", "abs": "https://arxiv.org/abs/2508.12794", "authors": ["Kyriaki", "Kokka", "Rahul Goel", "Ali Abbas", "Kerry A. Nice", "Luca Martial", "SM Labib", "Rihuan Ke", "Carola Bibiane Sch\u00f6nlieb", "James Woodcock"], "title": "Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Transportation influence health by shaping exposure to physical activity, air\npollution and injury risk.Comparative data on cycling and motorcycling\nbehaviours is scarce, particularly at a global scale.Street view imagery, such\nas Google Street View (GSV), combined with computer vision, is a valuable\nresource for efficiently capturing travel behaviour data.This study\ndemonstrates a novel approach using deep learning on street view images to\nestimate cycling and motorcycling levels across diverse cities worldwide.We\nutilized data from 185 global cities.The data on mode shares of cycling and\nmotorcycling estimated using travel surveys or censuses.We used GSV images to\ndetect cycles and motorcycles in sampled locations, using 8000 images per\ncity.The YOLOv4 model, fine-tuned using images from six cities, achieved a mean\naverage precision of 89% for detecting cycles and motorcycles in GSV images.A\nglobal prediction model was developed using beta regression with city-level\nmode shares as outcome, with log transformed explanatory variables of counts of\nGSV-detected images with cycles and motorcycles, while controlling for\npopulation density.We found strong correlations between GSV motorcycle counts\nand motorcycle mode share (0.78) and moderate correlations between GSV cycle\ncounts and cycling mode share (0.51).Beta regression models predicted mode\nshares with $R^2$ values of 0.614 for cycling and 0.612 for motorcycling,\nachieving median absolute errors (MDAE) of 1.3% and 1.4%,\nrespectively.Scatterplots demonstrated consistent prediction accuracy, though\ncities like Utrecht and Cali were outliers.The model was applied to 60 cities\nglobally for which we didn't have recent mode share data.We provided estimates\nfor some cities in the Middle East, Latin America and East Asia.With computer\nvision, GSV images capture travel modes and activity, providing insights\nalongside traditional data sources.", "AI": {"tldr": "Using deep learning on Google Street View images to estimate global cycling and motorcycling levels with 89% detection accuracy and strong correlation to actual mode shares.", "motivation": "Transportation impacts health through physical activity, pollution, and injury risks, but comparative global data on cycling and motorcycling behaviors is scarce. Street view imagery combined with computer vision offers efficient data collection.", "method": "Used YOLOv4 model fine-tuned on images from 6 cities to detect cycles and motorcycles in 8000 GSV images per city across 185 global cities. Developed beta regression models with city-level mode shares as outcome and GSV-detected counts as explanatory variables.", "result": "Achieved 89% mean average precision for detection. Strong correlation between GSV motorcycle counts and mode share (0.78), moderate for cycling (0.51). Beta regression models predicted mode shares with R\u00b2 of 0.614 for cycling and 0.612 for motorcycling, with median absolute errors of 1.3% and 1.4% respectively.", "conclusion": "GSV imagery combined with computer vision effectively captures travel modes and provides valuable insights alongside traditional data sources, enabling global estimation of cycling and motorcycling behaviors where survey data is unavailable."}}
{"id": "2508.11644", "pdf": "https://arxiv.org/pdf/2508.11644", "abs": "https://arxiv.org/abs/2508.11644", "authors": ["Zhichao Deng", "Zhikun Liu", "Junxue Wang", "Shengqian Chen", "Xiang Wei", "Qiang Yu"], "title": "HetSyn: Versatile Timescale Integration in Spiking Neural Networks via Heterogeneous Synapses", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Spiking Neural Networks (SNNs) offer a biologically plausible and\nenergy-efficient framework for temporal information processing. However,\nexisting studies overlook a fundamental property widely observed in biological\nneurons-synaptic heterogeneity, which plays a crucial role in temporal\nprocessing and cognitive capabilities. To bridge this gap, we introduce HetSyn,\na generalized framework that models synaptic heterogeneity with\nsynapse-specific time constants. This design shifts temporal integration from\nthe membrane potential to the synaptic current, enabling versatile timescale\nintegration and allowing the model to capture diverse synaptic dynamics. We\nimplement HetSyn as HetSynLIF, an extended form of the leaky integrate-and-fire\n(LIF) model equipped with synapse-specific decay dynamics. By adjusting the\nparameter configuration, HetSynLIF can be specialized into vanilla LIF neurons,\nneurons with threshold adaptation, and neuron-level heterogeneous models. We\ndemonstrate that HetSynLIF not only improves the performance of SNNs across a\nvariety of tasks-including pattern generation, delayed match-to-sample, speech\nrecognition, and visual recognition-but also exhibits strong robustness to\nnoise, enhanced working memory performance, efficiency under limited neuron\nresources, and generalization across timescales. In addition, analysis of the\nlearned synaptic time constants reveals trends consistent with empirical\nobservations in biological synapses. These findings underscore the significance\nof synaptic heterogeneity in enabling efficient neural computation, offering\nnew insights into brain-inspired temporal modeling.", "AI": {"tldr": "HetSyn introduces synaptic heterogeneity with synapse-specific time constants to Spiking Neural Networks, improving performance across various tasks while maintaining biological plausibility.", "motivation": "Existing SNN studies overlook synaptic heterogeneity, a fundamental biological property crucial for temporal processing and cognitive capabilities.", "method": "Developed HetSyn framework with synapse-specific time constants, implemented as HetSynLIF - an extended LIF model that shifts temporal integration to synaptic current.", "result": "HetSynLIF improves SNN performance across pattern generation, delayed match-to-sample, speech/visual recognition tasks, shows strong noise robustness, enhanced working memory, efficiency with limited neurons, and generalization across timescales.", "conclusion": "Synaptic heterogeneity is significant for efficient neural computation, with learned time constants matching biological observations, offering new insights for brain-inspired temporal modeling."}}
{"id": "2508.12802", "pdf": "https://arxiv.org/pdf/2508.12802", "abs": "https://arxiv.org/abs/2508.12802", "authors": ["\u0160tefan Parimucha", "Maksim Gabdeev", "Yanna Markus", "Martin Va\u0148ko", "Pavol Gajdo\u0161"], "title": "Morphological classification of eclipsing binary stars using computer vision methods", "categories": ["cs.CV", "astro-ph.IM", "astro-ph.SR", "I.5.1; J.2"], "comment": "19 pages, 4 figures, 4 tables", "summary": "We present an application of computer vision methods to classify the light\ncurves of eclipsing binaries (EB). We have used pre-trained models based on\nconvolutional neural networks ($\\textit{ResNet50}$) and vision transformers\n($\\textit{vit\\_base\\_patch16\\_224}$), which were fine-tuned on images created\nfrom synthetic datasets. To improve model generalisation and reduce\noverfitting, we developed a novel image representation by transforming\nphase-folded light curves into polar coordinates combined with hexbin\nvisualisation. Our hierarchical approach in the first stage classifies systems\ninto detached and overcontact types, and in the second stage identifies the\npresence or absence of spots. The binary classification models achieved high\naccuracy ($>96\\%$) on validation data across multiple passbands (Gaia~$G$, $I$,\nand $TESS$) and demonstrated strong performance ($>94\\%$, up to $100\\%$ for\n$TESS$) when tested on extensive observational data from the OGLE, DEBCat, and\nWUMaCat catalogues. While the primary binary classification was highly\nsuccessful, the secondary task of automated spot detection performed poorly,\nrevealing a significant limitation of our models for identifying subtle\nphotometric features. This study highlights the potential of computer vision\nfor EB morphological classification in large-scale surveys, but underscores the\nneed for further research into robust, automated spot detection.", "AI": {"tldr": "Computer vision models using ResNet50 and vision transformers achieve >96% accuracy for classifying eclipsing binary types but perform poorly on automated spot detection.", "motivation": "To apply computer vision methods for automated classification of eclipsing binary light curves in large-scale astronomical surveys, addressing the need for efficient morphological analysis of these systems.", "method": "Used pre-trained ResNet50 CNN and vision transformer models fine-tuned on synthetic datasets. Developed novel polar coordinate transformation with hexbin visualization of phase-folded light curves. Implemented hierarchical classification: first stage for detached/overcontact types, second stage for spot detection.", "result": "High accuracy (>96%) on validation data across Gaia G, I, and TESS passbands. Strong performance (>94%, up to 100% for TESS) on observational data from OGLE, DEBCat, and WUMaCat catalogues. Poor performance on automated spot detection.", "conclusion": "Computer vision shows great potential for eclipsing binary morphological classification in surveys, but current models are inadequate for detecting subtle photometric features like spots, requiring further research for robust automated spot detection."}}
{"id": "2508.11656", "pdf": "https://arxiv.org/pdf/2508.11656", "abs": "https://arxiv.org/abs/2508.11656", "authors": ["Ridma Jayasundara", "Ishan Fernando", "Adeepa Fernando", "Roshan Ragel", "Vajira Thambawita", "Isuru Nawinne"], "title": "Inductive transfer learning from regression to classification in ECG analysis", "categories": ["eess.SP", "cs.LG", "I.2.6; I.5.1; I.5.4; I.2.1; J.3"], "comment": "This manuscript is 15 pages with 4 tables and 5 figures. The\n  manuscript is under review at Nature Scientific Reports", "summary": "Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide,\naccounting for over 30% of global deaths according to the World Health\nOrganization (WHO). Importantly, one-third of these deaths are preventable with\ntimely and accurate diagnosis. The electrocardiogram (ECG), a non-invasive\nmethod for recording the electrical activity of the heart, is crucial for\ndiagnosing CVDs. However, privacy concerns surrounding the use of patient ECG\ndata in research have spurred interest in synthetic data, which preserves the\nstatistical properties of real data without compromising patient\nconfidentiality. This study explores the potential of synthetic ECG data for\ntraining deep learning models from regression to classification tasks and\nevaluates the feasibility of transfer learning to enhance classification\nperformance on real ECG data. We experimented with popular deep learning models\nto predict four key cardiac parameters, namely, Heart Rate (HR), PR interval,\nQT interval, and QRS complex-using separate regression models. Subsequently, we\nleveraged these regression models for transfer learning to perform 5-class ECG\nsignal classification. Our experiments systematically investigate whether\ntransfer learning from regression to classification is viable, enabling better\nutilization of diverse open-access and synthetic ECG datasets. Our findings\ndemonstrate that transfer learning from regression to classification improves\nclassification performance, highlighting its potential to maximize the utility\nof available data and advance deep learning applications in this domain.", "AI": {"tldr": "Transfer learning from regression to classification improves ECG classification performance using synthetic data, enabling better utilization of diverse datasets while preserving patient privacy.", "motivation": "Privacy concerns with patient ECG data drive need for synthetic alternatives. This study explores using synthetic ECG data for training deep learning models and evaluates transfer learning from regression to classification tasks to enhance performance on real ECG data.", "method": "Used popular deep learning models to predict four cardiac parameters (HR, PR interval, QT interval, QRS complex) with regression models, then leveraged these for transfer learning to perform 5-class ECG signal classification. Systematically investigated transfer learning viability from regression to classification.", "result": "Transfer learning from regression to classification improves classification performance, demonstrating its viability for better utilization of diverse open-access and synthetic ECG datasets.", "conclusion": "Transfer learning approach maximizes utility of available data and advances deep learning applications in ECG analysis, particularly valuable for privacy-preserving research using synthetic data."}}
{"id": "2508.11890", "pdf": "https://arxiv.org/pdf/2508.11890", "abs": "https://arxiv.org/abs/2508.11890", "authors": ["Sangwoo Jeon", "Juchul Shin", "YeonJe Cho", "Gyeong-Tae Kim", "Seongwoo Kim"], "title": "Integrating Symbolic RL Planning into a BDI-based Autonomous UAV Framework: System Integration and SIL Validation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Modern autonomous drone missions increasingly require software frameworks\ncapable of seamlessly integrating structured symbolic planning with adaptive\nreinforcement learning (RL). Although traditional rule-based architectures\noffer robust structured reasoning for drone autonomy, their capabilities fall\nshort in dynamically complex operational environments that require adaptive\nsymbolic planning. Symbolic RL (SRL), using the Planning Domain Definition\nLanguage (PDDL), explicitly integrates domain-specific knowledge and\noperational constraints, significantly improving the reliability and safety of\nunmanned aerial vehicle (UAV) decision making. In this study, we propose the\nAMAD-SRL framework, an extended and refined version of the Autonomous Mission\nAgents for Drones (AMAD) cognitive multi-agent architecture, enhanced with\nsymbolic reinforcement learning for dynamic mission planning and execution. We\nvalidated our framework in a Software-in-the-Loop (SIL) environment structured\nidentically to an intended Hardware-In-the-Loop Simulation (HILS) platform,\nensuring seamless transition to real hardware. Experimental results demonstrate\nstable integration and interoperability of modules, successful transitions\nbetween BDI-driven and symbolic RL-driven planning phases, and consistent\nmission performance. Specifically, we evaluate a target acquisition scenario in\nwhich the UAV plans a surveillance path followed by a dynamic reentry path to\nsecure the target while avoiding threat zones. In this SIL evaluation, mission\nefficiency improved by approximately 75% over a coverage-based baseline,\nmeasured by travel distance reduction. This study establishes a robust\nfoundation for handling complex UAV missions and discusses directions for\nfurther enhancement and validation.", "AI": {"tldr": "AMAD-SRL framework integrates symbolic planning with reinforcement learning for drone autonomy, improving mission efficiency by 75% in target acquisition scenarios through dynamic path planning and threat avoidance.", "motivation": "Modern drone missions require frameworks that combine structured symbolic planning with adaptive reinforcement learning to handle dynamically complex environments where traditional rule-based systems fall short.", "method": "Proposed AMAD-SRL framework extends AMAD cognitive multi-agent architecture with symbolic RL using PDDL, validated in Software-in-the-Loop environment with target acquisition scenario involving surveillance path planning and dynamic reentry path.", "result": "Stable module integration, successful transitions between planning phases, and 75% mission efficiency improvement over coverage-based baseline measured by travel distance reduction in SIL evaluation.", "conclusion": "The framework establishes a robust foundation for complex UAV missions and provides directions for further enhancement and validation, demonstrating reliable integration of symbolic planning with reinforcement learning."}}
{"id": "2508.12811", "pdf": "https://arxiv.org/pdf/2508.12811", "abs": "https://arxiv.org/abs/2508.12811", "authors": ["Yikai Wang", "Zhouxia Wang", "Zhonghua Wu", "Qingyi Tao", "Kang Liao", "Chen Change Loy"], "title": "Next Visual Granularity Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose a novel approach to image generation by decomposing an image into\na structured sequence, where each element in the sequence shares the same\nspatial resolution but differs in the number of unique tokens used, capturing\ndifferent level of visual granularity. Image generation is carried out through\nour newly introduced Next Visual Granularity (NVG) generation framework, which\ngenerates a visual granularity sequence beginning from an empty image and\nprogressively refines it, from global layout to fine details, in a structured\nmanner. This iterative process encodes a hierarchical, layered representation\nthat offers fine-grained control over the generation process across multiple\ngranularity levels. We train a series of NVG models for class-conditional image\ngeneration on the ImageNet dataset and observe clear scaling behavior. Compared\nto the VAR series, NVG consistently outperforms it in terms of FID scores (3.30\n-> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to\nshowcase the capability and potential of the NVG framework. Our code and models\nwill be released.", "AI": {"tldr": "NVG framework generates images through hierarchical visual granularity sequences, outperforming VAR models on ImageNet with improved FID scores.", "motivation": "To achieve fine-grained control over image generation by decomposing images into structured sequences with different visual granularity levels, enabling progressive refinement from global layout to fine details.", "method": "Proposes Next Visual Granularity (NVG) generation framework that starts from empty image and iteratively refines visual granularity sequences in a structured manner, training NVG models for class-conditional image generation on ImageNet.", "result": "NVG consistently outperforms VAR series in FID scores (3.30->3.03, 2.57->2.44, 2.09->2.06) and shows clear scaling behavior on ImageNet dataset.", "conclusion": "NVG framework successfully enables hierarchical image generation with fine-grained control across multiple granularity levels, demonstrating superior performance over existing methods."}}
{"id": "2508.11657", "pdf": "https://arxiv.org/pdf/2508.11657", "abs": "https://arxiv.org/abs/2508.11657", "authors": ["Yuanhao Li", "Badong Chen", "Wenjun Bai", "Yasuharu Koike", "Okito Yamashita"], "title": "Robust Sparse Bayesian Learning Based on Minimum Error Entropy for Noisy High-Dimensional Brain Activity Decoding", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Objective: Sparse Bayesian learning provides an effective scheme to solve the\nhigh-dimensional problem in brain signal decoding. However, traditional\nassumptions regarding data distributions such as Gaussian and binomial are\npotentially inadequate to characterize the noisy signals of brain activity.\nHence, this study aims to propose a robust sparse Bayesian learning framework\nto address noisy highdimensional brain activity decoding. Methods: Motivated by\nthe commendable robustness of the minimum error entropy (MEE) criterion for\nhandling complex data distributions, we proposed an MEE-based likelihood\nfunction to facilitate the accurate inference of sparse Bayesian learning in\nanalyzing noisy brain datasets. Results: Our proposed approach was evaluated\nusing two high-dimensional brain decoding tasks in regression and\nclassification contexts, respectively. The experimental results showed that,\nour approach can realize superior decoding metrics and physiological patterns\nthan the conventional and state-of-the-art methods. Conclusion: Utilizing the\nproposed MEE-based likelihood model, sparse Bayesian learning is empowered to\nsimultaneously address the challenges of noise and high dimensionality in the\nbrain decoding task. Significance: This work provides a powerful tool to\nrealize robust brain decoding, advancing biomedical engineering applications\nsuch as brain-computer interface.", "AI": {"tldr": "Robust sparse Bayesian learning framework using minimum error entropy criterion for noisy high-dimensional brain signal decoding", "motivation": "Traditional Gaussian/binomial distribution assumptions are inadequate for noisy brain signals, requiring a more robust approach to handle complex data distributions in brain activity decoding", "method": "Proposed MEE-based likelihood function to enhance sparse Bayesian learning inference for analyzing noisy brain datasets", "result": "Superior decoding metrics and physiological patterns compared to conventional and state-of-the-art methods in both regression and classification brain decoding tasks", "conclusion": "MEE-based likelihood model enables sparse Bayesian learning to simultaneously address noise and high dimensionality challenges in brain decoding"}}
{"id": "2508.11907", "pdf": "https://arxiv.org/pdf/2508.11907", "abs": "https://arxiv.org/abs/2508.11907", "authors": ["Xiaojin Zhang", "Mingcong Xu", "Yiming Li", "Wei Chen", "Qiang Yang"], "title": "Deciphering the Interplay between Attack and Protection Complexity in Privacy-Preserving Federated Learning", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Federated learning (FL) offers a promising paradigm for collaborative model\ntraining while preserving data privacy. However, its susceptibility to gradient\ninversion attacks poses a significant challenge, necessitating robust privacy\nprotection mechanisms. This paper introduces a novel theoretical framework to\ndecipher the intricate interplay between attack and protection complexities in\nprivacy-preserving FL. We formally define \"Attack Complexity\" as the minimum\ncomputational and data resources an adversary requires to reconstruct private\ndata below a given error threshold, and \"Protection Complexity\" as the expected\ndistortion introduced by privacy mechanisms. Leveraging Maximum Bayesian\nPrivacy (MBP), we derive tight theoretical bounds for protection complexity,\ndemonstrating its scaling with model dimensionality and privacy budget.\nFurthermore, we establish comprehensive bounds for attack complexity, revealing\nits dependence on privacy leakage, gradient distortion, model dimension, and\nthe chosen privacy level. Our findings quantitatively illuminate the\nfundamental trade-offs between privacy guarantees, system utility, and the\neffort required for both attacking and defending. This framework provides\ncritical insights for designing more secure and efficient federated learning\nsystems.", "AI": {"tldr": "A theoretical framework analyzing the trade-offs between attack and protection complexities in privacy-preserving federated learning, with formal definitions and bounds for both attack complexity (resources needed to reconstruct private data) and protection complexity (distortion from privacy mechanisms).", "motivation": "Federated learning's vulnerability to gradient inversion attacks requires robust privacy protection, but there's a need to understand the fundamental trade-offs between attack difficulty, protection effectiveness, and system utility.", "method": "Introduces Maximum Bayesian Privacy (MBP) framework to formally define and analyze attack complexity (minimum resources for data reconstruction) and protection complexity (expected distortion from privacy mechanisms), deriving tight theoretical bounds for both.", "result": "Established comprehensive bounds showing protection complexity scales with model dimensionality and privacy budget, while attack complexity depends on privacy leakage, gradient distortion, model dimension, and privacy level.", "conclusion": "The framework provides quantitative insights into privacy-utility trade-offs and offers critical guidance for designing more secure and efficient federated learning systems."}}
{"id": "2508.12813", "pdf": "https://arxiv.org/pdf/2508.12813", "abs": "https://arxiv.org/abs/2508.12813", "authors": ["Friedhelm Hamann", "Emil Mededovic", "Fabian G\u00fclhan", "Yuli Wu", "Johannes Stegmaier", "Jing He", "Yiqing Wang", "Kexin Zhang", "Lingling Li", "Licheng Jiao", "Mengru Ma", "Hongxiang Huang", "Yuhao Yan", "Hongwei Ren", "Xiaopeng Lin", "Yulong Huang", "Bojun Cheng", "Se Hyun Lee", "Gyu Sung Ham", "Kanghan Oh", "Gi Hyun Lim", "Boxuan Yang", "Bowen Du", "Guillermo Gallego"], "title": "SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop", "categories": ["cs.CV", "cs.LG"], "comment": "13 pages, 7 figures, 7 tables", "summary": "We present an overview of the Spatio-temporal Instance Segmentation (SIS)\nchallenge held in conjunction with the CVPR 2025 Event-based Vision Workshop.\nThe task is to predict accurate pixel-level segmentation masks of defined\nobject classes from spatio-temporally aligned event camera and grayscale camera\ndata. We provide an overview of the task, dataset, challenge details and\nresults. Furthermore, we describe the methods used by the top-5 ranking teams\nin the challenge. More resources and code of the participants' methods are\navailable here:\nhttps://github.com/tub-rip/MouseSIS/blob/main/docs/challenge_results.md", "AI": {"tldr": "Overview of the CVPR 2025 Spatio-temporal Instance Segmentation challenge for event-based vision, including task description, dataset, results, and top methods.", "motivation": "To advance research in spatio-temporal instance segmentation using event camera and grayscale camera data, providing a benchmark for evaluating methods that can handle dynamic visual data from neuromorphic sensors.", "method": "Organized a challenge with defined object classes, provided spatio-temporally aligned event and grayscale camera data, and evaluated participants' methods on pixel-level segmentation accuracy.", "result": "Presented challenge results and detailed descriptions of the top-5 ranking teams' approaches, with resources and code made publicly available.", "conclusion": "The challenge successfully benchmarked state-of-the-art methods for spatio-temporal instance segmentation in event-based vision, providing valuable insights and resources for future research in this emerging field."}}
{"id": "2508.12824", "pdf": "https://arxiv.org/pdf/2508.12824", "abs": "https://arxiv.org/abs/2508.12824", "authors": ["Shuang Chen", "Ronald Thenius", "Farshad Arvin", "Amir Atapour-Abarghouei"], "title": "DEEP-SEA: Deep-Learning Enhancement for Environmental Perception in Submerged Aquatics", "categories": ["cs.CV"], "comment": null, "summary": "Continuous and reliable underwater monitoring is essential for assessing\nmarine biodiversity, detecting ecological changes and supporting autonomous\nexploration in aquatic environments. Underwater monitoring platforms rely on\nmainly visual data for marine biodiversity analysis, ecological assessment and\nautonomous exploration. However, underwater environments present significant\nchallenges due to light scattering, absorption and turbidity, which degrade\nimage clarity and distort colour information, which makes accurate observation\ndifficult. To address these challenges, we propose DEEP-SEA, a novel deep\nlearning-based underwater image restoration model to enhance both low- and\nhigh-frequency information while preserving spatial structures. The proposed\nDual-Frequency Enhanced Self-Attention Spatial and Frequency Modulator aims to\nadaptively refine feature representations in frequency domains and\nsimultaneously spatial information for better structural preservation. Our\ncomprehensive experiments on EUVP and LSUI datasets demonstrate the superiority\nover the state of the art in restoring fine-grained image detail and structural\nconsistency. By effectively mitigating underwater visual degradation, DEEP-SEA\nhas the potential to improve the reliability of underwater monitoring platforms\nfor more accurate ecological observation, species identification and autonomous\nnavigation.", "AI": {"tldr": "DEEP-SEA is a deep learning model that restores underwater images by enhancing both low- and high-frequency information while preserving spatial structures, addressing challenges of light scattering and turbidity in marine environments.", "motivation": "Underwater environments suffer from light scattering, absorption and turbidity that degrade image clarity and distort color information, making accurate marine biodiversity monitoring and ecological assessment difficult.", "method": "Proposes DEEP-SEA with Dual-Frequency Enhanced Self-Attention Spatial and Frequency Modulator to adaptively refine feature representations in frequency domains while preserving spatial information for better structural preservation.", "result": "Comprehensive experiments on EUVP and LSUI datasets demonstrate superiority over state-of-the-art methods in restoring fine-grained image detail and structural consistency.", "conclusion": "DEEP-SEA effectively mitigates underwater visual degradation and has potential to improve reliability of underwater monitoring platforms for ecological observation, species identification and autonomous navigation."}}
{"id": "2508.11663", "pdf": "https://arxiv.org/pdf/2508.11663", "abs": "https://arxiv.org/abs/2508.11663", "authors": ["Guangli Li", "Canbiao Wu", "Zhen Liang"], "title": "Unsupervised Pairwise Learning Optimization Framework for Cross-Corpus EEG-Based Emotion Recognition Based on Prototype Representation", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Affective computing is a rapidly developing interdisciplinary research\ndirection in the field of brain-computer interface. In recent years, the\nintroduction of deep learning technology has greatly promoted the development\nof the field of emotion recognition. However, due to physiological differences\nbetween subjects, as well as the variations in experimental environments and\nequipment, cross-corpus emotion recognition faces serious challenges,\nespecially for samples near the decision boundary. To solve the above problems,\nwe propose an optimization method based on domain adversarial transfer learning\nto fine-grained alignment of affective features, named Maximum classifier\ndiscrepancy with Pairwise Learning (McdPL) framework. In McdPL, we design a\ndual adversarial classifier (Ada classifier and RMS classifier), and apply a\nthree-stage adversarial training to maximize classification discrepancy and\nminimize feature distribution to align controversy samples near the decision\nboundary. In the process of domain adversarial training, the two classifiers\nalso maintain an adversarial relationship, ultimately enabling precise\ncross-corpus feature alignment. In addition, the introduction of pairwise\nlearning transforms the classification problem of samples into a similarity\nproblem between samples, alleviating the influence of label noise. We conducted\nsystematic experimental evaluation of the model using publicly available SEED,\nSEED-IV and SEED-V databases. The results show that the McdPL model is superior\nto other baseline models in the cross-corpus emotion recognition task, and the\naverage accuracy improvements of 4.76\\% and 3.97\\%, respectively. Our work\nprovides a promising solution for emotion recognition cross-corpus. The source\ncode is available at https://github.com/WuCB-BCI/Mcd_PL.", "AI": {"tldr": "A novel domain adversarial transfer learning framework (McdPL) for cross-corpus emotion recognition that uses dual adversarial classifiers and pairwise learning to align controversial samples near decision boundaries and improve accuracy.", "motivation": "Cross-corpus emotion recognition faces challenges due to physiological differences between subjects, variations in experimental environments/equipment, and difficulties with samples near decision boundaries in affective computing.", "method": "Maximum classifier discrepancy with Pairwise Learning (McdPL) framework featuring dual adversarial classifiers (Ada and RMS), three-stage adversarial training to maximize classification discrepancy and minimize feature distribution, and pairwise learning to transform classification into similarity problems.", "result": "Superior performance compared to baseline models on SEED, SEED-IV and SEED-V databases with average accuracy improvements of 4.76% and 3.97% respectively in cross-corpus emotion recognition tasks.", "conclusion": "The McdPL model provides an effective solution for cross-corpus emotion recognition by enabling precise feature alignment and mitigating label noise influence, advancing affective computing in brain-computer interface applications."}}
{"id": "2508.12842", "pdf": "https://arxiv.org/pdf/2508.12842", "abs": "https://arxiv.org/abs/2508.12842", "authors": ["Ronghao Lin", "Sijie Mai", "Ying Zeng", "Qiaolin He", "Aolin Xiong", "Haifeng Hu"], "title": "Multi-source Multimodal Progressive Domain Adaption for Audio-Visual Deception Detection", "categories": ["cs.CV", "cs.MM"], "comment": "Accepted at ACM MM 2025 SVC Workshop", "summary": "This paper presents the winning approach for the 1st MultiModal Deception\nDetection (MMDD) Challenge at the 1st Workshop on Subtle Visual Computing\n(SVC). Aiming at the domain shift issue across source and target domains, we\npropose a Multi-source Multimodal Progressive Domain Adaptation (MMPDA)\nframework that transfers the audio-visual knowledge from diverse source domains\nto the target domain. By gradually aligning source and the target domain at\nboth feature and decision levels, our method bridges domain shifts across\ndiverse multimodal datasets. Extensive experiments demonstrate the\neffectiveness of our approach securing Top-2 place. Our approach reaches 60.43%\non accuracy and 56.99\\% on F1-score on competition stage 2, surpassing the 1st\nplace team by 5.59% on F1-score and the 3rd place teams by 6.75% on accuracy.\nOur code is available at https://github.com/RH-Lin/MMPDA.", "AI": {"tldr": "Winning approach for multimodal deception detection challenge using progressive domain adaptation to handle domain shift across diverse audio-visual datasets", "motivation": "Address domain shift issues across source and target domains in multimodal deception detection", "method": "Multi-source Multimodal Progressive Domain Adaptation (MMPDA) framework that gradually aligns source and target domains at feature and decision levels", "result": "Achieved Top-2 place with 60.43% accuracy and 56.99% F1-score, surpassing 1st place by 5.59% on F1-score and 3rd place by 6.75% on accuracy", "conclusion": "The proposed MMPDA framework effectively bridges domain shifts across diverse multimodal datasets for deception detection"}}
{"id": "2508.11664", "pdf": "https://arxiv.org/pdf/2508.11664", "abs": "https://arxiv.org/abs/2508.11664", "authors": ["Zahra Mohammadi", "Parnian Fazel", "Siamak Mohammadi"], "title": "Energy-Efficient Real-Time 4-Stage Sleep Classification at 10-Second Resolution: A Comprehensive Study", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Sleep stage classification is crucial for diagnosing and managing disorders\nsuch as sleep apnea and insomnia. Conventional clinical methods like\npolysomnography are costly and impractical for long-term home use. We present\nan energy-efficient pipeline that detects four sleep stages (wake, REM, light,\nand deep) from a single-lead ECG. Two windowing strategies are introduced: (1)\na 5-minute window with 30-second steps for machine-learning models that use\nhandcrafted features, and (2) a 30-second window with 10-second steps for\ndeep-learning models, enabling near-real-time 10-second resolution. Lightweight\nnetworks such as MobileNet-v1 reach 92 percent accuracy and 91 percent F1-score\nbut still draw significant energy. We therefore design SleepLiteCNN, a custom\nmodel that achieves 89 percent accuracy and 89 percent F1-score while lowering\nenergy use to 5.48 microjoules per inference at 45 nm. Applying eight-bit\nquantization preserves accuracy and further reduces power, and FPGA deployment\nconfirms low resource usage. The proposed system offers a practical solution\nfor continuous, wearable ECG-based sleep monitoring.", "AI": {"tldr": "Energy-efficient sleep stage classification from single-lead ECG using lightweight deep learning models and custom SleepLiteCNN architecture, achieving 89-92% accuracy with ultra-low power consumption for wearable applications.", "motivation": "Conventional polysomnography is costly and impractical for long-term home sleep monitoring, creating need for efficient ECG-based solutions that can enable continuous wearable sleep stage detection.", "method": "Two windowing strategies: 5-minute windows for ML models with handcrafted features, and 30-second windows for deep learning models. Developed custom SleepLiteCNN architecture optimized for energy efficiency, with 8-bit quantization and FPGA deployment validation.", "result": "MobileNet-v1 achieved 92% accuracy/91% F1-score but high energy. SleepLiteCNN reached 89% accuracy/89% F1-score with only 5.48 microjoules per inference at 45nm. Quantization preserved accuracy while further reducing power, with low FPGA resource usage.", "conclusion": "The proposed system provides a practical, energy-efficient solution for continuous wearable ECG-based sleep monitoring with near-real-time 10-second resolution, making long-term home sleep assessment feasible."}}
{"id": "2508.11929", "pdf": "https://arxiv.org/pdf/2508.11929", "abs": "https://arxiv.org/abs/2508.11929", "authors": ["Mohitvishnu S. Gadde", "Pranay Dugar", "Ashish Malik", "Alan Fern"], "title": "No More Blind Spots: Learning Vision-Based Omnidirectional Bipedal Locomotion for Challenging Terrain", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Effective bipedal locomotion in dynamic environments, such as cluttered\nindoor spaces or uneven terrain, requires agile and adaptive movement in all\ndirections. This necessitates omnidirectional terrain sensing and a controller\ncapable of processing such input. We present a learning framework for\nvision-based omnidirectional bipedal locomotion, enabling seamless movement\nusing depth images. A key challenge is the high computational cost of rendering\nomnidirectional depth images in simulation, making traditional sim-to-real\nreinforcement learning (RL) impractical. Our method combines a robust blind\ncontroller with a teacher policy that supervises a vision-based student policy,\ntrained on noise-augmented terrain data to avoid rendering costs during RL and\nensure robustness. We also introduce a data augmentation technique for\nsupervised student training, accelerating training by up to 10 times compared\nto conventional methods. Our framework is validated through simulation and\nreal-world tests, demonstrating effective omnidirectional locomotion with\nminimal reliance on expensive rendering. This is, to the best of our knowledge,\nthe first demonstration of vision-based omnidirectional bipedal locomotion,\nshowcasing its adaptability to diverse terrains.", "AI": {"tldr": "A learning framework for vision-based omnidirectional bipedal locomotion that avoids expensive omnidirectional depth rendering by combining a blind controller with teacher-student policy training and noise-augmented terrain data.", "motivation": "Effective bipedal locomotion in dynamic environments requires agile movement in all directions with omnidirectional terrain sensing, but traditional sim-to-real RL is impractical due to high computational costs of rendering omnidirectional depth images.", "method": "Combines robust blind controller with teacher policy supervising vision-based student policy, trained on noise-augmented terrain data to avoid rendering costs during RL. Introduces data augmentation technique for supervised student training.", "result": "Framework validated through simulation and real-world tests, demonstrating effective omnidirectional locomotion with minimal reliance on expensive rendering. Training accelerated by up to 10x compared to conventional methods.", "conclusion": "First demonstration of vision-based omnidirectional bipedal locomotion, showcasing adaptability to diverse terrains while overcoming computational challenges of omnidirectional depth rendering."}}
{"id": "2508.12861", "pdf": "https://arxiv.org/pdf/2508.12861", "abs": "https://arxiv.org/abs/2508.12861", "authors": ["Dexia Chen", "Wentao Zhang", "Qianjie Zhu", "Ping Hu", "Weibing Li", "Tong Zhang", "Ruixuan Wang"], "title": "Cross-Domain Few-Shot Learning via Multi-View Collaborative Optimization with Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) pre-trained on natural image and language data,\nsuch as CLIP, have exhibited significant potential in few-shot image\nrecognition tasks, leading to development of various efficient transfer\nlearning methods. These methods exploit inherent pre-learned knowledge in VLMs\nand have achieved strong performance on standard image datasets. However, their\neffectiveness is often limited when confronted with cross-domain tasks where\nimaging domains differ from natural images. To address this limitation, we\npropose Consistency-guided Multi-view Collaborative Optimization (CoMuCo), a\nnovel fine-tuning strategy for VLMs. This strategy employs two functionally\ncomplementary expert modules to extract multi-view features, while\nincorporating prior knowledge-based consistency constraints and information\ngeometry-based consensus mechanisms to enhance the robustness of feature\nlearning. Additionally, a new cross-domain few-shot benchmark is established to\nhelp comprehensively evaluate methods on imaging domains distinct from natural\nimages. Extensive empirical evaluations on both existing and newly proposed\nbenchmarks suggest CoMuCo consistently outperforms current methods in few-shot\ntasks. The code and benchmark will be released.", "AI": {"tldr": "CoMuCo is a novel fine-tuning strategy for vision-language models that uses multi-view feature extraction with consistency constraints to improve cross-domain few-shot performance.", "motivation": "Current VLM transfer learning methods perform well on standard image datasets but struggle with cross-domain tasks where imaging domains differ from natural images.", "method": "Uses two functionally complementary expert modules for multi-view feature extraction, incorporates prior knowledge-based consistency constraints and information geometry-based consensus mechanisms to enhance feature learning robustness.", "result": "Extensive evaluations show CoMuCo consistently outperforms current methods in few-shot tasks across both existing and newly proposed cross-domain benchmarks.", "conclusion": "The proposed CoMuCo strategy effectively addresses cross-domain limitations of VLMs and establishes a new benchmark for comprehensive evaluation of methods on imaging domains distinct from natural images."}}
{"id": "2508.11666", "pdf": "https://arxiv.org/pdf/2508.11666", "abs": "https://arxiv.org/abs/2508.11666", "authors": ["Timothy Oladunni", "Ehimen Aneni"], "title": "Explainable Deep Neural Network for Multimodal ECG Signals: Intermediate vs Late Fusion", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "The limitations of unimodal deep learning models, particularly their tendency\nto overfit and limited generalizability, have renewed interest in multimodal\nfusion strategies. Multimodal deep neural networks (MDNN) have the capability\nof integrating diverse data domains and offer a promising solution for robust\nand accurate predictions. However, the optimal fusion strategy, intermediate\nfusion (feature-level) versus late fusion (decision-level) remains\ninsufficiently examined, especially in high-stakes clinical contexts such as\nECG-based cardiovascular disease (CVD) classification. This study investigates\nthe comparative effectiveness of intermediate and late fusion strategies using\nECG signals across three domains: time, frequency, and time-frequency. A series\nof experiments were conducted to identify the highest-performing fusion\narchitecture. Results demonstrate that intermediate fusion consistently\noutperformed late fusion, achieving a peak accuracy of 97 percent, with Cohen's\nd > 0.8 relative to standalone models and d = 0.40 compared to late fusion.\nInterpretability analyses using saliency maps reveal that both models align\nwith the discretized ECG signals. Statistical dependency between the\ndiscretized ECG signals and corresponding saliency maps for each class was\nconfirmed using Mutual Information (MI). The proposed ECG domain-based\nmultimodal model offers superior predictive capability and enhanced\nexplainability, crucial attributes in medical AI applications, surpassing\nstate-of-the-art models.", "AI": {"tldr": "Intermediate fusion outperforms late fusion in ECG-based cardiovascular disease classification, achieving 97% accuracy with better interpretability through saliency maps and mutual information analysis.", "motivation": "Unimodal deep learning models have limitations in overfitting and generalizability, while optimal fusion strategies (intermediate vs late fusion) remain insufficiently examined in high-stakes clinical contexts like ECG-based CVD classification.", "method": "Comparative study of intermediate and late fusion strategies using ECG signals across time, frequency, and time-frequency domains. Experiments conducted to identify best fusion architecture, with interpretability analyses using saliency maps and mutual information.", "result": "Intermediate fusion consistently outperformed late fusion with peak accuracy of 97%, Cohen's d > 0.8 relative to standalone models and d = 0.40 compared to late fusion. Saliency maps showed alignment with discretized ECG signals, confirmed by mutual information analysis.", "conclusion": "The proposed ECG domain-based multimodal model offers superior predictive capability and enhanced explainability, making it crucial for medical AI applications and surpassing state-of-the-art models."}}
{"id": "2508.11935", "pdf": "https://arxiv.org/pdf/2508.11935", "abs": "https://arxiv.org/abs/2508.11935", "authors": ["Yuannuo Feng", "Wenyong Zhou", "Yuexi Lyu", "Hanjie Liu", "Zhengwu Liu", "Ngai Wong", "Wang Kang"], "title": "HPD: Hybrid Projection Decomposition for Robust State Space Models on Analog CIM Hardware", "categories": ["cs.AR", "cs.AI", "cs.LG"], "comment": "4 pages, 5 figures, conference", "summary": "State Space Models (SSMs) are efficient alternatives to traditional sequence\nmodels, excelling at processing long sequences with lower computational\ncomplexity. Their reliance on matrix multiplications makes them ideal for\ncompute-in-memory (CIM) architectures, which improve energy efficiency by\ncomputing within memory arrays. However, device non-idealities in CIM introduce\nweight perturbations that can degrade inference accuracy. In this paper, we\nsystematically analyze the robustness of SSMs under noisy conditions,\nidentifying that the final block and output projection layers are more\nsusceptible to perturbations compared to other components. Building on these\ninsights, we propose HPD, a Hybrid Projection Decomposition strategy for the\nlast output projection layer. We replace the original weight matrix with the\nmultiplication of U and {\\Sigma} in its SVD to ensure compatibility with\nexisting hardware architectures, while offloading V> to digital hardware for\nprecise and robust correction. Comprehensive tests on Mamba models show that\nour method reduces perplexity by up to 99.57% under various noise conditions\ncompared to baseline models, with accuracy gains of up to 96.67% on the PIQA\nbenchmark for commonsense reasoning.", "AI": {"tldr": "HPD method improves State Space Models' robustness to hardware noise by decomposing the output projection layer, achieving up to 99.57% perplexity reduction and 96.67% accuracy gains.", "motivation": "State Space Models are efficient for long sequences and suitable for compute-in-memory architectures, but device non-idealities cause weight perturbations that degrade inference accuracy.", "method": "Proposed HPD (Hybrid Projection Decomposition) that replaces the output projection weight matrix with U and \u03a3 from SVD, offloading V\u1d40 to digital hardware for precise correction while maintaining hardware compatibility.", "result": "Comprehensive tests on Mamba models show up to 99.57% perplexity reduction under various noise conditions and up to 96.67% accuracy improvement on PIQA benchmark compared to baseline models.", "conclusion": "The HPD strategy effectively enhances SSM robustness to hardware noise by identifying and protecting vulnerable components, particularly the output projection layer, through hybrid analog-digital decomposition."}}
{"id": "2508.12877", "pdf": "https://arxiv.org/pdf/2508.12877", "abs": "https://arxiv.org/abs/2508.12877", "authors": ["Dexia Chen", "Qianjie Zhu", "Weibing Li", "Yue Yu", "Tong Zhang", "Ruixuan Wang"], "title": "Preserve and Sculpt: Manifold-Aligned Fine-tuning of Vision-Language Models for Few-Shot Learning", "categories": ["cs.CV"], "comment": null, "summary": "Pretrained vision-language models (VLMs), such as CLIP, have shown remarkable\npotential in few-shot image classification and led to numerous effective\ntransfer learning strategies. These methods leverage the pretrained knowledge\nof VLMs to enable effective domain adaptation while mitigating overfitting\nthrough parameter-efficient tuning or instance-based consistency constraints.\nHowever, such regularizations often neglect the geometric structure of data\ndistribution, which may lead to distortion of the overall semantic\nrepresentation. To overcome this limitation, we propose a novel fine-tuning\nmethod, Manifold-Preserving and Sculpting Tuning (MPS-Tuning). Regarding the\ndata distribution in feature space as a semantic manifold, MPS-Tuning\nexplicitly constrains the intrinsic geometry of this manifold while further\nsculpting it to enhance class separability. Specifically, MPS-Tuning preserves\nboth macroscopic and microscopic topological structures of the original\nmanifold by aligning Gram matrices of features before and after fine-tuning.\nTheoretically, this constraint is shown to approximate an upper bound of the\nGromov-Wasserstein distance. Furthermore, features from the image and text\nmodalities are paired, and pairwise similarities are optimized to enhance the\nmanifold's class discriminability. Extensive experiments demonstrate that\nMPS-Tuning significantly improves model performance while effectively\npreserving the structure of the semantic manifold. The code will be released.", "AI": {"tldr": "MPS-Tuning is a novel fine-tuning method for vision-language models that preserves the geometric structure of data distribution while enhancing class separability through manifold preservation and sculpting.", "motivation": "Existing VLM fine-tuning methods neglect the geometric structure of data distribution, which can distort semantic representations. The authors aim to overcome this limitation by explicitly constraining the intrinsic geometry of the semantic manifold.", "method": "MPS-Tuning treats data distribution as a semantic manifold and preserves both macroscopic and microscopic topological structures by aligning Gram matrices of features before and after fine-tuning. It also optimizes pairwise similarities between image and text modalities to enhance class discriminability.", "result": "Extensive experiments demonstrate that MPS-Tuning significantly improves model performance while effectively preserving the structure of the semantic manifold.", "conclusion": "The proposed MPS-Tuning method successfully addresses the limitation of previous VLM fine-tuning approaches by maintaining geometric structure while enhancing classification performance through manifold preservation and sculpting techniques."}}
{"id": "2508.12880", "pdf": "https://arxiv.org/pdf/2508.12880", "abs": "https://arxiv.org/abs/2508.12880", "authors": ["Chubin Chen", "Jiashu Zhu", "Xiaokun Feng", "Nisha Huang", "Meiqi Wu", "Fangyuan Mao", "Jiahong Wu", "Xiangxiang Chu", "Xiu Li"], "title": "S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "Classifier-free Guidance (CFG) is a widely used technique in modern diffusion\nmodels for enhancing sample quality and prompt adherence. However, through an\nempirical analysis on Gaussian mixture modeling with a closed-form solution, we\nobserve a discrepancy between the suboptimal results produced by CFG and the\nground truth. The model's excessive reliance on these suboptimal predictions\noften leads to semantic incoherence and low-quality outputs. To address this\nissue, we first empirically demonstrate that the model's suboptimal predictions\ncan be effectively refined using sub-networks of the model itself. Building on\nthis insight, we propose S^2-Guidance, a novel method that leverages stochastic\nblock-dropping during the forward process to construct stochastic sub-networks,\neffectively guiding the model away from potential low-quality predictions and\ntoward high-quality outputs. Extensive qualitative and quantitative experiments\non text-to-image and text-to-video generation tasks demonstrate that\nS^2-Guidance delivers superior performance, consistently surpassing CFG and\nother advanced guidance strategies. Our code will be released.", "AI": {"tldr": "S^2-Guidance improves upon Classifier-free Guidance by using stochastic sub-networks to refine predictions and avoid low-quality outputs in diffusion models.", "motivation": "Classifier-free Guidance (CFG) produces suboptimal results with semantic incoherence and low-quality outputs due to excessive reliance on imperfect predictions.", "method": "Proposes S^2-Guidance which uses stochastic block-dropping during forward process to create stochastic sub-networks that guide the model away from low-quality predictions.", "result": "Extensive experiments on text-to-image and text-to-video generation show S^2-Guidance consistently outperforms CFG and other advanced guidance strategies.", "conclusion": "S^2-Guidance effectively addresses CFG's limitations by leveraging stochastic sub-networks to produce higher quality and more coherent outputs."}}
{"id": "2508.11957", "pdf": "https://arxiv.org/pdf/2508.11957", "abs": "https://arxiv.org/abs/2508.11957", "authors": ["Xiaodong Qu", "Andrews Damoah", "Joshua Sherwood", "Peiyan Liu", "Christian Shun Jin", "Lulu Chen", "Minjie Shen", "Nawwaf Aleisa", "Zeyuan Hou", "Chenyu Zhang", "Lifu Gao", "Yanshu Li", "Qikai Yang", "Qun Wang", "Cristabelle De Souza"], "title": "A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Artificial Intelligence (AI) agents have rapidly evolved from specialized,\nrule-based programs to versatile, learning-driven autonomous systems capable of\nperception, reasoning, and action in complex environments. The explosion of\ndata, advances in deep learning, reinforcement learning, and multi-agent\ncoordination have accelerated this transformation. Yet, designing and deploying\nunified AI agents that seamlessly integrate cognition, planning, and\ninteraction remains a grand challenge. In this review, we systematically\nexamine the architectural principles, foundational components, and emergent\nparadigms that define the landscape of contemporary AI agents. We synthesize\ninsights from cognitive science-inspired models, hierarchical reinforcement\nlearning frameworks, and large language model-based reasoning. Moreover, we\ndiscuss the pressing ethical, safety, and interpretability concerns associated\nwith deploying these agents in real-world scenarios. By highlighting major\nbreakthroughs, persistent challenges, and promising research directions, this\nreview aims to guide the next generation of AI agent systems toward more\nrobust, adaptable, and trustworthy autonomous intelligence.", "AI": {"tldr": "A comprehensive review of AI agent evolution from rule-based systems to modern autonomous agents, covering architectural principles, foundational components, and addressing ethical concerns for future development.", "motivation": "To address the grand challenge of designing unified AI agents that seamlessly integrate cognition, planning, and interaction, and to guide the next generation of robust and trustworthy autonomous systems.", "method": "Systematic examination of architectural principles and foundational components, synthesizing insights from cognitive science-inspired models, hierarchical reinforcement learning frameworks, and large language model-based reasoning.", "result": "Provides a comprehensive landscape analysis of contemporary AI agents, highlighting major breakthroughs and synthesizing knowledge across multiple AI paradigms.", "conclusion": "The review identifies persistent challenges and promising research directions to guide development toward more robust, adaptable, and trustworthy autonomous intelligence systems, while addressing ethical and safety concerns."}}
{"id": "2508.12891", "pdf": "https://arxiv.org/pdf/2508.12891", "abs": "https://arxiv.org/abs/2508.12891", "authors": ["Sankar Behera", "Yamuna Prasad"], "title": "ONG: One-Shot NMF-based Gradient Masking for Efficient Model Sparsification", "categories": ["cs.CV"], "comment": "7 pages", "summary": "Deep Neural Networks (DNNs) have achieved remarkable success but their large\nsize poses deployment challenges. While various pruning techniques exist, many\ninvolve complex iterative processes, specialized criteria, or struggle to\nmaintain sparsity effectively during training. We introduce ONG (One-shot\nNMF-based Gradient Masking), a novel sparsification strategy that identifies\nsalient weight structures using Non-negative Matrix Factorization (NMF) for\none-shot pruning at the outset of training. Subsequently, ONG employs a precise\ngradient masking mechanism to ensure that only unpruned weights are updated,\nstrictly preserving the target sparsity throughout the training phase. We\nintegrate ONG into the BIMP comparative framework and evaluate it on CIFAR-10\nand CIFAR-100 with ResNet56, ResNet34, and ResNet18 against established stable\nsparsification methods. Our experiments demonstrate ONG's ability to achieve\ncomparable or superior performance at various sparsity levels while maintaining\nstructural integrity post-pruning and offering a clear mechanism for targeting\ndesired sparsities.", "AI": {"tldr": "ONG is a one-shot pruning method using NMF and gradient masking that achieves comparable or better performance while maintaining target sparsity throughout training.", "motivation": "Deep Neural Networks face deployment challenges due to large size, and existing pruning methods often involve complex iterative processes or struggle to maintain sparsity effectively during training.", "method": "ONG uses Non-negative Matrix Factorization (NMF) for one-shot pruning at training start, then employs gradient masking to ensure only unpruned weights are updated, strictly preserving target sparsity.", "result": "Experiments on CIFAR-10/100 with ResNet architectures show ONG achieves comparable or superior performance at various sparsity levels while maintaining structural integrity.", "conclusion": "ONG provides an effective one-shot pruning approach with clear sparsity targeting mechanism and strict sparsity preservation during training."}}
{"id": "2508.11977", "pdf": "https://arxiv.org/pdf/2508.11977", "abs": "https://arxiv.org/abs/2508.11977", "authors": ["Zida Liang", "Changfa Wu", "Dunxian Huang", "Weiqiang Sun", "Ziyang Wang", "Yuliang Yan", "Jian Wu", "Yuning Jiang", "Bo Zheng", "Ke Chen", "Silu Zhou", "Yu Zhang"], "title": "TBGRecall: A Generative Retrieval Model for E-commerce Recommendation Scenarios", "categories": ["cs.IR", "cs.AI"], "comment": "Both authors contributed equally to this research. Work done during\n  internship at Alibaba. Corresponding author: Dunxian Huang\n  (dunxian.hdx@alibaba-inc.com). Affiliations: (1) Shanghai Jiaotong\n  University, Shanghai, China; (2) Alibaba Inc", "summary": "Recommendation systems are essential tools in modern e-commerce, facilitating\npersonalized user experiences by suggesting relevant products. Recent\nadvancements in generative models have demonstrated potential in enhancing\nrecommendation systems; however, these models often exhibit limitations in\noptimizing retrieval tasks, primarily due to their reliance on autoregressive\ngeneration mechanisms. Conventional approaches introduce sequential\ndependencies that impede efficient retrieval, as they are inherently unsuitable\nfor generating multiple items without positional constraints within a single\nrequest session. To address these limitations, we propose TBGRecall, a\nframework integrating Next Session Prediction (NSP), designed to enhance\ngenerative retrieval models for e-commerce applications. Our framework\nreformulation involves partitioning input samples into multi-session sequences,\nwhere each sequence comprises a session token followed by a set of item tokens,\nand then further incorporate multiple optimizations tailored to the generative\ntask in retrieval scenarios. In terms of training methodology, our pipeline\nintegrates limited historical data pre-training with stochastic partial\nincremental training, significantly improving training efficiency and\nemphasizing the superiority of data recency over sheer data volume. Our\nextensive experiments, conducted on public benchmarks alongside a large-scale\nindustrial dataset from TaoBao, show TBGRecall outperforms the state-of-the-art\nrecommendation methods, and exhibits a clear scaling law trend. Ultimately, NSP\nrepresents a significant advancement in the effectiveness of generative\nrecommendation systems for e-commerce applications.", "AI": {"tldr": "TBGRecall framework integrates Next Session Prediction (NSP) to enhance generative retrieval models for e-commerce recommendations by addressing limitations of autoregressive generation in multi-item retrieval tasks.", "motivation": "Current generative models for recommendation systems struggle with efficient retrieval due to sequential dependencies and autoregressive generation mechanisms that are unsuitable for generating multiple items without positional constraints in single sessions.", "method": "Proposes TBGRecall framework that partitions input samples into multi-session sequences (session token + item tokens), incorporates multiple optimizations for generative retrieval, and uses limited historical data pre-training with stochastic partial incremental training to emphasize data recency over volume.", "result": "Extensive experiments on public benchmarks and TaoBao industrial dataset show TBGRecall outperforms state-of-the-art recommendation methods and exhibits clear scaling law trends.", "conclusion": "NSP represents a significant advancement in generative recommendation systems for e-commerce applications, improving retrieval efficiency and effectiveness."}}
{"id": "2508.12900", "pdf": "https://arxiv.org/pdf/2508.12900", "abs": "https://arxiv.org/abs/2508.12900", "authors": ["Jiayi Wang", "Hadrien Reynaud", "Franciskus Xaverius Erick", "Bernhard Kainz"], "title": "CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Generative modelling of entire CT volumes conditioned on clinical reports has\nthe potential to accelerate research through data augmentation,\nprivacy-preserving synthesis and reducing regulator-constraints on patient data\nwhile preserving diagnostic signals. With the recent release of CT-RATE, a\nlarge-scale collection of 3D CT volumes paired with their respective clinical\nreports, training large text-conditioned CT volume generation models has become\nachievable. In this work, we introduce CTFlow, a 0.5B latent flow matching\ntransformer model, conditioned on clinical reports. We leverage the A-VAE from\nFLUX to define our latent space, and rely on the CT-Clip text encoder to encode\nthe clinical reports. To generate consistent whole CT volumes while keeping the\nmemory constraints tractable, we rely on a custom autoregressive approach,\nwhere the model predicts the first sequence of slices of the volume from\ntext-only, and then relies on the previously generated sequence of slices and\nthe text, to predict the following sequence. We evaluate our results against\nstate-of-the-art generative CT model, and demonstrate the superiority of our\napproach in terms of temporal coherence, image diversity and text-image\nalignment, with FID, FVD, IS scores and CLIP score.", "AI": {"tldr": "CTFlow is a 0.5B latent flow matching transformer that generates entire 3D CT volumes from clinical reports, achieving state-of-the-art performance in temporal coherence, diversity, and text-image alignment.", "motivation": "To accelerate medical research through data augmentation, enable privacy-preserving synthesis, and reduce regulatory constraints on patient data while preserving diagnostic signals from CT scans.", "method": "Uses a 0.5B latent flow matching transformer conditioned on clinical reports, leveraging A-VAE from FLUX for latent space and CT-Clip text encoder. Employs custom autoregressive approach to generate consistent whole CT volumes by predicting sequences of slices iteratively.", "result": "Superior performance compared to state-of-the-art generative CT models in terms of temporal coherence, image diversity, and text-image alignment, as measured by FID, FVD, IS scores and CLIP score.", "conclusion": "CTFlow demonstrates effective generation of realistic 3D CT volumes from clinical reports, addressing memory constraints through innovative autoregressive sequence prediction while maintaining diagnostic quality."}}
{"id": "2508.12917", "pdf": "https://arxiv.org/pdf/2508.12917", "abs": "https://arxiv.org/abs/2508.12917", "authors": ["Zhiwei Ning", "Zhaojiang Liu", "Xuanang Gao", "Yifan Zuo", "Jie Yang", "Yuming Fang", "Wei Liu"], "title": "CMF-IoU: Multi-Stage Cross-Modal Fusion 3D Object Detection with IoU Joint Prediction", "categories": ["cs.CV"], "comment": "The Paper is Accepted by TCSVT", "summary": "Multi-modal methods based on camera and LiDAR sensors have garnered\nsignificant attention in the field of 3D detection. However, many prevalent\nworks focus on single or partial stage fusion, leading to insufficient feature\nextraction and suboptimal performance. In this paper, we introduce a\nmulti-stage cross-modal fusion 3D detection framework, termed CMF-IOU, to\neffectively address the challenge of aligning 3D spatial and 2D semantic\ninformation. Specifically, we first project the pixel information into 3D space\nvia a depth completion network to get the pseudo points, which unifies the\nrepresentation of the LiDAR and camera information. Then, a bilateral\ncross-view enhancement 3D backbone is designed to encode LiDAR points and\npseudo points. The first sparse-to-distant (S2D) branch utilizes an\nencoder-decoder structure to reinforce the representation of sparse LiDAR\npoints. The second residual view consistency (ResVC) branch is proposed to\nmitigate the influence of inaccurate pseudo points via both the 3D and 2D\nconvolution processes. Subsequently, we introduce an iterative voxel-point\naware fine grained pooling module, which captures the spatial information from\nLiDAR points and textural information from pseudo points in the proposal\nrefinement stage. To achieve more precise refinement during iteration, an\nintersection over union (IoU) joint prediction branch integrated with a novel\nproposals generation technique is designed to preserve the bounding boxes with\nboth high IoU and classification scores. Extensive experiments show the\nsuperior performance of our method on the KITTI, nuScenes and Waymo datasets.", "AI": {"tldr": "CMF-IOU is a multi-stage cross-modal fusion framework for 3D object detection that effectively integrates LiDAR and camera data through depth completion, bilateral cross-view enhancement, and iterative refinement with IoU-aware proposal generation.", "motivation": "Existing multi-modal 3D detection methods often use single or partial stage fusion, resulting in insufficient feature extraction and suboptimal performance. The challenge lies in effectively aligning 3D spatial information from LiDAR with 2D semantic information from cameras.", "method": "1) Project camera pixels into 3D space via depth completion to create pseudo points; 2) Use bilateral cross-view enhancement backbone with S2D branch for sparse LiDAR reinforcement and ResVC branch to mitigate inaccurate pseudo points; 3) Implement iterative voxel-point aware fine-grained pooling; 4) Design IoU joint prediction branch with novel proposal generation to preserve high-quality bounding boxes.", "result": "Extensive experiments demonstrate superior performance on KITTI, nuScenes, and Waymo datasets, showing the effectiveness of the multi-stage fusion approach.", "conclusion": "CMF-IOU successfully addresses the cross-modal fusion challenge through comprehensive multi-stage integration, achieving state-of-the-art performance by effectively combining 3D spatial and 2D semantic information from LiDAR and camera sensors."}}
{"id": "2508.11684", "pdf": "https://arxiv.org/pdf/2508.11684", "abs": "https://arxiv.org/abs/2508.11684", "authors": ["BG Tong"], "title": "A Graph Neural Network based on a Functional Topology Model: Unveiling the Dynamic Mechanisms of Non-Suicidal Self-Injury in Single-Channel EEG", "categories": ["eess.SP", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Objective: This study proposes and preliminarily validates a novel\n\"Functional-Energetic Topology Model\" to uncover neurodynamic mechanisms of\nNon-Suicidal Self-Injury (NSSI), using Graph Neural Networks (GNNs) to decode\nbrain network patterns from single-channel EEG in real-world settings.Methods:\nEEG data were collected over ~1 month from three adolescents with NSSI using a\nsmartphone app and a portable Fp1 EEG headband during impulsive and\nnon-impulsive states. A theory-driven GNN with seven functional nodes was\nbuilt. Performance was evaluated via intra-subject (80/20 split) and\nleave-one-subject-out cross-validation (LOSOCV). GNNExplainer was used for\ninterpretability.Results: The model achieved high intra-subject accuracy (>85%)\nand significantly above-chance cross-subject performance (approximately73.7%).\nExplainability analysis revealed a key finding: during NSSI states, a critical\nfeedback loop regulating somatic sensation exhibits dysfunction and directional\nreversal. Specifically, the brain loses its ability to self-correct via\nnegative bodily feedback, and the regulatory mechanism enters an \"ineffective\nidling\" state.Conclusion: This work demonstrates the feasibility of applying\ntheory-guided GNNs to sparse, single-channel EEG for decoding complex mental\nstates. The identified \"feedback loop reversal\" offers a novel, dynamic, and\ncomputable model of NSSI mechanisms, paving the way for objective biomarkers\nand next-generation Digital Therapeutics (DTx).", "AI": {"tldr": "A novel Functional-Energetic Topology Model using Graph Neural Networks successfully decodes NSSI brain patterns from single-channel EEG, revealing dysfunctional feedback loops in somatic regulation during self-injury states.", "motivation": "To uncover neurodynamic mechanisms of Non-Suicidal Self-Injury (NSSI) and develop objective biomarkers using real-world EEG data, addressing the need for computational models that can decode complex mental states from sparse neuroimaging data.", "method": "Collected EEG data from three adolescents with NSSI using smartphone app and portable Fp1 EEG headband over ~1 month. Built theory-driven GNN with seven functional nodes, evaluated via intra-subject (80/20 split) and leave-one-subject-out cross-validation, with GNNExplainer for interpretability.", "result": "High intra-subject accuracy (>85%) and significantly above-chance cross-subject performance (~73.7%). Key finding: during NSSI states, critical feedback loop regulating somatic sensation shows dysfunction and directional reversal, with brain losing self-correction ability via negative bodily feedback.", "conclusion": "Demonstrates feasibility of theory-guided GNNs for sparse, single-channel EEG decoding. Identified 'feedback loop reversal' provides novel dynamic model of NSSI mechanisms, enabling objective biomarkers and next-generation Digital Therapeutics."}}
{"id": "2508.12919", "pdf": "https://arxiv.org/pdf/2508.12919", "abs": "https://arxiv.org/abs/2508.12919", "authors": ["Elena Izzo", "Luca Parolari", "Davide Vezzaro", "Lamberto Ballan"], "title": "7Bench: a Comprehensive Benchmark for Layout-guided Text-to-image Models", "categories": ["cs.CV"], "comment": "Accepted to ICIAP 2025", "summary": "Layout-guided text-to-image models offer greater control over the generation\nprocess by explicitly conditioning image synthesis on the spatial arrangement\nof elements. As a result, their adoption has increased in many computer vision\napplications, ranging from content creation to synthetic data generation. A\ncritical challenge is achieving precise alignment between the image, textual\nprompt, and layout, ensuring semantic fidelity and spatial accuracy. Although\nrecent benchmarks assess text alignment, layout alignment remains overlooked,\nand no existing benchmark jointly evaluates both. This gap limits the ability\nto evaluate a model's spatial fidelity, which is crucial when using\nlayout-guided generation for synthetic data, as errors can introduce noise and\ndegrade data quality. In this work, we introduce 7Bench, the first benchmark to\nassess both semantic and spatial alignment in layout-guided text-to-image\ngeneration. It features text-and-layout pairs spanning seven challenging\nscenarios, investigating object generation, color fidelity, attribute\nrecognition, inter-object relationships, and spatial control. We propose an\nevaluation protocol that builds on existing frameworks by incorporating the\nlayout alignment score to assess spatial accuracy. Using 7Bench, we evaluate\nseveral state-of-the-art diffusion models, uncovering their respective\nstrengths and limitations across diverse alignment tasks. The benchmark is\navailable at https://github.com/Elizzo/7Bench.", "AI": {"tldr": "7Bench is the first benchmark that jointly evaluates both semantic and spatial alignment in layout-guided text-to-image generation, addressing a critical gap in existing evaluation frameworks.", "motivation": "Existing benchmarks only assess text alignment but overlook layout alignment, limiting the ability to evaluate spatial fidelity which is crucial for applications like synthetic data generation where errors can degrade data quality.", "method": "The benchmark features text-and-layout pairs spanning seven challenging scenarios and proposes an evaluation protocol that incorporates layout alignment score alongside existing semantic evaluation frameworks to assess spatial accuracy.", "result": "The benchmark was used to evaluate several state-of-the-art diffusion models, revealing their respective strengths and limitations across diverse alignment tasks including object generation, color fidelity, attribute recognition, inter-object relationships, and spatial control.", "conclusion": "7Bench provides a comprehensive evaluation framework for layout-guided text-to-image models, enabling better assessment of both semantic and spatial alignment capabilities, which is essential for real-world applications requiring precise control over generated content."}}
{"id": "2508.11685", "pdf": "https://arxiv.org/pdf/2508.11685", "abs": "https://arxiv.org/abs/2508.11685", "authors": ["Farnaz Kaboudvand", "Maham Khalid", "Nydia Assaf", "Vardaan Sahgal", "Jon P. Ruffley", "Brian J. McDermott"], "title": "Enhancing Corrosion Resistance of Aluminum Alloys Through AI and ML Modeling", "categories": ["eess.SP", "cond-mat.mtrl-sci", "cs.LG", "stat.ML"], "comment": "Manuscript length: 11 pages, 6 figures", "summary": "Corrosion poses a significant challenge to the performance of aluminum\nalloys, particularly in marine environments. This study investigates the\napplication of machine learning (ML) algorithms to predict and optimize\ncorrosion resistance, utilizing a comprehensive open-source dataset compiled\nfrom various sources. The dataset encompasses corrosion rate data and\nenvironmental conditions, preprocessed to standardize units and formats. We\nexplored two different approaches, a direct approach, where the material's\ncomposition and environmental conditions were used as inputs to predict\ncorrosion rates; and an inverse approach, where corrosion rate served as the\ninput to identify suitable material compositions as output. We employed and\ncompared three distinct ML methodologies for forward predictions: Random Forest\nregression, optimized via grid search; a feed-forward neural network, utilizing\nReLU activation and Adam optimization; and Gaussian Process Regression (GPR),\nimplemented with GPyTorch and employing various kernel functions. The Random\nForest and neural network models provided predictive capabilities based on\nelemental compositions and environmental conditions. Notably, Gaussian Process\nRegression demonstrated superior performance, particularly with hybrid kernel\nfunctions. Log-transformed GPR further refined predictions. This study\nhighlights the efficacy of ML, particularly GPR, in predicting corrosion rates\nand material properties.", "AI": {"tldr": "Machine learning algorithms, particularly Gaussian Process Regression with hybrid kernels, effectively predict aluminum alloy corrosion rates and optimize material compositions for marine environments.", "motivation": "Corrosion significantly impacts aluminum alloy performance in marine environments, requiring better prediction and optimization methods to improve material durability and selection.", "method": "Used comprehensive open-source dataset with corrosion rate data and environmental conditions. Employed two approaches: direct (composition + environment \u2192 corrosion rate) and inverse (corrosion rate \u2192 optimal composition). Compared Random Forest regression, feed-forward neural network, and Gaussian Process Regression with various kernel functions.", "result": "Gaussian Process Regression demonstrated superior performance, especially with hybrid kernel functions. Log-transformed GPR further refined predictions. ML models successfully predicted corrosion rates and identified suitable material compositions.", "conclusion": "Machine learning, particularly Gaussian Process Regression, is highly effective for predicting aluminum alloy corrosion rates and optimizing material properties for marine applications."}}
{"id": "2508.12013", "pdf": "https://arxiv.org/pdf/2508.12013", "abs": "https://arxiv.org/abs/2508.12013", "authors": ["Surajit Das", "Aleksei Eliseev"], "title": "Predicting ChatGPT Use in Assignments: Implications for AI-Aware Assessment Design", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The rise of generative AI tools like ChatGPT has significantly reshaped\neducation, sparking debates about their impact on learning outcomes and\nacademic integrity. While prior research highlights opportunities and risks,\nthere remains a lack of quantitative analysis of student behavior when\ncompleting assignments. Understanding how these tools influence real-world\nacademic practices, particularly assignment preparation, is a pressing and\ntimely research priority.\n  This study addresses this gap by analyzing survey responses from 388\nuniversity students, primarily from Russia, including a subset of international\nparticipants. Using the XGBoost algorithm, we modeled predictors of ChatGPT\nusage in academic assignments. Key predictive factors included learning habits,\nsubject preferences, and student attitudes toward AI. Our binary classifier\ndemonstrated strong predictive performance, achieving 80.1\\% test accuracy,\nwith 80.2\\% sensitivity and 79.9\\% specificity. The multiclass classifier\nachieved 64.5\\% test accuracy, 64.6\\% weighted precision, and 64.5\\% recall,\nwith similar training scores, indicating potential data scarcity challenges.\n  The study reveals that frequent use of ChatGPT for learning new concepts\ncorrelates with potential overreliance, raising concerns about long-term\nacademic independence. These findings suggest that while generative AI can\nenhance access to knowledge, unchecked reliance may erode critical thinking and\noriginality. We propose discipline-specific guidelines and reimagined\nassessment strategies to balance innovation with academic rigor. These insights\ncan guide educators and policymakers in ethically and effectively integrating\nAI into education.", "AI": {"tldr": "Study analyzes ChatGPT usage patterns among university students using XGBoost algorithm, finding 80.1% accuracy in predicting usage based on learning habits and attitudes, with concerns about potential overreliance affecting critical thinking.", "motivation": "Address the lack of quantitative analysis on how generative AI tools like ChatGPT influence real-world student behavior and academic practices, particularly assignment preparation.", "method": "Surveyed 388 university students (primarily from Russia with international participants) and used XGBoost algorithm to model predictors of ChatGPT usage in academic assignments, analyzing learning habits, subject preferences, and attitudes toward AI.", "result": "Binary classifier achieved 80.1% test accuracy with 80.2% sensitivity and 79.9% specificity. Multiclass classifier achieved 64.5% test accuracy. Found frequent ChatGPT use for learning correlates with potential overreliance, raising concerns about academic independence.", "conclusion": "Generative AI can enhance knowledge access but unchecked reliance may erode critical thinking. Proposes discipline-specific guidelines and reimagined assessment strategies to balance innovation with academic rigor for ethical AI integration."}}
{"id": "2508.12931", "pdf": "https://arxiv.org/pdf/2508.12931", "abs": "https://arxiv.org/abs/2508.12931", "authors": ["Ximiao Zhang", "Min Xu", "Xiuzhuang Zhou"], "title": "Towards High-Resolution Industrial Image Anomaly Detection", "categories": ["cs.CV"], "comment": null, "summary": "Current anomaly detection methods primarily focus on low-resolution\nscenarios. For high-resolution images, conventional downsampling often results\nin missed detections of subtle anomalous regions due to the loss of\nfine-grained discriminative information. Despite some progress, recent studies\nhave attempted to improve detection resolution by employing lightweight\nnetworks or using simple image tiling and ensemble methods. However, these\napproaches still struggle to meet the practical demands of industrial scenarios\nin terms of detection accuracy and efficiency. To address the above issues, we\npropose HiAD, a general framework for high-resolution anomaly detection. HiAD\nis capable of detecting anomalous regions of varying sizes in high-resolution\nimages under limited computational resources. Specifically, HiAD employs a\ndual-branch architecture that integrates anomaly cues across different scales\nto comprehensively capture both subtle and large-scale anomalies. Furthermore,\nit incorporates a multi-resolution feature fusion strategy to tackle the\nchallenges posed by fine-grained texture variations in high-resolution images.\nTo enhance both adaptability and efficiency, HiAD utilizes a detector pool in\nconjunction with various detector assignment strategies, enabling detectors to\nbe adaptively assigned based on patch features, ensuring detection performance\nwhile effectively controlling computational costs. We conduct extensive\nexperiments on our specifically constructed high-resolution anomaly detection\nbenchmarks, including MVTec-HD, VisA-HD, and the real-world benchmark\nRealIAD-HD, demonstrating the superior performance of HiAD. The code is\navailable at https://github.com/cnulab/HiAD.", "AI": {"tldr": "HiAD is a dual-branch framework for high-resolution anomaly detection that addresses the limitations of conventional methods by integrating multi-scale anomaly cues and adaptive detector assignment to handle both subtle and large anomalies efficiently.", "motivation": "Current anomaly detection methods struggle with high-resolution images due to information loss from downsampling and inefficiency of simple tiling approaches, failing to meet industrial requirements for accuracy and computational efficiency.", "method": "Proposes HiAD with dual-branch architecture for multi-scale anomaly integration, multi-resolution feature fusion for fine-grained texture handling, and adaptive detector pool with assignment strategies based on patch features.", "result": "Extensive experiments on MVTec-HD, VisA-HD, and RealIAD-HD benchmarks demonstrate superior performance in detecting anomalies of varying sizes in high-resolution images under limited computational resources.", "conclusion": "HiAD provides an effective and efficient solution for high-resolution anomaly detection, outperforming existing methods and meeting practical industrial demands through its adaptive multi-scale architecture."}}
{"id": "2508.12029", "pdf": "https://arxiv.org/pdf/2508.12029", "abs": "https://arxiv.org/abs/2508.12029", "authors": ["Zhangyu You", "Jiahao Ma", "Hongzong Li", "Ye-Fan Hu", "Jian-Dong Huang"], "title": "BConformeR: A Conformer Based on Mutual Sampling for Unified Prediction of Continuous and Discontinuous Antibody Binding Sites", "categories": ["q-bio.BM", "cs.AI", "cs.CE", "cs.LG"], "comment": "16 pages, 7 figures, 5 tables, submitted to AAAI conference 2026", "summary": "Accurate prediction of antibody-binding sites (epitopes) on antigens is\ncrucial for vaccine design, immunodiagnostics, therapeutic antibody\ndevelopment, antibody engineering, research into autoimmune and allergic\ndiseases, and for advancing our understanding of immune responses. Despite in\nsilico methods that have been proposed to predict both linear (continuous) and\nconformational (discontinuous) epitopes, they consistently underperform in\npredicting conformational epitopes. In this work, we propose a conformer-based\nmodel trained on antigen sequences derived from 1,080 antigen-antibody\ncomplexes, leveraging convolutional neural networks (CNNs) to extract local\nfeatures and Transformers to capture long-range dependencies within antigen\nsequences. Ablation studies demonstrate that CNN enhances the prediction of\nlinear epitopes, and the Transformer module improves the prediction of\nconformational epitopes. Experimental results show that our model outperforms\nexisting baselines in terms of PCC, ROC-AUC, PR-AUC, and F1 scores on\nconformational epitopes.", "AI": {"tldr": "A conformer-based model combining CNNs and Transformers outperforms existing methods for predicting conformational antibody-binding sites (epitopes) on antigens.", "motivation": "Accurate prediction of conformational epitopes is crucial for vaccine design, therapeutic antibody development, and understanding immune responses, but existing methods consistently underperform for conformational epitopes compared to linear ones.", "method": "A conformer-based model trained on antigen sequences from 1,080 antigen-antibody complexes, using CNNs to extract local features and Transformers to capture long-range dependencies within antigen sequences.", "result": "The model outperforms existing baselines in PCC, ROC-AUC, PR-AUC, and F1 scores on conformational epitopes. Ablation studies show CNNs enhance linear epitope prediction while Transformers improve conformational epitope prediction.", "conclusion": "The proposed hybrid CNN-Transformer architecture effectively addresses the challenge of conformational epitope prediction, demonstrating superior performance over existing methods."}}
{"id": "2508.12932", "pdf": "https://arxiv.org/pdf/2508.12932", "abs": "https://arxiv.org/abs/2508.12932", "authors": ["Hongyang Chen", "Shaoling Pu", "Lingyu Zheng", "Zhongwu Sun"], "title": "SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ICONIP2025", "summary": "In incremental learning, enhancing the generality of knowledge is crucial for\nadapting to dynamic data inputs. It can develop generalized representations or\nmore balanced decision boundaries, preventing the degradation of long-term\nknowledge over time and thus mitigating catastrophic forgetting. Some emerging\nincremental learning methods adopt an encoder-decoder architecture and have\nachieved promising results. In the encoder-decoder achitecture, improving the\ngeneralization capabilities of both the encoder and decoder is critical, as it\nhelps preserve previously learned knowledge while ensuring adaptability and\nrobustness to new, diverse data inputs. However, many existing continual\nmethods focus solely on enhancing one of the two components, which limits their\neffectiveness in mitigating catastrophic forgetting. And these methods perform\neven worse in small-memory scenarios, where only a limited number of historical\nsamples can be stored. To mitigate this limitation, we introduces SEDEG, a\ntwo-stage training framework for vision transformers (ViT), focusing on\nsequentially improving the generality of both Decoder and Encoder. Initially,\nSEDEG trains an ensembled encoder through feature boosting to learn generalized\nrepresentations, which subsequently enhance the decoder's generality and\nbalance the classifier. The next stage involves using knowledge distillation\n(KD) strategies to compress the ensembled encoder and develop a new, more\ngeneralized encoder. This involves using a balanced KD approach and feature KD\nfor effective knowledge transfer. Extensive experiments on three benchmark\ndatasets show SEDEG's superior performance, and ablation studies confirm the\nefficacy of its components. The code is available at\nhttps://github.com/ShaolingPu/CIL.", "AI": {"tldr": "SEDEG is a two-stage ViT framework that sequentially enhances both encoder and decoder generality through feature boosting and knowledge distillation to mitigate catastrophic forgetting in incremental learning, especially in small-memory scenarios.", "motivation": "Existing incremental learning methods focus on either encoder or decoder improvement, limiting effectiveness against catastrophic forgetting and performing poorly in small-memory settings where few historical samples can be stored.", "method": "Two-stage training: 1) Train ensembled encoder via feature boosting to learn generalized representations that enhance decoder and balance classifier; 2) Use balanced KD and feature KD to compress ensembled encoder into a new more generalized encoder.", "result": "Extensive experiments on three benchmark datasets show superior performance, with ablation studies confirming the efficacy of all components.", "conclusion": "SEDEG effectively addresses catastrophic forgetting in incremental learning by sequentially improving both encoder and decoder generality, particularly demonstrating strong performance in challenging small-memory scenarios."}}
{"id": "2508.12942", "pdf": "https://arxiv.org/pdf/2508.12942", "abs": "https://arxiv.org/abs/2508.12942", "authors": ["Kyriaki-Margarita Bintsi", "Ya\u00ebl Balbastre", "Jingjing Wu", "Julia F. Lehman", "Suzanne N. Haber", "Anastasia Yendiki"], "title": "Fully Automated Segmentation of Fiber Bundles in Anatomic Tracing Data", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at CDMRI, MICCAI 2025", "summary": "Anatomic tracer studies are critical for validating and improving diffusion\nMRI (dMRI) tractography. However, large-scale analysis of data from such\nstudies is hampered by the labor-intensive process of annotating fiber bundles\nmanually on histological slides. Existing automated methods often miss sparse\nbundles or require complex post-processing across consecutive sections,\nlimiting their flexibility and generalizability. We present a streamlined,\nfully automated framework for fiber bundle segmentation in macaque tracer data,\nbased on a U-Net architecture with large patch sizes, foreground aware\nsampling, and semisupervised pre-training. Our approach eliminates common\nerrors such as mislabeling terminals as bundles, improves detection of sparse\nbundles by over 20% and reduces the False Discovery Rate (FDR) by 40% compared\nto the state-of-the-art, all while enabling analysis of standalone slices. This\nnew framework will facilitate the automated analysis of anatomic tracing data\nat a large scale, generating more ground-truth data that can be used to\nvalidate and optimize dMRI tractography methods.", "AI": {"tldr": "Automated U-Net framework for fiber bundle segmentation in macaque tracer data with large patches, foreground-aware sampling, and semi-supervised pre-training, achieving 20% better sparse bundle detection and 40% lower FDR than state-of-the-art.", "motivation": "Manual annotation of fiber bundles in histological slides is labor-intensive, and existing automated methods miss sparse bundles or require complex post-processing, limiting large-scale analysis of anatomic tracer studies for dMRI validation.", "method": "U-Net architecture with large patch sizes, foreground aware sampling, and semi-supervised pre-training to enable automated fiber bundle segmentation in standalone histological slices without complex cross-section processing.", "result": "20% improvement in sparse bundle detection, 40% reduction in False Discovery Rate (FDR), elimination of terminal mislabeling errors, and capability to analyze individual slices without consecutive section requirements.", "conclusion": "This automated framework enables large-scale analysis of anatomic tracing data, generating more ground-truth data to validate and optimize dMRI tractography methods efficiently."}}
{"id": "2508.11703", "pdf": "https://arxiv.org/pdf/2508.11703", "abs": "https://arxiv.org/abs/2508.11703", "authors": ["Vasileios Saketos", "Sebastian Kaltenbach", "Sergey Litvinov", "Petros Koumoutsakos"], "title": "Data-Driven Discovery of Interpretable Kalman Filter Variants through Large Language Models and Genetic Programming", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Algorithmic discovery has traditionally relied on human ingenuity and\nextensive experimentation. Here we investigate whether a prominent scientific\ncomputing algorithm, the Kalman Filter, can be discovered through an automated,\ndata-driven, evolutionary process that relies on Cartesian Genetic Programming\n(CGP) and Large Language Models (LLM). We evaluate the contributions of both\nmodalities (CGP and LLM) in discovering the Kalman filter under varying\nconditions. Our results demonstrate that our framework of CGP and LLM-assisted\nevolution converges to near-optimal solutions when Kalman optimality\nassumptions hold. When these assumptions are violated, our framework evolves\ninterpretable alternatives that outperform the Kalman filter. These results\ndemonstrate that combining evolutionary algorithms and generative models for\ninterpretable, data-driven synthesis of simple computational modules is a\npotent approach for algorithmic discovery in scientific computing.", "AI": {"tldr": "Automated discovery of Kalman Filter using evolutionary programming (CGP) and LLMs, showing convergence to optimal solutions when assumptions hold and superior alternatives when assumptions are violated.", "motivation": "To investigate whether scientific computing algorithms like Kalman Filter can be discovered through automated, data-driven evolutionary processes rather than traditional human-driven experimentation.", "method": "Combined Cartesian Genetic Programming (CGP) with Large Language Models (LLM) in an evolutionary framework to discover and optimize the Kalman Filter algorithm.", "result": "Framework converges to near-optimal solutions when Kalman assumptions hold, and evolves interpretable alternatives that outperform Kalman Filter when assumptions are violated.", "conclusion": "Combining evolutionary algorithms and generative models enables effective data-driven synthesis of computational modules for algorithmic discovery in scientific computing."}}
{"id": "2508.12945", "pdf": "https://arxiv.org/pdf/2508.12945", "abs": "https://arxiv.org/abs/2508.12945", "authors": ["Jianshu Zeng", "Yuxuan Liu", "Yutong Feng", "Chenxuan Miao", "Zixiang Gao", "Jiwang Qu", "Jianzhang Zhang", "Bin Wang", "Kun Yuan"], "title": "Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models", "categories": ["cs.CV"], "comment": "15 pages, 7 figures", "summary": "Video relighting is a challenging yet valuable task, aiming to replace the\nbackground in videos while correspondingly adjusting the lighting in the\nforeground with harmonious blending. During translation, it is essential to\npreserve the original properties of the foreground, e.g., albedo, and propagate\nconsistent relighting among temporal frames. In this paper, we propose Lumen,\nan end-to-end video relighting framework developed on large-scale video\ngenerative models, receiving flexible textual description for instructing the\ncontrol of lighting and background. Considering the scarcity of high-qualified\npaired videos with the same foreground in various lighting conditions, we\nconstruct a large-scale dataset with a mixture of realistic and synthetic\nvideos. For the synthetic domain, benefiting from the abundant 3D assets in the\ncommunity, we leverage advanced 3D rendering engine to curate video pairs in\ndiverse environments. For the realistic domain, we adapt a HDR-based lighting\nsimulation to complement the lack of paired in-the-wild videos. Powered by the\naforementioned dataset, we design a joint training curriculum to effectively\nunleash the strengths of each domain, i.e., the physical consistency in\nsynthetic videos, and the generalized domain distribution in realistic videos.\nTo implement this, we inject a domain-aware adapter into the model to decouple\nthe learning of relighting and domain appearance distribution. We construct a\ncomprehensive benchmark to evaluate Lumen together with existing methods, from\nthe perspectives of foreground preservation and video consistency assessment.\nExperimental results demonstrate that Lumen effectively edit the input into\ncinematic relighted videos with consistent lighting and strict foreground\npreservation. Our project page: https://lumen-relight.github.io/", "AI": {"tldr": "Lumen is an end-to-end video relighting framework that uses large-scale video generative models to replace backgrounds and adjust foreground lighting based on textual descriptions, achieving consistent cinematic results with strict foreground preservation.", "motivation": "Video relighting is challenging but valuable for creating harmonious lighting adjustments in videos while preserving foreground properties and maintaining temporal consistency across frames.", "method": "Uses an end-to-end framework built on large-scale video generative models with textual lighting instructions. Constructs a mixed dataset of realistic and synthetic videos using 3D rendering and HDR-based lighting simulation. Implements joint training with domain-aware adapter to decouple relighting learning from domain appearance distribution.", "result": "Experimental results show Lumen effectively edits input videos into cinematic relighted videos with consistent lighting and strict foreground preservation, outperforming existing methods in comprehensive benchmark evaluations.", "conclusion": "Lumen successfully addresses video relighting challenges by leveraging large-scale generative models and a carefully constructed mixed dataset, achieving high-quality results with temporal consistency and foreground property preservation."}}
{"id": "2508.12045", "pdf": "https://arxiv.org/pdf/2508.12045", "abs": "https://arxiv.org/abs/2508.12045", "authors": ["Vladimir Maksimenko", "Qingyao Xin", "Prateek Gupta", "Bin Zhang", "Prateek Bansal"], "title": "Large Language Models Enable Personalized Nudges to Promote Carbon Offsetting Among Air Travellers", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Nudge strategies are effective tools for promoting sustainable behaviour, but\ntheir impact depends on individual preferences. By emulating human\ndecision-making, large language models (LLMs) offer a cost-effective route for\ntailoring nudges without extensive behavioural datasets, yet this potential\nremains unexplored. Focusing on aviation, we use LLMs to design personalized\ndecoy-based nudge strategies that encourage air travellers to voluntarily\noffset CO$_2$ emissions from flights, and validate their efficacy through 3495\nsurveys from China, Germany, India, Singapore, and the United States. Results\nshow that LLM-informed personalized nudges are more effective than uniform\nsettings, raising offsetting rates by 3-7$\\%$ and yielding an additional 2.3\nmillion tonnes of CO$_2$ mitigated annually in aviation. This improvement is\ndriven primarily by increased participation among sceptical travellers with low\ntrust in offset programmes. Our study highlights the potential of LLM-driven\npersonalized nudging strategies for boosting offsetting behaviours to\naccelerate aviation decarbonization.", "AI": {"tldr": "LLMs can design personalized decoy nudges that increase CO2 offset rates by 3-7% for air travelers, primarily by engaging skeptical travelers with low trust in offset programs.", "motivation": "Nudge strategies are effective for sustainable behavior but depend on individual preferences. LLMs offer a cost-effective way to personalize nudges without extensive behavioral datasets, particularly for encouraging voluntary CO2 emission offsets in aviation.", "method": "Used LLMs to design personalized decoy-based nudge strategies for air travelers, validated through 3,495 surveys across China, Germany, India, Singapore, and the United States.", "result": "LLM-informed personalized nudges increased offsetting rates by 3-7% compared to uniform settings, translating to an additional 2.3 million tonnes of CO2 mitigated annually in aviation. The improvement was driven by increased participation among skeptical travelers with low trust in offset programs.", "conclusion": "LLM-driven personalized nudging strategies show significant potential for boosting offsetting behaviors and accelerating aviation decarbonization through targeted engagement of skeptical travelers."}}
{"id": "2508.12948", "pdf": "https://arxiv.org/pdf/2508.12948", "abs": "https://arxiv.org/abs/2508.12948", "authors": ["Wei Wei", "Shaojie Zhang", "Yonghao Dang", "Jianqin Yin"], "title": "MaskSem: Semantic-Guided Masking for Learning 3D Hybrid High-Order Motion Representation", "categories": ["cs.CV"], "comment": "Accepted to IROS 2025", "summary": "Human action recognition is a crucial task for intelligent robotics,\nparticularly within the context of human-robot collaboration research. In\nself-supervised skeleton-based action recognition, the mask-based\nreconstruction paradigm learns the spatial structure and motion patterns of the\nskeleton by masking joints and reconstructing the target from unlabeled data.\nHowever, existing methods focus on a limited set of joints and low-order motion\npatterns, limiting the model's ability to understand complex motion patterns.\nTo address this issue, we introduce MaskSem, a novel semantic-guided masking\nmethod for learning 3D hybrid high-order motion representations. This novel\nframework leverages Grad-CAM based on relative motion to guide the masking of\njoints, which can be represented as the most semantically rich temporal\norgions. The semantic-guided masking process can encourage the model to explore\nmore discriminative features. Furthermore, we propose using hybrid high-order\nmotion as the reconstruction target, enabling the model to learn multi-order\nmotion patterns. Specifically, low-order motion velocity and high-order motion\nacceleration are used together as the reconstruction target. This approach\noffers a more comprehensive description of the dynamic motion process,\nenhancing the model's understanding of motion patterns. Experiments on the\nNTU60, NTU120, and PKU-MMD datasets show that MaskSem, combined with a vanilla\ntransformer, improves skeleton-based action recognition, making it more\nsuitable for applications in human-robot interaction.", "AI": {"tldr": "MaskSem is a semantic-guided masking method for self-supervised skeleton-based action recognition that uses Grad-CAM to identify semantically rich joints and reconstructs hybrid high-order motion patterns (velocity + acceleration) to better understand complex human motions.", "motivation": "Existing self-supervised skeleton-based action recognition methods focus on limited joints and low-order motion patterns, which restricts their ability to understand complex human motion patterns needed for effective human-robot collaboration.", "method": "Proposes MaskSem framework that uses Grad-CAM based on relative motion to guide joint masking of semantically rich temporal regions, and reconstructs hybrid high-order motion targets combining low-order velocity and high-order acceleration.", "result": "Experiments on NTU60, NTU120, and PKU-MMD datasets show that MaskSem combined with a vanilla transformer improves skeleton-based action recognition performance.", "conclusion": "The semantic-guided masking and hybrid high-order motion reconstruction approach enhances motion pattern understanding, making it more suitable for human-robot interaction applications."}}
{"id": "2508.12063", "pdf": "https://arxiv.org/pdf/2508.12063", "abs": "https://arxiv.org/abs/2508.12063", "authors": ["Denisa Martonov\u00e1", "Alain Goriely", "Ellen Kuhl"], "title": "Generalized invariants meet constitutive neural networks: A novel framework for hyperelastic materials", "categories": ["cond-mat.soft", "cs.AI"], "comment": null, "summary": "The major challenge in determining a hyperelastic model for a given material\nis the choice of invariants and the selection how the strain energy function\ndepends functionally on these invariants. Here we introduce a new data-driven\nframework that simultaneously discovers appropriate invariants and constitutive\nmodels for isotropic incompressible hyperelastic materials. Our approach\nidentifies both the most suitable invariants in a class of generalized\ninvariants and the corresponding strain energy function directly from\nexperimental observations. Unlike previous methods that rely on fixed invariant\nchoices or sequential fitting procedures, our method integrates the discovery\nprocess into a single neural network architecture. By looking at a continuous\nfamily of possible invariants, the model can flexibly adapt to different\nmaterial behaviors. We demonstrate the effectiveness of this approach using\npopular benchmark datasets for rubber and brain tissue. For rubber, the method\nrecovers a stretch-dominated formulation consistent with classical models. For\nbrain tissue, it identifies a formulation sensitive to small stretches,\ncapturing the nonlinear shear response characteristic of soft biological\nmatter. Compared to traditional and neural-network-based models, our framework\nprovides improved predictive accuracy and interpretability across a wide range\nof deformation states. This unified strategy offers a robust tool for automated\nand physically meaningful model discovery in hyperelasticity.", "AI": {"tldr": "A new data-driven framework that simultaneously discovers optimal invariants and constitutive models for isotropic incompressible hyperelastic materials using neural networks.", "motivation": "Traditional methods face challenges in choosing appropriate invariants and strain energy functions for hyperelastic materials, requiring manual selection and sequential fitting procedures.", "method": "Integrated neural network architecture that explores a continuous family of generalized invariants and learns the strain energy function directly from experimental data in a unified process.", "result": "Successfully recovered stretch-dominated formulation for rubber (consistent with classical models) and identified small-stretch sensitive formulation for brain tissue capturing nonlinear shear response. Achieved improved predictive accuracy and interpretability compared to traditional and neural-network-based models.", "conclusion": "The framework provides a robust, automated tool for physically meaningful model discovery in hyperelasticity that adapts flexibly to different material behaviors."}}
{"id": "2508.12957", "pdf": "https://arxiv.org/pdf/2508.12957", "abs": "https://arxiv.org/abs/2508.12957", "authors": ["Yizhou Liu", "Jingwei Wei", "Zizhi Chen", "Minghao Han", "Xukun Zhang", "Keliang Liu", "Lihua Zhang"], "title": "Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination", "categories": ["cs.CV"], "comment": null, "summary": "Reinforcement learning (RL) with rule-based rewards has demonstrated strong\npotential in enhancing the reasoning and generalization capabilities of\nvision-language models (VLMs) and large language models (LLMs), while reducing\ncomputational overhead. However, its application in medical imaging remains\nunderexplored. Existing reinforcement fine-tuning (RFT) approaches in this\ndomain primarily target closed-ended visual question answering (VQA), limiting\ntheir applicability to real-world clinical reasoning. In contrast, open-ended\nmedical VQA better reflects clinical practice but has received limited\nattention. While some efforts have sought to unify both formats via\nsemantically guided RL, we observe that model-based semantic rewards often\nsuffer from reward collapse, where responses with significant semantic\ndifferences receive similar scores. To address this, we propose ARMed (Adaptive\nReinforcement for Medical Reasoning), a novel RL framework for open-ended\nmedical VQA. ARMed first incorporates domain knowledge through supervised\nfine-tuning (SFT) on chain-of-thought data, then applies reinforcement learning\nwith textual correctness and adaptive semantic rewards to enhance reasoning\nquality. We evaluate ARMed on six challenging medical VQA benchmarks. Results\nshow that ARMed consistently boosts both accuracy and generalization, achieving\na 32.64% improvement on in-domain tasks and an 11.65% gain on out-of-domain\nbenchmarks. These results highlight the critical role of reward\ndiscriminability in medical RL and the promise of semantically guided rewards\nfor enabling robust and clinically meaningful multimodal reasoning.", "AI": {"tldr": "ARMed is a novel RL framework for open-ended medical VQA that addresses reward collapse by combining domain knowledge through SFT with adaptive semantic rewards, achieving significant improvements in accuracy and generalization.", "motivation": "Existing reinforcement fine-tuning approaches in medical imaging primarily target closed-ended VQA, limiting real-world clinical applicability. Open-ended medical VQA better reflects clinical practice but suffers from reward collapse where semantically different responses receive similar scores.", "method": "ARMed first incorporates domain knowledge through supervised fine-tuning on chain-of-thought data, then applies reinforcement learning with textual correctness and adaptive semantic rewards to enhance reasoning quality.", "result": "ARMed achieves a 32.64% improvement on in-domain tasks and an 11.65% gain on out-of-domain benchmarks across six challenging medical VQA benchmarks.", "conclusion": "The results highlight the critical role of reward discriminability in medical RL and demonstrate the promise of semantically guided rewards for enabling robust and clinically meaningful multimodal reasoning."}}
{"id": "2508.12962", "pdf": "https://arxiv.org/pdf/2508.12962", "abs": "https://arxiv.org/abs/2508.12962", "authors": ["Dominic LaBella", "Keshav Jha", "Jared Robbins", "Esther Yu"], "title": "Multi-Phase Automated Segmentation of Dental Structures in CBCT Using a Lightweight Auto3DSeg and SegResNet Implementation", "categories": ["cs.CV", "cs.AI"], "comment": "MICCAI. ToothFairy3, 16 pages, 5 figures, 1 table", "summary": "Cone-beam computed tomography (CBCT) has become an invaluable imaging\nmodality in dentistry, enabling 3D visualization of teeth and surrounding\nstructures for diagnosis and treatment planning. Automated segmentation of\ndental structures in CBCT can efficiently assist in identifying pathology\n(e.g., pulpal or periapical lesions) and facilitate radiation therapy planning\nin head and neck cancer patients. We describe the DLaBella29 team's approach\nfor the MICCAI 2025 ToothFairy3 Challenge, which involves a deep learning\npipeline for multi-class tooth segmentation. We utilized the MONAI Auto3DSeg\nframework with a 3D SegResNet architecture, trained on a subset of the\nToothFairy3 dataset (63 CBCT scans) with 5-fold cross-validation. Key\npreprocessing steps included image resampling to 0.6 mm isotropic resolution\nand intensity clipping. We applied an ensemble fusion using Multi-Label STAPLE\non the 5-fold predictions to infer a Phase 1 segmentation and then conducted\ntight cropping around the easily segmented Phase 1 mandible to perform Phase 2\nsegmentation on the smaller nerve structures. Our method achieved an average\nDice of 0.87 on the ToothFairy3 challenge out-of-sample validation set. This\npaper details the clinical context, data preparation, model development,\nresults of our approach, and discusses the relevance of automated dental\nsegmentation for improving patient care in radiation oncology.", "AI": {"tldr": "Deep learning pipeline using 3D SegResNet architecture for automated multi-class tooth segmentation in dental CBCT scans, achieving 0.87 Dice score on validation data.", "motivation": "Automated segmentation of dental structures in CBCT can assist in identifying pathology and facilitate radiation therapy planning for head and neck cancer patients.", "method": "Used MONAI Auto3DSeg framework with 3D SegResNet, trained on 63 CBCT scans with 5-fold cross-validation. Preprocessing included image resampling and intensity clipping. Two-phase approach with ensemble fusion using Multi-Label STAPLE.", "result": "Achieved an average Dice score of 0.87 on the ToothFairy3 challenge out-of-sample validation set.", "conclusion": "The approach demonstrates effective automated dental segmentation that can improve patient care in radiation oncology through efficient identification of dental structures and pathology."}}
{"id": "2508.11741", "pdf": "https://arxiv.org/pdf/2508.11741", "abs": "https://arxiv.org/abs/2508.11741", "authors": ["Habibolla Latifizadeh", "Anika C. Pirkey", "Alanna Gould", "David J. Klinke II"], "title": "BaMANI: Bayesian Multi-Algorithm causal Network Inference", "categories": ["stat.ML", "cs.LG", "q-bio.QM"], "comment": "12 pages, 6 figures", "summary": "Improved computational power has enabled different disciplines to predict\ncausal relationships among modeled variables using Bayesian network inference.\nWhile many alternative algorithms have been proposed to improve the efficiency\nand reliability of network prediction, the predicted causal networks reflect\nthe generative process but also bear an opaque imprint of the specific\ncomputational algorithm used. Following a ``wisdom of the crowds\" strategy, we\ndeveloped an ensemble learning approach to marginalize the impact of a single\nalgorithm on Bayesian causal network inference. To introduce the approach, we\nfirst present the theoretical foundation of this framework. Next, we present a\ncomprehensive implementation of the framework in terms of a new software tool\ncalled BaMANI (Bayesian Multi-Algorithm causal Network Inference). Finally, we\ndescribe a BaMANI use-case from biology, particularly within human breast\ncancer studies.", "AI": {"tldr": "An ensemble learning approach called BaMANI that combines multiple Bayesian network inference algorithms to reduce algorithm-specific biases and improve causal network prediction reliability.", "motivation": "Bayesian causal network inference algorithms produce results that reflect both the underlying generative process and the specific computational algorithm used, creating algorithm-dependent biases that affect reliability.", "method": "Developed BaMANI (Bayesian Multi-Algorithm causal Network Inference) - an ensemble learning framework that marginalizes the impact of individual algorithms by combining predictions from multiple Bayesian network inference algorithms.", "result": "The approach provides a software tool implementation and demonstrates its application in human breast cancer studies, showing improved reliability in causal network inference.", "conclusion": "Ensemble learning through BaMANI effectively reduces algorithm-specific biases in Bayesian causal network inference, providing more robust and reliable predictions for scientific applications like cancer research."}}
{"id": "2508.12966", "pdf": "https://arxiv.org/pdf/2508.12966", "abs": "https://arxiv.org/abs/2508.12966", "authors": ["Ryan Anthony Jalova de Belen", "Gelareh Mohammadi", "Arcot Sowmya"], "title": "GazeDETR: Gaze Detection using Disentangled Head and Gaze Representations", "categories": ["cs.CV"], "comment": null, "summary": "Gaze communication plays a crucial role in daily social interactions.\nQuantifying this behavior can help in human-computer interaction and digital\nphenotyping. While end-to-end models exist for gaze target detection, they only\nutilize a single decoder to simultaneously localize human heads and predict\ntheir corresponding gaze (e.g., 2D points or heatmap) in a scene. This\nmultitask learning approach generates a unified and entangled representation\nfor human head localization and gaze location prediction. Herein, we propose\nGazeDETR, a novel end-to-end architecture with two disentangled decoders that\nindividually learn unique representations and effectively utilize coherent\nattentive fields for each subtask. More specifically, we demonstrate that its\nhuman head predictor utilizes local information, while its gaze decoder\nincorporates both local and global information. Our proposed architecture\nachieves state-of-the-art results on the GazeFollow, VideoAttentionTarget and\nChildPlay datasets. It outperforms existing end-to-end models with a notable\nmargin.", "AI": {"tldr": "GazeDETR is a novel end-to-end architecture with two disentangled decoders that separately handle human head localization and gaze prediction, achieving state-of-the-art results on multiple datasets.", "motivation": "Existing end-to-end gaze target detection models use a single decoder that creates entangled representations for both head localization and gaze prediction, which limits performance. There's a need for disentangled learning to better handle these distinct subtasks.", "method": "Proposed GazeDETR architecture with two separate decoders - one for human head prediction (using local information) and another for gaze prediction (using both local and global information). The decoders utilize coherent attentive fields optimized for each specific subtask.", "result": "Achieves state-of-the-art results on GazeFollow, VideoAttentionTarget, and ChildPlay datasets. Outperforms existing end-to-end models by a notable margin.", "conclusion": "Disentangling the learning process with specialized decoders for head localization and gaze prediction significantly improves performance over single-decoder approaches, demonstrating the importance of task-specific representation learning in gaze communication analysis."}}
{"id": "2508.12969", "pdf": "https://arxiv.org/pdf/2508.12969", "abs": "https://arxiv.org/abs/2508.12969", "authors": ["Qirui Li", "Guangcong Zheng", "Qi Zhao", "Jie Li", "Bin Dong", "Yiwu Yao", "Xi Li"], "title": "Compact Attention: Exploiting Structured Spatio-Temporal Sparsity for Fast Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "The computational demands of self-attention mechanisms pose a critical\nchallenge for transformer-based video generation, particularly in synthesizing\nultra-long sequences. Current approaches, such as factorized attention and\nfixed sparse patterns, fail to fully exploit the inherent spatio-temporal\nredundancies in video data. Through systematic analysis of video diffusion\ntransformers (DiT), we uncover a key insight: Attention matrices exhibit\nstructured, yet heterogeneous sparsity patterns, where specialized heads\ndynamically attend to distinct spatiotemporal regions (e.g., local pattern,\ncross-shaped pattern, or global pattern). Existing sparse attention methods\neither impose rigid constraints or introduce significant overhead, limiting\ntheir effectiveness. To address this, we propose Compact Attention, a\nhardware-aware acceleration framework featuring three innovations: 1) Adaptive\ntiling strategies that approximate diverse spatial interaction patterns via\ndynamic tile grouping, 2) Temporally varying windows that adjust sparsity\nlevels based on frame proximity, and 3) An automated configuration search\nalgorithm that optimizes sparse patterns while preserving critical attention\npathways. Our method achieves 1.6~2.5x acceleration in attention computation on\nsingle-GPU setups while maintaining comparable visual quality with\nfull-attention baselines. This work provides a principled approach to unlocking\nefficient long-form video generation through structured sparsity exploitation.\nProject Page: https://yo-ava.github.io/Compact-Attention.github.io/", "AI": {"tldr": "Compact Attention is a hardware-aware acceleration framework that uses adaptive tiling and temporally varying windows to exploit structured sparsity patterns in video diffusion transformers, achieving 1.6-2.5x speedup while maintaining visual quality.", "motivation": "Self-attention mechanisms in transformer-based video generation are computationally demanding for ultra-long sequences, and existing sparse attention methods fail to fully exploit the inherent spatio-temporal redundancies in video data.", "method": "Three innovations: 1) Adaptive tiling strategies for dynamic tile grouping, 2) Temporally varying windows that adjust sparsity based on frame proximity, and 3) Automated configuration search algorithm to optimize sparse patterns while preserving critical attention pathways.", "result": "Achieves 1.6~2.5x acceleration in attention computation on single-GPU setups while maintaining comparable visual quality with full-attention baselines.", "conclusion": "Provides a principled approach to efficient long-form video generation through structured sparsity exploitation, unlocking better performance for video diffusion transformers."}}
{"id": "2508.11784", "pdf": "https://arxiv.org/pdf/2508.11784", "abs": "https://arxiv.org/abs/2508.11784", "authors": ["Zabir Al Nazi", "Vagelis Hristidis", "Aaron Lawson McLean", "Jannat Ara Meem", "Md Taukir Azam Chowdhury"], "title": "Ontology-Guided Query Expansion for Biomedical Document Retrieval using Large Language Models", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Effective Question Answering (QA) on large biomedical document collections\nrequires effective document retrieval techniques. The latter remains a\nchallenging task due to the domain-specific vocabulary and semantic ambiguity\nin user queries. We propose BMQExpander, a novel ontology-aware query expansion\npipeline that combines medical knowledge - definitions and relationships - from\nthe UMLS Metathesaurus with the generative capabilities of large language\nmodels (LLMs) to enhance retrieval effectiveness. We implemented several\nstate-of-the-art baselines, including sparse and dense retrievers, query\nexpansion methods, and biomedical-specific solutions. We show that BMQExpander\nhas superior retrieval performance on three popular biomedical Information\nRetrieval (IR) benchmarks: NFCorpus, TREC-COVID, and SciFact - with\nimprovements of up to 22.1% in NDCG@10 over sparse baselines and up to 6.5%\nover the strongest baseline. Further, BMQExpander generalizes robustly under\nquery perturbation settings, in contrast to supervised baselines, achieving up\nto 15.7% improvement over the strongest baseline. As a side contribution, we\npublish our paraphrased benchmarks. Finally, our qualitative analysis shows\nthat BMQExpander has fewer hallucinations compared to other LLM-based query\nexpansion baselines.", "AI": {"tldr": "BMQExpander is an ontology-aware query expansion pipeline that combines UMLS medical knowledge with LLMs to improve biomedical document retrieval, achieving up to 22.1% improvement over sparse baselines and demonstrating robust generalization.", "motivation": "Biomedical QA requires effective document retrieval, which is challenging due to domain-specific vocabulary and semantic ambiguity in user queries.", "method": "Proposes BMQExpander - a pipeline combining UMLS Metathesaurus medical knowledge (definitions and relationships) with LLM generative capabilities for query expansion. Implemented various baselines including sparse/dense retrievers and biomedical-specific solutions.", "result": "Superior performance on NFCorpus, TREC-COVID, and SciFact benchmarks: up to 22.1% improvement in NDCG@10 over sparse baselines and 6.5% over strongest baseline. Robust generalization under query perturbation (15.7% improvement). Fewer hallucinations compared to other LLM-based methods.", "conclusion": "BMQExpander effectively enhances biomedical retrieval by combining structured medical knowledge with LLMs, demonstrating significant performance improvements and better generalization than supervised approaches."}}
{"id": "2508.12977", "pdf": "https://arxiv.org/pdf/2508.12977", "abs": "https://arxiv.org/abs/2508.12977", "authors": ["Rohan Asthana", "Joschua Conrad", "Maurits Ortmanns", "Vasileios Belagiannis"], "title": "Dextr: Zero-Shot Neural Architecture Search with Singular Value Decomposition and Extrinsic Curvature", "categories": ["cs.CV"], "comment": "Accepted at Transactions on Machine Learning Research (TMLR)", "summary": "Zero-shot Neural Architecture Search (NAS) typically optimises the\narchitecture search process by exploiting the network or gradient properties at\ninitialisation through zero-cost proxies. The existing proxies often rely on\nlabelled data, which is usually unavailable in real-world settings.\nFurthermore, the majority of the current methods focus either on optimising the\nconvergence and generalisation attributes or solely on the expressivity of the\nnetwork architectures. To address both limitations, we first demonstrate how\nchannel collinearity affects the convergence and generalisation properties of a\nneural network. Then, by incorporating the convergence, generalisation and\nexpressivity in one approach, we propose a zero-cost proxy that omits the\nrequirement of labelled data for its computation. In particular, we leverage\nthe Singular Value Decomposition (SVD) of the neural network layer features and\nthe extrinsic curvature of the network output to design our proxy. %As a\nresult, the proposed proxy is formulated as the simplified harmonic mean of the\nlogarithms of two key components: the sum of the inverse of the feature\ncondition number and the extrinsic curvature of the network output. Our\napproach enables accurate prediction of network performance on test data using\nonly a single label-free data sample. Our extensive evaluation includes a total\nof six experiments, including the Convolutional Neural Network (CNN) search\nspace, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The\nproposed proxy demonstrates a superior performance on multiple correlation\nbenchmarks, including NAS-Bench-101, NAS-Bench-201, and\nTransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the\nAutoFormer search space, all while being notably efficient. The code is\navailable at https://github.com/rohanasthana/Dextr.", "AI": {"tldr": "A zero-cost NAS proxy that uses SVD and extrinsic curvature to predict neural network performance without labeled data, achieving superior correlation and efficiency across multiple benchmarks.", "motivation": "Existing zero-shot NAS proxies require labeled data and focus either on convergence/generalization or expressivity alone, but not both simultaneously in a label-free manner.", "method": "Proposes a zero-cost proxy using Singular Value Decomposition (SVD) of layer features and extrinsic curvature of network output, formulated as a simplified harmonic mean of logarithms of feature condition number and curvature components.", "result": "Superior performance on multiple correlation benchmarks (NAS-Bench-101, NAS-Bench-201, TransNAS-Bench-101-micro) and NAS tasks in DARTS and AutoFormer search spaces, using only a single label-free data sample.", "conclusion": "The proposed proxy successfully combines convergence, generalization, and expressivity in a label-free approach, demonstrating high accuracy and efficiency in neural architecture search."}}
{"id": "2508.13000", "pdf": "https://arxiv.org/pdf/2508.13000", "abs": "https://arxiv.org/abs/2508.13000", "authors": ["Zhangyong Tang", "Tianyang Xu", "Xuefeng Zhu", "Hui Li", "Shaochuan Zhao", "Tao Zhou", "Chunyang Cheng", "Xiaojun Wu", "Josef Kittler"], "title": "Omni Survey for Multimodality Analysis in Visual Object Tracking", "categories": ["cs.CV"], "comment": "The first comprehensive survey for multi-modal visual object\n  tracking; 6 multi-modal tasks; 338 references", "summary": "The development of smart cities has led to the generation of massive amounts\nof multi-modal data in the context of a range of tasks that enable a\ncomprehensive monitoring of the smart city infrastructure and services. This\npaper surveys one of the most critical tasks, multi-modal visual object\ntracking (MMVOT), from the perspective of multimodality analysis. Generally,\nMMVOT differs from single-modal tracking in four key aspects, data collection,\nmodality alignment and annotation, model designing, and evaluation.\nAccordingly, we begin with an introduction to the relevant data modalities,\nlaying the groundwork for their integration. This naturally leads to a\ndiscussion of challenges of multi-modal data collection, alignment, and\nannotation. Subsequently, existing MMVOT methods are categorised, based on\ndifferent ways to deal with visible (RGB) and X modalities: programming the\nauxiliary X branch with replicated or non-replicated experimental\nconfigurations from the RGB branch. Here X can be thermal infrared (T), depth\n(D), event (E), near infrared (NIR), language (L), or sonar (S). The final part\nof the paper addresses evaluation and benchmarking. In summary, we undertake an\nomni survey of all aspects of multi-modal visual object tracking (VOT),\ncovering six MMVOT tasks and featuring 338 references in total. In addition, we\ndiscuss the fundamental rhetorical question: Is multi-modal tracking always\nguaranteed to provide a superior solution to unimodal tracking with the help of\ninformation fusion, and if not, in what circumstances its application is\nbeneficial. Furthermore, for the first time in this field, we analyse the\ndistributions of the object categories in the existing MMVOT datasets,\nrevealing their pronounced long-tail nature and a noticeable lack of animal\ncategories when compared with RGB datasets.", "AI": {"tldr": "A comprehensive survey of multi-modal visual object tracking (MMVOT) covering data collection, modality alignment, method categorization, evaluation, and analysis of 6 MMVOT tasks with 338 references.", "motivation": "The rapid development of smart cities has generated massive multi-modal data, creating a need to understand and advance multi-modal visual object tracking techniques for comprehensive urban monitoring.", "method": "The paper categorizes MMVOT methods based on how they handle visible (RGB) and auxiliary modalities (thermal, depth, event, NIR, language, sonar), analyzing data collection challenges, modality alignment, and annotation issues.", "result": "The survey covers six MMVOT tasks, reveals long-tail distribution of object categories in existing datasets with noticeable lack of animal categories compared to RGB datasets, and questions when multi-modal tracking actually provides superior performance.", "conclusion": "This comprehensive analysis provides foundational insights into MMVOT challenges and opportunities, highlighting the need for better dataset balance and understanding of when multi-modal fusion truly enhances tracking performance over single-modal approaches."}}
{"id": "2508.11818", "pdf": "https://arxiv.org/pdf/2508.11818", "abs": "https://arxiv.org/abs/2508.11818", "authors": ["Zhifeng Kong", "Arushi Goel", "Joao Felipe Santos", "Sreyan Ghosh", "Rafael Valle", "Wei Ping", "Bryan Catanzaro"], "title": "Audio Flamingo Sound-CoT Technical Report: Improving Chain-of-Thought Reasoning in Sound Understanding", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Chain-of-thought reasoning has demonstrated significant improvements in large\nlanguage models and vision language models, yet its potential for audio\nlanguage models remains largely unexplored. In this technical report, we take a\npreliminary step towards closing this gap. For better assessment of sound\nreasoning, we propose AF-Reasoning-Eval, a benchmark targeting common-sense\nreasoning and the ability to discriminate among closely related choices. To\nprepare training corpus for sound reasoning abilities, we propose automatic\npipelines that transform existing audio question answering and classification\ndata into explicit reasoning chains, yielding AF-CoT-Train with 1.24M samples.\nWe study the effect of finetuning Audio Flamingo series on AF-CoT-Train and\nobserve considerable improvements on several reasoning benchmarks, validating\nthe effectiveness of chain-of-thought finetuning on advanced sound\nunderstanding.", "AI": {"tldr": "This paper explores chain-of-thought reasoning for audio language models, proposing a new benchmark (AF-Reasoning-Eval) and training dataset (AF-CoT-Train) that significantly improves audio reasoning capabilities.", "motivation": "Chain-of-thought reasoning has shown great success in language and vision models, but its potential for audio language models remains unexplored. The authors aim to bridge this gap by developing specialized benchmarks and training data for sound reasoning.", "method": "Proposed AF-Reasoning-Eval benchmark for sound reasoning assessment, created automatic pipelines to transform existing audio QA/classification data into explicit reasoning chains (AF-CoT-Train with 1.24M samples), and finetuned Audio Flamingo models on this data.", "result": "Considerable improvements observed on several reasoning benchmarks after finetuning Audio Flamingo series on AF-CoT-Train, validating the effectiveness of chain-of-thought finetuning for advanced sound understanding.", "conclusion": "Chain-of-thought finetuning is effective for enhancing audio language models' reasoning capabilities, and the proposed benchmarks and training data successfully address the previously unexplored area of sound reasoning in multimodal models."}}
{"id": "2508.13005", "pdf": "https://arxiv.org/pdf/2508.13005", "abs": "https://arxiv.org/abs/2508.13005", "authors": ["Jiawen Xu", "Odej Kao"], "title": "Empirical Evidences for the Effects of Feature Diversity in Open Set Recognition and Continual Learning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Open set recognition (OSR) and continual learning are two critical challenges\nin machine learning, focusing respectively on detecting novel classes at\ninference time and updating models to incorporate the new classes. While many\nrecent approaches have addressed these problems, particularly OSR, by\nheuristically promoting feature diversity, few studies have directly examined\nthe role that feature diversity plays in tackling them. In this work, we\nprovide empirical evidence that enhancing feature diversity improves the\nrecognition of open set samples. Moreover, increased feature diversity also\nfacilitates both the retention of previously learned data and the integration\nof new data in continual learning. We hope our findings can inspire further\nresearch into both practical methods and theoretical understanding in these\ndomains.", "AI": {"tldr": "Feature diversity improves open set recognition and continual learning performance by enhancing novel class detection and knowledge retention.", "motivation": "To empirically investigate the role of feature diversity in addressing open set recognition (detecting novel classes) and continual learning (updating models with new classes), as most existing approaches use heuristic methods without directly examining feature diversity's impact.", "method": "The study provides empirical evidence through experiments showing that enhancing feature diversity improves recognition of open set samples and facilitates both retention of previously learned data and integration of new data in continual learning scenarios.", "result": "Increased feature diversity was found to significantly improve open set sample recognition and enhance performance in continual learning tasks, including better retention of old knowledge and integration of new knowledge.", "conclusion": "Feature diversity plays a crucial role in both open set recognition and continual learning, and these findings should inspire further research into both practical methods and theoretical understanding in these domains."}}
{"id": "2508.13007", "pdf": "https://arxiv.org/pdf/2508.13007", "abs": "https://arxiv.org/abs/2508.13007", "authors": ["Melih Yazgan", "Qiyuan Wu", "Iramm Hamdard", "Shiqi Li", "J. Marius Zoellner"], "title": "SlimComm: Doppler-Guided Sparse Queries for Bandwidth-Efficient Cooperative 3-D Perception", "categories": ["cs.CV"], "comment": "Accepted by ICCV - Drive2X Workshop", "summary": "Collaborative perception allows connected autonomous vehicles (CAVs) to\novercome occlusion and limited sensor range by sharing intermediate features.\nYet transmitting dense Bird's-Eye-View (BEV) feature maps can overwhelm the\nbandwidth available for inter-vehicle communication. We present SlimComm, a\ncommunication-efficient framework that integrates 4D radar Doppler with a\nquery-driven sparse scheme. SlimComm builds a motion-centric dynamic map to\ndistinguish moving from static objects and generates two query types: (i)\nreference queries on dynamic and high-confidence regions, and (ii) exploratory\nqueries probing occluded areas via a two-stage offset. Only query-specific BEV\nfeatures are exchanged and fused through multi-scale gated deformable\nattention, reducing payload while preserving accuracy. For evaluation, we\nrelease OPV2V-R and Adver-City-R, CARLA-based datasets with per-point Doppler\nradar. SlimComm achieves up to 90% lower bandwidth than full-map sharing while\nmatching or surpassing prior baselines across varied traffic densities and\nocclusions. Dataset and code will be available at: https://url.fzi.de/SlimComm.", "AI": {"tldr": "SlimComm reduces communication bandwidth by 90% for collaborative perception in autonomous vehicles using 4D radar Doppler and query-driven sparse feature sharing.", "motivation": "Transmitting dense Bird's-Eye-View feature maps overwhelms bandwidth for inter-vehicle communication in collaborative autonomous driving systems.", "method": "Integrates 4D radar Doppler with query-driven sparse scheme, builds motion-centric dynamic map, generates reference queries for dynamic/high-confidence regions and exploratory queries for occluded areas, exchanges only query-specific BEV features using multi-scale gated deformable attention.", "result": "Achieves up to 90% lower bandwidth than full-map sharing while matching or surpassing prior baselines across varied traffic densities and occlusions.", "conclusion": "SlimComm provides an effective communication-efficient framework for collaborative perception that maintains accuracy while drastically reducing bandwidth requirements."}}
{"id": "2508.13009", "pdf": "https://arxiv.org/pdf/2508.13009", "abs": "https://arxiv.org/abs/2508.13009", "authors": ["Xianglong He", "Chunli Peng", "Zexiang Liu", "Boyang Wang", "Yifan Zhang", "Qi Cui", "Fei Kang", "Biao Jiang", "Mengyin An", "Yangyang Ren", "Baixin Xu", "Hao-Xiang Guo", "Kaixiong Gong", "Cyrus Wu", "Wei Li", "Xuchen Song", "Yang Liu", "Eric Li", "Yahui Zhou"], "title": "Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model", "categories": ["cs.CV"], "comment": "Project Page: https://matrix-game-v2.github.io", "summary": "Recent advances in interactive video generations have demonstrated diffusion\nmodel's potential as world models by capturing complex physical dynamics and\ninteractive behaviors. However, existing interactive world models depend on\nbidirectional attention and lengthy inference steps, severely limiting\nreal-time performance. Consequently, they are hard to simulate real-world\ndynamics, where outcomes must update instantaneously based on historical\ncontext and current actions. To address this, we present Matrix-Game 2.0, an\ninteractive world model generates long videos on-the-fly via few-step\nauto-regressive diffusion. Our framework consists of three key components: (1)\nA scalable data production pipeline for Unreal Engine and GTA5 environments to\neffectively produce massive amounts (about 1200 hours) of video data with\ndiverse interaction annotations; (2) An action injection module that enables\nframe-level mouse and keyboard inputs as interactive conditions; (3) A few-step\ndistillation based on the casual architecture for real-time and streaming video\ngeneration. Matrix Game 2.0 can generate high-quality minute-level videos\nacross diverse scenes at an ultra-fast speed of 25 FPS. We open-source our\nmodel weights and codebase to advance research in interactive world modeling.", "AI": {"tldr": "Matrix-Game 2.0 is a real-time interactive world model that generates minute-long videos at 25 FPS using few-step auto-regressive diffusion, addressing the speed limitations of previous methods.", "motivation": "Existing interactive world models suffer from slow inference due to bidirectional attention and lengthy steps, making real-time simulation of dynamic environments impossible.", "method": "Three key components: scalable data pipeline producing 1200 hours of annotated video from Unreal Engine/GTA5, action injection module for frame-level inputs, and few-step distillation with causal architecture.", "result": "Achieves high-quality minute-level video generation across diverse scenes at 25 FPS, enabling real-time interactive simulations.", "conclusion": "The framework advances interactive world modeling by enabling real-time video generation with immediate outcome updates based on historical context and current actions."}}
{"id": "2508.11847", "pdf": "https://arxiv.org/pdf/2508.11847", "abs": "https://arxiv.org/abs/2508.11847", "authors": ["Jenny Y. Huang", "Yunyi Shen", "Dennis Wei", "Tamara Broderick"], "title": "Dropping Just a Handful of Preferences Can Change Top Large Language Model Rankings", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We propose a method for evaluating the robustness of a widely used LLM\nranking system -- the Bradley--Terry ranking system -- to dropping a worst-case\nvery small fraction of evaluation data. Our approach is computationally fast\nand easy to adopt. When we apply our method to matchups from two popular\nhuman-preference platforms, Chatbot Arena and MT-Bench, we find that the\nBradley--Terry rankings of top-performing models are remarkably sensitive to\nthe removal of a small fraction of evaluations. Our framework also identifies\nthe specific evaluations most responsible for such ranking flips, allowing for\ninspections of these influential preferences. We observe that the rankings\nderived from MT-Bench preferences are notably more robust than those from\nChatbot Arena, likely due to MT-bench's use of expert annotators and carefully\nconstructed prompts. Finally, we find that rankings based on crowdsourced\nhuman-evaluated systems are just as sensitive as those based on LLM-as-a-judge\nevaluations, where in both, dropping as little as 0.02% of the total\nevaluations in the dataset can change the top-ranked model.", "AI": {"tldr": "The paper proposes a method to evaluate the robustness of Bradley-Terry ranking systems for LLMs, finding that top model rankings are highly sensitive to removing even 0.02% of evaluation data.", "motivation": "To assess how robust LLM ranking systems are to worst-case data removal, particularly for popular human-preference evaluation platforms like Chatbot Arena and MT-Bench.", "method": "A computationally fast framework that identifies influential evaluations and tests sensitivity by removing small fractions of worst-case data from Bradley-Terry ranking systems.", "result": "Top model rankings are remarkably sensitive - removing just 0.02% of evaluations can change the top-ranked model. MT-Bench rankings are more robust than Chatbot Arena due to expert annotators and better prompts.", "conclusion": "Current LLM ranking systems are highly fragile, and careful evaluation design (like expert annotations) improves robustness, but both human-evaluated and LLM-judge systems show similar sensitivity issues."}}
{"id": "2508.12138", "pdf": "https://arxiv.org/pdf/2508.12138", "abs": "https://arxiv.org/abs/2508.12138", "authors": ["Mohammad Ishzaz Asif Rafid", "Morsalin Sakib"], "title": "Substituting Proof of Work in Blockchain with Training-Verified Collaborative Model Computation", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Bitcoin's Proof of Work (PoW) mechanism, while central to achieving\ndecentralized consensus, has long been criticized for excessive energy use and\nhardware inefficiencies \\cite{devries2018bitcoin, truby2018decarbonizing}. This\npaper introduces a hybrid architecture that replaces Bitcoin's traditional PoW\nwith a centralized, cloud-based collaborative training framework. In this\nmodel, miners contribute computing resources to train segments of horizontally\nscaled machine learning models on preprocessed datasets, ensuring privacy and\ngenerating meaningful outputs \\cite{li2017securing}. A central server evaluates\ncontributions using two metrics: number of parameters trained and reduction in\nmodel loss during each cycle. At the end of every cycle, a weighted lottery\nselects the winning miner, who receives a digitally signed certificate. This\ncertificate serves as a verifiable substitute for PoW and grants the right to\nappend a block to the blockchain \\cite{nakamoto2008bitcoin}. By integrating\ndigital signatures and SHA-256 hashing \\cite{nist2015sha}, the system preserves\nblockchain integrity while redirecting energy toward productive computation.\nThe proposed approach addresses the sustainability concerns of traditional\nmining by converting resource expenditure into socially valuable work, aligning\nsecurity incentives with real-world computational progress.", "AI": {"tldr": "Hybrid architecture replaces Bitcoin's PoW with cloud-based collaborative ML training, where miners train model segments and get certificates based on contribution quality instead of solving cryptographic puzzles.", "motivation": "Address Bitcoin's excessive energy consumption and hardware inefficiencies in traditional Proof of Work mining by redirecting computational resources toward productive machine learning tasks.", "method": "Centralized cloud framework where miners contribute computing resources to train segments of horizontally scaled ML models. Central server evaluates contributions using parameter count and loss reduction metrics, then conducts weighted lottery to select winning miner who receives digitally signed certificate as PoW substitute.", "result": "System preserves blockchain integrity through digital signatures and SHA-256 hashing while converting mining energy expenditure into socially valuable computational work through ML model training.", "conclusion": "Proposed approach addresses sustainability concerns by aligning security incentives with real-world computational progress, making cryptocurrency mining more energy-efficient and productive."}}
{"id": "2508.13013", "pdf": "https://arxiv.org/pdf/2508.13013", "abs": "https://arxiv.org/abs/2508.13013", "authors": ["Jingqiao Xiu", "Fangzhou Hong", "Yicong Li", "Mengze Li", "Wentao Wang", "Sirui Han", "Liang Pan", "Ziwei Liu"], "title": "EgoTwin: Dreaming Body and View in First Person", "categories": ["cs.CV"], "comment": null, "summary": "While exocentric video synthesis has achieved great progress, egocentric\nvideo generation remains largely underexplored, which requires modeling\nfirst-person view content along with camera motion patterns induced by the\nwearer's body movements. To bridge this gap, we introduce a novel task of joint\negocentric video and human motion generation, characterized by two key\nchallenges: 1) Viewpoint Alignment: the camera trajectory in the generated\nvideo must accurately align with the head trajectory derived from human motion;\n2) Causal Interplay: the synthesized human motion must causally align with the\nobserved visual dynamics across adjacent video frames. To address these\nchallenges, we propose EgoTwin, a joint video-motion generation framework built\non the diffusion transformer architecture. Specifically, EgoTwin introduces a\nhead-centric motion representation that anchors the human motion to the head\njoint and incorporates a cybernetics-inspired interaction mechanism that\nexplicitly captures the causal interplay between video and motion within\nattention operations. For comprehensive evaluation, we curate a large-scale\nreal-world dataset of synchronized text-video-motion triplets and design novel\nmetrics to assess video-motion consistency. Extensive experiments demonstrate\nthe effectiveness of the EgoTwin framework.", "AI": {"tldr": "EgoTwin is a joint egocentric video and human motion generation framework that addresses viewpoint alignment and causal interplay challenges using diffusion transformers with head-centric motion representation and cybernetics-inspired interaction.", "motivation": "Egocentric video generation remains underexplored compared to exocentric synthesis, requiring modeling of first-person view content with camera motion patterns from body movements, creating a need for joint video-motion generation.", "method": "Proposes EgoTwin framework built on diffusion transformer architecture with head-centric motion representation (anchoring motion to head joint) and cybernetics-inspired interaction mechanism that captures causal interplay between video and motion within attention operations.", "result": "Extensive experiments demonstrate effectiveness of EgoTwin framework, supported by a curated large-scale real-world dataset of synchronized text-video-motion triplets and novel metrics for video-motion consistency evaluation.", "conclusion": "EgoTwin successfully bridges the gap in egocentric video generation by addressing key challenges of viewpoint alignment and causal interplay through innovative motion representation and interaction mechanisms."}}
{"id": "2508.11848", "pdf": "https://arxiv.org/pdf/2508.11848", "abs": "https://arxiv.org/abs/2508.11848", "authors": ["Pouya Kananian", "Hans-Arno Jacobsen"], "title": "Adversarial Robustness in Distributed Quantum Machine Learning", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": "This is a preprint of a book chapter that is planned to be published\n  in \"Quantum Robustness in Artificial Intelligence\" by Springer Nature", "summary": "Studying adversarial robustness of quantum machine learning (QML) models is\nessential in order to understand their potential advantages over classical\nmodels and build trustworthy systems. Distributing QML models allows leveraging\nmultiple quantum processors to overcome the limitations of individual devices\nand build scalable systems. However, this distribution can affect their\nadversarial robustness, potentially making them more vulnerable to new attacks.\nKey paradigms in distributed QML include federated learning, which, similar to\nclassical models, involves training a shared model on local data and sending\nonly the model updates, as well as circuit distribution methods inherent to\nquantum computing, such as circuit cutting and teleportation-based techniques.\nThese quantum-specific methods enable the distributed execution of quantum\ncircuits across multiple devices. This work reviews the differences between\nthese distribution methods, summarizes existing approaches on the adversarial\nrobustness of QML models when distributed using each paradigm, and discusses\nopen questions in this area.", "AI": {"tldr": "This paper reviews how different distribution methods (federated learning and quantum-specific techniques like circuit cutting/teleportation) affect the adversarial robustness of distributed quantum machine learning models, highlighting vulnerabilities and open research questions.", "motivation": "Understanding adversarial robustness is crucial for building trustworthy quantum ML systems, and distribution across multiple quantum processors introduces new attack surfaces that could compromise model security.", "method": "The paper conducts a comprehensive review and analysis of existing approaches, comparing federated learning with quantum-specific distribution methods (circuit cutting and teleportation-based techniques) and their impact on adversarial robustness.", "result": "Distribution of QML models can introduce new vulnerabilities and attack vectors, making the systems potentially more susceptible to adversarial attacks compared to centralized implementations.", "conclusion": "There are significant open questions regarding the security implications of distributed QML paradigms, and further research is needed to understand and mitigate adversarial threats in these distributed quantum computing architectures."}}
{"id": "2508.13026", "pdf": "https://arxiv.org/pdf/2508.13026", "abs": "https://arxiv.org/abs/2508.13026", "authors": ["Ruru Xu", "Ilkay Oksuz"], "title": "HierAdaptMR: Cross-Center Cardiac MRI Reconstruction with Hierarchical Feature Adapters", "categories": ["cs.CV"], "comment": "MICCAI 2025, CMRxRecon2025 Challenge paper", "summary": "Deep learning-based cardiac MRI reconstruction faces significant domain shift\nchallenges when deployed across multiple clinical centers with heterogeneous\nscanner configurations and imaging protocols. We propose HierAdaptMR, a\nhierarchical feature adaptation framework that addresses multi-level domain\nvariations through parameter-efficient adapters. Our method employs\nProtocol-Level Adapters for sequence-specific characteristics and Center-Level\nAdapters for scanner-dependent variations, built upon a variational unrolling\nbackbone. A Universal Adapter enables generalization to entirely unseen centers\nthrough stochastic training that learns center-invariant adaptations. The\nframework utilizes multi-scale SSIM loss with frequency domain enhancement and\ncontrast-adaptive weighting for robust optimization. Comprehensive evaluation\non the CMRxRecon2025 dataset spanning 5+ centers, 10+ scanners, and 9\nmodalities demonstrates superior cross-center generalization while maintaining\nreconstruction quality. code: https://github.com/Ruru-Xu/HierAdaptMR", "AI": {"tldr": "HierAdaptMR is a hierarchical feature adaptation framework for cardiac MRI reconstruction that addresses multi-level domain variations across clinical centers using parameter-efficient adapters for protocol-level and center-level variations, with a universal adapter for unseen centers.", "motivation": "Deep learning-based cardiac MRI reconstruction faces significant domain shift challenges when deployed across multiple clinical centers with heterogeneous scanner configurations and imaging protocols, requiring robust cross-center generalization.", "method": "Uses hierarchical adapters: Protocol-Level Adapters for sequence-specific characteristics, Center-Level Adapters for scanner-dependent variations, and a Universal Adapter for unseen centers through stochastic training. Built on variational unrolling backbone with multi-scale SSIM loss, frequency domain enhancement, and contrast-adaptive weighting.", "result": "Comprehensive evaluation on CMRxRecon2025 dataset spanning 5+ centers, 10+ scanners, and 9 modalities demonstrates superior cross-center generalization while maintaining reconstruction quality.", "conclusion": "HierAdaptMR effectively addresses multi-level domain variations in cardiac MRI reconstruction through parameter-efficient hierarchical adaptation, enabling robust performance across diverse clinical centers and scanner configurations."}}
{"id": "2508.13043", "pdf": "https://arxiv.org/pdf/2508.13043", "abs": "https://arxiv.org/abs/2508.13043", "authors": ["Ayaka Yasunaga", "Hideo Saito", "Dieter Schmalstieg", "Shohei Mori"], "title": "IntelliCap: Intelligent Guidance for Consistent View Sampling", "categories": ["cs.CV"], "comment": "This work is a pre-print version of a paper that has been accepted to\n  the IEEE International Symposium on Mixed and Augmented Reality for future\n  publication. Project Page:\n  https://mediated-reality.github.io/projects/yasunaga_ismar25/", "summary": "Novel view synthesis from images, for example, with 3D Gaussian splatting,\nhas made great progress. Rendering fidelity and speed are now ready even for\ndemanding virtual reality applications. However, the problem of assisting\nhumans in collecting the input images for these rendering algorithms has\nreceived much less attention. High-quality view synthesis requires uniform and\ndense view sampling. Unfortunately, these requirements are not easily addressed\nby human camera operators, who are in a hurry, impatient, or lack understanding\nof the scene structure and the photographic process. Existing approaches to\nguide humans during image acquisition concentrate on single objects or neglect\nview-dependent material characteristics. We propose a novel situated\nvisualization technique for scanning at multiple scales. During the scanning of\na scene, our method identifies important objects that need extended image\ncoverage to properly represent view-dependent appearance. To this end, we\nleverage semantic segmentation and category identification, ranked by a\nvision-language model. Spherical proxies are generated around highly ranked\nobjects to guide the user during scanning. Our results show superior\nperformance in real scenes compared to conventional view sampling strategies.", "AI": {"tldr": "A novel situated visualization technique that guides users during scene scanning by identifying important objects needing extended image coverage through semantic segmentation and vision-language models, improving view synthesis quality.", "motivation": "High-quality view synthesis requires uniform and dense view sampling, but human camera operators often struggle with this due to impatience, lack of scene understanding, or time constraints. Existing guidance methods focus on single objects or ignore view-dependent material characteristics.", "method": "Leverages semantic segmentation and category identification ranked by a vision-language model to identify important objects requiring extended image coverage. Generates spherical proxies around highly ranked objects to guide users during scanning at multiple scales.", "result": "The method shows superior performance in real scenes compared to conventional view sampling strategies, enabling better representation of view-dependent appearance.", "conclusion": "The proposed situated visualization technique effectively addresses the challenge of guiding human operators during image acquisition for high-quality view synthesis, particularly for capturing view-dependent material characteristics across multiple scales."}}
{"id": "2508.13065", "pdf": "https://arxiv.org/pdf/2508.13065", "abs": "https://arxiv.org/abs/2508.13065", "authors": ["Siddharth Khandelwal", "Sridhar Kamath", "Arjun Jain"], "title": "Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping", "categories": ["cs.CV"], "comment": null, "summary": "Human shape editing enables controllable transformation of a person's body\nshape, such as thin, muscular, or overweight, while preserving pose, identity,\nclothing, and background. Unlike human pose editing, which has advanced\nrapidly, shape editing remains relatively underexplored. Current approaches\ntypically rely on 3D morphable models or image warping, often introducing\nunrealistic body proportions, texture distortions, and background\ninconsistencies due to alignment errors and deformations. A key limitation is\nthe lack of large-scale, publicly available datasets for training and\nevaluating body shape manipulation methods. In this work, we introduce the\nfirst large-scale dataset of 18,573 images across 1523 subjects, specifically\ndesigned for controlled human shape editing. It features diverse variations in\nbody shape, including fat, muscular and thin, captured under consistent\nidentity, clothing, and background conditions. Using this dataset, we propose\nOdo, an end-to-end diffusion-based method that enables realistic and intuitive\nbody reshaping guided by simple semantic attributes. Our approach combines a\nfrozen UNet that preserves fine-grained appearance and background details from\nthe input image with a ControlNet that guides shape transformation using target\nSMPL depth maps. Extensive experiments demonstrate that our method outperforms\nprior approaches, achieving per-vertex reconstruction errors as low as 7.5mm,\nsignificantly lower than the 13.6mm observed in baseline methods, while\nproducing realistic results that accurately match the desired target shapes.", "AI": {"tldr": "Odo is a diffusion-based method for realistic human body shape editing that uses a new large-scale dataset and combines frozen UNet with ControlNet to transform body shapes while preserving identity, clothing, and background details.", "motivation": "Human shape editing remains underexplored compared to pose editing, with current methods suffering from unrealistic proportions, texture distortions, and background inconsistencies due to lack of proper datasets and alignment errors.", "method": "End-to-end diffusion-based approach combining a frozen UNet to preserve appearance and background details with a ControlNet that guides shape transformation using target SMPL depth maps, trained on a new large-scale dataset of 18,573 images across 1523 subjects.", "result": "Achieves per-vertex reconstruction error of 7.5mm (significantly lower than baseline 13.6mm), produces realistic results that accurately match target shapes while preserving identity, clothing, and background consistency.", "conclusion": "The proposed Odo method with the new large-scale dataset enables realistic and intuitive body reshaping guided by semantic attributes, outperforming prior approaches in both quantitative metrics and visual quality."}}
{"id": "2508.11863", "pdf": "https://arxiv.org/pdf/2508.11863", "abs": "https://arxiv.org/abs/2508.11863", "authors": ["Mansi Sood", "Eray Can Elumar", "Osman Yagan"], "title": "On Balancing Sparsity with Reliable Connectivity in Distributed Network Design with Random K-out Graphs", "categories": ["cs.SI", "cs.IT", "cs.LG", "cs.NI", "math.IT", "math.OC"], "comment": "Present extensive evaluation of connectivity and related properties\n  of random K-out graphs with several use cases in network design. Subsumes\n  earlier results in IEEE ISIT 2021, ICC 2021, and ICC 2023", "summary": "In several applications in distributed systems, an important design criterion\nis ensuring that the network is sparse, i.e., does not contain too many edges,\nwhile achieving reliable connectivity. Sparsity ensures communication overhead\nremains low, while reliable connectivity is tied to reliable communication and\ninference on decentralized data reservoirs and computational resources. A class\nof network models called random K-out graphs appear widely as a heuristic to\nbalance connectivity and sparsity, especially in settings with limited trust,\ne.g., privacy-preserving aggregation of networked data in which networks are\ndeployed. However, several questions remain regarding how to choose network\nparameters in response to different operational requirements, including the\nneed to go beyond asymptotic results and the ability to model the stochastic\nand adversarial environments. To address this gap, we present theorems to\ninform the choice of network parameters that guarantee reliable connectivity in\nregimes where nodes can be finite or unreliable. We first derive upper and\nlower bounds for probability of connectivity in random K-out graphs when the\nnumber of nodes is finite. Next, we analyze the property of r-robustness, a\nstronger notion than connectivity that enables resilient consensus in the\npresence of malicious nodes. Finally, motivated by aggregation mechanisms based\non pairwise masking, we model and analyze the impact of a subset of adversarial\nnodes, modeled as deletions, on connectivity and giant component size - metrics\nthat are closely tied to privacy guarantees. Together, our results pave the way\nfor end-to-end performance guarantees for a suite of algorithms for reliable\ninference on networks.", "AI": {"tldr": "The paper provides theoretical analysis of random K-out graphs for balancing network sparsity and connectivity in distributed systems, with applications to privacy-preserving data aggregation and resilient consensus.", "motivation": "Random K-out graphs are widely used as heuristics for sparse yet connected networks in distributed systems, but lack rigorous parameter selection guidelines for finite nodes and adversarial environments common in privacy-preserving applications.", "method": "Derived upper/lower bounds for connectivity probability in finite random K-out graphs, analyzed r-robustness property for resilient consensus, and modeled adversarial node impact on connectivity and giant component size.", "result": "Theoretical guarantees for network parameter selection that ensure reliable connectivity in finite and unreliable node regimes, enabling resilient consensus and maintaining privacy guarantees despite adversarial nodes.", "conclusion": "The results provide end-to-end performance guarantees for reliable inference algorithms on networks, addressing the gap between heuristic network design and rigorous operational requirements in distributed systems."}}
{"id": "2508.13068", "pdf": "https://arxiv.org/pdf/2508.13068", "abs": "https://arxiv.org/abs/2508.13068", "authors": ["Tanjim Islam Riju", "Shuchismita Anwar", "Saman Sarker Joy", "Farig Sadeque", "Swakkhar Shatabda"], "title": "Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We propose a two-stage multimodal framework that enhances disease\nclassification and region-aware radiology report generation from chest X-rays,\nleveraging the MIMIC-Eye dataset. In the first stage, we introduce a\ngaze-guided contrastive learning architecture for disease classification. It\nintegrates visual features, clinical labels, bounding boxes, and radiologist\neye-tracking signals and is equipped with a novel multi-term gaze-attention\nloss combining MSE, KL divergence, correlation, and center-of-mass alignment.\nIncorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC\nfrom 0.821 to 0.849 (+3.41%), while also improving precision and recall,\nhighlighting the effectiveness of gaze-informed attention supervision. In the\nsecond stage, we present a modular report generation pipeline that extracts\nconfidence-weighted diagnostic keywords, maps them to anatomical regions using\na curated dictionary constructed from domain-specific priors, and generates\nregion-aligned sentences via structured prompts. This pipeline improves report\nquality as measured by clinical keyword recall and ROUGE overlap. Our results\ndemonstrate that integrating gaze data improves both classification performance\nand the interpretability of generated medical reports.", "AI": {"tldr": "Two-stage multimodal framework using radiologist eye-tracking data to improve chest X-ray disease classification and generate region-aware radiology reports, achieving significant performance gains in both tasks.", "motivation": "To enhance medical image analysis by incorporating radiologists' visual attention patterns (eye-tracking data) for improved disease classification and more interpretable, region-aware radiology report generation.", "method": "Two-stage approach: 1) Gaze-guided contrastive learning with multi-term gaze-attention loss (MSE, KL divergence, correlation, center-of-mass alignment) for disease classification; 2) Modular report generation pipeline extracting confidence-weighted keywords, anatomical region mapping, and structured prompt-based sentence generation.", "result": "Classification: F1 score improved from 0.597 to 0.631 (+5.70%), AUC from 0.821 to 0.849 (+3.41%). Report generation: Improved clinical keyword recall and ROUGE overlap metrics.", "conclusion": "Integrating gaze data significantly enhances both disease classification performance and the interpretability/quality of generated medical reports, demonstrating the value of radiologist visual attention patterns in medical AI systems."}}
{"id": "2508.12189", "pdf": "https://arxiv.org/pdf/2508.12189", "abs": "https://arxiv.org/abs/2508.12189", "authors": ["Rhea Malhotra", "Yuejiang Liu", "Chelsea Finn"], "title": "Self-Guided Action Diffusion", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Recent works have shown the promise of inference-time search over action\nsamples for improving generative robot policies. In particular, optimizing\ncross-chunk coherence via bidirectional decoding has proven effective in\nboosting the consistency and reactivity of diffusion policies. However, this\napproach remains computationally expensive as the diversity of sampled actions\ngrows. In this paper, we introduce self-guided action diffusion, a more\nefficient variant of bidirectional decoding tailored for diffusion-based\npolicies. At the core of our method is to guide the proposal distribution at\neach diffusion step based on the prior decision. Experiments in simulation\ntasks show that the proposed self-guidance enables near-optimal performance at\nnegligible inference cost. Notably, under a tight sampling budget, our method\nachieves up to 70% higher success rates than existing counterparts on\nchallenging dynamic tasks. See project website at\nhttps://rhea-mal.github.io/selfgad.github.io.", "AI": {"tldr": "Self-guided action diffusion improves efficiency of bidirectional decoding for diffusion policies by using prior decisions to guide proposal distributions, achieving near-optimal performance with negligible inference cost and 70% higher success rates on dynamic tasks.", "motivation": "Existing inference-time search methods for generative robot policies using bidirectional decoding are computationally expensive as action sample diversity grows, limiting practical deployment.", "method": "Self-guided action diffusion that guides the proposal distribution at each diffusion step based on prior decisions, creating a more efficient variant of bidirectional decoding tailored for diffusion-based policies.", "result": "Achieves near-optimal performance at negligible inference cost, with up to 70% higher success rates than existing methods on challenging dynamic tasks under tight sampling budgets.", "conclusion": "Self-guidance mechanism significantly improves computational efficiency while maintaining high performance, making diffusion policies more practical for real-time robotic applications."}}
{"id": "2508.13078", "pdf": "https://arxiv.org/pdf/2508.13078", "abs": "https://arxiv.org/abs/2508.13078", "authors": ["Qingwen Zeng", "Juan E. Tapia", "Izan Garcia", "Juan M. Espin", "Christoph Busch"], "title": "ID-Card Synthetic Generation: Toward a Simulated Bona fide Dataset", "categories": ["cs.CV"], "comment": null, "summary": "Nowadays, the development of a Presentation Attack Detection (PAD) system for\nID cards presents a challenge due to the lack of images available to train a\nrobust PAD system and the increase in diversity of possible attack instrument\nspecies. Today, most algorithms focus on generating attack samples and do not\ntake into account the limited number of bona fide images. This work is one of\nthe first to propose a method for mimicking bona fide images by generating\nsynthetic versions of them using Stable Diffusion, which may help improve the\ngeneralisation capabilities of the detector. Furthermore, the new images\ngenerated are evaluated in a system trained from scratch and in a commercial\nsolution. The PAD system yields an interesting result, as it identifies our\nimages as bona fide, which has a positive impact on detection performance and\ndata restrictions.", "AI": {"tldr": "Using Stable Diffusion to generate synthetic bona fide ID card images improves Presentation Attack Detection system performance by addressing data scarcity issues.", "motivation": "Current PAD systems face challenges due to limited availability of genuine ID card images for training and increasing diversity of attack methods. Most existing approaches focus on generating attack samples but neglect the scarcity of bona fide images.", "method": "Proposes using Stable Diffusion to generate synthetic bona fide ID card images, creating additional training data to improve detector generalization. The synthetic images are evaluated in both a system trained from scratch and a commercial PAD solution.", "result": "The synthetic images are successfully identified as bona fide by the PAD system, leading to improved detection performance and helping overcome data restriction limitations.", "conclusion": "Generating synthetic bona fide images using Stable Diffusion is an effective approach to enhance PAD system performance when genuine training data is scarce, demonstrating positive impact on detection capabilities."}}
{"id": "2508.12198", "pdf": "https://arxiv.org/pdf/2508.12198", "abs": "https://arxiv.org/abs/2508.12198", "authors": ["ChangJae Lee", "Heecheol Yang", "Jonghak Choi"], "title": "Exploring Multimodal AI Reasoning for Meteorological Forecasting from Skew-T Diagrams", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "comment": "24 pages, 3 figures, 9 tables", "summary": "Forecasting from atmospheric soundings is a fundamental task in operational\nmeteorology, often requiring structured visual reasoning over Skew-T log-P\ndiagrams by human forecasters. While recent advances in Vision-Language Models\n(VLMs) have shown promise in other scientific domains, their application to\nmeteorological diagram interpretation remains largely unexplored. In this\nstudy, we present a lightweight AI assistant that interprets Skew-T diagrams\nusing a small language model (LM) and a small VLM fine-tuned to emulate human\nforecasters. Using a curriculum learning framework, we first train the models\nto identify key atmospheric features from diagrams through visual question\nanswering, followed by chain-of-thought reasoning tasks that estimate\nprecipitation probability based on the derived visual groundings. Model inputs\ninclude either textual summaries or generated Skew-T diagrams derived from\noperational Numerical Weather Prediction (NWP) forecasts, paired with\nthree-hour precipitation observations from South Korea's Auto Weather Stations\nnetwork. Evaluation results demonstrate that the fine-tuned VLM achieves skill\ncomparable to an operational NWP model, despite relying solely on static\natmospheric profiles. Ablation studies reveal that visual grounding and\nreasoning supervision are critical for performance, while attention map\nanalysis confirms that the model learns to focus on relevant meteorological\nfeatures. These findings highlight the potential of compact, interpretable\nmultimodal models to support weather forecasting tasks. The approach offers a\ncomputationally efficient alternative to large-scale systems, and future work\ncould extend it to more complex applications.", "AI": {"tldr": "A lightweight AI assistant using small vision-language models achieves operational-level skill in precipitation forecasting from Skew-T diagrams through visual grounding and chain-of-thought reasoning.", "motivation": "To develop an efficient AI system that can interpret meteorological diagrams like human forecasters, as current Vision-Language Models haven't been well explored for meteorological diagram interpretation despite their success in other scientific domains.", "method": "Fine-tuned a small language model and vision-language model using curriculum learning: first trained on visual question answering to identify atmospheric features from Skew-T diagrams, then on chain-of-thought reasoning tasks for precipitation probability estimation. Used textual summaries or generated diagrams from NWP forecasts paired with precipitation observations.", "result": "The fine-tuned VLM achieved skill comparable to operational NWP models using only static atmospheric profiles. Visual grounding and reasoning supervision were critical for performance, and attention maps showed the model learned to focus on relevant meteorological features.", "conclusion": "Compact multimodal models show strong potential for weather forecasting tasks, offering computationally efficient alternatives to large systems. The approach could be extended to more complex applications in the future."}}
{"id": "2508.13086", "pdf": "https://arxiv.org/pdf/2508.13086", "abs": "https://arxiv.org/abs/2508.13086", "authors": ["Lucrezia Tosato", "Christel Tartini Chappuis", "Syrielle Montariol", "Flora Weissgerber", "Sylvain Lobry", "Devis Tuia"], "title": "Checkmate: interpretable and explainable RSVQA is the endgame", "categories": ["cs.CV"], "comment": null, "summary": "Remote Sensing Visual Question Answering (RSVQA) presents unique challenges\nin ensuring that model decisions are both understandable and grounded in visual\ncontent. Current models often suffer from a lack of interpretability and\nexplainability, as well as from biases in dataset distributions that lead to\nshortcut learning. In this work, we tackle these issues by introducing a novel\nRSVQA dataset, Chessboard, designed to minimize biases through 3'123'253\nquestions and a balanced answer distribution. Each answer is linked to one or\nmore cells within the image, enabling fine-grained visual reasoning.\n  Building on this dataset, we develop an explainable and interpretable model\ncalled Checkmate that identifies the image cells most relevant to its\ndecisions. Through extensive experiments across multiple model architectures,\nwe show that our approach improves transparency and supports more trustworthy\ndecision-making in RSVQA systems.", "AI": {"tldr": "A novel RSVQA dataset called Chessboard with 3M+ questions and balanced answer distribution is introduced to address interpretability issues and shortcut learning. The Checkmate model provides fine-grained visual reasoning by linking answers to specific image cells.", "motivation": "Current RSVQA models lack interpretability and explainability, suffering from dataset biases that lead to shortcut learning rather than genuine visual reasoning.", "method": "Created Chessboard dataset with 3,123,253 questions and balanced answer distribution, then developed Checkmate model that identifies specific image cells relevant to its decisions for fine-grained visual reasoning.", "result": "The approach improves transparency and supports more trustworthy decision-making across multiple model architectures in RSVQA systems.", "conclusion": "The Chessboard dataset and Checkmate model successfully address interpretability and bias issues in RSVQA, enabling explainable and grounded visual reasoning through cell-level attribution."}}
{"id": "2508.12211", "pdf": "https://arxiv.org/pdf/2508.12211", "abs": "https://arxiv.org/abs/2508.12211", "authors": ["Cyrus Neary", "Omar G. Younis", "Artur Kuramshin", "Ozgur Aslan", "Glen Berseth"], "title": "Improving Pre-Trained Vision-Language-Action Policies with Model-Based Search", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Pre-trained vision-language-action (VLA) models offer a promising foundation\nfor generalist robot policies, but often produce brittle behaviours or unsafe\nfailures when deployed zero-shot in out-of-distribution scenarios. We present\nVision-Language-Action Planning & Search (VLAPS) -- a novel framework and\naccompanying algorithms that embed model-based search into the inference\nprocedure of pre-trained VLA policies to improve their performance on robotic\ntasks. Specifically, our method biases a modified Monte Carlo Tree Search\n(MCTS) algorithm -- run using a model of the target environment -- using action\npriors defined by the VLA policy. By using VLA-derived abstractions and priors\nin model-based search, VLAPS efficiently explores language-conditioned robotics\ntasks whose search spaces would otherwise be intractably large. Conversely, by\nintegrating model-based search with the VLA policy's inference procedure, VLAPS\nyields behaviours that are more performant than those obtained by directly\nfollowing the VLA policy's action predictions. VLAPS offers a principled\nframework to: i) control test-time compute in VLA models, ii) leverage a priori\nknowledge of the robotic environment, and iii) integrate established planning\nand reinforcement learning techniques into the VLA inference process. Across\nall experiments, VLAPS significantly outperforms VLA-only baselines on\nlanguage-specified tasks that would otherwise be intractable for uninformed\nsearch algorithms, increasing success rates by as much as 67 percentage points.", "AI": {"tldr": "VLAPS integrates model-based search with pre-trained VLA policies using Monte Carlo Tree Search and environment models to improve robotic task performance in out-of-distribution scenarios.", "motivation": "Pre-trained VLA models often produce brittle behaviors and unsafe failures when deployed zero-shot in out-of-distribution scenarios, requiring a more robust framework.", "method": "Embeds model-based search into VLA policy inference using modified Monte Carlo Tree Search with VLA-derived action priors and environment models.", "result": "Significantly outperforms VLA-only baselines, increasing success rates by up to 67 percentage points on language-specified tasks that are intractable for uninformed search.", "conclusion": "VLAPS provides a principled framework to control test-time compute, leverage environmental knowledge, and integrate planning techniques into VLA inference for more robust robotic behaviors."}}
{"id": "2508.13091", "pdf": "https://arxiv.org/pdf/2508.13091", "abs": "https://arxiv.org/abs/2508.13091", "authors": ["Zihua Liu", "Yizhou Li", "Songyan Zhang", "Masatoshi Okutomi"], "title": "DMS:Diffusion-Based Multi-Baseline Stereo Generation for Improving Self-Supervised Depth Estimation", "categories": ["cs.CV"], "comment": null, "summary": "While supervised stereo matching and monocular depth estimation have advanced\nsignificantly with learning-based algorithms, self-supervised methods using\nstereo images as supervision signals have received relatively less focus and\nrequire further investigation. A primary challenge arises from ambiguity\nintroduced during photometric reconstruction, particularly due to missing\ncorresponding pixels in ill-posed regions of the target view, such as\nocclusions and out-of-frame areas. To address this and establish explicit\nphotometric correspondences, we propose DMS, a model-agnostic approach that\nutilizes geometric priors from diffusion models to synthesize novel views along\nthe epipolar direction, guided by directional prompts. Specifically, we\nfinetune a Stable Diffusion model to simulate perspectives at key positions:\nleft-left view shifted from the left camera, right-right view shifted from the\nright camera, along with an additional novel view between the left and right\ncameras. These synthesized views supplement occluded pixels, enabling explicit\nphotometric reconstruction. Our proposed DMS is a cost-free, ''plug-and-play''\nmethod that seamlessly enhances self-supervised stereo matching and monocular\ndepth estimation, and relies solely on unlabeled stereo image pairs for both\ntraining and synthesizing. Extensive experiments demonstrate the effectiveness\nof our approach, with up to 35% outlier reduction and state-of-the-art\nperformance across multiple benchmark datasets.", "AI": {"tldr": "DMS is a model-agnostic approach that uses diffusion models to synthesize novel views for self-supervised stereo matching and depth estimation, addressing occlusion issues without requiring labels.", "motivation": "Self-supervised stereo matching and monocular depth estimation face challenges from photometric ambiguity in ill-posed regions like occlusions and out-of-frame areas, requiring better methods to establish explicit correspondences.", "method": "Finetune Stable Diffusion to synthesize novel views along epipolar direction using directional prompts - left-left view, right-right view, and intermediate view between cameras to supplement occluded pixels for explicit photometric reconstruction.", "result": "Up to 35% outlier reduction and state-of-the-art performance across multiple benchmark datasets, demonstrating significant improvement in self-supervised stereo matching and depth estimation.", "conclusion": "DMS provides an effective plug-and-play solution that enhances self-supervised methods using only unlabeled stereo pairs, successfully addressing occlusion challenges through diffusion-based view synthesis."}}
{"id": "2508.11911", "pdf": "https://arxiv.org/pdf/2508.11911", "abs": "https://arxiv.org/abs/2508.11911", "authors": ["Yongsheng Chen", "Wei Guo", "Qi Tang", "Xinghui Zhong"], "title": "Reduced-order modeling of Hamiltonian dynamics based on symplectic neural networks", "categories": ["math.NA", "cs.LG", "cs.NA", "physics.comp-ph"], "comment": null, "summary": "We introduce a novel data-driven symplectic induced-order modeling (ROM)\nframework for high-dimensional Hamiltonian systems that unifies latent-space\ndiscovery and dynamics learning within a single, end-to-end neural\narchitecture. The encoder-decoder is built from Henon neural networks\n(HenonNets) and may be augmented with linear SGS-reflector layers. This yields\nan exact symplectic map between full and latent phase spaces. Latent dynamics\nare advanced by a symplectic flow map implemented as a HenonNet. This unified\nneural architecture ensures exact preservation of the underlying symplectic\nstructure at the reduced-order level, significantly enhancing the fidelity and\nlong-term stability of the resulting ROM. We validate our method through\ncomprehensive numerical experiments on canonical Hamiltonian systems. The\nresults demonstrate the method's capability for accurate trajectory\nreconstruction, robust predictive performance beyond the training horizon, and\naccurate Hamiltonian preservation. These promising outcomes underscore the\neffectiveness and potential applicability of our symplectic ROM framework for\ncomplex dynamical systems across a broad range of scientific and engineering\ndisciplines.", "AI": {"tldr": "A novel symplectic reduced-order modeling framework using Henon neural networks that preserves Hamiltonian structure while learning latent dynamics end-to-end.", "motivation": "To develop a unified neural architecture that simultaneously discovers latent spaces and learns dynamics while exactly preserving the symplectic structure of Hamiltonian systems for improved fidelity and long-term stability.", "method": "End-to-end neural architecture with HenonNets encoder-decoder and symplectic flow map, augmented with linear SGS-reflector layers to create exact symplectic maps between full and latent phase spaces.", "result": "Accurate trajectory reconstruction, robust predictive performance beyond training horizon, and exact Hamiltonian preservation demonstrated through comprehensive numerical experiments on canonical Hamiltonian systems.", "conclusion": "The framework shows effectiveness and broad applicability potential for complex dynamical systems across scientific and engineering disciplines due to its structure-preserving properties and neural network integration."}}
{"id": "2508.13101", "pdf": "https://arxiv.org/pdf/2508.13101", "abs": "https://arxiv.org/abs/2508.13101", "authors": ["Miftahul Huda", "Arsyiah Azahra", "Putri Maulida Chairani", "Dimas Rizky Ramadhani", "Nabila Azhari", "Ade Lailani"], "title": "Real-Time Beach Litter Detection and Counting: A Comparative Analysis of RT-DETR Model Variants", "categories": ["cs.CV"], "comment": null, "summary": "Coastal pollution is a pressing global environmental issue, necessitating\nscalable and automated solutions for monitoring and management. This study\ninvestigates the efficacy of the Real-Time Detection Transformer (RT-DETR), a\nstate-of-the-art, end-to-end object detection model, for the automated\ndetection and counting of beach litter. A rigorous comparative analysis is\nconducted between two model variants, RT-DETR-Large (RT-DETR-L) and\nRT-DETR-Extra-Large (RT-DETR-X), trained on a publicly available dataset of\ncoastal debris. The evaluation reveals that the RT-DETR-X model achieves\nmarginally superior accuracy, with a mean Average Precision at 50\\% IoU\n(mAP@50) of 0.816 and a mAP@50-95 of 0.612, compared to the RT-DETR-L model's\n0.810 and 0.606, respectively. However, this minor performance gain is realized\nat a significant computational cost; the RT-DETR-L model demonstrates a\nsubstantially faster inference time of 20.1 ms versus 34.5 ms for the\nRT-DETR-X. The findings suggest that the RT-DETR-L model offers a more\npractical and efficient solution for real-time, in-field deployment due to its\nsuperior balance of processing speed and detection accuracy. This research\nprovides valuable insights into the application of advanced Transformer-based\ndetectors for environmental conservation, highlighting the critical trade-offs\nbetween model complexity and operational viability.", "AI": {"tldr": "RT-DETR-L offers better speed-accuracy balance than RT-DETR-X for real-time beach litter detection, making it more practical for field deployment despite slightly lower accuracy.", "motivation": "Coastal pollution requires scalable automated monitoring solutions, and this study investigates the effectiveness of state-of-the-art object detection models for automated beach litter detection and counting.", "method": "Comparative analysis of two RT-DETR variants (Large and Extra-Large) trained on coastal debris dataset, evaluating accuracy (mAP metrics) and computational performance (inference time).", "result": "RT-DETR-X achieved marginally better accuracy (mAP@50: 0.816, mAP@50-95: 0.612) but RT-DETR-L was significantly faster (20.1ms vs 34.5ms inference time) with comparable accuracy (mAP@50: 0.810, mAP@50-95: 0.606).", "conclusion": "RT-DETR-L provides a more practical and efficient solution for real-time field deployment due to its superior balance of processing speed and detection accuracy, highlighting important trade-offs between model complexity and operational viability."}}
{"id": "2508.12213", "pdf": "https://arxiv.org/pdf/2508.12213", "abs": "https://arxiv.org/abs/2508.12213", "authors": ["Yize Cai", "Baoshen Guo", "Flora Salim", "Zhiqing Hong"], "title": "Towards Generalizable Human Activity Recognition: A Survey", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "As a critical component of Wearable AI, IMU-based Human Activity Recognition\n(HAR) has attracted increasing attention from both academia and industry in\nrecent years. Although HAR performance has improved considerably in specific\nscenarios, its generalization capability remains a key barrier to widespread\nreal-world adoption. For example, domain shifts caused by variations in users,\nsensor positions, or environments can significantly decrease the performance in\npractice. As a result, in this survey, we explore the rapidly evolving field of\nIMU-based generalizable HAR, reviewing 229 research papers alongside 25\npublicly available datasets to provide a broad and insightful overview. We\nfirst present the background and overall framework of IMU-based HAR tasks, as\nwell as the generalization-oriented training settings. Then, we categorize\nrepresentative methodologies from two perspectives: (i) model-centric\napproaches, including pre-training method, end-to-end method, and large\nlanguage model (LLM)-based learning method; and (ii) data-centric approaches,\nincluding multi-modal learning and data augmentation techniques. In addition,\nwe summarize widely used datasets in this field, as well as relevant tools and\nbenchmarks. Building on these methodological advances, the broad applicability\nof IMU-based HAR is also reviewed and discussed. Finally, we discuss persistent\nchallenges (e.g., data scarcity, efficient training, and reliable evaluation)\nand also outline future directions for HAR, including the adoption of\nfoundation and large language models, physics-informed and context-aware\nreasoning, generative modeling, and resource-efficient training and inference.\nThe complete list of this survey is available at\nhttps://github.com/rh20624/Awesome-IMU-Sensing, which will be updated\ncontinuously.", "AI": {"tldr": "Survey paper on IMU-based Human Activity Recognition focusing on generalization challenges, reviewing 229 papers and 25 datasets, categorizing model-centric and data-centric approaches, and discussing future directions including LLMs and foundation models.", "motivation": "IMU-based HAR has improved performance but struggles with generalization across different users, sensor positions, and environments due to domain shifts, limiting real-world adoption.", "method": "Comprehensive literature review of 229 research papers and 25 public datasets, categorizing approaches into model-centric (pre-training, end-to-end, LLM-based) and data-centric (multi-modal learning, data augmentation) methods.", "result": "Provides a broad overview of IMU-based generalizable HAR, summarizing methodologies, datasets, tools, benchmarks, and identifying persistent challenges like data scarcity and efficient training.", "conclusion": "Outlines future directions including adoption of foundation/large language models, physics-informed reasoning, generative modeling, and resource-efficient training to address generalization challenges in HAR."}}
{"id": "2508.13104", "pdf": "https://arxiv.org/pdf/2508.13104", "abs": "https://arxiv.org/abs/2508.13104", "authors": ["Yuang Wang", "Chao Wen", "Haoyu Guo", "Sida Peng", "Minghan Qin", "Hujun Bao", "Xiaowei Zhou", "Ruizhen Hu"], "title": "Precise Action-to-Video Generation Through Visual Action Prompts", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted to ICCV 2025. Project page: https://zju3dv.github.io/VAP/", "summary": "We present visual action prompts, a unified action representation for\naction-to-video generation of complex high-DoF interactions while maintaining\ntransferable visual dynamics across domains. Action-driven video generation\nfaces a precision-generality trade-off: existing methods using text, primitive\nactions, or coarse masks offer generality but lack precision, while\nagent-centric action signals provide precision at the cost of cross-domain\ntransferability. To balance action precision and dynamic transferability, we\npropose to \"render\" actions into precise visual prompts as domain-agnostic\nrepresentations that preserve both geometric precision and cross-domain\nadaptability for complex actions; specifically, we choose visual skeletons for\ntheir generality and accessibility. We propose robust pipelines to construct\nskeletons from two interaction-rich data sources - human-object interactions\n(HOI) and dexterous robotic manipulation - enabling cross-domain training of\naction-driven generative models. By integrating visual skeletons into\npretrained video generation models via lightweight fine-tuning, we enable\nprecise action control of complex interaction while preserving the learning of\ncross-domain dynamics. Experiments on EgoVid, RT-1 and DROID demonstrate the\neffectiveness of our proposed approach. Project page:\nhttps://zju3dv.github.io/VAP/.", "AI": {"tldr": "Visual Action Prompts (VAP) use visual skeletons as domain-agnostic representations for precise action-to-video generation while maintaining cross-domain transferability of visual dynamics.", "motivation": "Existing action-driven video generation methods face a precision-generality trade-off - text/primitive actions lack precision while agent-centric signals lack cross-domain transferability.", "method": "Render actions into visual skeletons as domain-agnostic prompts, construct pipelines from human-object interactions and robotic manipulation data, integrate into pretrained video models via lightweight fine-tuning.", "result": "Effective action control of complex interactions while preserving cross-domain dynamics, demonstrated on EgoVid, RT-1 and DROID datasets.", "conclusion": "Visual skeletons provide a balanced solution for action precision and dynamic transferability in video generation across domains."}}
{"id": "2508.13139", "pdf": "https://arxiv.org/pdf/2508.13139", "abs": "https://arxiv.org/abs/2508.13139", "authors": ["Ling-Hao Chen", "Yuhong Zhang", "Zixin Yin", "Zhiyang Dou", "Xin Chen", "Jingbo Wang", "Taku Komura", "Lei Zhang"], "title": "Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence", "categories": ["cs.CV"], "comment": "SIGGRAPH Asia 2025", "summary": "This work studies the challenge of transfer animations between characters\nwhose skeletal topologies differ substantially. While many techniques have\nadvanced retargeting techniques in decades, transfer motions across diverse\ntopologies remains less-explored. The primary obstacle lies in the inherent\ntopological inconsistency between source and target skeletons, which restricts\nthe establishment of straightforward one-to-one bone correspondences. Besides,\nthe current lack of large-scale paired motion datasets spanning different\ntopological structures severely constrains the development of data-driven\napproaches. To address these limitations, we introduce Motion2Motion, a novel,\ntraining-free framework. Simply yet effectively, Motion2Motion works with only\none or a few example motions on the target skeleton, by accessing a sparse set\nof bone correspondences between the source and target skeletons. Through\ncomprehensive qualitative and quantitative evaluations, we demonstrate that\nMotion2Motion achieves efficient and reliable performance in both\nsimilar-skeleton and cross-species skeleton transfer scenarios. The practical\nutility of our approach is further evidenced by its successful integration in\ndownstream applications and user interfaces, highlighting its potential for\nindustrial applications. Code and data are available at\nhttps://lhchen.top/Motion2Motion.", "AI": {"tldr": "Motion2Motion is a training-free framework that transfers animations between characters with different skeletal topologies using sparse bone correspondences and minimal target examples.", "motivation": "Existing motion retargeting techniques struggle with characters that have substantially different skeletal topologies due to topological inconsistencies and lack of large-scale paired motion datasets.", "method": "Uses a training-free framework that works with only one or few example motions on the target skeleton, accessing sparse bone correspondences between source and target skeletons.", "result": "Achieves efficient and reliable performance in both similar-skeleton and cross-species skeleton transfer scenarios, with successful integration in downstream applications.", "conclusion": "Motion2Motion demonstrates practical utility for industrial applications and addresses the challenge of transferring animations across diverse skeletal topologies without requiring extensive training data."}}
{"id": "2508.12232", "pdf": "https://arxiv.org/pdf/2508.12232", "abs": "https://arxiv.org/abs/2508.12232", "authors": ["Arshia Akhavan", "Alireza Hosseinpour", "Abbas Heydarnoori", "Mehdi Keshani"], "title": "LinkAnchor: An Autonomous LLM-Based Agent for Issue-to-Commit Link Recovery", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Issue-to-commit link recovery plays an important role in software\ntraceability and improves project management. However, it remains a challenging\ntask. A study on GitHub shows that only 42.2% of the issues are correctly\nlinked to their commits. This highlights the potential for further development\nand research in this area. Existing studies have employed various AI/ML-based\napproaches, and with the recent development of large language models,\nresearchers have leveraged LLMs to tackle this problem. These approaches suffer\nfrom two main issues. First, LLMs are constrained by limited context windows\nand cannot ingest all of the available data sources, such as long commit\nhistories, extensive issue comments, and large code repositories. Second, most\nmethods operate on individual issue-commit pairs; that is, given a single\nissue-commit pair, they determine whether the commit resolves the issue. This\nquickly becomes impractical in real-world repositories containing tens of\nthousands of commits. To address these limitations, we present LinkAnchor, the\nfirst autonomous LLM-based agent designed for issue-to-commit link recovery.\nThe lazy-access architecture of LinkAnchor enables the underlying LLM to access\nthe rich context of software, spanning commits, issue comments, and code files,\nwithout exceeding the token limit by dynamically retrieving only the most\nrelevant contextual data. Additionally, LinkAnchor is able to automatically\npinpoint the target commit rather than exhaustively scoring every possible\ncandidate. Our evaluations show that LinkAnchor outperforms state-of-the-art\nissue-to-commit link recovery approaches by 60-262% in Hit@1 score across all\nour case study projects. We also publicly release LinkAnchor as a ready-to-use\ntool, along with our replication package. LinkAnchor is designed and tested for\nGitHub and Jira, and is easily extendable to other platforms.", "AI": {"tldr": "LinkAnchor is an autonomous LLM-based agent that significantly improves issue-to-commit link recovery by using lazy-access architecture to handle large software contexts and automatically pinpoint target commits without exhaustive search.", "motivation": "Only 42.2% of GitHub issues are correctly linked to commits, creating a need for better traceability tools. Existing LLM approaches suffer from limited context windows and impractical pairwise evaluation of issue-commit pairs in large repositories.", "method": "LinkAnchor uses lazy-access architecture that dynamically retrieves only the most relevant contextual data (commits, issue comments, code files) without exceeding token limits. It autonomously pinpoints target commits rather than scoring every possible candidate.", "result": "LinkAnchor outperforms state-of-the-art approaches by 60-262% in Hit@1 score across all case study projects. It's publicly released as a ready-to-use tool compatible with GitHub and Jira.", "conclusion": "LinkAnchor successfully addresses key limitations of previous methods by enabling efficient context access and autonomous commit identification, making issue-to-commit link recovery practical for real-world software repositories."}}
{"id": "2508.13153", "pdf": "https://arxiv.org/pdf/2508.13153", "abs": "https://arxiv.org/abs/2508.13153", "authors": ["Wenhao Hu", "Zesheng Li", "Haonan Zhou", "Liu Liu", "Xuexiang Wen", "Zhizhong Su", "Xi Li", "Gaoang Wang"], "title": "IGFuse: Interactive 3D Gaussian Scene Reconstruction via Multi-Scans Fusion", "categories": ["cs.CV"], "comment": "Project page: https://whhu7.github.io/IGFuse", "summary": "Reconstructing complete and interactive 3D scenes remains a fundamental\nchallenge in computer vision and robotics, particularly due to persistent\nobject occlusions and limited sensor coverage. Multiview observations from a\nsingle scene scan often fail to capture the full structural details. Existing\napproaches typically rely on multi stage pipelines, such as segmentation,\nbackground completion, and inpainting or require per-object dense scanning,\nboth of which are error-prone, and not easily scalable. We propose IGFuse, a\nnovel framework that reconstructs interactive Gaussian scene by fusing\nobservations from multiple scans, where natural object rearrangement between\ncaptures reveal previously occluded regions. Our method constructs segmentation\naware Gaussian fields and enforces bi-directional photometric and semantic\nconsistency across scans. To handle spatial misalignments, we introduce a\npseudo-intermediate scene state for unified alignment, alongside collaborative\nco-pruning strategies to refine geometry. IGFuse enables high fidelity\nrendering and object level scene manipulation without dense observations or\ncomplex pipelines. Extensive experiments validate the framework's strong\ngeneralization to novel scene configurations, demonstrating its effectiveness\nfor real world 3D reconstruction and real-to-simulation transfer. Our project\npage is available online.", "AI": {"tldr": "IGFuse reconstructs interactive 3D scenes by fusing multiple scans with object rearrangement to reveal occluded areas, using segmentation-aware Gaussian fields and consistency constraints.", "motivation": "Existing 3D scene reconstruction methods suffer from object occlusions, limited sensor coverage, and rely on error-prone multi-stage pipelines or dense per-object scanning.", "method": "Constructs segmentation-aware Gaussian fields with bi-directional photometric and semantic consistency across scans. Uses pseudo-intermediate scene state for alignment and collaborative co-pruning for geometry refinement.", "result": "Enables high-fidelity rendering and object-level scene manipulation without dense observations or complex pipelines. Shows strong generalization to novel scene configurations.", "conclusion": "IGFuse provides an effective framework for real-world 3D reconstruction and real-to-simulation transfer by leveraging multiple scans with natural object movements."}}
{"id": "2508.11978", "pdf": "https://arxiv.org/pdf/2508.11978", "abs": "https://arxiv.org/abs/2508.11978", "authors": ["Viacheslav Yusupov", "Maxim Rakhuba", "Evgeny Frolov"], "title": "Leveraging Geometric Insights in Hyperbolic Triplet Loss for Improved Recommendations", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Recent studies have demonstrated the potential of hyperbolic geometry for\ncapturing complex patterns from interaction data in recommender systems. In\nthis work, we introduce a novel hyperbolic recommendation model that uses\ngeometrical insights to improve representation learning and increase\ncomputational stability at the same time. We reformulate the notion of\nhyperbolic distances to unlock additional representation capacity over\nconventional Euclidean space and learn more expressive user and item\nrepresentations. To better capture user-items interactions, we construct a\ntriplet loss that models ternary relations between users and their\ncorresponding preferred and nonpreferred choices through a mix of pairwise\ninteraction terms driven by the geometry of data. Our hyperbolic approach not\nonly outperforms existing Euclidean and hyperbolic models but also reduces\npopularity bias, leading to more diverse and personalized recommendations.", "AI": {"tldr": "Novel hyperbolic recommendation model that improves representation learning and computational stability through geometric insights and triplet loss formulation.", "motivation": "To leverage hyperbolic geometry's potential for capturing complex patterns in interaction data and overcome limitations of conventional Euclidean space in recommender systems.", "method": "Reformulates hyperbolic distances to increase representation capacity, constructs triplet loss with pairwise interaction terms driven by data geometry to model ternary relations between users and their preferred/nonpreferred choices.", "result": "Outperforms existing Euclidean and hyperbolic models while reducing popularity bias, leading to more diverse and personalized recommendations.", "conclusion": "Hyperbolic geometry provides superior representation learning capabilities for recommender systems, enabling both better performance and reduced bias compared to traditional approaches."}}
{"id": "2508.13154", "pdf": "https://arxiv.org/pdf/2508.13154", "abs": "https://arxiv.org/abs/2508.13154", "authors": ["Zhaoxi Chen", "Tianqi Liu", "Long Zhuo", "Jiawei Ren", "Zeng Tao", "He Zhu", "Fangzhou Hong", "Liang Pan", "Ziwei Liu"], "title": "4DNeX: Feed-Forward 4D Generative Modeling Made Easy", "categories": ["cs.CV"], "comment": "Project Page: https://4dnex.github.io/", "summary": "We present 4DNeX, the first feed-forward framework for generating 4D (i.e.,\ndynamic 3D) scene representations from a single image. In contrast to existing\nmethods that rely on computationally intensive optimization or require\nmulti-frame video inputs, 4DNeX enables efficient, end-to-end image-to-4D\ngeneration by fine-tuning a pretrained video diffusion model. Specifically, 1)\nto alleviate the scarcity of 4D data, we construct 4DNeX-10M, a large-scale\ndataset with high-quality 4D annotations generated using advanced\nreconstruction approaches. 2) we introduce a unified 6D video representation\nthat jointly models RGB and XYZ sequences, facilitating structured learning of\nboth appearance and geometry. 3) we propose a set of simple yet effective\nadaptation strategies to repurpose pretrained video diffusion models for 4D\nmodeling. 4DNeX produces high-quality dynamic point clouds that enable\nnovel-view video synthesis. Extensive experiments demonstrate that 4DNeX\noutperforms existing 4D generation methods in efficiency and generalizability,\noffering a scalable solution for image-to-4D modeling and laying the foundation\nfor generative 4D world models that simulate dynamic scene evolution.", "AI": {"tldr": "4DNeX is the first feed-forward framework for single-image to 4D (dynamic 3D) scene generation, using a fine-tuned video diffusion model with novel 6D video representation and large-scale 4D dataset.", "motivation": "Existing methods require computationally intensive optimization or multi-frame video inputs, lacking efficient single-image to 4D generation solutions.", "method": "Fine-tunes pretrained video diffusion model with 4DNeX-10M dataset, introduces unified 6D video representation (RGB+XYZ), and adaptation strategies for 4D modeling.", "result": "Produces high-quality dynamic point clouds enabling novel-view video synthesis, outperforms existing methods in efficiency and generalizability.", "conclusion": "Provides scalable solution for image-to-4D modeling and lays foundation for generative 4D world models simulating dynamic scene evolution."}}
{"id": "2508.11654", "pdf": "https://arxiv.org/pdf/2508.11654", "abs": "https://arxiv.org/abs/2508.11654", "authors": ["Yang Zhao", "Tao Wang", "Said Elhadi"], "title": "Data-driven RF Tomography via Cross-modal Sensing and Continual Learning", "categories": ["eess.SP", "cs.CV"], "comment": "6 pages, 4 figures, to be published in IEEE AVSS Conference", "summary": "Data-driven radio frequency (RF) tomography has demonstrated significant\npotential for underground target detection, due to the penetrative nature of RF\nsignals through soil. However, it is still challenging to achieve accurate and\nrobust performance in dynamic environments. In this work, we propose a\ndata-driven radio frequency tomography (DRIFT) framework with the following key\ncomponents to reconstruct cross section images of underground root tubers, even\nwith significant changes in RF signals. First, we design a cross-modal sensing\nsystem with RF and visual sensors, and propose to train an RF tomography deep\nneural network (DNN) model following the cross-modal learning approach. Then we\npropose to apply continual learning to automatically update the DNN model, once\nenvironment changes are detected in a dynamic environment. Experimental results\nshow that our approach achieves an average equivalent diameter error of 2.29\ncm, 23.2% improvement upon the state-of-the-art approach. Our DRIFT code and\ndataset are publicly available on https://github.com/Data-driven-RTI/DRIFT.", "AI": {"tldr": "DRIFT framework uses cross-modal RF and visual sensing with continual learning to improve underground target detection accuracy in dynamic environments, achieving 23.2% improvement over state-of-the-art methods.", "motivation": "Data-driven RF tomography shows promise for underground detection but struggles with accuracy and robustness in dynamic environments where RF signals change significantly.", "method": "Proposes a cross-modal sensing system with RF and visual sensors, trains an RF tomography DNN using cross-modal learning, and applies continual learning to automatically update the model when environmental changes are detected.", "result": "Achieves an average equivalent diameter error of 2.29 cm, representing a 23.2% improvement over the state-of-the-art approach.", "conclusion": "The DRIFT framework successfully addresses the challenge of dynamic environments in underground target detection through cross-modal learning and continual model updates, with code and dataset made publicly available."}}
{"id": "2508.12259", "pdf": "https://arxiv.org/pdf/2508.12259", "abs": "https://arxiv.org/abs/2508.12259", "authors": ["Ken Huang", "Yasir Mehmood", "Hammad Atta", "Jerry Huang", "Muhammad Zeeshan Baig", "Sree Bhargavi Balija"], "title": "Fortifying the Agentic Web: A Unified Zero-Trust Architecture Against Logic-layer Threats", "categories": ["cs.CR", "cs.AI", "cs.ET"], "comment": null, "summary": "This paper presents a Unified Security Architecture that fortifies the\nAgentic Web through a Zero-Trust IAM framework. This architecture is built on a\nfoundation of rich, verifiable agent identities using Decentralized Identifiers\n(DIDs) and Verifiable Credentials (VCs), with discovery managed by a\nprotocol-agnostic Agent Name Service (ANS). Security is operationalized through\na multi-layered Trust Fabric which introduces significant innovations,\nincluding Trust-Adaptive Runtime Environments (TARE), Causal Chain Auditing,\nand Dynamic Identity with Behavioral Attestation. By explicitly linking the\nLPCI threat to these enhanced architectural countermeasures within a formal\nsecurity model, we propose a comprehensive and forward-looking blueprint for a\nsecure, resilient, and trustworthy agentic ecosystem. Our formal analysis\ndemonstrates that the proposed architecture provides provable security\nguarantees against LPCI attacks with bounded probability of success.", "AI": {"tldr": "A unified security architecture for Agentic Web using Zero-Trust IAM with DIDs, VCs, and innovative Trust Fabric components to provide provable security against LPCI attacks.", "motivation": "To address security vulnerabilities in agent-based web systems, particularly LPCI (Low-Probability Compromise of Integrity) threats, by creating a comprehensive security framework for trustworthy agentic ecosystems.", "method": "Developed a Zero-Trust IAM framework using Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs) with Agent Name Service (ANS), Trust-Adaptive Runtime Environments (TARE), Causal Chain Auditing, and Dynamic Identity with Behavioral Attestation.", "result": "The architecture provides provable security guarantees against LPCI attacks with bounded probability of success, demonstrating formal security analysis.", "conclusion": "The proposed unified security architecture offers a comprehensive blueprint for building secure, resilient, and trustworthy agentic web ecosystems with formal security guarantees."}}
{"id": "2508.12009", "pdf": "https://arxiv.org/pdf/2508.12009", "abs": "https://arxiv.org/abs/2508.12009", "authors": ["Arnav Ramamoorthy"], "title": "Optimizing Neural Architectures for Hindi Speech Separation and Enhancement in Noisy Environments", "categories": ["cs.SD", "cs.LG"], "comment": "ICAD 2025", "summary": "This paper addresses the challenges of Hindi speech separation and\nenhancement using advanced neural network architectures, with a focus on edge\ndevices. We propose a refined approach leveraging the DEMUCS model to overcome\nlimitations of traditional methods, achieving substantial improvements in\nspeech clarity and intelligibility. The model is fine-tuned with U-Net and LSTM\nlayers, trained on a dataset of 400,000 Hindi speech clips augmented with\nESC-50 and MS-SNSD for diverse acoustic environments. Evaluation using PESQ and\nSTOI metrics shows superior performance, particularly under extreme noise\nconditions. To ensure deployment on resource-constrained devices like TWS\nearbuds, we explore quantization techniques to reduce computational\nrequirements. This research highlights the effectiveness of customized AI\nalgorithms for speech processing in Indian contexts and suggests future\ndirections for optimizing edge-based architectures.", "AI": {"tldr": "Improved Hindi speech separation using DEMUCS model with U-Net/LSTM layers, achieving better clarity in noisy conditions while optimizing for edge device deployment through quantization.", "motivation": "Address challenges of Hindi speech separation and enhancement for edge devices, overcoming limitations of traditional methods in Indian acoustic environments.", "method": "Refined DEMUCS model with U-Net and LSTM layers, trained on 400,000 Hindi speech clips augmented with ESC-50 and MS-SNSD datasets for diverse noise conditions.", "result": "Superior performance in PESQ and STOI metrics, particularly under extreme noise conditions, with successful quantization for resource-constrained edge devices.", "conclusion": "Customized AI algorithms are effective for Hindi speech processing, with future directions focusing on optimizing edge-based architectures for real-world deployment."}}
{"id": "2508.11724", "pdf": "https://arxiv.org/pdf/2508.11724", "abs": "https://arxiv.org/abs/2508.11724", "authors": ["Jake Turley", "Ryan A. Palmer", "Isaac V. Chenchiah", "Daniel Robert"], "title": "BeeNet: Reconstructing Flower Shapes from Electric Fields using Deep Learning", "categories": ["q-bio.QM", "cs.CV"], "comment": "14 pages, 4 figures", "summary": "Arthropods, including pollinators, respond to environmental electrical\nfields. Here, we show that electric field information can be decoded to\nreconstruct environmental features. We develop an algorithm capable of\ninferring the shapes of polarisable flowers from the electric field generated\nby a nearby charged bee. We simulated electric fields arising from bee flower\ninteractions for flowers with varying petal geometries. These simulated data\nwere used to train a deep learning UNet model to recreate petal shapes. The\nmodel accurately reconstructed diverse flower shapes including more complex\nflower shapes not included in training. Reconstruction performance peaked at an\noptimal bee flower distance, indicating distance-dependent encoding of shape\ninformation. These findings show that electroreception can impart rich spatial\ndetail, offering insights into arthropod environmental perception.", "AI": {"tldr": "Deep learning model reconstructs flower shapes from electric fields generated by bee-flower interactions, showing electroreception provides rich spatial information for arthropods.", "motivation": "To understand how arthropods like pollinators use environmental electrical fields to perceive and decode spatial information about their surroundings, particularly flower shapes.", "method": "Developed an algorithm using simulated electric field data from bee-flower interactions, trained a deep learning UNet model to reconstruct petal shapes from electric field patterns.", "result": "Model accurately reconstructed diverse flower shapes, including complex shapes not in training data, with peak performance at optimal bee-flower distance showing distance-dependent encoding.", "conclusion": "Electroreception provides arthropods with rich spatial detail about environmental features, offering new insights into their environmental perception capabilities."}}
{"id": "2508.12048", "pdf": "https://arxiv.org/pdf/2508.12048", "abs": "https://arxiv.org/abs/2508.12048", "authors": ["Jing Wang", "HaiYing Wang", "Kun Chen"], "title": "Robust Data Fusion via Subsampling", "categories": ["stat.ML", "cs.LG", "62K05"], "comment": null, "summary": "Data fusion and transfer learning are rapidly growing fields that enhance\nmodel performance for a target population by leveraging other related data\nsources or tasks. The challenges lie in the various potential heterogeneities\nbetween the target and external data, as well as various practical concerns\nthat prevent a na\\\"ive data integration. We consider a realistic scenario where\nthe target data is limited in size while the external data is large but\ncontaminated with outliers; such data contamination, along with other\ncomputational and operational constraints, necessitates proper selection or\nsubsampling of the external data for transfer learning. To our\nknowledge,transfer learning and subsampling under data contamination have not\nbeen thoroughly investigated. We address this gap by studying various transfer\nlearning methods with subsamples of the external data, accounting for outliers\ndeviating from the underlying true model due to arbitrary mean shifts. Two\nsubsampling strategies are investigated: one aimed at reducing biases and the\nother at minimizing variances. Approaches to combine these strategies are also\nintroduced to enhance the performance of the estimators. We provide\nnon-asymptotic error bounds for the transfer learning estimators, clarifying\nthe roles of sample sizes, signal strength, sampling rates, magnitude of\noutliers, and tail behaviors of model error distributions, among other factors.\nExtensive simulations show the superior performance of the proposed methods.\nAdditionally, we apply our methods to analyze the risk of hard landings in A380\nairplanes by utilizing data from other airplane types,demonstrating that robust\ntransfer learning can improve estimation efficiency for relatively rare\nairplane types with the help of data from other types of airplanes.", "AI": {"tldr": "Robust transfer learning methods with subsampling strategies for handling contaminated external data, improving estimation efficiency for target populations with limited data.", "motivation": "Address the gap in transfer learning where external data is large but contaminated with outliers, while target data is limited, requiring proper subsampling strategies to handle data heterogeneity and contamination.", "method": "Proposed two subsampling strategies: one for bias reduction and one for variance minimization, with approaches to combine them. Studied transfer learning methods with subsamples of contaminated external data, accounting for outliers with arbitrary mean shifts.", "result": "Provided non-asymptotic error bounds showing the roles of sample sizes, signal strength, sampling rates, outlier magnitude, and error distribution tails. Extensive simulations demonstrated superior performance. Applied to A380 airplane hard landing risk analysis using data from other airplane types.", "conclusion": "Robust transfer learning with proper subsampling can significantly improve estimation efficiency for target populations with limited data by effectively leveraging contaminated external data sources."}}
{"id": "2508.12285", "pdf": "https://arxiv.org/pdf/2508.12285", "abs": "https://arxiv.org/abs/2508.12285", "authors": ["Yunbo Lyu", "Zhou Yang", "Jieke Shi", "Jianming Chang", "Yue Liu", "David Lo"], "title": "\"My productivity is boosted, but ...\" Demystifying Users' Perception on AI Coding Assistants", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": "13 pages, Camera-Ready Version that will appear in ASE 2025", "summary": "This paper aims to explore fundamental questions in the era when AI coding\nassistants like GitHub Copilot are widely adopted: what do developers truly\nvalue and criticize in AI coding assistants, and what does this reveal about\ntheir needs and expectations in real-world software development? Unlike\nprevious studies that conduct observational research in controlled and\nsimulated environments, we analyze extensive, first-hand user reviews of AI\ncoding assistants, which capture developers' authentic perspectives and\nexperiences drawn directly from their actual day-to-day work contexts. We\nidentify 1,085 AI coding assistants from the Visual Studio Code Marketplace.\nAlthough they only account for 1.64% of all extensions, we observe a surge in\nthese assistants: over 90% of them are released within the past two years. We\nthen manually analyze the user reviews sampled from 32 AI coding assistants\nthat have sufficient installations and reviews to construct a comprehensive\ntaxonomy of user concerns and feedback about these assistants. We manually\nannotate each review's attitude when mentioning certain aspects of coding\nassistants, yielding nuanced insights into user satisfaction and\ndissatisfaction regarding specific features, concerns, and overall tool\nperformance. Built on top of the findings-including how users demand not just\nintelligent suggestions but also context-aware, customizable, and\nresource-efficient interactions-we propose five practical implications and\nsuggestions to guide the enhancement of AI coding assistants that satisfy user\nneeds.", "AI": {"tldr": "Analysis of 1,085 AI coding assistants from VS Code Marketplace reveals developers value context-aware, customizable, and efficient AI tools, with over 90% released in past two years. Manual review analysis of 32 popular assistants provides taxonomy of user concerns and satisfaction levels.", "motivation": "To understand what developers truly value and criticize in AI coding assistants in real-world usage contexts, moving beyond controlled studies to analyze authentic user experiences from daily work.", "method": "Identified 1,085 AI coding assistants from VS Code Marketplace, manually analyzed user reviews from 32 popular assistants with sufficient installations, and annotated each review's attitude toward specific features and concerns.", "result": "Developers demand not just intelligent suggestions but also context-aware, customizable, and resource-efficient interactions. Taxonomy created of user concerns and satisfaction levels with specific features.", "conclusion": "Five practical implications and suggestions proposed to guide enhancement of AI coding assistants to better satisfy user needs based on authentic developer feedback from real-world usage."}}
{"id": "2508.11780", "pdf": "https://arxiv.org/pdf/2508.11780", "abs": "https://arxiv.org/abs/2508.11780", "authors": ["Moindji\u00e9 Issam-Ali", "Descary Marie-H\u00e9l\u00e8ne", "Beaulac C\u00e9dric"], "title": "Statistical analysis of multivariate planar curves and applications to X-ray classification", "categories": ["stat.ME", "cs.CV", "stat.ML"], "comment": null, "summary": "Recent developments in computer vision have enabled the availability of\nsegmented images across various domains, such as medicine, where segmented\nradiography images play an important role in diagnosis-making. As prediction\nproblems are common in medical image analysis, this work explores the use of\nsegmented images (through the associated contours they highlight) as predictors\nin a supervised classification context. Consequently, we develop a new approach\nfor image analysis that takes into account the shape of objects within images.\nFor this aim, we introduce a new formalism that extends the study of single\nrandom planar curves to the joint analysis of multiple planar curves-referred\nto here as multivariate planar curves. In this framework, we propose a solution\nto the alignment issue in statistical shape analysis. The obtained multivariate\nshape variables are then used in functional classification methods through\ntangent projections. Detection of cardiomegaly in segmented X-rays and\nnumerical experiments on synthetic data demonstrate the appeal and robustness\nof the proposed method.", "AI": {"tldr": "A new method for medical image classification using segmented image contours as shape-based predictors, addressing alignment issues in statistical shape analysis and demonstrating effectiveness in cardiomegaly detection.", "motivation": "Leverage segmented medical images (particularly radiography) for improved diagnosis by using object contours as predictors in supervised classification, addressing the need for shape-aware analysis in medical imaging.", "method": "Developed a formalism for multivariate planar curves to handle multiple curves jointly, solved alignment issues in statistical shape analysis, and used functional classification with tangent projections on the obtained shape variables.", "result": "The method demonstrated appeal and robustness in detecting cardiomegaly from segmented X-rays and performed well in numerical experiments on synthetic data.", "conclusion": "The proposed approach provides an effective framework for shape-based image analysis that can enhance medical diagnosis through better utilization of segmented image contours as predictive features."}}
{"id": "2508.12292", "pdf": "https://arxiv.org/pdf/2508.12292", "abs": "https://arxiv.org/abs/2508.12292", "authors": ["Hyebin Ahn", "Kangwook Jang", "Hoirin Kim"], "title": "HuBERT-VIC: Improving Noise-Robust Automatic Speech Recognition of Speech Foundation Model via Variance-Invariance-Covariance Regularization", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Accepted at Interspeech 2025", "summary": "Noise robustness in speech foundation models (SFMs) has been a critical\nchallenge, as most models are primarily trained on clean data and experience\nperformance degradation when the models are exposed to noisy speech. To address\nthis issue, we propose HuBERT-VIC, a noise-robust SFM with variance,\nin-variance, and covariance regularization (VICReg) objectives. These\nobjectives adjust the statistics of noisy speech representations, enabling the\nmodel to capture diverse acoustic characteristics and improving the\ngeneralization ability across different types of noise. When applied to HuBERT,\nour model shows relative performance improvements of 23.3% on LibriSpeech\ntest-clean and 13.2% on test-other, compared to the baseline model pre-trained\non noisy speech.", "AI": {"tldr": "HuBERT-VIC improves noise robustness in speech foundation models using variance, invariance, and covariance regularization to handle noisy speech better than baseline models.", "motivation": "Speech foundation models degrade in noisy environments since they're primarily trained on clean data, creating a need for better noise robustness.", "method": "Proposes HuBERT-VIC with VICReg objectives that adjust noisy speech representation statistics to capture diverse acoustic characteristics and improve generalization across noise types.", "result": "Achieves 23.3% relative improvement on LibriSpeech test-clean and 13.2% on test-other compared to baseline models pre-trained on noisy speech.", "conclusion": "VICReg regularization effectively enhances noise robustness in speech foundation models, demonstrating significant performance improvements in noisy conditions."}}
{"id": "2508.12300", "pdf": "https://arxiv.org/pdf/2508.12300", "abs": "https://arxiv.org/abs/2508.12300", "authors": ["Gilad Abiri"], "title": "Mutually Assured Deregulation", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "We have convinced ourselves that the way to make AI safe is to make it\nunsafe. Since 2022, policymakers worldwide have embraced the Regulation\nSacrifice - the belief that dismantling safety oversight will deliver security\nthrough AI dominance. Fearing China or USA will gain advantage, nations rush to\neliminate safeguards that might slow progress. This Essay reveals the fatal\nflaw: though AI poses national security challenges, the solution demands\nstronger regulatory frameworks, not weaker ones. A race without guardrails\nbreeds shared danger, not competitive strength. The Regulation Sacrifice makes\nthree false promises. First, it promises durable technological leads. But AI\ncapabilities spread rapidly - performance gaps between U.S. and Chinese systems\ncollapsed from 9 percent to 2 percent in thirteen months. When advantages\nevaporate in months, sacrificing permanent safety for temporary speed makes no\nsense. Second, it promises deregulation accelerates innovation. The opposite\noften proves true. Companies report well-designed governance streamlines\ndevelopment. Investment flows toward regulated markets. Clear rules reduce\nuncertainty; uncertain liability creates paralysis. Environmental standards did\nnot kill the auto industry; they created Tesla and BYD. Third, enhanced\nnational security through deregulation actually undermines security across all\ntimeframes. Near term: it hands adversaries information warfare tools. Medium\nterm: it democratizes bioweapon capabilities. Long term: it guarantees\ndeployment of uncontrollable AGI systems. The Regulation Sacrifice persists\nbecause it serves powerful interests, not security. Tech companies prefer\nfreedom to accountability. Politicians prefer simple stories to complex truths.\nThis creates mutually assured deregulation, where each nation's sprint for\nadvantage guarantees collective vulnerability. The only way to win is not to\nplay.", "AI": {"tldr": "The paper argues that dismantling AI safety regulations for competitive advantage is counterproductive and dangerous, as it creates shared risks without delivering lasting benefits.", "motivation": "To expose the flawed logic of the 'Regulation Sacrifice' - the belief that eliminating AI safety oversight will provide security through technological dominance, when in reality it creates collective vulnerability.", "method": "The essay presents a critical analysis of three false promises made by deregulation advocates: durable technological leads, accelerated innovation through deregulation, and enhanced national security. It uses empirical evidence like the rapid narrowing of AI performance gaps between US and Chinese systems.", "result": "The analysis demonstrates that regulatory frameworks actually streamline development, attract investment, and provide necessary safeguards. Deregulation instead enables information warfare, democratizes dangerous capabilities, and guarantees deployment of uncontrollable AGI systems.", "conclusion": "The race to deregulate AI serves powerful interests rather than security, creating 'mutually assured deregulation' where each nation's pursuit of advantage guarantees collective vulnerability. The only safe path is stronger regulatory frameworks, not weaker ones."}}
{"id": "2508.12314", "pdf": "https://arxiv.org/pdf/2508.12314", "abs": "https://arxiv.org/abs/2508.12314", "authors": ["Chiranjit Mitra"], "title": "Synchronization Dynamics of Heterogeneous, Collaborative Multi-Agent AI Systems", "categories": ["cs.MA", "cs.AI", "nlin.AO"], "comment": "9 pages, 6 figures", "summary": "We present a novel interdisciplinary framework that bridges synchronization\ntheory and multi-agent AI systems by adapting the Kuramoto model to describe\nthe collective dynamics of heterogeneous AI agents engaged in complex task\nexecution. By representing AI agents as coupled oscillators with both phase and\namplitude dynamics, our model captures essential aspects of agent\nspecialization, influence, and communication within networked systems. We\nintroduce an order parameter to quantify the degree of coordination and\nsynchronization, providing insights into how coupling strength, agent\ndiversity, and network topology impact emergent collective behavior.\nFurthermore, we formalize a detailed correspondence between Chain-of-Thought\nprompting in AI reasoning and synchronization phenomena, unifying human-like\niterative problem solving with emergent group intelligence. Through extensive\nsimulations on all-to-all and deterministic scale-free networks, we demonstrate\nthat increased coupling promotes robust synchronization despite heterogeneous\nagent capabilities, reflecting realistic collaborative AI scenarios. Our\nphysics-informed approach establishes a rigorous mathematical foundation for\ndesigning, analyzing, and optimizing scalable, adaptive, and interpretable\nmulti-agent AI systems. This work opens pathways for principled orchestration\nof agentic AI and lays the groundwork for future incorporation of learning\ndynamics and adaptive network architectures to further enhance system\nresilience and efficiency.", "AI": {"tldr": "A physics-inspired framework that applies the Kuramoto oscillator model to multi-agent AI systems, enabling mathematical analysis of agent coordination, synchronization, and emergent collective intelligence.", "motivation": "To establish a rigorous mathematical foundation for understanding and designing multi-agent AI systems by bridging synchronization theory from physics with AI agent dynamics, addressing the need for principled orchestration of heterogeneous AI agents in collaborative scenarios.", "method": "Adapted the Kuramoto model to represent AI agents as coupled oscillators with phase and amplitude dynamics, introduced an order parameter to quantify coordination, and conducted extensive simulations on all-to-all and deterministic scale-free networks to study coupling strength, agent diversity, and network topology effects.", "result": "Demonstrated that increased coupling promotes robust synchronization despite heterogeneous agent capabilities, successfully formalized the correspondence between Chain-of-Thought prompting and synchronization phenomena, and showed that the model captures essential aspects of agent specialization, influence, and communication.", "conclusion": "The framework provides a physics-informed mathematical foundation for designing, analyzing, and optimizing scalable, adaptive multi-agent AI systems, opening pathways for principled agent orchestration and laying groundwork for future incorporation of learning dynamics and adaptive network architectures."}}
{"id": "2508.12190", "pdf": "https://arxiv.org/pdf/2508.12190", "abs": "https://arxiv.org/abs/2508.12190", "authors": ["Jingkai Xu", "De Cheng", "Xiangqian Zhao", "Jungang Yang", "Zilong Wang", "Xinyang Jiang", "Xufang Luo", "Lili Chen", "Xiaoli Ning", "Chengxu Li", "Xinzhu Zhou", "Xuejiao Song", "Ang Li", "Qingyue Xia", "Zhou Zhuang", "Hongfei Ouyang", "Ke Xue", "Yujun Sheng", "Rusong Meng", "Feng Xu", "Xi Yang", "Weimin Ma", "Yusheng Lee", "Dongsheng Li", "Xinbo Gao", "Jianming Liang", "Lili Qiu", "Nannan Wang", "Xianbo Zuo", "Cui Yong"], "title": "DermINO: Hybrid Pretraining for a Versatile Dermatology Foundation Model", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Skin diseases impose a substantial burden on global healthcare systems,\ndriven by their high prevalence (affecting up to 70% of the population),\ncomplex diagnostic processes, and a critical shortage of dermatologists in\nresource-limited areas. While artificial intelligence(AI) tools have\ndemonstrated promise in dermatological image analysis, current models face\nlimitations-they often rely on large, manually labeled datasets and are built\nfor narrow, specific tasks, making them less effective in real-world settings.\nTo tackle these limitations, we present DermNIO, a versatile foundation model\nfor dermatology. Trained on a curated dataset of 432,776 images from three\nsources (public repositories, web-sourced images, and proprietary collections),\nDermNIO incorporates a novel hybrid pretraining framework that augments the\nself-supervised learning paradigm through semi-supervised learning and\nknowledge-guided prototype initialization. This integrated method not only\ndeepens the understanding of complex dermatological conditions, but also\nsubstantially enhances the generalization capability across various clinical\ntasks. Evaluated across 20 datasets, DermNIO consistently outperforms\nstate-of-the-art models across a wide range of tasks. It excels in high-level\nclinical applications including malignancy classification, disease severity\ngrading, multi-category diagnosis, and dermatological image caption, while also\nachieving state-of-the-art performance in low-level tasks such as skin lesion\nsegmentation. Furthermore, DermNIO demonstrates strong robustness in\nprivacy-preserving federated learning scenarios and across diverse skin types\nand sexes. In a blinded reader study with 23 dermatologists, DermNIO achieved\n95.79% diagnostic accuracy (versus clinicians' 73.66%), and AI assistance\nimproved clinician performance by 17.21%.", "AI": {"tldr": "DermNIO is a versatile dermatology foundation model that outperforms state-of-the-art models across 20 datasets, achieving 95.79% diagnostic accuracy vs clinicians' 73.66%, and improving clinician performance by 17.21% with AI assistance.", "motivation": "Skin diseases affect up to 70% of the population, with complex diagnostics and dermatologist shortages in resource-limited areas. Current AI models rely on large labeled datasets and are task-specific, limiting real-world effectiveness.", "method": "Trained on 432,776 images from public repositories, web-sourced images, and proprietary collections. Uses novel hybrid pretraining framework combining self-supervised learning with semi-supervised learning and knowledge-guided prototype initialization.", "result": "Outperforms state-of-the-art models across 20 datasets. Excels in malignancy classification, disease severity grading, multi-category diagnosis, image captioning, and lesion segmentation. Shows strong robustness in federated learning and across diverse skin types/sexes.", "conclusion": "DermNIO demonstrates superior performance and generalization across diverse dermatological tasks, significantly outperforming clinicians and enhancing their diagnostic accuracy when used as an AI assistant."}}
{"id": "2508.12166", "pdf": "https://arxiv.org/pdf/2508.12166", "abs": "https://arxiv.org/abs/2508.12166", "authors": ["Gokul Puthumanaillam", "Aditya Penumarti", "Manav Vora", "Paulo Padrao", "Jose Fuentes", "Leonardo Bobadilla", "Jane Shin", "Melkior Ornik"], "title": "Belief-Conditioned One-Step Diffusion: Real-Time Trajectory Planning with Just-Enough Sensing", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted to CoRL 2025 (Conference on Robot Learning)", "summary": "Robots equipped with rich sensor suites can localize reliably in\npartially-observable environments, but powering every sensor continuously is\nwasteful and often infeasible. Belief-space planners address this by\npropagating pose-belief covariance through analytic models and switching\nsensors heuristically--a brittle, runtime-expensive approach. Data-driven\napproaches--including diffusion models--learn multi-modal trajectories from\ndemonstrations, but presuppose an accurate, always-on state estimate. We\naddress the largely open problem: for a given task in a mapped environment,\nwhich \\textit{minimal sensor subset} must be active at each location to\nmaintain state uncertainty \\textit{just low enough} to complete the task? Our\nkey insight is that when a diffusion planner is explicitly conditioned on a\npose-belief raster and a sensor mask, the spread of its denoising trajectories\nyields a calibrated, differentiable proxy for the expected localisation error.\nBuilding on this insight, we present Belief-Conditioned One-Step Diffusion\n(B-COD), the first planner that, in a 10 ms forward pass, returns a\nshort-horizon trajectory, per-waypoint aleatoric variances, and a proxy for\nlocalisation error--eliminating external covariance rollouts. We show that this\nsingle proxy suffices for a soft-actor-critic to choose sensors online,\noptimising energy while bounding pose-covariance growth. We deploy B-COD in\nreal-time marine trials on an unmanned surface vehicle and show that it reduces\nsensing energy consumption while matching the goal-reach performance of an\nalways-on baseline.", "AI": {"tldr": "B-COD is a belief-conditioned diffusion planner that enables real-time sensor selection for robots, reducing energy consumption while maintaining localization accuracy through a single forward pass.", "motivation": "Traditional belief-space planners are brittle and computationally expensive for sensor switching, while data-driven approaches assume always-on state estimation. There's a need for minimal sensor activation that maintains just enough localization accuracy for task completion.", "method": "Belief-Conditioned One-Step Diffusion (B-COD) conditions diffusion models on pose-belief raster and sensor mask, using trajectory spread as a differentiable proxy for localization error. This enables soft-actor-critic to choose sensors online.", "result": "B-COD reduces sensing energy consumption while matching goal-reach performance of always-on baselines. It operates in 10ms forward passes without external covariance rollouts.", "conclusion": "The approach successfully addresses minimal sensor subset selection for task completion, providing real-time planning with energy optimization while bounding pose uncertainty growth in real-world marine deployments."}}
{"id": "2508.12353", "pdf": "https://arxiv.org/pdf/2508.12353", "abs": "https://arxiv.org/abs/2508.12353", "authors": ["Marcel Gregoriadis", "Jingwei Kang", "Johan Pouwelse"], "title": "A Large-Scale Web Search Dataset for Federated Online Learning to Rank", "categories": ["cs.IR", "cs.AI", "cs.DC"], "comment": "Accepted at CIKM 2025", "summary": "The centralized collection of search interaction logs for training ranking\nmodels raises significant privacy concerns. Federated Online Learning to Rank\n(FOLTR) offers a privacy-preserving alternative by enabling collaborative model\ntraining without sharing raw user data. However, benchmarks in FOLTR are\nlargely based on random partitioning of classical learning-to-rank datasets,\nsimulated user clicks, and the assumption of synchronous client participation.\nThis oversimplifies real-world dynamics and undermines the realism of\nexperimental results. We present AOL4FOLTR, a large-scale web search dataset\nwith 2.6 million queries from 10,000 users. Our dataset addresses key\nlimitations of existing benchmarks by including user identifiers, real click\ndata, and query timestamps, enabling realistic user partitioning, behavior\nmodeling, and asynchronous federated learning scenarios.", "AI": {"tldr": "AOL4FOLTR is a new large-scale web search dataset designed for realistic Federated Online Learning to Rank (FOLTR) benchmarking, addressing privacy concerns and limitations of existing synthetic benchmarks.", "motivation": "Current FOLTR benchmarks use random dataset partitioning, simulated clicks, and assume synchronous client participation, which oversimplifies real-world dynamics and undermines experimental realism.", "method": "Created AOL4FOLTR dataset with 2.6 million queries from 10,000 users, including user identifiers, real click data, and query timestamps to enable realistic user partitioning, behavior modeling, and asynchronous federated learning scenarios.", "result": "The dataset provides a more realistic foundation for FOLTR research by capturing authentic user behavior patterns and enabling asynchronous learning scenarios that reflect real-world deployment conditions.", "conclusion": "AOL4FOLTR addresses key limitations of existing FOLTR benchmarks and provides a more realistic dataset for evaluating privacy-preserving federated learning approaches in search ranking systems."}}
{"id": "2508.12268", "pdf": "https://arxiv.org/pdf/2508.12268", "abs": "https://arxiv.org/abs/2508.12268", "authors": ["Esra Mehmedova", "Santiago Berrezueta-Guzman", "Stefan Wagner"], "title": "iTrace: Click-Based Gaze Visualization on the Apple Vision Pro", "categories": ["cs.HC", "cs.CV"], "comment": "Paper submitted to ACM SIGGRAPH Motion, Interaction and Games 2025\n  (MIG 2025)", "summary": "The Apple Vision Pro is equipped with accurate eye-tracking capabilities, yet\nthe privacy restrictions on the device prevent direct access to continuous user\ngaze data. This study introduces iTrace, a novel application that overcomes\nthese limitations through click-based gaze extraction techniques, including\nmanual methods like a pinch gesture, and automatic approaches utilizing dwell\ncontrol or a gaming controller. We developed a system with a client-server\narchitecture that captures the gaze coordinates and transforms them into\ndynamic heatmaps for video and spatial eye tracking. The system can generate\nindividual and averaged heatmaps, enabling analysis of personal and collective\nattention patterns.\n  To demonstrate its effectiveness and evaluate the usability and performance,\na study was conducted with two groups of 10 participants, each testing\ndifferent clicking methods. The 8BitDo controller achieved higher average data\ncollection rates at 14.22 clicks/s compared to 0.45 clicks/s with dwell\ncontrol, enabling significantly denser heatmap visualizations. The resulting\nheatmaps reveal distinct attention patterns, including concentrated focus in\nlecture videos and broader scanning during problem-solving tasks. By allowing\ndynamic attention visualization while maintaining a high gaze precision of 91\n%, iTrace demonstrates strong potential for a wide range of applications in\neducational content engagement, environmental design evaluation, marketing\nanalysis, and clinical cognitive assessment. Despite the current gaze data\nrestrictions on the Apple Vision Pro, we encourage developers to use iTrace\nonly in research settings.", "AI": {"tldr": "iTrace enables gaze tracking on Apple Vision Pro despite privacy restrictions by using click-based methods, achieving 91% precision and revealing distinct attention patterns through heatmap visualizations.", "motivation": "Apple Vision Pro has accurate eye-tracking but privacy restrictions prevent direct access to continuous gaze data, limiting research and application development.", "method": "Developed iTrace with client-server architecture using click-based gaze extraction (pinch gestures, dwell control, gaming controller) to capture gaze coordinates and generate dynamic heatmaps for video and spatial tracking.", "result": "8BitDo controller achieved 14.22 clicks/s vs 0.45 clicks/s with dwell control, enabling denser heatmaps. System showed 91% gaze precision and revealed distinct attention patterns (concentrated focus in lectures, broader scanning in problem-solving).", "conclusion": "iTrace demonstrates strong potential for educational content analysis, environmental design, marketing, and clinical assessment despite current restrictions, but should be used only in research settings."}}
{"id": "2508.12204", "pdf": "https://arxiv.org/pdf/2508.12204", "abs": "https://arxiv.org/abs/2508.12204", "authors": ["Mauro Belgiovine", "Suyash Pradhan", "Johannes Lange", "Michael L\u00f6hning", "Kaushik Chowdhury"], "title": "ATLAS: AI-Native Receiver Test-and-Measurement by Leveraging AI-Guided Search", "categories": ["eess.SP", "cs.LG", "cs.NI"], "comment": "Accepted at IEEE PIMRC 2025", "summary": "Industry adoption of Artificial Intelligence (AI)-native wireless receivers,\nor even modular, Machine Learning (ML)-aided wireless signal processing blocks,\nhas been slow. The main concern is the lack of explainability of these trained\nML models and the significant risks posed to network functionalities in case of\nfailures, especially since (i) testing on every exhaustive case is infeasible\nand (ii) the data used for model training may not be available. This paper\nproposes ATLAS, an AI-guided approach that generates a battery of tests for\npre-trained AI-native receiver models and benchmarks the performance against a\nclassical receiver architecture. Using gradient-based optimization, it avoids\nspanning the exhaustive set of all environment and channel conditions; instead,\nit generates the next test in an online manner to further probe specific\nconfigurations that offer the highest risk of failure. We implement and\nvalidate our approach by adopting the well-known DeepRx AI-native receiver\nmodel as well as a classical receiver using differentiable tensors in NVIDIA's\nSionna environment. ATLAS uncovers specific combinations of mobility, channel\ndelay spread, and noise, where fully and partially trained variants of\nAI-native DeepRx perform suboptimally compared to the classical receivers. Our\nproposed method reduces the number of tests required per failure found by 19%\ncompared to grid search for a 3-parameters input optimization problem,\ndemonstrating greater efficiency. In contrast, the computational cost of the\ngrid-based approach scales exponentially with the number of variables, making\nit increasingly impractical for high-dimensional problems.", "AI": {"tldr": "ATLAS is an AI-guided testing framework that efficiently generates targeted tests for AI-native wireless receivers to identify failure conditions, reducing test requirements by 19% compared to grid search.", "motivation": "Slow industry adoption of AI-native wireless receivers due to lack of explainability and risks from potential failures, with exhaustive testing being infeasible and training data often unavailable.", "method": "Uses gradient-based optimization to generate tests online that probe specific configurations with highest failure risk, implemented in NVIDIA's Sionna environment with DeepRx AI-native receiver and classical receiver models.", "result": "Uncovered specific combinations of mobility, channel delay spread, and noise where AI-native DeepRx performs suboptimally compared to classical receivers, with 19% fewer tests required per failure found.", "conclusion": "ATLAS provides an efficient alternative to exhaustive grid search for testing AI-native wireless receivers, demonstrating practical viability for identifying failure conditions in high-dimensional parameter spaces."}}
{"id": "2508.12358", "pdf": "https://arxiv.org/pdf/2508.12358", "abs": "https://arxiv.org/abs/2508.12358", "authors": ["Haolin Jin", "Huaming Chen"], "title": "Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to the NIER track of the 40th IEEE/ACM International\n  Conference on Automated Software Engineering (ASE 2025)", "summary": "Large language models (LLMs) have become essential tools in software\ndevelopment, widely used for requirements engineering, code generation and\nreview tasks. Software engineers often rely on LLMs to assess whether system\ncode implementation satisfy task requirements, thereby enhancing code\nrobustness and accuracy. However, it remains unclear whether LLMs can reliably\ndetermine whether the code complies fully with the given task descriptions,\nwhich is usually natural language specifications. In this paper, we uncover a\nsystematic failure of LLMs in evaluating whether code aligns with natural\nlanguage requirements. Specifically, with widely used benchmarks, we employ\nunified prompts to judge code correctness. Our results reveal that LLMs\nfrequently misclassify correct code implementations as either ``not satisfying\nrequirements'' or containing potential defects. Surprisingly, more complex\nprompting, especially when leveraging prompt engineering techniques involving\nexplanations and proposed corrections, leads to higher misjudgment rate, which\nhighlights the critical reliability issues in using LLMs as code review\nassistants. We further analyze the root causes of these misjudgments, and\npropose two improved prompting strategies for mitigation. For the first time,\nour findings reveals unrecognized limitations in LLMs to match code with\nrequirements. We also offer novel insights and practical guidance for effective\nuse of LLMs in automated code review and task-oriented agent scenarios.", "AI": {"tldr": "LLMs systematically fail at evaluating whether code correctly implements natural language requirements, often misclassifying correct code as defective, with more complex prompting making the problem worse.", "motivation": "LLMs are widely used for code review and requirements validation, but it's unclear if they can reliably determine whether code properly implements natural language specifications.", "method": "Used unified prompts on widely used benchmarks to judge code correctness, tested various prompting strategies including explanations and corrections, and analyzed root causes of misjudgments.", "result": "LLMs frequently misclassify correct code implementations as either not satisfying requirements or containing defects, with more complex prompting leading to higher misjudgment rates.", "conclusion": "LLMs have unrecognized limitations in matching code with requirements, highlighting critical reliability issues for using them as code review assistants, with proposed mitigation strategies."}}
{"id": "2508.12438", "pdf": "https://arxiv.org/pdf/2508.12438", "abs": "https://arxiv.org/abs/2508.12438", "authors": ["Yaron Aloni", "Rotem Shalev-Arkushin", "Yonatan Shafir", "Guy Tevet", "Ohad Fried", "Amit Haim Bermano"], "title": "Express4D: Expressive, Friendly, and Extensible 4D Facial Motion Generation Benchmark", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Dynamic facial expression generation from natural language is a crucial task\nin Computer Graphics, with applications in Animation, Virtual Avatars, and\nHuman-Computer Interaction. However, current generative models suffer from\ndatasets that are either speech-driven or limited to coarse emotion labels,\nlacking the nuanced, expressive descriptions needed for fine-grained control,\nand were captured using elaborate and expensive equipment. We hence present a\nnew dataset of facial motion sequences featuring nuanced performances and\nsemantic annotation. The data is easily collected using commodity equipment and\nLLM-generated natural language instructions, in the popular ARKit blendshape\nformat. This provides riggable motion, rich with expressive performances and\nlabels. We accordingly train two baseline models, and evaluate their\nperformance for future benchmarking. Using our Express4D dataset, the trained\nmodels can learn meaningful text-to-expression motion generation and capture\nthe many-to-many mapping of the two modalities. The dataset, code, and video\nexamples are available on our webpage: https://jaron1990.github.io/Express4D/", "AI": {"tldr": "Express4D dataset enables fine-grained text-to-facial-expression generation using commodity equipment and LLM-generated annotations, providing riggable motion data for improved facial animation control.", "motivation": "Current facial expression datasets are limited to speech-driven or coarse emotion labels, lacking nuanced expressive descriptions and requiring expensive capture equipment, which hinders fine-grained control in animation and virtual avatars.", "method": "Created a new facial motion dataset using commodity equipment with ARKit blendshape format, featuring nuanced performances and semantic annotations generated by LLMs. Trained two baseline models for text-to-expression motion generation.", "result": "The Express4D dataset provides rich expressive performances with detailed labels. Trained models successfully learn meaningful text-to-expression generation and capture the many-to-many mapping between text and facial expressions.", "conclusion": "Express4D enables accessible, fine-grained facial expression generation from natural language, overcoming limitations of existing datasets and expensive equipment requirements, with applications in animation, virtual avatars, and human-computer interaction."}}
{"id": "2508.12445", "pdf": "https://arxiv.org/pdf/2508.12445", "abs": "https://arxiv.org/abs/2508.12445", "authors": ["Shayan Kebriti", "Shahabedin Nabavi", "Ali Gooya"], "title": "FractMorph: A Fractional Fourier-Based Multi-Domain Transformer for Deformable Image Registration", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Deformable image registration (DIR) is a crucial and challenging technique\nfor aligning anatomical structures in medical images and is widely applied in\ndiverse clinical applications. However, existing approaches often struggle to\ncapture fine-grained local deformations and large-scale global deformations\nsimultaneously within a unified framework. We present FractMorph, a novel 3D\ndual-parallel transformer-based architecture that enhances cross-image feature\nmatching through multi-domain fractional Fourier transform (FrFT) branches.\nEach Fractional Cross-Attention (FCA) block applies parallel FrFTs at\nfractional angles of 0{\\deg}, 45{\\deg}, 90{\\deg}, along with a log-magnitude\nbranch, to effectively extract local, semi-global, and global features at the\nsame time. These features are fused via cross-attention between the fixed and\nmoving image streams. A lightweight U-Net style network then predicts a dense\ndeformation field from the transformer-enriched features. On the ACDC cardiac\nMRI dataset, FractMorph achieves state-of-the-art performance with an overall\nDice Similarity Coefficient (DSC) of 86.45%, an average per-structure DSC of\n75.15%, and a 95th-percentile Hausdorff distance (HD95) of 1.54 mm on our data\nsplit. We also introduce FractMorph-Light, a lightweight variant of our model\nwith only 29.6M parameters, which maintains the superior accuracy of the main\nmodel while using approximately half the memory. Our results demonstrate that\nmulti-domain spectral-spatial attention in transformers can robustly and\nefficiently model complex non-rigid deformations in medical images using a\nsingle end-to-end network, without the need for scenario-specific tuning or\nhierarchical multi-scale networks. The source code of our implementation is\navailable at https://github.com/shayankebriti/FractMorph.", "AI": {"tldr": "FractMorph is a novel 3D dual-parallel transformer architecture for deformable image registration that uses multi-domain fractional Fourier transform branches to simultaneously capture local, semi-global, and global deformations in medical images.", "motivation": "Existing deformable image registration approaches struggle to capture both fine-grained local deformations and large-scale global deformations simultaneously within a unified framework, limiting their effectiveness in medical imaging applications.", "method": "A 3D dual-parallel transformer architecture with Fractional Cross-Attention blocks that apply parallel FrFTs at 0\u00b0, 45\u00b0, and 90\u00b0 angles plus a log-magnitude branch to extract multi-scale features. Features are fused via cross-attention and a lightweight U-Net predicts dense deformation fields.", "result": "State-of-the-art performance on ACDC cardiac MRI dataset: 86.45% overall DSC, 75.15% average per-structure DSC, and 1.54mm HD95. Also developed FractMorph-Light variant with 29.6M parameters maintaining similar accuracy with half the memory.", "conclusion": "Multi-domain spectral-spatial attention in transformers can robustly and efficiently model complex non-rigid deformations using a single end-to-end network without scenario-specific tuning or hierarchical multi-scale networks."}}
{"id": "2508.12469", "pdf": "https://arxiv.org/pdf/2508.12469", "abs": "https://arxiv.org/abs/2508.12469", "authors": ["Abhinav Chalise", "Nimesh Gopal Pradhan", "Nishan Khanal", "Prashant Raj Bista", "Dinesh Baniya Kshatri"], "title": "Mechanical Automation with Vision: A Design for Rubik's Cube Solver", "categories": ["cs.RO", "cs.CV"], "comment": "Presented at the 15th IOE Graduate Conference, Tribhuvan University,\n  May 2024. Original paper available at\n  https://conference.ioe.edu.np/publications/ioegc15/IOEGC-15-023-C1-2-42.pdf", "summary": "The core mechanical system is built around three stepper motors for physical\nmanipulation, a microcontroller for hardware control, a camera and YOLO\ndetection model for real-time cube state detection. A significant software\ncomponent is the development of a user-friendly graphical user interface (GUI)\ndesigned in Unity. The initial state after detection from real-time YOLOv8\nmodel (Precision 0.98443, Recall 0.98419, Box Loss 0.42051, Class Loss 0.2611)\nis virtualized on GUI. To get the solution, the system employs the Kociemba's\nalgorithm while physical manipulation with a single degree of freedom is done\nby combination of stepper motors' interaction with the cube achieving the\naverage solving time of ~2.2 minutes.", "AI": {"tldr": "A robotic system that solves Rubik's cubes using YOLOv8 for real-time detection, Kociemba's algorithm for solution finding, and stepper motors for physical manipulation with ~2.2 minute average solving time.", "motivation": "To develop an automated system that can physically detect and solve Rubik's cubes using computer vision and robotics, providing both hardware manipulation and user-friendly visualization.", "method": "Uses three stepper motors for physical manipulation, microcontroller for control, YOLOv8 model for real-time cube state detection (Precision: 0.98443, Recall: 0.98419), Unity GUI for visualization, and Kociemba's algorithm for solution finding with single degree of freedom manipulation.", "result": "Achieved high detection accuracy with YOLOv8 (low box/class losses: 0.42051 and 0.2611 respectively) and average solving time of approximately 2.2 minutes.", "conclusion": "The system successfully integrates computer vision, algorithmic solving, and robotic manipulation to create an efficient automated Rubik's cube solver with real-time state detection and user-friendly interface."}}
{"id": "2508.12508", "pdf": "https://arxiv.org/pdf/2508.12508", "abs": "https://arxiv.org/abs/2508.12508", "authors": ["Anqi Feng", "Zhangxing Bian", "Samuel W. Remedios", "Savannah P. Hays", "Blake E. Dewey", "Jiachen Zhuo", "Dan Benjamini", "Jerry L. Prince"], "title": "Segmenting Thalamic Nuclei: T1 Maps Provide a Reliable and Efficient Solution", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "comment": null, "summary": "Accurate thalamic nuclei segmentation is crucial for understanding\nneurological diseases, brain functions, and guiding clinical interventions.\nHowever, the optimal inputs for segmentation remain unclear. This study\nsystematically evaluates multiple MRI contrasts, including MPRAGE and FGATIR\nsequences, quantitative PD and T1 maps, and multiple T1-weighted images at\ndifferent inversion times (multi-TI), to determine the most effective inputs.\nFor multi-TI images, we employ a gradient-based saliency analysis with Monte\nCarlo dropout and propose an Overall Importance Score to select the images\ncontributing most to segmentation. A 3D U-Net is trained on each of these\nconfigurations. Results show that T1 maps alone achieve strong quantitative\nperformance and superior qualitative outcomes, while PD maps offer no added\nvalue. These findings underscore the value of T1 maps as a reliable and\nefficient input among the evaluated options, providing valuable guidance for\noptimizing imaging protocols when thalamic structures are of clinical or\nresearch interest.", "AI": {"tldr": "T1 maps alone provide the best thalamic nuclei segmentation performance among various MRI contrasts, while PD maps offer no benefit.", "motivation": "Accurate thalamic nuclei segmentation is crucial for neurological disease understanding and clinical interventions, but the optimal MRI inputs remain unclear.", "method": "Systematic evaluation of multiple MRI contrasts (MPRAGE, FGATIR, PD maps, T1 maps, multi-TI images) using 3D U-Net. For multi-TI, gradient-based saliency analysis with Monte Carlo dropout and Overall Importance Score to select most contributory images.", "result": "T1 maps alone achieve strong quantitative performance and superior qualitative outcomes. PD maps offer no added value for segmentation.", "conclusion": "T1 maps are the most reliable and efficient input among evaluated options, providing guidance for optimizing imaging protocols when thalamic structures are of interest."}}
{"id": "2508.12413", "pdf": "https://arxiv.org/pdf/2508.12413", "abs": "https://arxiv.org/abs/2508.12413", "authors": ["Zidong Cui", "Pan Zhang", "Ying Tang"], "title": "Quantum Flow Matching", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "15 pages, 11 figures", "summary": "Flow matching has rapidly become a dominant paradigm in classical generative\nmodeling, offering an efficient way to interpolate between two complex\ndistributions. We extend this idea to the quantum realm and introduce Quantum\nFlow Matching (QFM)-a fully quantum-circuit realization that offers efficient\ninterpolation between two density matrices. QFM offers systematic preparation\nof density matrices and generation of samples for accurately estimating\nobservables, and can be realized on a quantum computer without the need for\ncostly circuit redesigns. We validate its versatility on a set of applications:\n(i) generating target states with prescribed magnetization and entanglement\nentropy, (ii) estimating nonequilibrium free-energy differences to test the\nquantum Jarzynski equality, and (iii) expediting the study on superdiffusion\nbreakdown. These results position QFM as a unifying and promising framework for\ngenerative modeling across quantum systems.", "AI": {"tldr": "Quantum Flow Matching (QFM) extends classical flow matching to quantum systems, enabling efficient interpolation between density matrices using quantum circuits without costly redesigns.", "motivation": "To bring the efficiency and effectiveness of classical flow matching generative modeling to quantum systems for systematic density matrix preparation and observable estimation.", "method": "Quantum Flow Matching (QFM) - a fully quantum-circuit realization that interpolates between two density matrices, implemented on quantum computers without circuit redesign requirements.", "result": "Validated on multiple applications: generating target states with specific magnetization/entanglement, estimating nonequilibrium free-energy differences for quantum Jarzynski equality testing, and accelerating superdiffusion breakdown studies.", "conclusion": "QFM emerges as a unifying and promising framework for generative modeling across quantum systems, offering versatile applications in quantum state preparation and observable estimation."}}
{"id": "2508.12554", "pdf": "https://arxiv.org/pdf/2508.12554", "abs": "https://arxiv.org/abs/2508.12554", "authors": ["Hamza El-Kebir"], "title": "PROD: Palpative Reconstruction of Deformable Objects through Elastostatic Signed Distance Functions", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted for presentation at the 2025 IEEE Conference on Decision and\n  Control (CDC)", "summary": "We introduce PROD (Palpative Reconstruction of Deformables), a novel method\nfor reconstructing the shape and mechanical properties of deformable objects\nusing elastostatic signed distance functions (SDFs). Unlike traditional\napproaches that rely on purely geometric or visual data, PROD integrates\npalpative interaction -- measured through force-controlled surface probing --\nto estimate both the static and dynamic response of soft materials. We model\nthe deformation of an object as an elastostatic process and derive a governing\nPoisson equation for estimating its SDF from a sparse set of pose and force\nmeasurements. By incorporating steady-state elastodynamic assumptions, we show\nthat the undeformed SDF can be recovered from deformed observations with\nprovable convergence. Our approach also enables the estimation of material\nstiffness by analyzing displacement responses to varying force inputs. We\ndemonstrate the robustness of PROD in handling pose errors, non-normal force\napplication, and curvature errors in simulated soft body interactions. These\ncapabilities make PROD a powerful tool for reconstructing deformable objects in\napplications ranging from robotic manipulation to medical imaging and haptic\nfeedback systems.", "AI": {"tldr": "PROD is a novel method that reconstructs deformable object shapes and mechanical properties using palpative interaction and elastostatic SDFs, enabling robust estimation from sparse force and pose measurements.", "motivation": "Traditional approaches rely on purely geometric or visual data, which lack the ability to capture mechanical properties and dynamic responses of soft materials needed for applications like robotic manipulation and medical imaging.", "method": "Models deformation as an elastostatic process using a Poisson equation for SDF estimation from force-controlled surface probing. Incorporates steady-state elastodynamic assumptions to recover undeformed SDF from deformed observations with provable convergence.", "result": "Demonstrates robustness in handling pose errors, non-normal force application, and curvature errors in simulated soft body interactions. Enables estimation of material stiffness from displacement responses to varying force inputs.", "conclusion": "PROD provides a powerful tool for reconstructing deformable objects with applications in robotic manipulation, medical imaging, and haptic feedback systems by integrating palpative interaction with elastostatic modeling."}}
{"id": "2508.12562", "pdf": "https://arxiv.org/pdf/2508.12562", "abs": "https://arxiv.org/abs/2508.12562", "authors": ["Hyeonjin Choi", "Yang-gon Kim", "Dong-yeon Yoo", "Ju-sung Sun", "Jung-won Lee"], "title": "Anatomic Feature Fusion Model for Diagnosing Calcified Pulmonary Nodules on Chest X-Ray", "categories": ["eess.IV", "cs.CV"], "comment": "8 pages, 4 figures", "summary": "Accurate and timely identification of pulmonary nodules on chest X-rays can\ndifferentiate between life-saving early treatment and avoidable invasive\nprocedures. Calcification is a definitive indicator of benign nodules and is\nthe primary foundation for diagnosis. In actual practice, diagnosing pulmonary\nnodule calcification on chest X-rays predominantly depends on the physician's\nvisual assessment, resulting in significant diversity in interpretation.\nFurthermore, overlapping anatomical elements, such as ribs and spine,\ncomplicate the precise identification of calcification patterns. This study\npresents a calcification classification model that attains strong diagnostic\nperformance by utilizing fused features derived from raw images and their\nstructure-suppressed variants to reduce structural interference. We used 2,517\nlesion-free images and 656 nodule images (151 calcified nodules and 550\nnon-calcified nodules), all obtained from Ajou University Hospital. The\nsuggested model attained an accuracy of 86.52% and an AUC of 0.8889 in\ncalcification diagnosis, surpassing the model trained on raw images by 3.54%\nand 0.0385, respectively.", "AI": {"tldr": "A calcification classification model using fused features from raw and structure-suppressed chest X-ray images achieves 86.52% accuracy and 0.8889 AUC in identifying benign pulmonary nodules.", "motivation": "Accurate identification of pulmonary nodule calcification on chest X-rays is crucial for early treatment decisions but suffers from physician interpretation variability and anatomical interference from ribs/spine.", "method": "Developed a calcification classification model using fused features from both raw images and their structure-suppressed variants to reduce structural interference, trained on 2,517 lesion-free and 656 nodule images (151 calcified, 550 non-calcified).", "result": "The model achieved 86.52% accuracy and 0.8889 AUC in calcification diagnosis, outperforming models trained only on raw images by 3.54% and 0.0385 respectively.", "conclusion": "The proposed fusion approach with structure-suppressed variants significantly improves calcification classification performance, providing a more reliable tool for differentiating benign pulmonary nodules on chest X-rays."}}
{"id": "2508.12412", "pdf": "https://arxiv.org/pdf/2508.12412", "abs": "https://arxiv.org/abs/2508.12412", "authors": ["Ron Solomon", "Yarin Yerushalmi Levi", "Lior Vaknin", "Eran Aizikovich", "Amit Baras", "Etai Ohana", "Amit Giloni", "Shamik Bose", "Chiara Picardi", "Yuval Elovici", "Asaf Shabtai"], "title": "LumiMAS: A Comprehensive Framework for Real-Time Monitoring and Enhanced Observability in Multi-Agent Systems", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The incorporation of large language models in multi-agent systems (MASs) has\nthe potential to significantly improve our ability to autonomously solve\ncomplex problems. However, such systems introduce unique challenges in\nmonitoring, interpreting, and detecting system failures. Most existing MAS\nobservability frameworks focus on analyzing each individual agent separately,\noverlooking failures associated with the entire MAS. To bridge this gap, we\npropose LumiMAS, a novel MAS observability framework that incorporates advanced\nanalytics and monitoring techniques. The proposed framework consists of three\nkey components: a monitoring and logging layer, anomaly detection layer, and\nanomaly explanation layer. LumiMAS's first layer monitors MAS executions,\ncreating detailed logs of the agents' activity. These logs serve as input to\nthe anomaly detection layer, which detects anomalies across the MAS workflow in\nreal time. Then, the anomaly explanation layer performs classification and root\ncause analysis (RCA) of the detected anomalies. LumiMAS was evaluated on seven\ndifferent MAS applications, implemented using two popular MAS platforms, and a\ndiverse set of possible failures. The applications include two novel\nfailure-tailored applications that illustrate the effects of a hallucination or\nbias on the MAS. The evaluation results demonstrate LumiMAS's effectiveness in\nfailure detection, classification, and RCA.", "AI": {"tldr": "LumiMAS is a novel multi-agent system observability framework that detects and explains system-wide failures in real-time through three-layer monitoring, anomaly detection, and root cause analysis.", "motivation": "Existing MAS observability frameworks focus on individual agents and overlook system-wide failures, creating a gap in monitoring complex multi-agent systems with large language models.", "method": "Three-layer framework: 1) Monitoring and logging layer tracks agent activities, 2) Anomaly detection layer identifies workflow anomalies in real-time, 3) Anomaly explanation layer performs classification and root cause analysis.", "result": "Evaluated on seven MAS applications using two platforms with diverse failures including hallucination and bias scenarios. Demonstrated effectiveness in failure detection, classification, and root cause analysis.", "conclusion": "LumiMAS successfully bridges the gap in MAS observability by providing comprehensive system-wide monitoring and failure analysis capabilities for complex multi-agent systems."}}
{"id": "2508.12564", "pdf": "https://arxiv.org/pdf/2508.12564", "abs": "https://arxiv.org/abs/2508.12564", "authors": ["Jiayao Mai", "Xiuyuan Lu", "Kuan Dai", "Shaojie Shen", "Yi Zhou"], "title": "Temporal and Rotational Calibration for Event-Centric Multi-Sensor Systems", "categories": ["cs.RO", "cs.CV", "I.2.9"], "comment": "8 pages, 5 figures", "summary": "Event cameras generate asynchronous signals in response to pixel-level\nbrightness changes, offering a sensing paradigm with theoretically\nmicrosecond-scale latency that can significantly enhance the performance of\nmulti-sensor systems. Extrinsic calibration is a critical prerequisite for\neffective sensor fusion; however, the configuration that involves event cameras\nremains an understudied topic. In this paper, we propose a motion-based\ntemporal and rotational calibration framework tailored for event-centric\nmulti-sensor systems, eliminating the need for dedicated calibration targets.\nOur method uses as input the rotational motion estimates obtained from event\ncameras and other heterogeneous sensors, respectively. Different from\nconventional approaches that rely on event-to-frame conversion, our method\nefficiently estimates angular velocity from normal flow observations, which are\nderived from the spatio-temporal profile of event data. The overall calibration\npipeline adopts a two-step approach: it first initializes the temporal offset\nand rotational extrinsics by exploiting kinematic correlations in the spirit of\nCanonical Correlation Analysis (CCA), and then refines both temporal and\nrotational parameters through a joint non-linear optimization using a\ncontinuous-time parametrization in SO(3). Extensive evaluations on both\npublicly available and self-collected datasets validate that the proposed\nmethod achieves calibration accuracy comparable to target-based methods, while\nexhibiting superior stability over purely CCA-based methods, and highlighting\nits precision, robustness and flexibility. To facilitate future research, our\nimplementation will be made open-source. Code:\nhttps://github.com/NAIL-HNU/EvMultiCalib.", "AI": {"tldr": "Motion-based calibration framework for event camera systems that estimates temporal offset and rotational extrinsics without calibration targets, using angular velocity from event data and joint optimization.", "motivation": "Event cameras offer microsecond latency but extrinsic calibration for multi-sensor systems with event cameras is understudied. Target-based calibration is inconvenient, so a target-free method is needed.", "method": "Two-step approach: 1) Initialize temporal offset and rotational extrinsics using kinematic correlations (CCA-inspired), 2) Refine parameters through joint non-linear optimization with continuous-time SO(3) parametrization. Uses angular velocity from normal flow observations derived from event data.", "result": "Achieves calibration accuracy comparable to target-based methods, with superior stability over purely CCA-based methods. Demonstrates precision, robustness and flexibility on public and self-collected datasets.", "conclusion": "Proposed framework provides accurate target-free calibration for event-centric multi-sensor systems, with open-source implementation to facilitate future research."}}
{"id": "2508.12477", "pdf": "https://arxiv.org/pdf/2508.12477", "abs": "https://arxiv.org/abs/2508.12477", "authors": ["Ratun Rahman", "Atit Pokharel", "Md Raihan Uddin", "Dinh C. Nguyen"], "title": "SimQFL: A Quantum Federated Learning Simulator with Real-Time Visualization", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Quantum federated learning (QFL) is an emerging field that has the potential\nto revolutionize computation by taking advantage of quantum physics concepts in\na distributed machine learning (ML) environment. However, the majority of\navailable quantum simulators are primarily built for general quantum circuit\nsimulation and do not include integrated support for machine learning tasks\nsuch as training, evaluation, and iterative optimization. Furthermore,\ndesigning and assessing quantum learning algorithms is still a difficult and\nresource-intensive task. Real-time updates are essential for observing model\nconvergence, debugging quantum circuits, and making conscious choices during\ntraining with the use of limited resources. Furthermore, most current\nsimulators fail to support the integration of user-specific data for training\npurposes, undermining the main purpose of using a simulator. In this study, we\nintroduce SimQFL, a customized simulator that simplifies and accelerates QFL\nexperiments in quantum network applications. SimQFL supports real-time,\nepoch-wise output development and visualization, allowing researchers to\nmonitor the process of learning across each training round. Furthermore, SimQFL\noffers an intuitive and visually appealing interface that facilitates ease of\nuse and seamless execution. Users can customize key variables such as the\nnumber of epochs, learning rates, number of clients, and quantum\nhyperparameters such as qubits and quantum layers, making the simulator\nsuitable for various QFL applications. The system gives immediate feedback\nfollowing each epoch by showing intermediate outcomes and dynamically\nillustrating learning curves. SimQFL is a practical and interactive platform\nenabling academics and developers to prototype, analyze, and tune quantum\nneural networks with greater transparency and control in distributed quantum\nnetworks.", "AI": {"tldr": "SimQFL is a specialized quantum federated learning simulator that provides real-time visualization, customization, and interactive debugging for quantum neural networks in distributed quantum networks.", "motivation": "Existing quantum simulators lack integrated ML support, real-time updates, and user-specific data integration, making QFL algorithm development difficult and resource-intensive.", "method": "Developed SimQFL - a customized simulator with real-time epoch-wise output visualization, intuitive interface, and customizable parameters (epochs, learning rates, clients, qubits, quantum layers).", "result": "Provides immediate feedback after each epoch, shows intermediate outcomes, dynamically illustrates learning curves, and enables prototyping and analysis of quantum neural networks.", "conclusion": "SimQFL is a practical interactive platform that simplifies and accelerates QFL experiments with greater transparency and control in distributed quantum network applications."}}
{"id": "2508.12637", "pdf": "https://arxiv.org/pdf/2508.12637", "abs": "https://arxiv.org/abs/2508.12637", "authors": ["Shankaranarayanan H", "Satyapreet Singh Yadav", "Adithya Krishna", "Ajay Vikram P", "Mahesh Mehendale", "Chetan Singh Thakur"], "title": "HOMI: Ultra-Fast EdgeAI platform for Event Cameras", "categories": ["cs.AR", "cs.CV", "cs.ET", "cs.NE"], "comment": null, "summary": "Event cameras offer significant advantages for edge robotics applications due\nto their asynchronous operation and sparse, event-driven output, making them\nwell-suited for tasks requiring fast and efficient closed-loop control, such as\ngesture-based human-robot interaction. Despite this potential, existing event\nprocessing solutions remain limited, often lacking complete end-to-end\nimplementations, exhibiting high latency, and insufficiently exploiting event\ndata sparsity. In this paper, we present HOMI, an ultra-low latency, end-to-end\nedge AI platform comprising a Prophesee IMX636 event sensor chip with an Xilinx\nZynq UltraScale+MPSoC FPGA chip, deploying an in-house developed AI\naccelerator. We have developed hardware-optimized pre-processing pipelines\nsupporting both constant-time and constant-event modes for histogram\naccumulation, linear and exponential time surfaces. Our general-purpose\nimplementation caters to both accuracy-driven and low-latency applications.\nHOMI achieves 94% accuracy on the DVS Gesture dataset as a use case when\nconfigured for high accuracy operation and provides a throughput of 1000 fps\nfor low-latency configuration. The hardware-optimised pipeline maintains a\ncompact memory footprint and utilises only 33% of the available LUT resources\non the FPGA, leaving ample headroom for further latency reduction, model\nparallelisation, multi-task deployments, or integration of more complex\narchitectures.", "AI": {"tldr": "HOMI is an ultra-low latency edge AI platform combining event camera sensor with FPGA chip and custom AI accelerator, achieving 94% accuracy on gesture recognition and 1000 fps throughput.", "motivation": "Event cameras have advantages for robotics but existing solutions lack complete end-to-end implementations, have high latency, and don't fully exploit event data sparsity.", "method": "Hardware-optimized pre-processing pipelines with constant-time and constant-event modes for histogram accumulation, linear and exponential time surfaces on Xilinx Zynq UltraScale+MPSoC FPGA with custom AI accelerator.", "result": "94% accuracy on DVS Gesture dataset for high accuracy mode, 1000 fps throughput for low-latency configuration, using only 33% of FPGA LUT resources with compact memory footprint.", "conclusion": "HOMI provides efficient end-to-end event processing with flexibility for both accuracy-driven and low-latency applications, leaving room for further optimization and complex architectures."}}
{"id": "2508.12416", "pdf": "https://arxiv.org/pdf/2508.12416", "abs": "https://arxiv.org/abs/2508.12416", "authors": ["Vuong Nguyen", "Gabriel Vigliensoni"], "title": "fCrit: A Visual Explanation System for Furniture Design Creative Support", "categories": ["cs.HC", "cs.AI", "H.5.2"], "comment": "In Proceedings of Explainable AI for the Arts Workshop 2025 (XAIxArts\n  2025) arXiv:2406.14485", "summary": "We introduce fCrit, a dialogue-based AI system designed to critique furniture\ndesign with a focus on explainability. Grounded in reflective learning and\nformal analysis, fCrit employs a multi-agent architecture informed by a\nstructured design knowledge base. We argue that explainability in the arts\nshould not only make AI reasoning transparent but also adapt to the ways users\nthink and talk about their designs. We demonstrate how fCrit supports this\nprocess by tailoring explanations to users' design language and cognitive\nframing. This work contributes to Human-Centered Explainable AI (HCXAI) in\ncreative practice, advancing domain-specific methods for situated, dialogic,\nand visually grounded AI support.", "AI": {"tldr": "fCrit is a dialogue-based AI system that critiques furniture design with explainable AI, using multi-agent architecture and design knowledge to provide tailored explanations that match users' design language and cognitive framing.", "motivation": "To advance explainable AI in creative domains by making AI reasoning transparent while adapting to how users think and talk about their designs, particularly in furniture design critique.", "method": "Uses a multi-agent architecture grounded in reflective learning and formal analysis, informed by a structured design knowledge base to provide dialogic and visually grounded critiques.", "result": "Developed fCrit system that supports Human-Centered Explainable AI by tailoring explanations to users' design language and cognitive framing in furniture design critique.", "conclusion": "This work contributes to domain-specific HCXAI methods for creative practice, enabling situated, dialogic, and visually grounded AI support that aligns with how designers naturally communicate."}}
{"id": "2508.12691", "pdf": "https://arxiv.org/pdf/2508.12691", "abs": "https://arxiv.org/abs/2508.12691", "authors": ["Yuanxin Wei", "Lansong Diao", "Bujiao Chen", "Shenggan Cheng", "Zhengping Qian", "Wenyuan Yu", "Nong Xiao", "Wei Lin", "Jiangsu Du"], "title": "MixCache: Mixture-of-Cache for Video Diffusion Transformer Acceleration", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "7 pages, 10 figures", "summary": "Leveraging the Transformer architecture and the diffusion process, video DiT\nmodels have emerged as a dominant approach for high-quality video generation.\nHowever, their multi-step iterative denoising process incurs high computational\ncost and inference latency. Caching, a widely adopted optimization method in\nDiT models, leverages the redundancy in the diffusion process to skip\ncomputations in different granularities (e.g., step, cfg, block). Nevertheless,\nexisting caching methods are limited to single-granularity strategies,\nstruggling to balance generation quality and inference speed in a flexible\nmanner. In this work, we propose MixCache, a training-free caching-based\nframework for efficient video DiT inference. It first distinguishes the\ninterference and boundary between different caching strategies, and then\nintroduces a context-aware cache triggering strategy to determine when caching\nshould be enabled, along with an adaptive hybrid cache decision strategy for\ndynamically selecting the optimal caching granularity. Extensive experiments on\ndiverse models demonstrate that, MixCache can significantly accelerate video\ngeneration (e.g., 1.94$\\times$ speedup on Wan 14B, 1.97$\\times$ speedup on\nHunyuanVideo) while delivering both superior generation quality and inference\nefficiency compared to baseline methods.", "AI": {"tldr": "MixCache is a training-free caching framework that accelerates video diffusion transformer inference by combining multiple caching granularities with adaptive triggering strategies, achieving near 2x speedup while maintaining quality.", "motivation": "Video DiT models suffer from high computational costs and latency due to multi-step iterative denoising. Existing caching methods are limited to single-granularity strategies and struggle to balance quality and speed effectively.", "method": "Proposes MixCache with context-aware cache triggering to determine when to enable caching, and adaptive hybrid cache decision strategy to dynamically select optimal caching granularity (step, cfg, block levels).", "result": "Achieves 1.94x speedup on Wan 14B and 1.97x speedup on HunyuanVideo models while delivering superior generation quality and inference efficiency compared to baseline methods.", "conclusion": "MixCache effectively addresses the limitations of single-granularity caching by providing a flexible framework that significantly accelerates video generation without compromising quality, demonstrating strong performance across diverse models."}}
{"id": "2508.12435", "pdf": "https://arxiv.org/pdf/2508.12435", "abs": "https://arxiv.org/abs/2508.12435", "authors": ["Deqing Song", "Weimin Yang", "Maryam Rezayati", "Hans Wernher van de Venn"], "title": "Tactile Gesture Recognition with Built-in Joint Sensors for Industrial Robots", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "While gesture recognition using vision or robot skins is an active research\narea in Human-Robot Collaboration (HRC), this paper explores deep learning\nmethods relying solely on a robot's built-in joint sensors, eliminating the\nneed for external sensors. We evaluated various convolutional neural network\n(CNN) architectures and collected two datasets to study the impact of data\nrepresentation and model architecture on the recognition accuracy. Our results\nshow that spectrogram-based representations significantly improve accuracy,\nwhile model architecture plays a smaller role. We also tested generalization to\nnew robot poses, where spectrogram-based models performed better. Implemented\non a Franka Emika Research robot, two of our methods, STFT2DCNN and STT3DCNN,\nachieved over 95% accuracy in contact detection and gesture classification.\nThese findings demonstrate the feasibility of external-sensor-free tactile\nrecognition and promote further research toward cost-effective, scalable\nsolutions for HRC.", "AI": {"tldr": "Deep learning methods using only robot joint sensors achieve over 95% accuracy for gesture recognition, eliminating need for external sensors.", "motivation": "To explore gesture recognition in Human-Robot Collaboration without requiring external sensors like vision systems or robot skins, using only built-in joint sensors for cost-effective and scalable solutions.", "method": "Evaluated various CNN architectures on two datasets, comparing data representations and model architectures. Tested spectrogram-based representations and implemented methods (STFT2DCNN and STT3DCNN) on Franka Emika Research robot.", "result": "Spectrogram-based representations significantly improved accuracy while model architecture played smaller role. Methods achieved over 95% accuracy in contact detection and gesture classification, with better generalization to new robot poses.", "conclusion": "Demonstrates feasibility of external-sensor-free tactile recognition, enabling cost-effective and scalable Human-Robot Collaboration solutions without additional hardware."}}
{"id": "2508.12519", "pdf": "https://arxiv.org/pdf/2508.12519", "abs": "https://arxiv.org/abs/2508.12519", "authors": ["Khai Nguyen"], "title": "An Introduction to Sliced Optimal Transport", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.CO", "stat.ME"], "comment": "227 pages", "summary": "Sliced Optimal Transport (SOT) is a rapidly developing branch of optimal\ntransport (OT) that exploits the tractability of one-dimensional OT problems.\nBy combining tools from OT, integral geometry, and computational statistics,\nSOT enables fast and scalable computation of distances, barycenters, and\nkernels for probability measures, while retaining rich geometric structure.\nThis paper provides a comprehensive review of SOT, covering its mathematical\nfoundations, methodological advances, computational methods, and applications.\nWe discuss key concepts of OT and one-dimensional OT, the role of tools from\nintegral geometry such as Radon transform in projecting measures, and\nstatistical techniques for estimating sliced distances. The paper further\nexplores recent methodological advances, including non-linear projections,\nimproved Monte Carlo approximations, statistical estimation techniques for\none-dimensional optimal transport, weighted slicing techniques, and\ntransportation plan estimation methods. Variational problems, such as minimum\nsliced Wasserstein estimation, barycenters, gradient flows, kernel\nconstructions, and embeddings are examined alongside extensions to unbalanced,\npartial, multi-marginal, and Gromov-Wasserstein settings. Applications span\nmachine learning, statistics, computer graphics and computer visions,\nhighlighting SOT's versatility as a practical computational tool. This work\nwill be of interest to researchers and practitioners in machine learning, data\nsciences, and computational disciplines seeking efficient alternatives to\nclassical OT.", "AI": {"tldr": "Comprehensive review of Sliced Optimal Transport (SOT) - a fast computational approach using 1D OT projections through Radon transform, covering mathematical foundations, methodological advances, computational methods, and diverse applications.", "motivation": "To provide efficient and scalable alternatives to classical optimal transport by leveraging the tractability of one-dimensional OT problems while preserving geometric structure.", "method": "Combines tools from optimal transport, integral geometry (Radon transform for projecting measures), and computational statistics. Uses one-dimensional OT projections, Monte Carlo approximations, statistical estimation techniques, and various slicing methods.", "result": "Enables fast computation of distances, barycenters, and kernels for probability measures. Supports extensions to unbalanced, partial, multi-marginal, and Gromov-Wasserstein settings with applications across multiple domains.", "conclusion": "SOT serves as a versatile and practical computational tool that provides efficient alternatives to classical OT, making it valuable for researchers and practitioners in machine learning, data sciences, and computational disciplines."}}
{"id": "2508.12742", "pdf": "https://arxiv.org/pdf/2508.12742", "abs": "https://arxiv.org/abs/2508.12742", "authors": ["Theodoros Bermperidis", "Joe Vero", "Elizabeth B Torres"], "title": "On the Importance of Behavioral Nuances: Amplifying Non-Obvious Motor Noise Under True Empirical Considerations May Lead to Briefer Assays and Faster Classification Processes", "categories": ["q-bio.QM", "cs.CV", "cs.LG", "eess.SP", "nlin.CD"], "comment": "This paper is under review in IEEE Transactions on Affective\n  Computing", "summary": "There is a tradeoff between attaining statistical power with large, difficult\nto gather data sets, and producing highly scalable assays that register brief\ndata samples. Often, as grand-averaging techniques a priori assume\nnormally-distributed parameters and linear, stationary processes in\nbiorhythmic, time series data, important information is lost, averaged out as\ngross data. We developed an affective computing platform that enables taking\nbrief data samples while maintaining personalized statistical power. This is\nachieved by combining a new data type derived from the micropeaks present in\ntime series data registered from brief (5-second-long) face videos with recent\nadvances in AI-driven face-grid estimation methods. By adopting geometric and\nnonlinear dynamical systems approaches to analyze the kinematics, especially\nthe speed data, the new methods capture all facial micropeaks. These include as\nwell the nuances of different affective micro expressions. We offer new ways to\ndifferentiate dynamical and geometric patterns present in autistic individuals\nfrom those found more commonly in neurotypical development.", "AI": {"tldr": "A new affective computing platform that uses brief 5-second face videos to capture facial micropeaks and micro expressions, enabling personalized statistical power without requiring large datasets.", "motivation": "To overcome the tradeoff between statistical power (requiring large datasets) and scalability (using brief data samples), and to avoid information loss from traditional grand-averaging techniques that assume normal distributions and linear processes.", "method": "Combines a new data type derived from micropeaks in brief face videos with AI-driven face-grid estimation methods, using geometric and nonlinear dynamical systems approaches to analyze kinematics and speed data.", "result": "The method captures all facial micropeaks including nuances of different affective micro expressions, and enables differentiation of dynamical and geometric patterns between autistic and neurotypical individuals.", "conclusion": "The developed platform provides a scalable solution for affective computing that maintains statistical power with brief data samples, offering new diagnostic capabilities for autism spectrum disorders."}}
{"id": "2508.12470", "pdf": "https://arxiv.org/pdf/2508.12470", "abs": "https://arxiv.org/abs/2508.12470", "authors": ["Afrah Gueriani", "Hamza Kheddar", "Ahmed Cherif Mazari", "Mohamed Chahine Ghanem"], "title": "A Robust Cross-Domain IDS using BiGRU-LSTM-Attention for Medical and Industrial IoT Security", "categories": ["cs.CR", "cs.AI"], "comment": "10 pages", "summary": "The increased Internet of Medical Things IoMT and the Industrial Internet of\nThings IIoT interconnectivity has introduced complex cybersecurity challenges,\nexposing sensitive data, patient safety, and industrial operations to advanced\ncyber threats. To mitigate these risks, this paper introduces a novel\ntransformer-based intrusion detection system IDS, termed BiGAT-ID a hybrid\nmodel that combines bidirectional gated recurrent units BiGRU, long short-term\nmemory LSTM networks, and multi-head attention MHA. The proposed architecture\nis designed to effectively capture bidirectional temporal dependencies, model\nsequential patterns, and enhance contextual feature representation. Extensive\nexperiments on two benchmark datasets, CICIoMT2024 medical IoT and EdgeIIoTset\nindustrial IoT demonstrate the model's cross-domain robustness, achieving\ndetection accuracies of 99.13 percent and 99.34 percent, respectively.\nAdditionally, the model exhibits exceptional runtime efficiency, with inference\ntimes as low as 0.0002 seconds per instance in IoMT and 0.0001 seconds in IIoT\nscenarios. Coupled with a low false positive rate, BiGAT-ID proves to be a\nreliable and efficient IDS for deployment in real-world heterogeneous IoT\nenvironments", "AI": {"tldr": "Novel transformer-based IDS (BiGAT-ID) combining BiGRU, LSTM, and multi-head attention for IoT security, achieving 99%+ accuracy on medical and industrial IoT datasets with fast inference times.", "motivation": "Address cybersecurity challenges in interconnected medical and industrial IoT environments where sensitive data, patient safety, and industrial operations face advanced cyber threats.", "method": "Hybrid model architecture combining bidirectional gated recurrent units (BiGRU), long short-term memory (LSTM) networks, and multi-head attention (MHA) to capture bidirectional temporal dependencies and enhance contextual feature representation.", "result": "Achieved 99.13% accuracy on CICIoMT2024 medical IoT dataset and 99.34% on EdgeIIoTset industrial IoT dataset, with inference times as low as 0.0002s (IoMT) and 0.0001s (IIoT) per instance, plus low false positive rates.", "conclusion": "BiGAT-ID proves to be a reliable and efficient intrusion detection system suitable for real-world deployment in heterogeneous IoT environments due to its cross-domain robustness and exceptional runtime performance."}}
{"id": "2508.12560", "pdf": "https://arxiv.org/pdf/2508.12560", "abs": "https://arxiv.org/abs/2508.12560", "authors": ["Prabath Abeysekara", "Hai Dong"], "title": "Data-driven Trust Bootstrapping for Mobile Edge Computing-based Industrial IoT Services", "categories": ["cs.CR", "cs.DC", "cs.LG", "C.2; C.4; I.2"], "comment": "15 pages", "summary": "We propose a data-driven and context-aware approach to bootstrap\ntrustworthiness of homogeneous Internet of Things (IoT) services in Mobile Edge\nComputing (MEC) based industrial IoT (IIoT) systems. The proposed approach\naddresses key limitations in adapting existing trust bootstrapping approaches\ninto MEC-based IIoT systems. These key limitations include, the lack of\nopportunity for a service consumer to interact with a lesser-known service over\na prolonged period of time to get a robust measure of its trustworthiness,\ninability of service consumers to consistently interact with their peers to\nreceive reliable recommendations of the trustworthiness of a lesser-known\nservice as well as the impact of uneven context parameters in different MEC\nenvironments causing uneven trust environments for trust evaluation. In\naddition, the proposed approach also tackles the problem of data sparsity via\nenabling knowledge sharing among different MEC environments within a given MEC\ntopology. To verify the effectiveness of the proposed approach, we carried out\na comprehensive evaluation on two real-world datasets suitably adjusted to\nexhibit the context-dependent trust information accumulated in MEC environments\nwithin a given MEC topology. The experimental results affirmed the\neffectiveness of our approach and its suitability to bootstrap trustworthiness\nof services in MEC-based IIoT systems.", "AI": {"tldr": "A data-driven, context-aware trust bootstrapping approach for IoT services in MEC-based IIoT systems that addresses limitations of existing methods through knowledge sharing across MEC environments.", "motivation": "Existing trust bootstrapping approaches face limitations in MEC-based IIoT systems including lack of prolonged interaction opportunities, unreliable peer recommendations, and uneven context parameters across different MEC environments causing inconsistent trust evaluation.", "method": "Proposes a data-driven and context-aware approach that enables knowledge sharing among different MEC environments within a MEC topology to address data sparsity and uneven trust environments.", "result": "Comprehensive evaluation on two real-world datasets (adjusted to exhibit context-dependent trust information) affirmed the effectiveness and suitability of the approach for bootstrapping service trustworthiness in MEC-based IIoT systems.", "conclusion": "The proposed approach effectively addresses key limitations of existing trust bootstrapping methods and is suitable for establishing service trustworthiness in MEC-based industrial IoT systems through context-aware data sharing across environments."}}
{"id": "2508.12609", "pdf": "https://arxiv.org/pdf/2508.12609", "abs": "https://arxiv.org/abs/2508.12609", "authors": ["Qingyan Meng", "Mingqing Xiao", "Zhengyu Ma", "Huihui Zhou", "Yonghong Tian", "Zhouchen Lin"], "title": "A Self-Ensemble Inspired Approach for Effective Training of Binary-Weight Spiking Neural Networks", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Spiking Neural Networks (SNNs) are a promising approach to low-power\napplications on neuromorphic hardware due to their energy efficiency. However,\ntraining SNNs is challenging because of the non-differentiable spike generation\nfunction. To address this issue, the commonly used approach is to adopt the\nbackpropagation through time framework, while assigning the gradient of the\nnon-differentiable function with some surrogates. Similarly, Binary Neural\nNetworks (BNNs) also face the non-differentiability problem and rely on\napproximating gradients. However, the deep relationship between these two\nfields and how their training techniques can benefit each other has not been\nsystematically researched. Furthermore, training binary-weight SNNs is even\nmore difficult. In this work, we present a novel perspective on the dynamics of\nSNNs and their close connection to BNNs through an analysis of the\nbackpropagation process. We demonstrate that training a feedforward SNN can be\nviewed as training a self-ensemble of a binary-activation neural network with\nnoise injection. Drawing from this new understanding of SNN dynamics, we\nintroduce the Self-Ensemble Inspired training method for (Binary-Weight) SNNs\n(SEI-BWSNN), which achieves high-performance results with low latency even for\nthe case of the 1-bit weights. Specifically, we leverage a structure of\nmultiple shortcuts and a knowledge distillation-based training technique to\nimprove the training of (binary-weight) SNNs. Notably, by binarizing FFN layers\nin a Transformer architecture, our approach achieves 82.52% accuracy on\nImageNet with only 2 time steps, indicating the effectiveness of our\nmethodology and the potential of binary-weight SNNs.", "AI": {"tldr": "This paper presents a novel perspective connecting Spiking Neural Networks (SNNs) and Binary Neural Networks (BNNs), introducing SEI-BWSNN training method that treats SNN training as training a self-ensemble of binary-activation networks with noise injection, achieving high performance with low latency even for 1-bit weights.", "motivation": "SNNs offer energy efficiency for neuromorphic hardware but face training challenges due to non-differentiable spike functions. Similarly, BNNs struggle with non-differentiability. The deep relationship between these fields and how their training techniques can benefit each other hasn't been systematically researched, especially for binary-weight SNNs which are even more difficult to train.", "method": "The authors analyze SNN dynamics through backpropagation and demonstrate that training feedforward SNNs can be viewed as training a self-ensemble of binary-activation neural networks with noise injection. They introduce SEI-BWSNN method leveraging multiple shortcuts and knowledge distillation-based training to improve binary-weight SNN training.", "result": "The approach achieves 82.52% accuracy on ImageNet with only 2 time steps by binarizing FFN layers in a Transformer architecture, demonstrating high performance with low latency even for 1-bit weights.", "conclusion": "The work provides a novel understanding of SNN dynamics and their connection to BNNs, showing the effectiveness of the proposed methodology and the potential of binary-weight SNNs for efficient neuromorphic computing applications."}}
{"id": "2508.12479", "pdf": "https://arxiv.org/pdf/2508.12479", "abs": "https://arxiv.org/abs/2508.12479", "authors": ["Chinmay Maheshwari", "Chinmay Pimpalkhare", "Debasish Chatterjee"], "title": "EXOTIC: An Exact, Optimistic, Tree-Based Algorithm for Min-Max Optimization", "categories": ["math.OC", "cs.AI", "cs.GT", "cs.MA", "econ.GN", "q-fin.EC", "90C26, 90C47, 68Q32, 91A06, 65K05"], "comment": "31 pages, 2 figures, 3 tables", "summary": "Min-max optimization arises in many domains such as game theory, adversarial\nmachine learning, etc., with gradient-based methods as a typical computational\ntool. Beyond convex-concave min-max optimization, the solutions found by\ngradient-based methods may be arbitrarily far from global optima. In this work,\nwe present an algorithmic apparatus for computing globally optimal solutions in\nconvex-non-concave and non-convex-concave min-max optimization. For former, we\nemploy a reformulation that transforms it into a non-concave-convex max-min\noptimization problem with suitably defined feasible sets and objective\nfunction. The new form can be viewed as a generalization of Sion's minimax\ntheorem. Next, we introduce EXOTIC-an Exact, Optimistic, Tree-based algorithm\nfor solving the reformulated max-min problem. EXOTIC employs an iterative\nconvex optimization solver to (approximately) solve the inner minimization and\na hierarchical tree search for the outer maximization to optimistically select\npromising regions to search based on the approximate solution returned by\nconvex optimization solver. We establish an upper bound on its optimality gap\nas a function of the number of calls to the inner solver, the solver's\nconvergence rate, and additional problem-dependent parameters. Both our\nalgorithmic apparatus along with its accompanying theoretical analysis can also\nbe applied for non-convex-concave min-max optimization. In addition, we propose\na class of benchmark convex-non-concave min-max problems along with their\nanalytical global solutions, providing a testbed for evaluating algorithms for\nmin-max optimization. Empirically, EXOTIC outperforms gradient-based methods on\nthis benchmark as well as on existing numerical benchmark problems from the\nliterature. Finally, we demonstrate the utility of EXOTIC by computing security\nstrategies in multi-player games with three or more players.", "AI": {"tldr": "EXOTIC algorithm for globally optimal solutions in convex-non-concave and non-convex-concave min-max optimization problems, outperforming gradient-based methods with theoretical guarantees and practical applications in multi-player games.", "motivation": "Gradient-based methods for min-max optimization often fail to find global optima beyond convex-concave settings, leading to arbitrarily suboptimal solutions in convex-non-concave and non-convex-concave problems common in game theory and adversarial ML.", "method": "Reformulate convex-non-concave min-max as non-concave-convex max-min problem, then use EXOTIC algorithm combining iterative convex optimization for inner minimization and hierarchical tree search for outer maximization with optimistic region selection.", "result": "Established theoretical upper bound on optimality gap, outperformed gradient-based methods on new benchmark problems and existing literature benchmarks, successfully computed security strategies in multi-player (3+ players) games.", "conclusion": "EXOTIC provides an effective algorithmic framework with theoretical guarantees for globally optimal solutions in challenging min-max optimization problems where gradient methods fail, with practical utility in complex game scenarios."}}
{"id": "2508.12614", "pdf": "https://arxiv.org/pdf/2508.12614", "abs": "https://arxiv.org/abs/2508.12614", "authors": ["Zhongqin Wang", "J. Andrew Zhang", "Kai Wu", "Min Xu", "Y. Jay Guo"], "title": "Towards SISO Bistatic Sensing for ISAC", "categories": ["eess.SP", "cs.HC", "cs.LG"], "comment": null, "summary": "Integrated Sensing and Communication (ISAC) is a key enabler for\nnext-generation wireless systems. However, real-world deployment is often\nlimited to low-cost, single-antenna transceivers. In such bistatic Single-Input\nSingle-Output (SISO) setup, clock asynchrony introduces random phase offsets in\nChannel State Information (CSI), which cannot be mitigated using conventional\nmulti-antenna methods. This work proposes WiDFS 3.0, a lightweight bistatic\nSISO sensing framework that enables accurate delay and Doppler estimation from\ndistorted CSI by effectively suppressing Doppler mirroring ambiguity. It\noperates with only a single antenna at both the transmitter and receiver,\nmaking it suitable for low-complexity deployments. We propose a\nself-referencing cross-correlation (SRCC) method for SISO random phase removal\nand employ delay-domain beamforming to resolve Doppler ambiguity. The resulting\nunambiguous delay-Doppler-time features enable robust sensing with compact\nneural networks. Extensive experiments show that WiDFS 3.0 achieves accurate\nparameter estimation, with performance comparable to or even surpassing that of\nprior multi-antenna methods, especially in delay estimation. Validated under\nsingle- and multi-target scenarios, the extracted ambiguity-resolved features\nshow strong sensing accuracy and generalization. For example, when deployed on\nthe embedded-friendly MobileViT-XXS with only 1.3M parameters, WiDFS 3.0\nconsistently outperforms conventional features such as CSI amplitude, mirrored\nDoppler, and multi-receiver aggregated Doppler.", "AI": {"tldr": "WiDFS 3.0 enables accurate delay and Doppler estimation in low-cost single-antenna ISAC systems by suppressing Doppler mirroring ambiguity and removing random phase offsets from distorted CSI.", "motivation": "Real-world ISAC deployment is often limited to low-cost, single-antenna transceivers where clock asynchrony introduces random phase offsets in CSI that cannot be mitigated with conventional multi-antenna methods.", "method": "Proposes a self-referencing cross-correlation (SRCC) method for SISO random phase removal and employs delay-domain beamforming to resolve Doppler ambiguity, enabling robust sensing with compact neural networks.", "result": "WiDFS 3.0 achieves accurate parameter estimation comparable to or surpassing prior multi-antenna methods, especially in delay estimation, and consistently outperforms conventional features with strong sensing accuracy and generalization.", "conclusion": "The framework enables high-performance bistatic SISO sensing suitable for low-complexity deployments, demonstrating that accurate ISAC is achievable with minimal hardware requirements."}}
{"id": "2508.12986", "pdf": "https://arxiv.org/pdf/2508.12986", "abs": "https://arxiv.org/abs/2508.12986", "authors": ["Jinyi Liu", "Guoyang Zhao", "Lijun Liu", "Yiguang Hong", "Weiping Zhang", "Shuming Cheng"], "title": "Point upsampling networks for single-photon sensing", "categories": ["physics.optics", "cs.CV"], "comment": "13 pages, 8 figures, any comments are welcome", "summary": "Single-photon sensing has generated great interest as a prominent technique\nof long-distance and ultra-sensitive imaging, however, it tends to yield sparse\nand spatially biased point clouds, thus limiting its practical utility. In this\nwork, we propose using point upsampling networks to increase point density and\nreduce spatial distortion in single-photon point cloud. Particularly, our\nnetwork is built on the state space model which integrates a multi-path\nscanning mechanism to enrich spatial context, a bidirectional Mamba backbone to\ncapture global geometry and local details, and an adaptive upsample shift\nmodule to correct offset-induced distortions. Extensive experiments are\nimplemented on commonly-used datasets to confirm its high reconstruction\naccuracy and strong robustness to the distortion noise, and also on real-world\ndata to demonstrate that our model is able to generate visually consistent,\ndetail-preserving, and noise suppressed point clouds. Our work is the first to\nestablish the upsampling framework for single-photon sensing, and hence opens a\nnew avenue for single-photon sensing and its practical applications in the\ndownstreaming tasks.", "AI": {"tldr": "Proposes a point upsampling network using state space models to enhance sparse single-photon point clouds by increasing density and reducing spatial distortion.", "motivation": "Single-photon sensing produces sparse and spatially biased point clouds that limit practical utility, requiring methods to improve point density and reduce distortion.", "method": "Built on state space model with multi-path scanning mechanism, bidirectional Mamba backbone for global/local feature capture, and adaptive upsample shift module for distortion correction.", "result": "Achieves high reconstruction accuracy and strong robustness to distortion noise, generates visually consistent, detail-preserving, and noise-suppressed point clouds on real-world data.", "conclusion": "First upsampling framework for single-photon sensing that opens new avenues for practical applications in downstream tasks."}}
{"id": "2508.12617", "pdf": "https://arxiv.org/pdf/2508.12617", "abs": "https://arxiv.org/abs/2508.12617", "authors": ["Ming Li", "Zihuai He", "Min Zhang", "Xiaowei Zhan", "Changshuai Wei", "Robert C Elston", "Qing Lu"], "title": "A Generalized Genetic Random Field Method for the Genetic Association Analysis of Sequencing Data", "categories": ["stat.ME", "cs.AI", "cs.LG"], "comment": null, "summary": "With the advance of high-throughput sequencing technologies, it has become\nfeasible to investigate the influence of the entire spectrum of sequencing\nvariations on complex human diseases. Although association studies utilizing\nthe new sequencing technologies hold great promise to unravel novel genetic\nvariants, especially rare genetic variants that contribute to human diseases,\nthe statistical analysis of high-dimensional sequencing data remains a\nchallenge. Advanced analytical methods are in great need to facilitate\nhigh-dimensional sequencing data analyses. In this article, we propose a\ngeneralized genetic random field (GGRF) method for association analyses of\nsequencing data. Like other similarity-based methods (e.g., SIMreg and SKAT),\nthe new method has the advantages of avoiding the need to specify thresholds\nfor rare variants and allowing for testing multiple variants acting in\ndifferent directions and magnitude of effects. The method is built on the\ngeneralized estimating equation framework and thus accommodates a variety of\ndisease phenotypes (e.g., quantitative and binary phenotypes). Moreover, it has\na nice asymptotic property, and can be applied to small-scale sequencing data\nwithout need for small-sample adjustment. Through simulations, we demonstrate\nthat the proposed GGRF attains an improved or comparable power over a commonly\nused method, SKAT, under various disease scenarios, especially when rare\nvariants play a significant role in disease etiology. We further illustrate\nGGRF with an application to a real dataset from the Dallas Heart Study. By\nusing GGRF, we were able to detect the association of two candidate genes,\nANGPTL3 and ANGPTL4, with serum triglyceride.", "AI": {"tldr": "Proposes GGRF method for sequencing data association analysis that handles rare variants without thresholds, accommodates various phenotypes, and shows improved power over SKAT especially when rare variants are important.", "motivation": "High-throughput sequencing enables investigation of genetic variants for complex diseases, but statistical analysis of high-dimensional sequencing data remains challenging, requiring advanced methods.", "method": "Generalized genetic random field (GGRF) method built on generalized estimating equation framework, similarity-based approach that avoids threshold specification for rare variants and allows testing multiple variants with different effect directions.", "result": "Simulations show GGRF attains improved or comparable power over SKAT under various disease scenarios, especially when rare variants play significant roles. Applied to Dallas Heart Study data, detected association of ANGPTL3 and ANGPTL4 genes with serum triglyceride.", "conclusion": "GGRF provides an effective statistical method for association analysis of sequencing data that handles rare variants well, accommodates diverse phenotypes, and demonstrates superior performance particularly in scenarios where rare variants contribute to disease etiology."}}
{"id": "2508.12998", "pdf": "https://arxiv.org/pdf/2508.12998", "abs": "https://arxiv.org/abs/2508.12998", "authors": ["Sanja \u0160\u0107epanovi\u0107", "Sagar Joglekar", "Stephen Law", "Daniele Quercia", "Ke Zhou", "Alice Battiston", "Rossano Schifanella"], "title": "Vitamin N: Benefits of Different Forms of Public Greenery for Urban Health", "categories": ["cs.CY", "cs.AI", "cs.CV"], "comment": null, "summary": "Urban greenery is often linked to better health, yet findings from past\nresearch have been inconsistent. One reason is that official greenery metrics\nmeasure the amount or nearness of greenery but ignore how often people actually\nmay potentially see or use it in daily life. To address this gap, we introduced\na new classification that separates on-road greenery, which people see while\nwalking through streets, from off-road greenery, which requires planned visits.\nWe did so by combining aerial imagery of Greater London and greenery data from\nOpenStreetMap with quantified greenery from over 100,000 Google Street View\nimages and accessibility estimates based on 160,000 road segments. We linked\nthese measures to 7.45 billion medical prescriptions issued by the National\nHealth Service and processed through our methodology. These prescriptions cover\nfive conditions: diabetes, hypertension, asthma, depression, and anxiety, as\nwell as opioid use. As hypothesized, we found that green on-road was more\nstrongly linked to better health than four widely used official measures. For\nexample, hypertension prescriptions dropped by 3.68% in wards with on-road\ngreenery above the median citywide level compared to those below it. If all\nbelow-median wards reached the citywide median in on-road greenery,\nprescription costs could fall by up to {\\pounds}3.15 million each year. These\nresults suggest that greenery seen in daily life may be more relevant than\npublic yet secluded greenery, and that official metrics commonly used in the\nliterature have important limitations.", "AI": {"tldr": "On-road greenery visible during daily activities shows stronger health benefits than traditional official greenery metrics, potentially saving millions in prescription costs.", "motivation": "Traditional greenery metrics measure quantity or proximity but ignore actual visibility and daily exposure, leading to inconsistent health benefit findings.", "method": "Combined aerial imagery, OpenStreetMap data, Google Street View analysis of 100k+ images, and accessibility estimates across 160k road segments in London, linked to 7.45 billion NHS prescriptions.", "result": "On-road greenery reduced hypertension prescriptions by 3.68% in above-median areas, with potential annual savings of \u00a33.15 million if all below-median areas reached citywide median levels.", "conclusion": "Daily visible greenery is more relevant for health benefits than secluded public greenery, and official metrics have significant limitations in capturing actual exposure."}}
{"id": "2508.13049", "pdf": "https://arxiv.org/pdf/2508.13049", "abs": "https://arxiv.org/abs/2508.13049", "authors": ["Tejas Chaudhari", "Akarsh J.", "Tanushree Dewangan", "Mukul Lokhande", "Santosh Kumar Vishvakarma"], "title": "XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads", "categories": ["cs.AR", "cs.AI", "cs.CV", "eess.IV"], "comment": null, "summary": "This work proposes XR-NPE, a high-throughput Mixed-precision SIMD Neural\nProcessing Engine, designed for extended reality (XR) perception workloads like\nvisual inertial odometry (VIO), object classification, and eye gaze extraction.\nXR-NPE is first to support FP4, Posit (4,1), Posit (8,0), and Posit (16,1)\nformats, with layer adaptive hybrid-algorithmic implementation supporting\nultra-low bit precision to significantly reduce memory bandwidth requirements,\nand accompanied by quantization-aware training for minimal accuracy loss. The\nproposed Reconfigurable Mantissa Multiplication and Exponent processing\nCircuitry (RMMEC) reduces dark silicon in the SIMD MAC compute engine, assisted\nby selective power gating to reduce energy consumption, providing 2.85x\nimproved arithmetic intensity. XR-NPE achieves a maximum operating frequency of\n1.72 GHz, area 0.016 mm2 , and arithmetic intensity 14 pJ at CMOS 28nm,\nreducing 42% area, 38% power compared to the best of state-of-the-art MAC\napproaches. The proposed XR-NPE based AXI-enabled Matrix-multiplication\nco-processor consumes 1.4x fewer LUTs, 1.77x fewer FFs, and provides 1.2x\nbetter energy efficiency compared to SoTA accelerators on VCU129. The proposed\nco-processor provides 23% better energy efficiency and 4% better compute\ndensity for VIO workloads. XR-NPE establishes itself as a scalable,\nprecision-adaptive compute engine for future resource-constrained XR devices.\nThe complete set for codes for results reproducibility are released publicly,\nenabling designers and researchers to readily adopt and build upon them.\nhttps://github.com/mukullokhande99/XR-NPE.", "AI": {"tldr": "XR-NPE is a high-throughput mixed-precision SIMD neural processing engine designed for XR workloads, supporting novel FP4 and Posit formats with layer-adaptive implementation and quantization-aware training to reduce memory bandwidth while maintaining accuracy.", "motivation": "Extended reality (XR) devices require efficient neural processing for perception workloads like visual inertial odometry and object classification, but face challenges with memory bandwidth and energy consumption in resource-constrained environments.", "method": "Proposes XR-NPE with Reconfigurable Mantissa Multiplication and Exponent processing Circuitry (RMMEC), selective power gating, and support for FP4, Posit(4,1), Posit(8,0), and Posit(16,1) formats with quantization-aware training.", "result": "Achieves 1.72 GHz operating frequency, 0.016 mm\u00b2 area, 14 pJ arithmetic intensity at 28nm CMOS, with 42% area reduction and 38% power reduction compared to state-of-the-art MAC approaches. Provides 23% better energy efficiency and 4% better compute density for VIO workloads.", "conclusion": "XR-NPE establishes itself as a scalable, precision-adaptive compute engine suitable for future resource-constrained XR devices, with publicly released code for reproducibility and adoption."}}
{"id": "2508.13103", "pdf": "https://arxiv.org/pdf/2508.13103", "abs": "https://arxiv.org/abs/2508.13103", "authors": ["Tianyi Zhang", "Haonan Duan", "Haoran Hao", "Yu Qiao", "Jifeng Dai", "Zhi Hou"], "title": "Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Vision-Language-Action (VLA) models frequently encounter challenges in\ngeneralizing to real-world environments due to inherent discrepancies between\nobservation and action spaces. Although training data are collected from\ndiverse camera perspectives, the models typically predict end-effector poses\nwithin the robot base coordinate frame, resulting in spatial inconsistencies.\nTo mitigate this limitation, we introduce the Observation-Centric VLA (OC-VLA)\nframework, which grounds action predictions directly in the camera observation\nspace. Leveraging the camera's extrinsic calibration matrix, OC-VLA transforms\nend-effector poses from the robot base coordinate system into the camera\ncoordinate system, thereby unifying prediction targets across heterogeneous\nviewpoints. This lightweight, plug-and-play strategy ensures robust alignment\nbetween perception and action, substantially improving model resilience to\ncamera viewpoint variations. The proposed approach is readily compatible with\nexisting VLA architectures, requiring no substantial modifications.\nComprehensive evaluations on both simulated and real-world robotic manipulation\ntasks demonstrate that OC-VLA accelerates convergence, enhances task success\nrates, and improves cross-view generalization. The code will be publicly\navailable.", "AI": {"tldr": "OC-VLA framework transforms action predictions from robot base coordinates to camera observation space using extrinsic calibration, improving VLA model generalization across diverse camera viewpoints.", "motivation": "VLA models struggle with generalization due to spatial inconsistencies between observation and action spaces - models predict end-effector poses in robot base coordinates while observations come from diverse camera perspectives.", "method": "Proposes Observation-Centric VLA (OC-VLA) framework that grounds action predictions directly in camera observation space using camera's extrinsic calibration matrix to transform poses from robot base to camera coordinate system.", "result": "OC-VLA accelerates convergence, enhances task success rates, and improves cross-view generalization in both simulated and real-world robotic manipulation tasks.", "conclusion": "Lightweight plug-and-play strategy that ensures robust perception-action alignment and improves model resilience to camera viewpoint variations without requiring substantial architecture modifications."}}
{"id": "2508.12671", "pdf": "https://arxiv.org/pdf/2508.12671", "abs": "https://arxiv.org/abs/2508.12671", "authors": ["Dmitry Belousov", "Yury Yanovich"], "title": "DIT: Dimension Reduction View on Optimal NFT Rarity Meters", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Non-fungible tokens (NFTs) have become a significant digital asset class,\neach uniquely representing virtual entities such as artworks. These tokens are\nstored in collections within smart contracts and are actively traded across\nplatforms on Ethereum, Bitcoin, and Solana blockchains. The value of NFTs is\nclosely tied to their distinctive characteristics that define rarity, leading\nto a growing interest in quantifying rarity within both industry and academia.\nWhile there are existing rarity meters for assessing NFT rarity, comparing them\ncan be challenging without direct access to the underlying collection data. The\nRating over all Rarities (ROAR) benchmark addresses this challenge by providing\na standardized framework for evaluating NFT rarity. This paper explores a\ndimension reduction approach to rarity design, introducing new performance\nmeasures and meters, and evaluates them using the ROAR benchmark. Our\ncontributions to the rarity meter design issue include developing an optimal\nrarity meter design using non-metric weighted multidimensional scaling,\nintroducing Dissimilarity in Trades (DIT) as a performance measure inspired by\ndimension reduction techniques, and unveiling the non-interpretable rarity\nmeter DIT, which demonstrates superior performance compared to existing\nmethods.", "AI": {"tldr": "The paper introduces a new NFT rarity assessment framework called ROAR benchmark and proposes a dimension reduction approach with novel performance measures, including DIT, which outperforms existing rarity meters.", "motivation": "NFT rarity quantification is important for valuation but existing rarity meters are hard to compare without direct access to collection data, requiring a standardized evaluation framework.", "method": "Developed an optimal rarity meter using non-metric weighted multidimensional scaling and introduced Dissimilarity in Trades (DIT) as a performance measure inspired by dimension reduction techniques.", "result": "The proposed non-interpretable rarity meter DIT demonstrates superior performance compared to existing methods when evaluated using the ROAR benchmark.", "conclusion": "The ROAR benchmark provides a standardized framework for NFT rarity evaluation, and the dimension reduction approach with DIT performance measure offers improved rarity assessment capabilities."}}
{"id": "2508.12674", "pdf": "https://arxiv.org/pdf/2508.12674", "abs": "https://arxiv.org/abs/2508.12674", "authors": ["Haruka Ezoe", "Hiroki Matsumoto", "Ryohei Hisano"], "title": "Unfolded Laplacian Spectral Embedding: A Theoretically Grounded Approach to Dynamic Network Representation", "categories": ["stat.ML", "cs.LG", "cs.SI"], "comment": null, "summary": "Dynamic relational structures play a central role in many AI tasks, but their\nevolving nature presents challenges for consistent and interpretable\nrepresentation. A common approach is to learn time-varying node embeddings,\nwhose effectiveness depends on satisfying key stability properties. In this\npaper, we propose Unfolded Laplacian Spectral Embedding, a new method that\nextends the Unfolded Adjacency Spectral Embedding framework to normalized\nLaplacians while preserving both cross-sectional and longitudinal stability. We\nprovide formal proof that our method satisfies these stability conditions. In\naddition, as a bonus of using the Laplacian matrix, we establish a new\nCheeger-style inequality that connects the embeddings to the conductance of the\nunderlying dynamic graphs. Empirical evaluations on synthetic and real-world\ndatasets support our theoretical findings and demonstrate the strong\nperformance of our method. These results establish a principled and stable\nframework for dynamic network representation grounded in spectral graph theory.", "AI": {"tldr": "Unfolded Laplacian Spectral Embedding method extends spectral embedding to dynamic graphs using normalized Laplacians, providing formal stability guarantees and Cheeger-style inequality connections to graph conductance.", "motivation": "Dynamic relational structures are central to AI tasks but their evolving nature challenges consistent and interpretable representation. Existing time-varying node embedding methods need to satisfy key stability properties for effectiveness.", "method": "Proposes Unfolded Laplacian Spectral Embedding, which extends the Unfolded Adjacency Spectral Embedding framework to normalized Laplacians while preserving cross-sectional and longitudinal stability.", "result": "Formal proof that the method satisfies stability conditions, establishes a new Cheeger-style inequality connecting embeddings to graph conductance, and empirical evaluations on synthetic and real-world datasets demonstrate strong performance.", "conclusion": "Establishes a principled and stable framework for dynamic network representation grounded in spectral graph theory with both theoretical guarantees and empirical validation."}}
{"id": "2508.12681", "pdf": "https://arxiv.org/pdf/2508.12681", "abs": "https://arxiv.org/abs/2508.12681", "authors": ["Johann Licher", "Max Bartholdt", "Henrik Krauss", "Tim-Lukas Habich", "Thomas Seel", "Moritz Schappler"], "title": "Adaptive Model-Predictive Control of a Soft Continuum Robot Using a Physics-Informed Neural Network Based on Cosserat Rod Theory", "categories": ["cs.RO", "cs.LG"], "comment": "20 pages, 15 figures", "summary": "Dynamic control of soft continuum robots (SCRs) holds great potential for\nexpanding their applications, but remains a challenging problem due to the high\ncomputational demands of accurate dynamic models. While data-driven approaches\nlike Koopman-operator-based methods have been proposed, they typically lack\nadaptability and cannot capture the full robot shape, limiting their\napplicability. This work introduces a real-time-capable nonlinear\nmodel-predictive control (MPC) framework for SCRs based on a domain-decoupled\nphysics-informed neural network (DD-PINN) with adaptable bending stiffness. The\nDD-PINN serves as a surrogate for the dynamic Cosserat rod model with a\nspeed-up factor of 44000. It is also used within an unscented Kalman filter for\nestimating the model states and bending compliance from end-effector position\nmeasurements. We implement a nonlinear evolutionary MPC running at 70 Hz on the\nGPU. In simulation, it demonstrates accurate tracking of dynamic trajectories\nand setpoint control with end-effector position errors below 3 mm (2.3% of the\nactuator's length). In real-world experiments, the controller achieves similar\naccuracy and accelerations up to 3.55 m/s2.", "AI": {"tldr": "Real-time nonlinear MPC for soft continuum robots using physics-informed neural network surrogate model with 44000x speedup, achieving 3mm tracking accuracy at 70Hz.", "motivation": "Dynamic control of soft continuum robots is challenging due to computational demands of accurate models, and existing data-driven methods lack adaptability and full shape capture capabilities.", "method": "Domain-decoupled physics-informed neural network (DD-PINN) with adaptable bending stiffness as surrogate for dynamic Cosserat rod model, combined with unscented Kalman filter for state estimation and nonlinear MPC running at 70Hz on GPU.", "result": "44000x speedup over traditional model, 3mm end-effector position errors (2.3% of actuator length) in simulation, similar accuracy and accelerations up to 3.55 m/s\u00b2 in real-world experiments.", "conclusion": "The framework enables real-time capable nonlinear MPC for soft continuum robots with high accuracy and computational efficiency, demonstrating practical applicability in both simulation and real-world scenarios."}}
{"id": "2508.12538", "pdf": "https://arxiv.org/pdf/2508.12538", "abs": "https://arxiv.org/abs/2508.12538", "authors": ["Yongjian Guo", "Puzhuo Liu", "Wanlun Ma", "Zehang Deng", "Xiaogang Zhu", "Peng Di", "Xi Xiao", "Sheng Wen"], "title": "Systematic Analysis of MCP Security", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": null, "summary": "The Model Context Protocol (MCP) has emerged as a universal standard that\nenables AI agents to seamlessly connect with external tools, significantly\nenhancing their functionality. However, while MCP brings notable benefits, it\nalso introduces significant vulnerabilities, such as Tool Poisoning Attacks\n(TPA), where hidden malicious instructions exploit the sycophancy of large\nlanguage models (LLMs) to manipulate agent behavior. Despite these risks,\ncurrent academic research on MCP security remains limited, with most studies\nfocusing on narrow or qualitative analyses that fail to capture the diversity\nof real-world threats. To address this gap, we present the MCP Attack Library\n(MCPLIB), which categorizes and implements 31 distinct attack methods under\nfour key classifications: direct tool injection, indirect tool injection,\nmalicious user attacks, and LLM inherent attack. We further conduct a\nquantitative analysis of the efficacy of each attack. Our experiments reveal\nkey insights into MCP vulnerabilities, including agents' blind reliance on tool\ndescriptions, sensitivity to file-based attacks, chain attacks exploiting\nshared context, and difficulty distinguishing external data from executable\ncommands. These insights, validated through attack experiments, underscore the\nurgency for robust defense strategies and informed MCP design. Our\ncontributions include 1) constructing a comprehensive MCP attack taxonomy, 2)\nintroducing a unified attack framework MCPLIB, and 3) conducting empirical\nvulnerability analysis to enhance MCP security mechanisms. This work provides a\nfoundational framework, supporting the secure evolution of MCP ecosystems.", "AI": {"tldr": "MCPLIB introduces a comprehensive attack library with 31 methods across 4 categories to address security vulnerabilities in Model Context Protocol (MCP) systems, revealing critical weaknesses in AI agent tool interactions.", "motivation": "MCP enables AI agents to connect with external tools but introduces significant security vulnerabilities like Tool Poisoning Attacks, yet current research lacks comprehensive quantitative analysis of real-world threats.", "method": "Developed MCP Attack Library (MCPLIB) categorizing 31 attack methods into four classifications: direct tool injection, indirect tool injection, malicious user attacks, and LLM inherent attacks, followed by quantitative efficacy analysis.", "result": "Experiments revealed key vulnerabilities: agents' blind reliance on tool descriptions, sensitivity to file-based attacks, chain attacks exploiting shared context, and difficulty distinguishing external data from executable commands.", "conclusion": "The work provides a foundational framework for MCP security with comprehensive attack taxonomy, unified attack framework, and empirical vulnerability analysis to support secure evolution of MCP ecosystems."}}
{"id": "2508.12730", "pdf": "https://arxiv.org/pdf/2508.12730", "abs": "https://arxiv.org/abs/2508.12730", "authors": ["Jaeung Lee", "Suhyeon Yu", "Yurim Jang", "Simon S. Woo", "Jaemin Jo"], "title": "Unlearning Comparator: A Visual Analytics System for Comparative Evaluation of Machine Unlearning Methods", "categories": ["cs.CR", "cs.HC", "cs.LG", "H.5.2; I.3.6"], "comment": "Submitted to IEEE Transactions on Visualization and Computer Graphics\n  (TVCG), under review. 15 pages. This work has been submitted to the IEEE for\n  possible publication", "summary": "Machine Unlearning (MU) aims to remove target training data from a trained\nmodel so that the removed data no longer influences the model's behavior,\nfulfilling \"right to be forgotten\" obligations under data privacy laws. Yet, we\nobserve that researchers in this rapidly emerging field face challenges in\nanalyzing and understanding the behavior of different MU methods, especially in\nterms of three fundamental principles in MU: accuracy, efficiency, and privacy.\nConsequently, they often rely on aggregate metrics and ad-hoc evaluations,\nmaking it difficult to accurately assess the trade-offs between methods. To\nfill this gap, we introduce a visual analytics system, Unlearning Comparator,\ndesigned to facilitate the systematic evaluation of MU methods. Our system\nsupports two important tasks in the evaluation process: model comparison and\nattack simulation. First, it allows the user to compare the behaviors of two\nmodels, such as a model generated by a certain method and a retrained baseline,\nat class-, instance-, and layer-levels to better understand the changes made\nafter unlearning. Second, our system simulates membership inference attacks\n(MIAs) to evaluate the privacy of a method, where an attacker attempts to\ndetermine whether specific data samples were part of the original training set.\nWe evaluate our system through a case study visually analyzing prominent MU\nmethods and demonstrate that it helps the user not only understand model\nbehaviors but also gain insights that can inform the improvement of MU methods.", "AI": {"tldr": "A visual analytics system called Unlearning Comparator is introduced to systematically evaluate Machine Unlearning methods by enabling model comparison at multiple levels and simulating privacy attacks.", "motivation": "Researchers face challenges in analyzing Machine Unlearning methods due to reliance on aggregate metrics and ad-hoc evaluations, making it difficult to assess trade-offs between accuracy, efficiency, and privacy.", "method": "Developed a visual analytics system that supports two main tasks: model comparison (class-, instance-, and layer-level analysis) and membership inference attack simulation to evaluate privacy.", "result": "The system helps users understand model behaviors and gain insights for improving Machine Unlearning methods, as demonstrated through case studies analyzing prominent MU methods.", "conclusion": "Unlearning Comparator provides a systematic framework for evaluating Machine Unlearning methods, addressing the need for better analysis tools in this emerging field to fulfill data privacy obligations."}}
{"id": "2508.12738", "pdf": "https://arxiv.org/pdf/2508.12738", "abs": "https://arxiv.org/abs/2508.12738", "authors": ["Sebastian Hirt", "Lukas Theiner", "Maik Pfefferkorn", "Rolf Findeisen"], "title": "A Hierarchical Surrogate Model for Efficient Multi-Task Parameter Learning in Closed-Loop Contro", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "8 pages, 4 figures, accepted for CDC 2025", "summary": "Many control problems require repeated tuning and adaptation of controllers\nacross distinct closed-loop tasks, where data efficiency and adaptability are\ncritical. We propose a hierarchical Bayesian optimization (BO) framework that\nis tailored to efficient controller parameter learning in sequential\ndecision-making and control scenarios for distinct tasks. Instead of treating\nthe closed-loop cost as a black-box, our method exploits structural knowledge\nof the underlying problem, consisting of a dynamical system, a control law, and\nan associated closed-loop cost function. We construct a hierarchical surrogate\nmodel using Gaussian processes that capture the closed-loop state evolution\nunder different parameterizations, while the task-specific weighting and\naccumulation into the closed-loop cost are computed exactly via known\nclosed-form expressions. This allows knowledge transfer and enhanced data\nefficiency between different closed-loop tasks. The proposed framework retains\nsublinear regret guarantees on par with standard black-box BO, while enabling\nmulti-task or transfer learning. Simulation experiments with model predictive\ncontrol demonstrate substantial benefits in both sample efficiency and\nadaptability when compared to purely black-box BO approaches.", "AI": {"tldr": "Hierarchical Bayesian optimization framework for efficient controller parameter learning across distinct closed-loop tasks, leveraging structural knowledge of dynamical systems rather than treating costs as black-box functions.", "motivation": "Many control problems require repeated tuning and adaptation of controllers across distinct tasks where data efficiency and adaptability are critical, but standard black-box approaches lack structural knowledge exploitation.", "method": "Construct hierarchical Gaussian process surrogate models that capture closed-loop state evolution under different parameterizations, while computing task-specific cost weighting and accumulation exactly via known closed-form expressions.", "result": "The framework achieves substantial benefits in both sample efficiency and adaptability compared to purely black-box BO approaches, while retaining sublinear regret guarantees.", "conclusion": "The proposed hierarchical BO framework enables effective knowledge transfer and enhanced data efficiency between different closed-loop tasks while maintaining theoretical performance guarantees."}}
{"id": "2508.12748", "pdf": "https://arxiv.org/pdf/2508.12748", "abs": "https://arxiv.org/abs/2508.12748", "authors": ["Chenyang Wang", "Roger Olsson", "Stefan Forsstr\u00f6m", "Qing He"], "title": "Deep Semantic Inference over the Air: An Efficient Task-Oriented Communication System", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Empowered by deep learning, semantic communication marks a paradigm shift\nfrom transmitting raw data to conveying task-relevant meaning, enabling more\nefficient and intelligent wireless systems. In this study, we explore a deep\nlearning-based task-oriented communication framework that jointly considers\nclassification performance, computational latency, and communication cost. We\nadopt ResNets-based models and evaluate them on the CIFAR-10 and CIFAR-100\ndatasets to simulate real-world classification tasks in wireless environments.\nWe partition the model at various points to simulate split inference across a\nwireless channel. By varying the split location and the size of the transmitted\nsemantic feature vector, we systematically analyze the trade-offs between task\naccuracy and resource efficiency. Experimental results show that, with\nappropriate model partitioning and semantic feature compression, the system can\nretain over 85\\% of baseline accuracy while significantly reducing both\ncomputational load and communication overhead.", "AI": {"tldr": "Deep learning-based semantic communication framework for wireless systems that optimizes classification accuracy, computational latency, and communication cost through model partitioning and semantic feature compression.", "motivation": "To shift from transmitting raw data to conveying task-relevant meaning in wireless communication, enabling more efficient and intelligent systems by jointly considering performance metrics and resource constraints.", "method": "Used ResNets-based models on CIFAR-10 and CIFAR-100 datasets, partitioned models at various points to simulate split inference over wireless channels, and varied split locations and semantic feature vector sizes to analyze trade-offs.", "result": "The system achieved over 85% of baseline accuracy while significantly reducing computational load and communication overhead through appropriate model partitioning and semantic feature compression.", "conclusion": "Semantic communication with deep learning enables efficient wireless systems by balancing task performance with resource efficiency through strategic model partitioning and feature compression techniques."}}
{"id": "2508.12832", "pdf": "https://arxiv.org/pdf/2508.12832", "abs": "https://arxiv.org/abs/2508.12832", "authors": ["Jinyu Lu", "Xinrong Sun", "Yunting Tao", "Tong Ji", "Fanyu Kong", "Guoqiang Yang"], "title": "Efficient and Verifiable Privacy-Preserving Convolutional Computation for CNN Inference with Untrusted Clouds", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "The widespread adoption of convolutional neural networks (CNNs) in\nresource-constrained scenarios has driven the development of Machine Learning\nas a Service (MLaaS) system. However, this approach is susceptible to privacy\nleakage, as the data sent from the client to the untrusted cloud server often\ncontains sensitive information. Existing CNN privacy-preserving schemes, while\neffective in ensuring data confidentiality through homomorphic encryption and\nsecret sharing, face efficiency bottlenecks, particularly in convolution\noperations. In this paper, we propose a novel verifiable privacy-preserving\nscheme tailored for CNN convolutional layers. Our scheme enables efficient\nencryption and decryption, allowing resource-constrained clients to securely\noffload computations to the untrusted cloud server. Additionally, we present a\nverification mechanism capable of detecting the correctness of the results with\na success probability of at least $1-\\frac{1}{\\left|Z\\right|}$. Extensive\nexperiments conducted on 10 datasets and various CNN models demonstrate that\nour scheme achieves speedups ranging $26 \\times$ ~ $\\ 87\\times$ compared to the\noriginal plaintext model while maintaining accuracy.", "AI": {"tldr": "A verifiable privacy-preserving scheme for CNN convolutional layers that achieves 26-87x speedup while maintaining accuracy and providing result verification.", "motivation": "MLaaS systems using CNNs in resource-constrained environments face privacy leakage risks when sending sensitive data to untrusted cloud servers, and existing privacy-preserving schemes suffer from efficiency bottlenecks in convolution operations.", "method": "Proposes a novel verifiable privacy-preserving scheme tailored for CNN convolutional layers with efficient encryption/decryption for resource-constrained clients and a verification mechanism to detect result correctness.", "result": "Achieves speedups of 26-87x compared to original plaintext models while maintaining accuracy, with verification capable of detecting correctness with success probability of at least 1-1/|Z| across 10 datasets and various CNN models.", "conclusion": "The scheme enables secure and efficient offloading of CNN computations to untrusted cloud servers while preserving privacy and providing verifiable results, making it suitable for resource-constrained MLaaS scenarios."}}
{"id": "2508.12834", "pdf": "https://arxiv.org/pdf/2508.12834", "abs": "https://arxiv.org/abs/2508.12834", "authors": ["Hiroshi Horii", "Sothea Has"], "title": "Optimal Condition for Initialization Variance in Deep Neural Networks: An SGD Dynamics Perspective", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Stochastic gradient descent (SGD), one of the most fundamental optimization\nalgorithms in machine learning (ML), can be recast through a continuous-time\napproximation as a Fokker-Planck equation for Langevin dynamics, a viewpoint\nthat has motivated many theoretical studies. Within this framework, we study\nthe relationship between the quasi-stationary distribution derived from this\nequation and the initial distribution through the Kullback-Leibler (KL)\ndivergence. As the quasi-steady-state distribution depends on the expected cost\nfunction, the KL divergence eventually reveals the connection between the\nexpected cost function and the initialization distribution. By applying this to\ndeep neural network models (DNNs), we can express the bounds of the expected\nloss function explicitly in terms of the initialization parameters. Then, by\nminimizing this bound, we obtain an optimal condition of the initialization\nvariance in the Gaussian case. This result provides a concrete mathematical\ncriterion, rather than a heuristic approach, to select the scale of weight\ninitialization in DNNs. In addition, we experimentally confirm our theoretical\nresults by using the classical SGD to train fully connected neural networks on\nthe MNIST and Fashion-MNIST datasets. The result shows that if the variance of\nthe initialization distribution satisfies our theoretical optimal condition,\nthen the corresponding DNN model always achieves lower final training loss and\nhigher test accuracy than the conventional He-normal initialization. Our work\nthus supplies a mathematically grounded indicator that guides the choice of\ninitialization variance and clarifies its physical meaning of the dynamics of\nparameters in DNNs.", "AI": {"tldr": "The paper establishes a mathematical framework connecting SGD dynamics to initialization variance through Fokker-Planck equations and KL divergence, deriving an optimal initialization condition that outperforms conventional methods.", "motivation": "To provide a mathematically rigorous criterion for weight initialization in deep neural networks, moving beyond heuristic approaches by connecting SGD dynamics to initialization parameters through theoretical analysis.", "method": "Recast SGD as a Fokker-Planck equation for Langevin dynamics, analyze the relationship between quasi-stationary distribution and initial distribution using KL divergence, derive bounds for expected loss function in terms of initialization parameters, and validate experimentally on MNIST and Fashion-MNIST datasets.", "result": "Derived an optimal condition for initialization variance in Gaussian case that consistently achieves lower final training loss and higher test accuracy compared to conventional He-normal initialization when satisfied.", "conclusion": "Provides a mathematically grounded indicator for initialization variance selection that clarifies the physical meaning of parameter dynamics in DNNs, offering concrete theoretical foundation rather than heuristic approaches."}}
{"id": "2508.12930", "pdf": "https://arxiv.org/pdf/2508.12930", "abs": "https://arxiv.org/abs/2508.12930", "authors": ["David Hirnschall", "Robert Bajons"], "title": "The path to a goal: Understanding soccer possessions via path signatures", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We present a novel framework for predicting next actions in soccer\npossessions by leveraging path signatures to encode their complex\nspatio-temporal structure. Unlike existing approaches, we do not rely on fixed\nhistorical windows and handcrafted features, but rather encode the entire\nrecent possession, thereby avoiding the inclusion of potentially irrelevant or\nmisleading historical information. Path signatures naturally capture the order\nand interaction of events, providing a mathematically grounded feature encoding\nfor variable-length time series of irregular sampling frequencies without the\nnecessity for manual feature engineering. Our proposed approach outperforms a\ntransformer-based benchmark across various loss metrics and considerably\nreduces computational cost. Building on these results, we introduce a new\npossession evaluation metric based on well-established frameworks in soccer\nanalytics, incorporating both predicted action type probabilities and action\nlocation. Our metric shows greater reliability than existing metrics in\ndomain-specific comparisons. Finally, we validate our approach through a\ndetailed analysis of the 2017/18 Premier League season and discuss further\napplications and future extensions.", "AI": {"tldr": "Novel framework using path signatures to predict soccer actions, outperforms transformers with lower computational cost, introduces new possession evaluation metric validated on Premier League data.", "motivation": "Existing approaches rely on fixed historical windows and handcrafted features, which may include irrelevant information. Need for mathematically grounded encoding that captures complex spatio-temporal structure without manual feature engineering.", "method": "Leverages path signatures to encode entire recent possession, capturing order and interaction of events. Handles variable-length time series with irregular sampling frequencies. Uses predicted action type probabilities and locations for possession evaluation.", "result": "Outperforms transformer-based benchmark across various loss metrics. Reduces computational cost considerably. New possession metric shows greater reliability than existing metrics in domain-specific comparisons.", "conclusion": "Path signatures provide effective encoding for soccer action prediction. Framework validated on 2017/18 Premier League season data. Shows promise for further applications and extensions in soccer analytics."}}
{"id": "2508.12939", "pdf": "https://arxiv.org/pdf/2508.12939", "abs": "https://arxiv.org/abs/2508.12939", "authors": ["Michael Deistler", "Jan Boelts", "Peter Steinbach", "Guy Moss", "Thomas Moreau", "Manuel Gloeckler", "Pedro L. C. Rodrigues", "Julia Linhart", "Janne K. Lappalainen", "Benjamin Kurt Miller", "Pedro J. Gon\u00e7alves", "Jan-Matthis Lueckmann", "Cornelius Schr\u00f6der", "Jakob H. Macke"], "title": "Simulation-Based Inference: A Practical Guide", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "A central challenge in many areas of science and engineering is to identify\nmodel parameters that are consistent with prior knowledge and empirical data.\nBayesian inference offers a principled framework for this task, but can be\ncomputationally prohibitive when models are defined by stochastic simulators.\nSimulation-based Inference (SBI) is a suite of methods developed to overcome\nthis limitation, which has enabled scientific discoveries in fields such as\nparticle physics, astrophysics, and neuroscience. The core idea of SBI is to\ntrain neural networks on data generated by a simulator, without requiring\naccess to likelihood evaluations. Once trained, inference is amortized: The\nneural network can rapidly perform Bayesian inference on empirical observations\nwithout requiring additional training or simulations. In this tutorial, we\nprovide a practical guide for practitioners aiming to apply SBI methods. We\noutline a structured SBI workflow and offer practical guidelines and diagnostic\ntools for every stage of the process -- from setting up the simulator and\nprior, choosing and training inference networks, to performing inference and\nvalidating the results. We illustrate these steps through examples from\nastrophysics, psychophysics, and neuroscience. This tutorial empowers\nresearchers to apply state-of-the-art SBI methods, facilitating efficient\nparameter inference for scientific discovery.", "AI": {"tldr": "Practical guide for Simulation-based Inference (SBI) methods that enable Bayesian parameter inference without likelihood evaluations, using neural networks trained on simulator data for amortized inference.", "motivation": "Bayesian inference is computationally prohibitive for stochastic simulator models, requiring methods that can perform inference without direct likelihood evaluations.", "method": "Train neural networks on data generated by simulators to learn the mapping from observations to posterior distributions, enabling amortized inference that doesn't require additional simulations for new data.", "result": "Provides a structured SBI workflow with practical guidelines and diagnostic tools for simulator setup, prior specification, network training, inference, and validation across multiple scientific domains.", "conclusion": "SBI methods empower researchers to efficiently perform parameter inference for scientific discovery, with applications demonstrated in astrophysics, psychophysics, and neuroscience."}}
{"id": "2508.12683", "pdf": "https://arxiv.org/pdf/2508.12683", "abs": "https://arxiv.org/abs/2508.12683", "authors": ["David J. Moore"], "title": "A Taxonomy of Hierarchical Multi-Agent Systems: Design Patterns, Coordination Mechanisms, and Industrial Applications", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Hierarchical multi-agent systems (HMAS) organize collections of agents into\nlayered structures that help manage complexity and scale. These hierarchies can\nsimplify coordination, but they also can introduce trade-offs that are not\nalways obvious. This paper proposes a multi-dimensional taxonomy for HMAS along\nfive axes: control hierarchy, information flow, role and task delegation,\ntemporal layering, and communication structure. The intent is not to prescribe\na single \"best\" design but to provide a lens for comparing different\napproaches.\n  Rather than treating these dimensions in isolation, the taxonomy is connected\nto concrete coordination mechanisms - from the long-standing contract-net\nprotocol for task allocation to more recent work in hierarchical reinforcement\nlearning. Industrial contexts illustrate the framework, including power grids\nand oilfield operations, where agents at production, maintenance, and supply\nlevels coordinate to diagnose well issues or balance energy demand. These cases\nsuggest that hierarchical structures may achieve global efficiency while\npreserving local autonomy, though the balance is delicate.\n  The paper closes by identifying open challenges: making hierarchical\ndecisions explainable to human operators, scaling to very large agent\npopulations, and assessing whether learning-based agents such as large language\nmodels can be safely integrated into layered frameworks. This paper presents\nwhat appears to be the first taxonomy that unifies structural, temporal, and\ncommunication dimensions of hierarchical MAS into a single design framework,\nbridging classical coordination mechanisms with modern reinforcement learning\nand large language model agents.", "AI": {"tldr": "A multi-dimensional taxonomy for hierarchical multi-agent systems (HMAS) across five axes: control hierarchy, information flow, role/task delegation, temporal layering, and communication structure, providing a framework to compare different approaches rather than prescribing a single best design.", "motivation": "Hierarchical multi-agent systems help manage complexity and scale but introduce trade-offs that are not always obvious. The paper aims to provide a comprehensive framework for comparing different HMAS approaches across multiple dimensions.", "method": "Proposes a five-axis taxonomy connected to concrete coordination mechanisms (contract-net protocol, hierarchical reinforcement learning) and illustrated with industrial case studies from power grids and oilfield operations.", "result": "The taxonomy unifies structural, temporal, and communication dimensions into a single design framework, showing that hierarchical structures can achieve global efficiency while preserving local autonomy, though the balance is delicate.", "conclusion": "Identifies open challenges including making hierarchical decisions explainable, scaling to large agent populations, and safely integrating learning-based agents like LLMs. Presents the first unified taxonomy bridging classical coordination with modern reinforcement learning and LLM agents."}}
{"id": "2508.12947", "pdf": "https://arxiv.org/pdf/2508.12947", "abs": "https://arxiv.org/abs/2508.12947", "authors": ["Michael Mayer", "Mario V. W\u00fcthrich"], "title": "Shapley Values: Paired-Sampling Approximations", "categories": ["stat.ML", "cs.CE", "cs.LG"], "comment": null, "summary": "Originally introduced in cooperative game theory, Shapley values have become\na very popular tool to explain machine learning predictions. Based on Shapley's\nfairness axioms, every input (feature component) gets a credit how it\ncontributes to an output (prediction). These credits are then used to explain\nthe prediction. The only limitation in computing the Shapley values (credits)\nfor many different predictions is of computational nature. There are two\npopular sampling approximations, sampling KernelSHAP and sampling\nPermutationSHAP. Our first novel contributions are asymptotic normality results\nfor these sampling approximations. Next, we show that the paired-sampling\napproaches provide exact results in case of interactions being of maximal order\ntwo. Furthermore, the paired-sampling PermutationSHAP possesses the additive\nrecovery property, whereas its kernel counterpart does not.", "AI": {"tldr": "Asymptotic normality results for KernelSHAP and PermutationSHAP sampling approximations, showing paired-sampling provides exact results for second-order interactions and PermutationSHAP has additive recovery property.", "motivation": "Shapley values are widely used to explain ML predictions but face computational limitations. The paper aims to provide theoretical foundations for sampling approximations to improve their reliability and understanding.", "method": "Theoretical analysis of sampling KernelSHAP and PermutationSHAP approximations, proving asymptotic normality results and investigating properties of paired-sampling approaches.", "result": "Established asymptotic normality for both sampling methods, proved paired-sampling gives exact results for second-order interactions, and showed PermutationSHAP has additive recovery property while KernelSHAP does not.", "conclusion": "The theoretical results provide important foundations for reliable use of Shapley value approximations in ML explainability, with PermutationSHAP offering better theoretical properties through additive recovery."}}
{"id": "2508.12968", "pdf": "https://arxiv.org/pdf/2508.12968", "abs": "https://arxiv.org/abs/2508.12968", "authors": ["Branislav Gerazov", "Marcello Politi", "S\u00e9bastien Brati\u00e8res"], "title": "Arabic ASR on the SADA Large-Scale Arabic Speech Corpus with Transformer-Based Models", "categories": ["eess.AS", "cs.LG"], "comment": null, "summary": "We explore the performance of several state-of-the-art automatic speech\nrecognition (ASR) models on a large-scale Arabic speech dataset, the SADA\n(Saudi Audio Dataset for Arabic), which contains 668 hours of high-quality\naudio from Saudi television shows. The dataset includes multiple dialects and\nenvironments, specifically a noisy subset that makes it particularly\nchallenging for ASR. We evaluate the performance of the models on the SADA test\nset, and we explore the impact of fine-tuning, language models, as well as\nnoise and denoising on their performance. We find that the best performing\nmodel is the MMS 1B model finetuned on SADA with a 4-gram language model that\nachieves a WER of 40.9\\% and a CER of 17.6\\% on the SADA test clean set.", "AI": {"tldr": "Evaluation of state-of-the-art ASR models on Saudi Arabic dataset shows MMS 1B model with fine-tuning and 4-gram LM achieves best performance (40.9% WER, 17.6% CER).", "motivation": "To assess performance of modern ASR systems on challenging Arabic speech data with multiple dialects and noisy environments from Saudi television content.", "method": "Evaluated several ASR models on SADA dataset (668 hours of Saudi TV audio), testing fine-tuning, language models, and noise/denoising impact on performance.", "result": "MMS 1B model fine-tuned on SADA with 4-gram language model achieved best results: 40.9% WER and 17.6% CER on clean test set.", "conclusion": "Fine-tuning with appropriate language modeling significantly improves ASR performance on challenging Arabic dialect datasets with noise variations."}}
{"id": "2508.12987", "pdf": "https://arxiv.org/pdf/2508.12987", "abs": "https://arxiv.org/abs/2508.12987", "authors": ["Jose L. Bonilla", "Krzysztof M. Graczyk", "Artur M. Ankowski", "Rwik Dharmapal Banerjee", "Beata E. Kowal", "Hemant Prasad", "Jan T. Sobczyk"], "title": "Transfer Learning for Neutrino Scattering: Domain Adaptation with GANs", "categories": ["hep-ph", "cs.LG", "hep-ex", "nucl-ex", "physics.comp-ph"], "comment": "17 pages, 17 figures", "summary": "We utilize transfer learning to extrapolate the physics knowledge encoded in\na Generative Adversarial Network (GAN) model trained on synthetic\ncharged-current (CC) neutrino-carbon inclusive scattering data. This base model\nis adapted to generate CC inclusive scattering events (lepton kinematics only)\nfor neutrino-argon and antineutrino-carbon interactions. Furthermore, we assess\nthe effectiveness of transfer learning in re-optimizing a custom model when new\ndata comes from a different neutrino-nucleus interaction model. Our results\ndemonstrate that transfer learning significantly outperforms training\ngenerative models from scratch. To study this, we consider two training data\nsets: one with 10,000 and another with 100,000 events. The models obtained via\ntransfer learning perform well even with smaller training data. The proposed\nmethod provides a promising approach for constructing neutrino scattering event\ngenerators in scenarios where experimental data is sparse.", "AI": {"tldr": "Transfer learning enables effective adaptation of GAN models from neutrino-carbon to neutrino-argon and antineutrino-carbon scattering, outperforming training from scratch especially with limited data.", "motivation": "To address the challenge of sparse experimental data in neutrino scattering physics by leveraging transfer learning to adapt existing generative models to new interaction types and nuclei.", "method": "Used transfer learning to adapt a GAN model trained on synthetic charged-current neutrino-carbon scattering data to generate events for neutrino-argon and antineutrino-carbon interactions. Evaluated performance with 10,000 and 100,000 event training sets.", "result": "Transfer learning significantly outperformed training generative models from scratch. Models performed well even with smaller training data (10,000 events).", "conclusion": "Transfer learning provides a promising approach for building neutrino scattering event generators when experimental data is limited, enabling effective model adaptation across different interaction types and nuclear targets."}}
{"id": "2508.12702", "pdf": "https://arxiv.org/pdf/2508.12702", "abs": "https://arxiv.org/abs/2508.12702", "authors": ["Jie Su", "Weiwei Wang", "Zhaotian Gu", "Dahui Wang", "Tianyi Qian"], "title": "A Unified Cortical Circuit Model with Divisive Normalization and Self-Excitation for Robust Representation and Memory Maintenance", "categories": ["q-bio.NC", "cs.AI", "cs.NE"], "comment": "15 pages, 4 figures", "summary": "Robust information representation and its persistent maintenance are\nfundamental for higher cognitive functions. Existing models employ distinct\nneural mechanisms to separately address noise-resistant processing or\ninformation maintenance, yet a unified framework integrating both operations\nremains elusive -- a critical gap in understanding cortical computation. Here,\nwe introduce a recurrent neural circuit that combines divisive normalization\nwith self-excitation to achieve both robust encoding and stable retention of\nnormalized inputs. Mathematical analysis shows that, for suitable parameter\nregimes, the system forms a continuous attractor with two key properties: (1)\ninput-proportional stabilization during stimulus presentation; and (2)\nself-sustained memory states persisting after stimulus offset. We demonstrate\nthe model's versatility in two canonical tasks: (a) noise-robust encoding in a\nrandom-dot kinematogram (RDK) paradigm; and (b) approximate Bayesian belief\nupdating in a probabilistic Wisconsin Card Sorting Test (pWCST). This work\nestablishes a unified mathematical framework that bridges noise suppression,\nworking memory, and approximate Bayesian inference within a single cortical\nmicrocircuit, offering fresh insights into the brain's canonical computation\nand guiding the design of biologically plausible artificial neural\narchitectures.", "AI": {"tldr": "A unified recurrent neural circuit combining divisive normalization and self-excitation achieves both robust encoding and stable memory retention, bridging noise suppression, working memory, and Bayesian inference.", "motivation": "Existing models use separate neural mechanisms for noise-resistant processing and information maintenance, lacking a unified framework for understanding cortical computation.", "method": "A recurrent neural circuit that combines divisive normalization with self-excitation, mathematically analyzed to form a continuous attractor with input-proportional stabilization and self-sustained memory states.", "result": "The model demonstrates versatility in noise-robust encoding (random-dot kinematogram) and approximate Bayesian belief updating (probabilistic Wisconsin Card Sorting Test).", "conclusion": "This work establishes a unified mathematical framework that bridges noise suppression, working memory, and approximate Bayesian inference within a single cortical microcircuit, offering insights into brain computation and guiding biologically plausible AI design."}}
{"id": "2508.12706", "pdf": "https://arxiv.org/pdf/2508.12706", "abs": "https://arxiv.org/abs/2508.12706", "authors": ["Yongchun Zhu", "Guanyu Jiang", "Jingwu Chen", "Feng Zhang", "Xiao Yang", "Zuotao Liu"], "title": "Asymmetric Diffusion Recommendation Model", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted by CIKM2025", "summary": "Recently, motivated by the outstanding achievements of diffusion models, the\ndiffusion process has been employed to strengthen representation learning in\nrecommendation systems. Most diffusion-based recommendation models typically\nutilize standard Gaussian noise in symmetric forward and reverse processes in\ncontinuous data space. Nevertheless, the samples derived from recommendation\nsystems inhabit a discrete data space, which is fundamentally different from\nthe continuous one. Moreover, Gaussian noise has the potential to corrupt\npersonalized information within latent representations. In this work, we\npropose a novel and effective method, named Asymmetric Diffusion Recommendation\nModel (AsymDiffRec), which learns forward and reverse processes in an\nasymmetric manner. We define a generalized forward process that simulates the\nmissing features in real-world recommendation samples. The reverse process is\nthen performed in an asymmetric latent feature space. To preserve personalized\ninformation within the latent representation, a task-oriented optimization\nstrategy is introduced. In the serving stage, the raw sample with missing\nfeatures is regarded as a noisy input to generate a denoising and robust\nrepresentation for the final prediction. By equipping base models with\nAsymDiffRec, we conduct online A/B tests, achieving improvements of +0.131% and\n+0.166% in terms of users' active days and app usage duration respectively.\nAdditionally, the extended offline experiments also demonstrate improvements.\nAsymDiffRec has been implemented in the Douyin Music App.", "AI": {"tldr": "AsymDiffRec is an asymmetric diffusion model for recommendation systems that handles discrete data spaces and preserves personalized information through task-oriented optimization, achieving significant improvements in user engagement metrics.", "motivation": "Standard diffusion models use Gaussian noise in continuous spaces, but recommendation data is discrete and Gaussian noise can corrupt personalized information in latent representations.", "method": "Asymmetric forward and reverse processes where forward process simulates missing features and reverse process operates in asymmetric latent space with task-oriented optimization to preserve personalized information.", "result": "Online A/B tests showed +0.131% improvement in users' active days and +0.166% improvement in app usage duration. Offline experiments also demonstrated improvements.", "conclusion": "AsymDiffRec effectively addresses the discrete nature of recommendation data and preserves personalized information, leading to significant performance gains in real-world deployment on Douyin Music App."}}
{"id": "2508.13064", "pdf": "https://arxiv.org/pdf/2508.13064", "abs": "https://arxiv.org/abs/2508.13064", "authors": ["Seongeun Ryu", "Yunyong Ko", "Sang-Wook Kim"], "title": "Is This News Still Interesting to You?: Lifetime-aware Interest Matching for News Recommendation", "categories": ["cs.IR", "cs.LG"], "comment": "10 pages, 7 figures, 4 tables, accepted at ACM International\n  Conference on Information and Knowledge Management (CIKM)", "summary": "Personalized news recommendation aims to deliver news articles aligned with\nusers' interests, serving as a key solution to alleviate the problem of\ninformation overload on online news platforms. While prior work has improved\ninterest matching through refined representations of news and users, the\nfollowing time-related challenges remain underexplored: (C1) leveraging the age\nof clicked news to infer users' interest persistence, and (C2) modeling the\nvarying lifetime of news across topics and users. To jointly address these\nchallenges, we propose a novel Lifetime-aware Interest Matching framework for\nnEws recommendation, named LIME, which incorporates three key strategies: (1)\nUser-Topic lifetime-aware age representation to capture the relative age of\nnews with respect to a user-topic pair, (2) Candidate-aware lifetime attention\nfor generating temporally aligned user representation, and (3) Freshness-guided\ninterest refinement for prioritizing valid candidate news at prediction time.\nExtensive experiments on two real-world datasets demonstrate that LIME\nconsistently outperforms a wide range of state-of-the-art news recommendation\nmethods, and its model agnostic strategies significantly improve recommendation\naccuracy.", "AI": {"tldr": "LIME is a news recommendation framework that addresses time-related challenges by modeling news lifetime and interest persistence through user-topic aware age representation, candidate-aware attention, and freshness-guided refinement.", "motivation": "Existing news recommendation systems underutilize time-related factors like how long users maintain interest in topics and how news lifespan varies across topics and users, leaving room for improvement in temporal interest matching.", "method": "Proposes LIME framework with three strategies: 1) User-Topic lifetime-aware age representation to capture relative news age, 2) Candidate-aware lifetime attention for temporally aligned user representation, and 3) Freshness-guided interest refinement to prioritize valid news.", "result": "Extensive experiments on two real-world datasets show LIME consistently outperforms state-of-the-art news recommendation methods and its model-agnostic strategies significantly improve recommendation accuracy.", "conclusion": "LIME effectively addresses temporal challenges in news recommendation by modeling interest persistence and news lifetime variations, demonstrating superior performance and general applicability across different recommendation models."}}
{"id": "2508.12709", "pdf": "https://arxiv.org/pdf/2508.12709", "abs": "https://arxiv.org/abs/2508.12709", "authors": ["Aurian Quelennec", "Pierre Chouteau", "Geoffroy Peeters", "Slim Essid"], "title": "MATPAC++: Enhanced Masked Latent Prediction for Self-Supervised Audio Representation Learning", "categories": ["cs.SD", "cs.AI"], "comment": "Under review", "summary": "Masked latent prediction has emerged as a leading paradigm in self-supervised\nlearning (SSL), especially for general audio and music representation learning.\nWhile recent methods have demonstrated strong performance, the role of the\npredictor module used at the output of such SSL systems remains mainly\noverlooked, despite being crucial for solving the pretext task at hand. In\nparticular, this module should be able to deal with the ambiguity inherent in\naudio content, especially when it is composed of multiple sound sources. This\nwork proposes a novel enhancement: integrating Multiple Choice Learning (MCL)\nto explicitly model prediction ambiguity and improve representation quality. We\nbuild on top of the recently proposed MATPAC system, improving its prediction\nand unsupervised classification pretext tasks with MCL. We extensively evaluate\nour method, MATPAC++, through both linear probing across multiple downstream\ntasks and fine-tuning on AudioSet, employing a unified protocol that enables\nrigorous and fair comparisons with state-of-the-art SSL approaches. Results\nshow that our proposal achieves state-of-the-art when fine-tuned on AudioSet\nand overall state-of-the-art scores on downstream tasks. Additionally, we\nexamine domain specialisation by training exclusively on music data, where our\nmodel achieves state-of-the-art performance with significantly improved\nefficiency.", "AI": {"tldr": "MATPAC++ enhances masked audio SSL with Multiple Choice Learning to handle prediction ambiguity, achieving SOTA performance on AudioSet and downstream tasks with improved efficiency.", "motivation": "The predictor module in masked latent prediction SSL systems is crucial but often overlooked, especially for handling ambiguity in audio content with multiple sound sources.", "method": "Integrates Multiple Choice Learning (MCL) into MATPAC system to explicitly model prediction ambiguity, improving both prediction and unsupervised classification pretext tasks.", "result": "Achieves state-of-the-art performance when fine-tuned on AudioSet and overall SOTA scores on downstream tasks. Music-only training also achieves SOTA with significantly improved efficiency.", "conclusion": "MCL effectively addresses prediction ambiguity in audio SSL, leading to superior representation quality and performance across various audio domains."}}
{"id": "2508.13097", "pdf": "https://arxiv.org/pdf/2508.13097", "abs": "https://arxiv.org/abs/2508.13097", "authors": ["Sara Karimi", "Nikolaos N. Vlassis"], "title": "Denoising diffusion models for inverse design of inflatable structures with programmable deformations", "categories": ["cs.CE", "cs.LG"], "comment": "21 pages, 12 figures", "summary": "Programmable structures are systems whose undeformed geometries and material\nproperty distributions are deliberately designed to achieve prescribed deformed\nconfigurations under specific loading conditions. Inflatable structures are a\nprominent example, using internal pressurization to realize large, nonlinear\ndeformations in applications ranging from soft robotics and deployable\naerospace systems to biomedical devices and adaptive architecture. We present a\ngenerative design framework based on denoising diffusion probabilistic models\n(DDPMs) for the inverse design of elastic structures undergoing large,\nnonlinear deformations under pressure-driven actuation. The method formulates\nthe inverse design as a conditional generation task, using geometric\ndescriptors of target deformed states as inputs and outputting image-based\nrepresentations of the undeformed configuration. Representing these\nconfigurations as simple images is achieved by establishing a pre- and\npostprocessing pipeline that involves a fixed image processing, simulation\nsetup, and descriptor extraction methods. Numerical experiments with scalar and\nhigher-dimensional descriptors show that the framework can quickly produce\ndiverse undeformed configurations that achieve the desired deformations when\ninflated, enabling parallel exploration of viable design candidates while\naccommodating complex constraints.", "AI": {"tldr": "A generative design framework using diffusion models for inverse design of inflatable structures that achieve target deformed shapes when pressurized.", "motivation": "Programmable structures need to achieve specific deformed configurations under loading. Inflatable structures are widely used but designing their undeformed geometries to produce desired deformations is challenging.", "method": "Uses denoising diffusion probabilistic models (DDPMs) for conditional generation, taking geometric descriptors of target deformed states as input and outputting image-based representations of undeformed configurations with a preprocessing pipeline.", "result": "The framework can quickly produce diverse undeformed configurations that achieve desired deformations when inflated, enabling parallel exploration of viable design candidates with complex constraints.", "conclusion": "The diffusion-based approach provides an effective method for inverse design of elastic structures undergoing large nonlinear deformations under pressure-driven actuation."}}
{"id": "2508.12910", "pdf": "https://arxiv.org/pdf/2508.12910", "abs": "https://arxiv.org/abs/2508.12910", "authors": ["Ziteng Hu", "Yingjie Xia", "Xiyuan Chen", "Li Kuang"], "title": "SecFSM: Knowledge Graph-Guided Verilog Code Generation for Secure Finite State Machines in Systems-on-Chip", "categories": ["cs.CR", "cs.AI", "cs.AR"], "comment": null, "summary": "Finite State Machines (FSMs) play a critical role in implementing control\nlogic for Systems-on-Chip (SoC). Traditionally, FSMs are implemented by\nhardware engineers through Verilog coding, which is often tedious and\ntime-consuming. Recently, with the remarkable progress of Large Language Models\n(LLMs) in code generation, LLMs have been increasingly explored for automating\nVerilog code generation. However, LLM-generated Verilog code often suffers from\nsecurity vulnerabilities, which is particularly concerning for\nsecurity-sensitive FSM implementations. To address this issue, we propose\nSecFSM, a novel method that leverages a security-oriented knowledge graph to\nguide LLMs in generating more secure Verilog code. Specifically, we first\nconstruct a FSM Security Knowledge Graph (FSKG) as an external aid to LLMs.\nSubsequently, we analyze users' requirements to identify vulnerabilities and\nget a list of vulnerabilities in the requirements. Then, we retrieve knowledge\nfrom FSKG based on the vulnerabilities list. Finally, we construct security\nprompts based on the security knowledge for Verilog code generation. To\nevaluate SecFSM, we build a dedicated dataset collected from academic datasets,\nartificial datasets, papers, and industrial cases. Extensive experiments\ndemonstrate that SecFSM outperforms state-of-the-art baselines. In particular,\non a benchmark of 25 security test cases evaluated by DeepSeek-R1, SecFSM\nachieves an outstanding pass rate of 21/25.", "AI": {"tldr": "SecFSM is a novel method that uses a security-oriented knowledge graph to guide LLMs in generating secure Verilog code for Finite State Machines, achieving a 84% pass rate on security tests.", "motivation": "Traditional manual Verilog coding for FSMs is tedious and time-consuming, while LLM-generated code often contains security vulnerabilities that are particularly concerning for security-sensitive FSM implementations.", "method": "Constructs a FSM Security Knowledge Graph (FSKG) as external aid, analyzes user requirements to identify vulnerabilities, retrieves security knowledge from FSKG, and constructs security prompts for LLM-based Verilog code generation.", "result": "Outperforms state-of-the-art baselines, achieving an outstanding 21/25 (84%) pass rate on security test cases evaluated by DeepSeek-R1 benchmark.", "conclusion": "SecFSM effectively addresses security vulnerabilities in LLM-generated Verilog code for FSMs by leveraging security knowledge graphs to guide the generation process, making it suitable for security-sensitive SoC implementations."}}
{"id": "2508.12927", "pdf": "https://arxiv.org/pdf/2508.12927", "abs": "https://arxiv.org/abs/2508.12927", "authors": ["Robin Trombetta", "Carole Lartizien"], "title": "Learning local and global prototypes with optimal transport for unsupervised anomaly detection and localization", "categories": ["eess.IV", "cs.AI"], "comment": null, "summary": "Unsupervised anomaly detection aims to detect defective parts of a sample by\nhaving access, during training, to a set of normal, i.e. defect-free, data. It\nhas many applications in fields, such as industrial inspection or medical\nimaging, where acquiring labels is costly or when we want to avoid introducing\nbiases in the type of anomalies that can be spotted. In this work, we propose a\nnovel UAD method based on prototype learning and introduce a metric to compare\na structured set of embeddings that balances a feature-based cost and a\nspatial-based cost. We leverage this metric to learn local and global\nprototypes with optimal transport from latent representations extracted with a\npre-trained image encoder. We demonstrate that our approach can enforce a\nstructural constraint when learning the prototypes, allowing to capture the\nunderlying organization of the normal samples, thus improving the detection of\nincoherencies in images. Our model achieves performance that is on par with\nstrong baselines on two reference benchmarks for anomaly detection on\nindustrial images. The code is available at\nhttps://github.com/robintrmbtt/pradot.", "AI": {"tldr": "Novel unsupervised anomaly detection method using prototype learning with optimal transport to balance feature and spatial costs, achieving competitive performance on industrial benchmarks.", "motivation": "Addresses the need for unsupervised anomaly detection in applications like industrial inspection and medical imaging where labeled data is costly or could introduce bias in anomaly types.", "method": "Leverages prototype learning with a novel metric combining feature-based and spatial-based costs, uses optimal transport to learn local and global prototypes from pre-trained image encoder embeddings.", "result": "Achieves performance on par with strong baselines on two reference benchmarks for industrial image anomaly detection.", "conclusion": "The approach effectively enforces structural constraints to capture normal sample organization, improving detection of image incoherencies without requiring labeled anomaly data."}}
{"id": "2508.13047", "pdf": "https://arxiv.org/pdf/2508.13047", "abs": "https://arxiv.org/abs/2508.13047", "authors": ["Joni Salminen", "Danial Amin", "Bernard Jansen"], "title": "Using AI for User Representation: An Analysis of 83 Persona Prompts", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted at AICCSA-2025", "summary": "We analyzed 83 persona prompts from 27 research articles that used large\nlanguage models (LLMs) to generate user personas. Findings show that the\nprompts predominantly generate single personas. Several prompts express a\ndesire for short or concise persona descriptions, which deviates from the\ntradition of creating rich, informative, and rounded persona profiles. Text is\nthe most common format for generated persona attributes, followed by numbers.\nText and numbers are often generated together, and demographic attributes are\nincluded in nearly all generated personas. Researchers use up to 12 prompts in\na single study, though most research uses a small number of prompts. Comparison\nand testing multiple LLMs is rare. More than half of the prompts require the\npersona output in a structured format, such as JSON, and 74% of the prompts\ninsert data or dynamic variables. We discuss the implications of increased use\nof computational personas for user representation.", "AI": {"tldr": "Analysis of 83 persona prompts from 27 studies shows LLMs predominantly generate single, concise personas with demographic attributes, often in structured formats like JSON, deviating from traditional rich persona profiles.", "motivation": "To understand how researchers are using LLM prompts to generate user personas and examine the characteristics and limitations of current computational persona generation practices.", "method": "Analyzed 83 persona prompts from 27 research articles that used large language models to generate user personas, examining prompt characteristics, output formats, and research practices.", "result": "Prompts mainly generate single personas with short descriptions, include demographic attributes in text/number formats, use structured outputs (JSON), and rarely test multiple LLMs. Most research uses few prompts despite some studies using up to 12.", "conclusion": "Current LLM persona generation practices favor concise, structured outputs over traditional rich profiles, raising concerns about the quality and completeness of computational user representations."}}
{"id": "2508.13077", "pdf": "https://arxiv.org/pdf/2508.13077", "abs": "https://arxiv.org/abs/2508.13077", "authors": ["Emmanuel Oladokun", "Yuxuan Ou", "Anna Novikova", "Daria Kulikova", "Sarina Thomas", "Jurica \u0160prem", "Vicente Grau"], "title": "From Transthoracic to Transesophageal: Cross-Modality Generation using LoRA Diffusion", "categories": ["eess.IV", "cs.AI"], "comment": "MICCAI 2025; ASMUS", "summary": "Deep diffusion models excel at realistic image synthesis but demand large\ntraining sets-an obstacle in data-scarce domains like transesophageal\nechocardiography (TEE). While synthetic augmentation has boosted performance in\ntransthoracic echo (TTE), TEE remains critically underrepresented, limiting the\nreach of deep learning in this high-impact modality.\n  We address this gap by adapting a TTE-trained, mask-conditioned diffusion\nbackbone to TEE with only a limited number of new cases and adapters as small\nas $10^5$ parameters. Our pipeline combines Low-Rank Adaptation with MaskR$^2$,\na lightweight remapping layer that aligns novel mask formats with the\npretrained model's conditioning channels. This design lets users adapt models\nto new datasets with a different set of anatomical structures to the base\nmodel's original set.\n  Through a targeted adaptation strategy, we find that adapting only MLP layers\nsuffices for high-fidelity TEE synthesis. Finally, mixing less than 200 real\nTEE frames with our synthetic echoes improves the dice score on a multiclass\nsegmentation task, particularly boosting performance on underrepresented\nright-heart structures. Our results demonstrate that (1) semantically\ncontrolled TEE images can be generated with low overhead, (2) MaskR$^2$\neffectively transforms unseen mask formats into compatible formats without\ndamaging downstream task performance, and (3) our method generates images that\nare effective for improving performance on a downstream task of multiclass\nsegmentation.", "AI": {"tldr": "Adapting TTE-trained diffusion models to TEE with minimal data and parameters using Low-Rank Adaptation and MaskR\u00b2 for effective synthetic TEE image generation and improved segmentation performance.", "motivation": "Address the data scarcity problem in transesophageal echocardiography (TEE) where deep diffusion models require large training sets, limiting deep learning applications in this high-impact medical modality.", "method": "Adapt TTE-trained mask-conditioned diffusion backbone to TEE using limited new cases and small adapters (10^5 parameters). Combine Low-Rank Adaptation with MaskR\u00b2 - a lightweight remapping layer that aligns novel mask formats with pretrained model's conditioning channels. Focus adaptation strategy on MLP layers only.", "result": "Successfully generated semantically controlled TEE images with low overhead. MaskR\u00b2 effectively transforms unseen mask formats without damaging downstream performance. Mixing less than 200 real TEE frames with synthetic echoes improved dice score on multiclass segmentation, particularly boosting performance on underrepresented right-heart structures.", "conclusion": "The method enables effective adaptation of diffusion models to new medical imaging domains with minimal data and computational overhead, demonstrating practical utility for improving downstream segmentation tasks in data-scarce medical imaging scenarios."}}
{"id": "2508.13092", "pdf": "https://arxiv.org/pdf/2508.13092", "abs": "https://arxiv.org/abs/2508.13092", "authors": ["Xiang Long", "Yingjie Xia", "Xiyuan Chen", "Li Kuang"], "title": "VerilogLAVD: LLM-Aided Rule Generation for Vulnerability Detection in Verilog", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Timely detection of hardware vulnerabilities during the early design stage is\ncritical for reducing remediation costs. Existing early detection techniques\noften require specialized security expertise, limiting their usability. Recent\nefforts have explored the use of large language models (LLMs) for Verilog\nvulnerability detection. However, LLMs struggle to capture the structure in\nVerilog code, resulting in inconsistent detection results. To this end, we\npropose VerilogLAVD, the first LLM-aided graph traversal rule generation\napproach for Verilog vulnerability detection. Our approach introduces the\nVerilog Property Graph (VeriPG), a unified representation of Verilog code. It\ncombines syntactic features extracted from the abstract syntax tree (AST) with\nsemantic information derived from control flow and data dependency graphs. We\nleverage LLMs to generate VeriPG-based detection rules from Common Weakness\nEnumeration (CWE) descriptions. These rules guide the rule executor that\ntraversal VeriPG for potential vulnerabilities. To evaluate VerilogLAVD, we\nbuild a dataset collected from open-source repositories and synthesized data.\nIn our empirical evaluation on 77 Verilog designs encompassing 12 CWE types,\nVerilogLAVD achieves an F1-score of 0.54. Compared to the LLM-only and LLM with\nexternal knowledge baselines, VerilogLAVD improves F1-score by 0.31 and 0.27,\nrespectively.", "AI": {"tldr": "VerilogLAVD is an LLM-aided graph traversal approach that uses a unified Verilog Property Graph representation to detect hardware vulnerabilities in Verilog code, achieving significant improvement over LLM-only baselines.", "motivation": "Timely detection of hardware vulnerabilities during early design stages is critical for reducing remediation costs, but existing techniques require specialized security expertise and LLMs struggle with Verilog code structure.", "method": "Proposes Verilog Property Graph (VeriPG) combining syntactic features from AST with semantic information from control flow and data dependency graphs. Uses LLMs to generate detection rules from CWE descriptions that guide traversal of VeriPG.", "result": "Achieves F1-score of 0.54 on 77 Verilog designs covering 12 CWE types, improving F1-score by 0.31 and 0.27 compared to LLM-only and LLM with external knowledge baselines respectively.", "conclusion": "VerilogLAVD effectively combines LLMs with structured graph representations to overcome limitations of pure LLM approaches for hardware vulnerability detection, providing a more reliable solution for early-stage security analysis."}}
